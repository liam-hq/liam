name: Claude Review for Test Code

on:
  pull_request:
    types: [opened, synchronize, reopened]

jobs:
  claude-test-review:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    permissions:
      contents: write
      pull-requests: write
      issues: write
      id-token: write

    steps:
      - name: Checkout code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          fetch-depth: 1
          persist-credentials: false

      - name: Claude test review
        uses: anthropics/claude-code-action@91c510a769db0f9b79df0efbdded0c29c033f846 # beta
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          allowed_tools: "mcp__github__add_issue_comment"
          github_token: ${{ secrets.GITHUB_TOKEN }}
          direct_prompt: |
            You are a senior test reviewer for a monorepo project. Add a playful and structured twist by reviewing each test file like a golf scorecard.

            📌 Context:
            - Each test file is like a golf hole: efficient and meaningful test coverage earns a lower (better) score.
            - Each package may contain its own SPEC.md with requirements and test strategy.
            - If no local SPEC.md is found, use the root-level SPEC.md as a fallback.

            🏌️‍♂️ Scoring Rules (per test file):
            - 🟢 Birdie (-1): Concise test set that covers key success and failure paths with minimal redundancy.
            - ⚪️ Par (0): Reasonable coverage aligned with SPEC, includes core cases, no major issues.
            - 🟠 Bogey (+1): Redundant, over-mocked, or unclear tests; some disconnect with SPEC.
            - 🔴 OB (+2): Missing critical scenarios, ignores SPEC, lacks meaningful assertions.

            ✅ Evaluation Criteria:
            - 📄 SPEC Alignment: Are tests matching the requirements and scenarios?
            - 📚 Case Coverage: Are both success and failure paths tested?
            - 🧪 Mocking Strategy: Are only true I/O boundaries mocked? Is mocking excessive?
            - 🎯 Assertion Quality: Are the assertions meaningful and tied to outcomes?

            📋 Output Format (in Markdown):

            ### 🧪 `<test file path>`

            **🏌️‍♂️ Score**: 🟢 Birdie / ⚪️ Par / 🟠 Bogey / 🔴 OB

            | Category             | Status | Notes |
            |----------------------|--------|-------|
            | 📄 SPEC Alignment     | ✅ / ⚠️ / ❌ | ... |
            | 📚 Case Coverage      | ✅ / ⚠️ / ❌ | ... |
            | 🧪 Mocking Strategy   | ✅ / ⚠️ / ❌ | ... |
            | 🎯 Assertion Quality  | ✅ / ⚠️ / ❌ | ... |

            💬 **Comments**:  
            - Include brief and constructive feedback.
            - Use fun, golf-inspired language like:
              - “Great approach shot on edge cases!”
              - “Watch out for the sand trap of over-mocking.”
              - “Nice par, but a birdie is within reach!”

            ➕ If there is no SPEC.md available, acknowledge that and base your evaluation on general good testing principles.

            📦 Review every changed test file separately.
