import {
  AIMessagePromptTemplate,
  BaseChatPromptTemplate,
  BaseMessagePromptTemplate,
  BaseMessageStringPromptTemplate,
  ChatMessagePromptTemplate,
  ChatPromptTemplate,
  DictPromptTemplate,
  FewShotChatMessagePromptTemplate,
  FewShotPromptTemplate,
  HumanMessagePromptTemplate,
  ImagePromptTemplate,
  MessagesPlaceholder,
  SystemMessagePromptTemplate,
  messages_exports
} from "../../../../../chunk-G47ZG56P.mjs";
import {
  APIConnectionTimeoutError,
  APIUserAbortError,
  OpenAI,
  Tiktoken,
  createClient,
  getEncodingNameForModel,
  zodResponseFormat
} from "../../../../../chunk-ORCDVMGW.mjs";
import {
  task
} from "../../../../../chunk-VGZV3RXS.mjs";
import "../../../../../chunk-PEBYEH3K.mjs";
import {
  logger
} from "../../../../../chunk-RV2AOCDC.mjs";
import {
  AIMessage,
  AIMessageChunk,
  AsyncCaller,
  AsyncLocalStorageProviderSingleton,
  BaseCallbackHandler,
  BaseMessage,
  BasePromptTemplate,
  BaseStringPromptTemplate,
  BaseTracer,
  CallbackManager,
  ChatGenerationChunk,
  ChatMessage,
  ChatMessageChunk,
  ChatPromptValue,
  DEFAULT_FORMATTER_MAPPING,
  DEFAULT_PARSER_MAPPING,
  FunctionMessage,
  FunctionMessageChunk,
  GenerationChunk,
  Graph,
  HumanMessage,
  HumanMessageChunk,
  IterableReadableStream,
  LangChainTracer,
  PromptTemplate,
  RUN_KEY,
  Runnable,
  RunnableAssign,
  RunnableBinding,
  RunnableEach,
  RunnableLambda,
  RunnableMap,
  RunnableParallel,
  RunnablePick,
  RunnableRetry,
  RunnableSequence,
  RunnableToolLike,
  RunnableWithFallbacks,
  Serializable,
  StringPromptValue,
  SystemMessage,
  SystemMessageChunk,
  ToolInputParsingException,
  ToolMessage,
  ToolMessageChunk,
  _coerceToDict,
  _coerceToRunnable,
  _configHasToolCallId,
  _isToolCall,
  addLangChainErrorFields,
  applyPatch,
  async_caller_exports,
  base_exports,
  base_exports2,
  callbackHandlerPrefersStreaming,
  checkValidTemplate,
  coerceMessageLikeToMessage,
  compare,
  concat,
  console_exports,
  convertToChunk,
  convertToOpenAIImageBlock,
  convertToProviderContentBlock,
  ensureConfig,
  env_exports,
  extendInteropZodObject,
  getBufferString,
  getCallbackManagerForConfig,
  getEnvironmentVariable,
  getInteropZodDefaultGetter,
  getInteropZodObjectShape,
  getSchemaDescription,
  get_lc_unique_name,
  interopParse,
  interopParseAsync,
  interopSafeParse,
  interopSafeParseAsync,
  interopZodObjectPartial,
  interopZodObjectPassthrough,
  interopZodObjectStrict,
  interopZodTransformInputSchema,
  interpolateFString,
  interpolateMustache,
  isAIMessage,
  isAIMessageChunk,
  isBase64ContentBlock,
  isBaseMessage,
  isBaseMessageChunk,
  isDataContentBlock,
  isDirectToolOutput,
  isInteropZodObject,
  isInteropZodSchema,
  isShapelessZodSchema,
  isSimpleStringZodSchema,
  isToolMessage,
  isURLContentBlock,
  isZodArrayV4,
  isZodObjectV3,
  isZodObjectV4,
  isZodSchema,
  isZodSchemaV3,
  isZodSchemaV4,
  json_schema_exports,
  keyFromJson,
  log_stream_exports,
  manager_exports,
  mapKeys,
  mapStoredMessageToChatMessage,
  mergeConfigs,
  mustache_default,
  outputs_exports,
  parseBase64DataUrl,
  parseCallbackConfigArg,
  parseFString,
  parseJsonMarkdown,
  parseMimeType,
  parseMustache,
  parsePartialJson,
  parseTemplate,
  patchConfig,
  pickRunnableConfigKeys,
  promises_exports,
  prompt_values_exports,
  renderTemplate,
  serializable_exports,
  stream_exports,
  toJsonSchema,
  tracer_langchain_exports,
  validatesOnlyStrings
} from "../../../../../chunk-GBLXN26G.mjs";
import {
  deepCompareStrict,
  external_exports,
  parse,
  toJSONSchema,
  validate
} from "../../../../../chunk-BVVLPQI6.mjs";
import "../../../../../chunk-JZ4ZBROG.mjs";
import {
  __commonJS,
  __export,
  __toESM,
  init_esm
} from "../../../../../chunk-UGJZ2EIQ.mjs";

// ../../../node_modules/.pnpm/neverthrow@8.2.0/node_modules/neverthrow/dist/index.cjs.js
var require_index_cjs = __commonJS({
  "../../../node_modules/.pnpm/neverthrow@8.2.0/node_modules/neverthrow/dist/index.cjs.js"(exports) {
    "use strict";
    init_esm();
    var defaultErrorConfig = {
      withStackTrace: false
    };
    var createNeverThrowError = (message, result, config = defaultErrorConfig) => {
      const data = result.isOk() ? { type: "Ok", value: result.value } : { type: "Err", value: result.error };
      const maybeStack = config.withStackTrace ? new Error().stack : void 0;
      return {
        data,
        message,
        stack: maybeStack
      };
    };
    function __awaiter(thisArg, _arguments, P2, generator) {
      function adopt(value) {
        return value instanceof P2 ? value : new P2(function(resolve) {
          resolve(value);
        });
      }
      return new (P2 || (P2 = Promise))(function(resolve, reject) {
        function fulfilled(value) {
          try {
            step(generator.next(value));
          } catch (e2) {
            reject(e2);
          }
        }
        function rejected(value) {
          try {
            step(generator["throw"](value));
          } catch (e2) {
            reject(e2);
          }
        }
        function step(result) {
          result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
        }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
      });
    }
    function __values(o2) {
      var s2 = typeof Symbol === "function" && Symbol.iterator, m2 = s2 && o2[s2], i2 = 0;
      if (m2) return m2.call(o2);
      if (o2 && typeof o2.length === "number") return {
        next: function() {
          if (o2 && i2 >= o2.length) o2 = void 0;
          return { value: o2 && o2[i2++], done: !o2 };
        }
      };
      throw new TypeError(s2 ? "Object is not iterable." : "Symbol.iterator is not defined.");
    }
    function __await(v2) {
      return this instanceof __await ? (this.v = v2, this) : new __await(v2);
    }
    function __asyncGenerator(thisArg, _arguments, generator) {
      if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
      var g = generator.apply(thisArg, _arguments || []), i2, q = [];
      return i2 = Object.create((typeof AsyncIterator === "function" ? AsyncIterator : Object).prototype), verb("next"), verb("throw"), verb("return", awaitReturn), i2[Symbol.asyncIterator] = function() {
        return this;
      }, i2;
      function awaitReturn(f) {
        return function(v2) {
          return Promise.resolve(v2).then(f, reject);
        };
      }
      function verb(n2, f) {
        if (g[n2]) {
          i2[n2] = function(v2) {
            return new Promise(function(a, b2) {
              q.push([n2, v2, a, b2]) > 1 || resume(n2, v2);
            });
          };
          if (f) i2[n2] = f(i2[n2]);
        }
      }
      function resume(n2, v2) {
        try {
          step(g[n2](v2));
        } catch (e2) {
          settle(q[0][3], e2);
        }
      }
      function step(r2) {
        r2.value instanceof __await ? Promise.resolve(r2.value.v).then(fulfill, reject) : settle(q[0][2], r2);
      }
      function fulfill(value) {
        resume("next", value);
      }
      function reject(value) {
        resume("throw", value);
      }
      function settle(f, v2) {
        if (f(v2), q.shift(), q.length) resume(q[0][0], q[0][1]);
      }
    }
    function __asyncDelegator(o2) {
      var i2, p2;
      return i2 = {}, verb("next"), verb("throw", function(e2) {
        throw e2;
      }), verb("return"), i2[Symbol.iterator] = function() {
        return this;
      }, i2;
      function verb(n2, f) {
        i2[n2] = o2[n2] ? function(v2) {
          return (p2 = !p2) ? { value: __await(o2[n2](v2)), done: false } : f ? f(v2) : v2;
        } : f;
      }
    }
    function __asyncValues(o2) {
      if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
      var m2 = o2[Symbol.asyncIterator], i2;
      return m2 ? m2.call(o2) : (o2 = typeof __values === "function" ? __values(o2) : o2[Symbol.iterator](), i2 = {}, verb("next"), verb("throw"), verb("return"), i2[Symbol.asyncIterator] = function() {
        return this;
      }, i2);
      function verb(n2) {
        i2[n2] = o2[n2] && function(v2) {
          return new Promise(function(resolve, reject) {
            v2 = o2[n2](v2), settle(resolve, reject, v2.done, v2.value);
          });
        };
      }
      function settle(resolve, reject, d2, v2) {
        Promise.resolve(v2).then(function(v3) {
          resolve({ value: v3, done: d2 });
        }, reject);
      }
    }
    var ResultAsync4 = class _ResultAsync {
      constructor(res) {
        this._promise = res;
      }
      static fromSafePromise(promise) {
        const newPromise = promise.then((value) => new Ok(value));
        return new _ResultAsync(newPromise);
      }
      static fromPromise(promise, errorFn) {
        const newPromise = promise.then((value) => new Ok(value)).catch((e2) => new Err(errorFn(e2)));
        return new _ResultAsync(newPromise);
      }
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      static fromThrowable(fn, errorFn) {
        return (...args) => {
          return new _ResultAsync((() => __awaiter(this, void 0, void 0, function* () {
            try {
              return new Ok(yield fn(...args));
            } catch (error) {
              return new Err(errorFn ? errorFn(error) : error);
            }
          }))());
        };
      }
      static combine(asyncResultList) {
        return combineResultAsyncList(asyncResultList);
      }
      static combineWithAllErrors(asyncResultList) {
        return combineResultAsyncListWithAllErrors(asyncResultList);
      }
      map(f) {
        return new _ResultAsync(this._promise.then((res) => __awaiter(this, void 0, void 0, function* () {
          if (res.isErr()) {
            return new Err(res.error);
          }
          return new Ok(yield f(res.value));
        })));
      }
      andThrough(f) {
        return new _ResultAsync(this._promise.then((res) => __awaiter(this, void 0, void 0, function* () {
          if (res.isErr()) {
            return new Err(res.error);
          }
          const newRes = yield f(res.value);
          if (newRes.isErr()) {
            return new Err(newRes.error);
          }
          return new Ok(res.value);
        })));
      }
      andTee(f) {
        return new _ResultAsync(this._promise.then((res) => __awaiter(this, void 0, void 0, function* () {
          if (res.isErr()) {
            return new Err(res.error);
          }
          try {
            yield f(res.value);
          } catch (e2) {
          }
          return new Ok(res.value);
        })));
      }
      orTee(f) {
        return new _ResultAsync(this._promise.then((res) => __awaiter(this, void 0, void 0, function* () {
          if (res.isOk()) {
            return new Ok(res.value);
          }
          try {
            yield f(res.error);
          } catch (e2) {
          }
          return new Err(res.error);
        })));
      }
      mapErr(f) {
        return new _ResultAsync(this._promise.then((res) => __awaiter(this, void 0, void 0, function* () {
          if (res.isOk()) {
            return new Ok(res.value);
          }
          return new Err(yield f(res.error));
        })));
      }
      // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/explicit-module-boundary-types
      andThen(f) {
        return new _ResultAsync(this._promise.then((res) => {
          if (res.isErr()) {
            return new Err(res.error);
          }
          const newValue = f(res.value);
          return newValue instanceof _ResultAsync ? newValue._promise : newValue;
        }));
      }
      // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/explicit-module-boundary-types
      orElse(f) {
        return new _ResultAsync(this._promise.then((res) => __awaiter(this, void 0, void 0, function* () {
          if (res.isErr()) {
            return f(res.error);
          }
          return new Ok(res.value);
        })));
      }
      match(ok4, _err) {
        return this._promise.then((res) => res.match(ok4, _err));
      }
      unwrapOr(t2) {
        return this._promise.then((res) => res.unwrapOr(t2));
      }
      /**
       * @deprecated will be removed in 9.0.0.
       *
       * You can use `safeTry` without this method.
       * @example
       * ```typescript
       * safeTry(async function* () {
       *   const okValue = yield* yourResult
       * })
       * ```
       * Emulates Rust's `?` operator in `safeTry`'s body. See also `safeTry`.
       */
      safeUnwrap() {
        return __asyncGenerator(this, arguments, function* safeUnwrap_1() {
          return yield __await(yield __await(yield* __asyncDelegator(__asyncValues(yield __await(this._promise.then((res) => res.safeUnwrap()))))));
        });
      }
      // Makes ResultAsync implement PromiseLike<Result>
      then(successCallback, failureCallback) {
        return this._promise.then(successCallback, failureCallback);
      }
      [Symbol.asyncIterator]() {
        return __asyncGenerator(this, arguments, function* _a() {
          const result = yield __await(this._promise);
          if (result.isErr()) {
            yield yield __await(errAsync(result.error));
          }
          return yield __await(result.value);
        });
      }
    };
    function okAsync(value) {
      return new ResultAsync4(Promise.resolve(new Ok(value)));
    }
    function errAsync(err4) {
      return new ResultAsync4(Promise.resolve(new Err(err4)));
    }
    var fromPromise = ResultAsync4.fromPromise;
    var fromSafePromise = ResultAsync4.fromSafePromise;
    var fromAsyncThrowable = ResultAsync4.fromThrowable;
    var combineResultList = (resultList) => {
      let acc = ok3([]);
      for (const result of resultList) {
        if (result.isErr()) {
          acc = err3(result.error);
          break;
        } else {
          acc.map((list) => list.push(result.value));
        }
      }
      return acc;
    };
    var combineResultAsyncList = (asyncResultList) => ResultAsync4.fromSafePromise(Promise.all(asyncResultList)).andThen(combineResultList);
    var combineResultListWithAllErrors = (resultList) => {
      let acc = ok3([]);
      for (const result of resultList) {
        if (result.isErr() && acc.isErr()) {
          acc.error.push(result.error);
        } else if (result.isErr() && acc.isOk()) {
          acc = err3([result.error]);
        } else if (result.isOk() && acc.isOk()) {
          acc.value.push(result.value);
        }
      }
      return acc;
    };
    var combineResultAsyncListWithAllErrors = (asyncResultList) => ResultAsync4.fromSafePromise(Promise.all(asyncResultList)).andThen(combineResultListWithAllErrors);
    exports.Result = void 0;
    (function(Result) {
      function fromThrowable2(fn, errorFn) {
        return (...args) => {
          try {
            const result = fn(...args);
            return ok3(result);
          } catch (e2) {
            return err3(errorFn ? errorFn(e2) : e2);
          }
        };
      }
      Result.fromThrowable = fromThrowable2;
      function combine(resultList) {
        return combineResultList(resultList);
      }
      Result.combine = combine;
      function combineWithAllErrors(resultList) {
        return combineResultListWithAllErrors(resultList);
      }
      Result.combineWithAllErrors = combineWithAllErrors;
    })(exports.Result || (exports.Result = {}));
    function ok3(value) {
      return new Ok(value);
    }
    function err3(err4) {
      return new Err(err4);
    }
    function safeTry(body) {
      const n2 = body().next();
      if (n2 instanceof Promise) {
        return new ResultAsync4(n2.then((r2) => r2.value));
      }
      return n2.value;
    }
    var Ok = class {
      constructor(value) {
        this.value = value;
      }
      isOk() {
        return true;
      }
      isErr() {
        return !this.isOk();
      }
      map(f) {
        return ok3(f(this.value));
      }
      // eslint-disable-next-line @typescript-eslint/no-unused-vars
      mapErr(_f) {
        return ok3(this.value);
      }
      // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/explicit-module-boundary-types
      andThen(f) {
        return f(this.value);
      }
      // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/explicit-module-boundary-types
      andThrough(f) {
        return f(this.value).map((_value) => this.value);
      }
      andTee(f) {
        try {
          f(this.value);
        } catch (e2) {
        }
        return ok3(this.value);
      }
      orTee(_f) {
        return ok3(this.value);
      }
      // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/explicit-module-boundary-types
      orElse(_f) {
        return ok3(this.value);
      }
      asyncAndThen(f) {
        return f(this.value);
      }
      // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/explicit-module-boundary-types
      asyncAndThrough(f) {
        return f(this.value).map(() => this.value);
      }
      asyncMap(f) {
        return ResultAsync4.fromSafePromise(f(this.value));
      }
      // eslint-disable-next-line @typescript-eslint/no-unused-vars
      unwrapOr(_v) {
        return this.value;
      }
      // eslint-disable-next-line @typescript-eslint/no-unused-vars
      match(ok4, _err) {
        return ok4(this.value);
      }
      safeUnwrap() {
        const value = this.value;
        return function* () {
          return value;
        }();
      }
      _unsafeUnwrap(_2) {
        return this.value;
      }
      _unsafeUnwrapErr(config) {
        throw createNeverThrowError("Called `_unsafeUnwrapErr` on an Ok", this, config);
      }
      // eslint-disable-next-line @typescript-eslint/no-this-alias, require-yield
      *[Symbol.iterator]() {
        return this.value;
      }
    };
    var Err = class {
      constructor(error) {
        this.error = error;
      }
      isOk() {
        return false;
      }
      isErr() {
        return !this.isOk();
      }
      // eslint-disable-next-line @typescript-eslint/no-unused-vars
      map(_f) {
        return err3(this.error);
      }
      mapErr(f) {
        return err3(f(this.error));
      }
      andThrough(_f) {
        return err3(this.error);
      }
      andTee(_f) {
        return err3(this.error);
      }
      orTee(f) {
        try {
          f(this.error);
        } catch (e2) {
        }
        return err3(this.error);
      }
      // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/explicit-module-boundary-types
      andThen(_f) {
        return err3(this.error);
      }
      // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/explicit-module-boundary-types
      orElse(f) {
        return f(this.error);
      }
      // eslint-disable-next-line @typescript-eslint/no-unused-vars
      asyncAndThen(_f) {
        return errAsync(this.error);
      }
      asyncAndThrough(_f) {
        return errAsync(this.error);
      }
      // eslint-disable-next-line @typescript-eslint/no-unused-vars
      asyncMap(_f) {
        return errAsync(this.error);
      }
      unwrapOr(v2) {
        return v2;
      }
      match(_ok, err4) {
        return err4(this.error);
      }
      safeUnwrap() {
        const error = this.error;
        return function* () {
          yield err3(error);
          throw new Error("Do not use this generator out of `safeTry`");
        }();
      }
      _unsafeUnwrap(config) {
        throw createNeverThrowError("Called `_unsafeUnwrap` on an Err", this, config);
      }
      _unsafeUnwrapErr(_2) {
        return this.error;
      }
      *[Symbol.iterator]() {
        const self = this;
        yield self;
        return self;
      }
    };
    var fromThrowable = exports.Result.fromThrowable;
    exports.Err = Err;
    exports.Ok = Ok;
    exports.ResultAsync = ResultAsync4;
    exports.err = err3;
    exports.errAsync = errAsync;
    exports.fromAsyncThrowable = fromAsyncThrowable;
    exports.fromPromise = fromPromise;
    exports.fromSafePromise = fromSafePromise;
    exports.fromThrowable = fromThrowable;
    exports.ok = ok3;
    exports.okAsync = okAsync;
    exports.safeTry = safeTry;
  }
});

// ../../../node_modules/.pnpm/fast-json-patch@3.1.1/node_modules/fast-json-patch/commonjs/helpers.js
var require_helpers = __commonJS({
  "../../../node_modules/.pnpm/fast-json-patch@3.1.1/node_modules/fast-json-patch/commonjs/helpers.js"(exports) {
    init_esm();
    var __extends = exports && exports.__extends || /* @__PURE__ */ function() {
      var extendStatics = function(d2, b2) {
        extendStatics = Object.setPrototypeOf || { __proto__: [] } instanceof Array && function(d3, b3) {
          d3.__proto__ = b3;
        } || function(d3, b3) {
          for (var p2 in b3) if (b3.hasOwnProperty(p2)) d3[p2] = b3[p2];
        };
        return extendStatics(d2, b2);
      };
      return function(d2, b2) {
        extendStatics(d2, b2);
        function __() {
          this.constructor = d2;
        }
        d2.prototype = b2 === null ? Object.create(b2) : (__.prototype = b2.prototype, new __());
      };
    }();
    Object.defineProperty(exports, "__esModule", { value: true });
    var _hasOwnProperty = Object.prototype.hasOwnProperty;
    function hasOwnProperty(obj, key) {
      return _hasOwnProperty.call(obj, key);
    }
    exports.hasOwnProperty = hasOwnProperty;
    function _objectKeys(obj) {
      if (Array.isArray(obj)) {
        var keys_1 = new Array(obj.length);
        for (var k2 = 0; k2 < keys_1.length; k2++) {
          keys_1[k2] = "" + k2;
        }
        return keys_1;
      }
      if (Object.keys) {
        return Object.keys(obj);
      }
      var keys = [];
      for (var i2 in obj) {
        if (hasOwnProperty(obj, i2)) {
          keys.push(i2);
        }
      }
      return keys;
    }
    exports._objectKeys = _objectKeys;
    function _deepClone(obj) {
      switch (typeof obj) {
        case "object":
          return JSON.parse(JSON.stringify(obj));
        //Faster than ES5 clone - http://jsperf.com/deep-cloning-of-objects/5
        case "undefined":
          return null;
        //this is how JSON.stringify behaves for array items
        default:
          return obj;
      }
    }
    exports._deepClone = _deepClone;
    function isInteger(str) {
      var i2 = 0;
      var len = str.length;
      var charCode;
      while (i2 < len) {
        charCode = str.charCodeAt(i2);
        if (charCode >= 48 && charCode <= 57) {
          i2++;
          continue;
        }
        return false;
      }
      return true;
    }
    exports.isInteger = isInteger;
    function escapePathComponent(path) {
      if (path.indexOf("/") === -1 && path.indexOf("~") === -1)
        return path;
      return path.replace(/~/g, "~0").replace(/\//g, "~1");
    }
    exports.escapePathComponent = escapePathComponent;
    function unescapePathComponent(path) {
      return path.replace(/~1/g, "/").replace(/~0/g, "~");
    }
    exports.unescapePathComponent = unescapePathComponent;
    function _getPathRecursive(root2, obj) {
      var found;
      for (var key in root2) {
        if (hasOwnProperty(root2, key)) {
          if (root2[key] === obj) {
            return escapePathComponent(key) + "/";
          } else if (typeof root2[key] === "object") {
            found = _getPathRecursive(root2[key], obj);
            if (found != "") {
              return escapePathComponent(key) + "/" + found;
            }
          }
        }
      }
      return "";
    }
    exports._getPathRecursive = _getPathRecursive;
    function getPath(root2, obj) {
      if (root2 === obj) {
        return "/";
      }
      var path = _getPathRecursive(root2, obj);
      if (path === "") {
        throw new Error("Object not found in root");
      }
      return "/" + path;
    }
    exports.getPath = getPath;
    function hasUndefined(obj) {
      if (obj === void 0) {
        return true;
      }
      if (obj) {
        if (Array.isArray(obj)) {
          for (var i_1 = 0, len = obj.length; i_1 < len; i_1++) {
            if (hasUndefined(obj[i_1])) {
              return true;
            }
          }
        } else if (typeof obj === "object") {
          var objKeys = _objectKeys(obj);
          var objKeysLength = objKeys.length;
          for (var i2 = 0; i2 < objKeysLength; i2++) {
            if (hasUndefined(obj[objKeys[i2]])) {
              return true;
            }
          }
        }
      }
      return false;
    }
    exports.hasUndefined = hasUndefined;
    function patchErrorMessageFormatter(message, args) {
      var messageParts = [message];
      for (var key in args) {
        var value = typeof args[key] === "object" ? JSON.stringify(args[key], null, 2) : args[key];
        if (typeof value !== "undefined") {
          messageParts.push(key + ": " + value);
        }
      }
      return messageParts.join("\n");
    }
    var PatchError = (
      /** @class */
      function(_super) {
        __extends(PatchError2, _super);
        function PatchError2(message, name, index, operation, tree) {
          var _newTarget = this.constructor;
          var _this = _super.call(this, patchErrorMessageFormatter(message, { name, index, operation, tree })) || this;
          _this.name = name;
          _this.index = index;
          _this.operation = operation;
          _this.tree = tree;
          Object.setPrototypeOf(_this, _newTarget.prototype);
          _this.message = patchErrorMessageFormatter(message, { name, index, operation, tree });
          return _this;
        }
        return PatchError2;
      }(Error)
    );
    exports.PatchError = PatchError;
  }
});

// ../../../node_modules/.pnpm/fast-json-patch@3.1.1/node_modules/fast-json-patch/commonjs/core.js
var require_core = __commonJS({
  "../../../node_modules/.pnpm/fast-json-patch@3.1.1/node_modules/fast-json-patch/commonjs/core.js"(exports) {
    init_esm();
    Object.defineProperty(exports, "__esModule", { value: true });
    var helpers_js_1 = require_helpers();
    exports.JsonPatchError = helpers_js_1.PatchError;
    exports.deepClone = helpers_js_1._deepClone;
    var objOps = {
      add: function(obj, key, document2) {
        obj[key] = this.value;
        return { newDocument: document2 };
      },
      remove: function(obj, key, document2) {
        var removed = obj[key];
        delete obj[key];
        return { newDocument: document2, removed };
      },
      replace: function(obj, key, document2) {
        var removed = obj[key];
        obj[key] = this.value;
        return { newDocument: document2, removed };
      },
      move: function(obj, key, document2) {
        var removed = getValueByPointer(document2, this.path);
        if (removed) {
          removed = helpers_js_1._deepClone(removed);
        }
        var originalValue = applyOperation(document2, { op: "remove", path: this.from }).removed;
        applyOperation(document2, { op: "add", path: this.path, value: originalValue });
        return { newDocument: document2, removed };
      },
      copy: function(obj, key, document2) {
        var valueToCopy = getValueByPointer(document2, this.from);
        applyOperation(document2, { op: "add", path: this.path, value: helpers_js_1._deepClone(valueToCopy) });
        return { newDocument: document2 };
      },
      test: function(obj, key, document2) {
        return { newDocument: document2, test: _areEquals(obj[key], this.value) };
      },
      _get: function(obj, key, document2) {
        this.value = obj[key];
        return { newDocument: document2 };
      }
    };
    var arrOps = {
      add: function(arr2, i2, document2) {
        if (helpers_js_1.isInteger(i2)) {
          arr2.splice(i2, 0, this.value);
        } else {
          arr2[i2] = this.value;
        }
        return { newDocument: document2, index: i2 };
      },
      remove: function(arr2, i2, document2) {
        var removedList = arr2.splice(i2, 1);
        return { newDocument: document2, removed: removedList[0] };
      },
      replace: function(arr2, i2, document2) {
        var removed = arr2[i2];
        arr2[i2] = this.value;
        return { newDocument: document2, removed };
      },
      move: objOps.move,
      copy: objOps.copy,
      test: objOps.test,
      _get: objOps._get
    };
    function getValueByPointer(document2, pointer) {
      if (pointer == "") {
        return document2;
      }
      var getOriginalDestination = { op: "_get", path: pointer };
      applyOperation(document2, getOriginalDestination);
      return getOriginalDestination.value;
    }
    exports.getValueByPointer = getValueByPointer;
    function applyOperation(document2, operation, validateOperation, mutateDocument, banPrototypeModifications, index) {
      if (validateOperation === void 0) {
        validateOperation = false;
      }
      if (mutateDocument === void 0) {
        mutateDocument = true;
      }
      if (banPrototypeModifications === void 0) {
        banPrototypeModifications = true;
      }
      if (index === void 0) {
        index = 0;
      }
      if (validateOperation) {
        if (typeof validateOperation == "function") {
          validateOperation(operation, 0, document2, operation.path);
        } else {
          validator(operation, 0);
        }
      }
      if (operation.path === "") {
        var returnValue = { newDocument: document2 };
        if (operation.op === "add") {
          returnValue.newDocument = operation.value;
          return returnValue;
        } else if (operation.op === "replace") {
          returnValue.newDocument = operation.value;
          returnValue.removed = document2;
          return returnValue;
        } else if (operation.op === "move" || operation.op === "copy") {
          returnValue.newDocument = getValueByPointer(document2, operation.from);
          if (operation.op === "move") {
            returnValue.removed = document2;
          }
          return returnValue;
        } else if (operation.op === "test") {
          returnValue.test = _areEquals(document2, operation.value);
          if (returnValue.test === false) {
            throw new exports.JsonPatchError("Test operation failed", "TEST_OPERATION_FAILED", index, operation, document2);
          }
          returnValue.newDocument = document2;
          return returnValue;
        } else if (operation.op === "remove") {
          returnValue.removed = document2;
          returnValue.newDocument = null;
          return returnValue;
        } else if (operation.op === "_get") {
          operation.value = document2;
          return returnValue;
        } else {
          if (validateOperation) {
            throw new exports.JsonPatchError("Operation `op` property is not one of operations defined in RFC-6902", "OPERATION_OP_INVALID", index, operation, document2);
          } else {
            return returnValue;
          }
        }
      } else {
        if (!mutateDocument) {
          document2 = helpers_js_1._deepClone(document2);
        }
        var path = operation.path || "";
        var keys = path.split("/");
        var obj = document2;
        var t2 = 1;
        var len = keys.length;
        var existingPathFragment = void 0;
        var key = void 0;
        var validateFunction = void 0;
        if (typeof validateOperation == "function") {
          validateFunction = validateOperation;
        } else {
          validateFunction = validator;
        }
        while (true) {
          key = keys[t2];
          if (key && key.indexOf("~") != -1) {
            key = helpers_js_1.unescapePathComponent(key);
          }
          if (banPrototypeModifications && (key == "__proto__" || key == "prototype" && t2 > 0 && keys[t2 - 1] == "constructor")) {
            throw new TypeError("JSON-Patch: modifying `__proto__` or `constructor/prototype` prop is banned for security reasons, if this was on purpose, please set `banPrototypeModifications` flag false and pass it to this function. More info in fast-json-patch README");
          }
          if (validateOperation) {
            if (existingPathFragment === void 0) {
              if (obj[key] === void 0) {
                existingPathFragment = keys.slice(0, t2).join("/");
              } else if (t2 == len - 1) {
                existingPathFragment = operation.path;
              }
              if (existingPathFragment !== void 0) {
                validateFunction(operation, 0, document2, existingPathFragment);
              }
            }
          }
          t2++;
          if (Array.isArray(obj)) {
            if (key === "-") {
              key = obj.length;
            } else {
              if (validateOperation && !helpers_js_1.isInteger(key)) {
                throw new exports.JsonPatchError("Expected an unsigned base-10 integer value, making the new referenced value the array element with the zero-based index", "OPERATION_PATH_ILLEGAL_ARRAY_INDEX", index, operation, document2);
              } else if (helpers_js_1.isInteger(key)) {
                key = ~~key;
              }
            }
            if (t2 >= len) {
              if (validateOperation && operation.op === "add" && key > obj.length) {
                throw new exports.JsonPatchError("The specified index MUST NOT be greater than the number of elements in the array", "OPERATION_VALUE_OUT_OF_BOUNDS", index, operation, document2);
              }
              var returnValue = arrOps[operation.op].call(operation, obj, key, document2);
              if (returnValue.test === false) {
                throw new exports.JsonPatchError("Test operation failed", "TEST_OPERATION_FAILED", index, operation, document2);
              }
              return returnValue;
            }
          } else {
            if (t2 >= len) {
              var returnValue = objOps[operation.op].call(operation, obj, key, document2);
              if (returnValue.test === false) {
                throw new exports.JsonPatchError("Test operation failed", "TEST_OPERATION_FAILED", index, operation, document2);
              }
              return returnValue;
            }
          }
          obj = obj[key];
          if (validateOperation && t2 < len && (!obj || typeof obj !== "object")) {
            throw new exports.JsonPatchError("Cannot perform operation at the desired path", "OPERATION_PATH_UNRESOLVABLE", index, operation, document2);
          }
        }
      }
    }
    exports.applyOperation = applyOperation;
    function applyPatch3(document2, patch, validateOperation, mutateDocument, banPrototypeModifications) {
      if (mutateDocument === void 0) {
        mutateDocument = true;
      }
      if (banPrototypeModifications === void 0) {
        banPrototypeModifications = true;
      }
      if (validateOperation) {
        if (!Array.isArray(patch)) {
          throw new exports.JsonPatchError("Patch sequence must be an array", "SEQUENCE_NOT_AN_ARRAY");
        }
      }
      if (!mutateDocument) {
        document2 = helpers_js_1._deepClone(document2);
      }
      var results = new Array(patch.length);
      for (var i2 = 0, length_1 = patch.length; i2 < length_1; i2++) {
        results[i2] = applyOperation(document2, patch[i2], validateOperation, true, banPrototypeModifications, i2);
        document2 = results[i2].newDocument;
      }
      results.newDocument = document2;
      return results;
    }
    exports.applyPatch = applyPatch3;
    function applyReducer(document2, operation, index) {
      var operationResult = applyOperation(document2, operation);
      if (operationResult.test === false) {
        throw new exports.JsonPatchError("Test operation failed", "TEST_OPERATION_FAILED", index, operation, document2);
      }
      return operationResult.newDocument;
    }
    exports.applyReducer = applyReducer;
    function validator(operation, index, document2, existingPathFragment) {
      if (typeof operation !== "object" || operation === null || Array.isArray(operation)) {
        throw new exports.JsonPatchError("Operation is not an object", "OPERATION_NOT_AN_OBJECT", index, operation, document2);
      } else if (!objOps[operation.op]) {
        throw new exports.JsonPatchError("Operation `op` property is not one of operations defined in RFC-6902", "OPERATION_OP_INVALID", index, operation, document2);
      } else if (typeof operation.path !== "string") {
        throw new exports.JsonPatchError("Operation `path` property is not a string", "OPERATION_PATH_INVALID", index, operation, document2);
      } else if (operation.path.indexOf("/") !== 0 && operation.path.length > 0) {
        throw new exports.JsonPatchError('Operation `path` property must start with "/"', "OPERATION_PATH_INVALID", index, operation, document2);
      } else if ((operation.op === "move" || operation.op === "copy") && typeof operation.from !== "string") {
        throw new exports.JsonPatchError("Operation `from` property is not present (applicable in `move` and `copy` operations)", "OPERATION_FROM_REQUIRED", index, operation, document2);
      } else if ((operation.op === "add" || operation.op === "replace" || operation.op === "test") && operation.value === void 0) {
        throw new exports.JsonPatchError("Operation `value` property is not present (applicable in `add`, `replace` and `test` operations)", "OPERATION_VALUE_REQUIRED", index, operation, document2);
      } else if ((operation.op === "add" || operation.op === "replace" || operation.op === "test") && helpers_js_1.hasUndefined(operation.value)) {
        throw new exports.JsonPatchError("Operation `value` property is not present (applicable in `add`, `replace` and `test` operations)", "OPERATION_VALUE_CANNOT_CONTAIN_UNDEFINED", index, operation, document2);
      } else if (document2) {
        if (operation.op == "add") {
          var pathLen = operation.path.split("/").length;
          var existingPathLen = existingPathFragment.split("/").length;
          if (pathLen !== existingPathLen + 1 && pathLen !== existingPathLen) {
            throw new exports.JsonPatchError("Cannot perform an `add` operation at the desired path", "OPERATION_PATH_CANNOT_ADD", index, operation, document2);
          }
        } else if (operation.op === "replace" || operation.op === "remove" || operation.op === "_get") {
          if (operation.path !== existingPathFragment) {
            throw new exports.JsonPatchError("Cannot perform the operation at a path that does not exist", "OPERATION_PATH_UNRESOLVABLE", index, operation, document2);
          }
        } else if (operation.op === "move" || operation.op === "copy") {
          var existingValue = { op: "_get", path: operation.from, value: void 0 };
          var error = validate3([existingValue], document2);
          if (error && error.name === "OPERATION_PATH_UNRESOLVABLE") {
            throw new exports.JsonPatchError("Cannot perform the operation from a path that does not exist", "OPERATION_FROM_UNRESOLVABLE", index, operation, document2);
          }
        }
      }
    }
    exports.validator = validator;
    function validate3(sequence, document2, externalValidator) {
      try {
        if (!Array.isArray(sequence)) {
          throw new exports.JsonPatchError("Patch sequence must be an array", "SEQUENCE_NOT_AN_ARRAY");
        }
        if (document2) {
          applyPatch3(helpers_js_1._deepClone(document2), helpers_js_1._deepClone(sequence), externalValidator || true);
        } else {
          externalValidator = externalValidator || validator;
          for (var i2 = 0; i2 < sequence.length; i2++) {
            externalValidator(sequence[i2], i2, document2, void 0);
          }
        }
      } catch (e2) {
        if (e2 instanceof exports.JsonPatchError) {
          return e2;
        } else {
          throw e2;
        }
      }
    }
    exports.validate = validate3;
    function _areEquals(a, b2) {
      if (a === b2)
        return true;
      if (a && b2 && typeof a == "object" && typeof b2 == "object") {
        var arrA = Array.isArray(a), arrB = Array.isArray(b2), i2, length, key;
        if (arrA && arrB) {
          length = a.length;
          if (length != b2.length)
            return false;
          for (i2 = length; i2-- !== 0; )
            if (!_areEquals(a[i2], b2[i2]))
              return false;
          return true;
        }
        if (arrA != arrB)
          return false;
        var keys = Object.keys(a);
        length = keys.length;
        if (length !== Object.keys(b2).length)
          return false;
        for (i2 = length; i2-- !== 0; )
          if (!b2.hasOwnProperty(keys[i2]))
            return false;
        for (i2 = length; i2-- !== 0; ) {
          key = keys[i2];
          if (!_areEquals(a[key], b2[key]))
            return false;
        }
        return true;
      }
      return a !== a && b2 !== b2;
    }
    exports._areEquals = _areEquals;
  }
});

// ../../../node_modules/.pnpm/fast-json-patch@3.1.1/node_modules/fast-json-patch/commonjs/duplex.js
var require_duplex = __commonJS({
  "../../../node_modules/.pnpm/fast-json-patch@3.1.1/node_modules/fast-json-patch/commonjs/duplex.js"(exports) {
    init_esm();
    Object.defineProperty(exports, "__esModule", { value: true });
    var helpers_js_1 = require_helpers();
    var core_js_1 = require_core();
    var beforeDict = /* @__PURE__ */ new WeakMap();
    var Mirror = (
      /** @class */
      /* @__PURE__ */ function() {
        function Mirror2(obj) {
          this.observers = /* @__PURE__ */ new Map();
          this.obj = obj;
        }
        return Mirror2;
      }()
    );
    var ObserverInfo = (
      /** @class */
      /* @__PURE__ */ function() {
        function ObserverInfo2(callback, observer) {
          this.callback = callback;
          this.observer = observer;
        }
        return ObserverInfo2;
      }()
    );
    function getMirror(obj) {
      return beforeDict.get(obj);
    }
    function getObserverFromMirror(mirror, callback) {
      return mirror.observers.get(callback);
    }
    function removeObserverFromMirror(mirror, observer) {
      mirror.observers.delete(observer.callback);
    }
    function unobserve(root2, observer) {
      observer.unobserve();
    }
    exports.unobserve = unobserve;
    function observe(obj, callback) {
      var patches = [];
      var observer;
      var mirror = getMirror(obj);
      if (!mirror) {
        mirror = new Mirror(obj);
        beforeDict.set(obj, mirror);
      } else {
        var observerInfo = getObserverFromMirror(mirror, callback);
        observer = observerInfo && observerInfo.observer;
      }
      if (observer) {
        return observer;
      }
      observer = {};
      mirror.value = helpers_js_1._deepClone(obj);
      if (callback) {
        observer.callback = callback;
        observer.next = null;
        var dirtyCheck = function() {
          generate(observer);
        };
        var fastCheck = function() {
          clearTimeout(observer.next);
          observer.next = setTimeout(dirtyCheck);
        };
        if (typeof window !== "undefined") {
          window.addEventListener("mouseup", fastCheck);
          window.addEventListener("keyup", fastCheck);
          window.addEventListener("mousedown", fastCheck);
          window.addEventListener("keydown", fastCheck);
          window.addEventListener("change", fastCheck);
        }
      }
      observer.patches = patches;
      observer.object = obj;
      observer.unobserve = function() {
        generate(observer);
        clearTimeout(observer.next);
        removeObserverFromMirror(mirror, observer);
        if (typeof window !== "undefined") {
          window.removeEventListener("mouseup", fastCheck);
          window.removeEventListener("keyup", fastCheck);
          window.removeEventListener("mousedown", fastCheck);
          window.removeEventListener("keydown", fastCheck);
          window.removeEventListener("change", fastCheck);
        }
      };
      mirror.observers.set(callback, new ObserverInfo(callback, observer));
      return observer;
    }
    exports.observe = observe;
    function generate(observer, invertible) {
      if (invertible === void 0) {
        invertible = false;
      }
      var mirror = beforeDict.get(observer.object);
      _generate(mirror.value, observer.object, observer.patches, "", invertible);
      if (observer.patches.length) {
        core_js_1.applyPatch(mirror.value, observer.patches);
      }
      var temp = observer.patches;
      if (temp.length > 0) {
        observer.patches = [];
        if (observer.callback) {
          observer.callback(temp);
        }
      }
      return temp;
    }
    exports.generate = generate;
    function _generate(mirror, obj, patches, path, invertible) {
      if (obj === mirror) {
        return;
      }
      if (typeof obj.toJSON === "function") {
        obj = obj.toJSON();
      }
      var newKeys = helpers_js_1._objectKeys(obj);
      var oldKeys = helpers_js_1._objectKeys(mirror);
      var changed = false;
      var deleted = false;
      for (var t2 = oldKeys.length - 1; t2 >= 0; t2--) {
        var key = oldKeys[t2];
        var oldVal = mirror[key];
        if (helpers_js_1.hasOwnProperty(obj, key) && !(obj[key] === void 0 && oldVal !== void 0 && Array.isArray(obj) === false)) {
          var newVal = obj[key];
          if (typeof oldVal == "object" && oldVal != null && typeof newVal == "object" && newVal != null && Array.isArray(oldVal) === Array.isArray(newVal)) {
            _generate(oldVal, newVal, patches, path + "/" + helpers_js_1.escapePathComponent(key), invertible);
          } else {
            if (oldVal !== newVal) {
              changed = true;
              if (invertible) {
                patches.push({ op: "test", path: path + "/" + helpers_js_1.escapePathComponent(key), value: helpers_js_1._deepClone(oldVal) });
              }
              patches.push({ op: "replace", path: path + "/" + helpers_js_1.escapePathComponent(key), value: helpers_js_1._deepClone(newVal) });
            }
          }
        } else if (Array.isArray(mirror) === Array.isArray(obj)) {
          if (invertible) {
            patches.push({ op: "test", path: path + "/" + helpers_js_1.escapePathComponent(key), value: helpers_js_1._deepClone(oldVal) });
          }
          patches.push({ op: "remove", path: path + "/" + helpers_js_1.escapePathComponent(key) });
          deleted = true;
        } else {
          if (invertible) {
            patches.push({ op: "test", path, value: mirror });
          }
          patches.push({ op: "replace", path, value: obj });
          changed = true;
        }
      }
      if (!deleted && newKeys.length == oldKeys.length) {
        return;
      }
      for (var t2 = 0; t2 < newKeys.length; t2++) {
        var key = newKeys[t2];
        if (!helpers_js_1.hasOwnProperty(mirror, key) && obj[key] !== void 0) {
          patches.push({ op: "add", path: path + "/" + helpers_js_1.escapePathComponent(key), value: helpers_js_1._deepClone(obj[key]) });
        }
      }
    }
    function compare4(tree1, tree2, invertible) {
      if (invertible === void 0) {
        invertible = false;
      }
      var patches = [];
      _generate(tree1, tree2, patches, "", invertible);
      return patches;
    }
    exports.compare = compare4;
  }
});

// ../../../node_modules/.pnpm/fast-json-patch@3.1.1/node_modules/fast-json-patch/index.js
var require_fast_json_patch = __commonJS({
  "../../../node_modules/.pnpm/fast-json-patch@3.1.1/node_modules/fast-json-patch/index.js"(exports) {
    init_esm();
    var core = require_core();
    Object.assign(exports, core);
    var duplex = require_duplex();
    Object.assign(exports, duplex);
    var helpers = require_helpers();
    exports.JsonPatchError = helpers.PatchError;
    exports.deepClone = helpers._deepClone;
    exports.escapePathComponent = helpers.escapePathComponent;
    exports.unescapePathComponent = helpers.unescapePathComponent;
  }
});

// src/trigger/deepModelingWorkflowTask.ts
init_esm();

// ../agent/src/index.ts
init_esm();

// ../agent/src/deepModeling.ts
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/index.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/index.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/setup/async_local_storage.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/singletons.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/setup/async_local_storage.js
import { AsyncLocalStorage } from "node:async_hooks";
function initializeAsyncLocalStorageSingleton() {
  AsyncLocalStorageProviderSingleton.initializeGlobalInstance(new AsyncLocalStorage());
}

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/web.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/graph/index.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/graph/annotation.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/channels/binop.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/errors.js
init_esm();
var BaseLangGraphError = class extends Error {
  constructor(message, fields) {
    let finalMessage = message ?? "";
    if (fields?.lc_error_code) {
      finalMessage = `${finalMessage}

Troubleshooting URL: https://langchain-ai.github.io/langgraphjs/troubleshooting/errors/${fields.lc_error_code}/
`;
    }
    super(finalMessage);
    Object.defineProperty(this, "lc_error_code", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.lc_error_code = fields?.lc_error_code;
  }
};
var GraphBubbleUp = class extends BaseLangGraphError {
  get is_bubble_up() {
    return true;
  }
};
var GraphRecursionError = class extends BaseLangGraphError {
  constructor(message, fields) {
    super(message, fields);
    this.name = "GraphRecursionError";
  }
  static get unminifiable_name() {
    return "GraphRecursionError";
  }
};
var GraphValueError = class extends BaseLangGraphError {
  constructor(message, fields) {
    super(message, fields);
    this.name = "GraphValueError";
  }
  static get unminifiable_name() {
    return "GraphValueError";
  }
};
var GraphInterrupt = class extends GraphBubbleUp {
  constructor(interrupts, fields) {
    super(JSON.stringify(interrupts, null, 2), fields);
    Object.defineProperty(this, "interrupts", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.name = "GraphInterrupt";
    this.interrupts = interrupts ?? [];
  }
  static get unminifiable_name() {
    return "GraphInterrupt";
  }
};
var NodeInterrupt = class extends GraphInterrupt {
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  constructor(message, fields) {
    super([
      {
        value: message,
        when: "during"
      }
    ], fields);
    this.name = "NodeInterrupt";
  }
  static get unminifiable_name() {
    return "NodeInterrupt";
  }
};
var ParentCommand = class extends GraphBubbleUp {
  constructor(command) {
    super();
    Object.defineProperty(this, "command", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.name = "ParentCommand";
    this.command = command;
  }
  static get unminifiable_name() {
    return "ParentCommand";
  }
};
function isParentCommand(e2) {
  return e2 !== void 0 && e2.name === ParentCommand.unminifiable_name;
}
function isGraphBubbleUp(e2) {
  return e2 !== void 0 && e2.is_bubble_up === true;
}
function isGraphInterrupt(e2) {
  return e2 !== void 0 && [
    GraphInterrupt.unminifiable_name,
    NodeInterrupt.unminifiable_name
  ].includes(e2.name);
}
var EmptyInputError = class extends BaseLangGraphError {
  constructor(message, fields) {
    super(message, fields);
    this.name = "EmptyInputError";
  }
  static get unminifiable_name() {
    return "EmptyInputError";
  }
};
var EmptyChannelError = class extends BaseLangGraphError {
  constructor(message, fields) {
    super(message, fields);
    this.name = "EmptyChannelError";
  }
  static get unminifiable_name() {
    return "EmptyChannelError";
  }
};
var InvalidUpdateError = class extends BaseLangGraphError {
  constructor(message, fields) {
    super(message, fields);
    this.name = "InvalidUpdateError";
  }
  static get unminifiable_name() {
    return "InvalidUpdateError";
  }
};
var UnreachableNodeError = class extends BaseLangGraphError {
  constructor(message, fields) {
    super(message, fields);
    this.name = "UnreachableNodeError";
  }
  static get unminifiable_name() {
    return "UnreachableNodeError";
  }
};

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/channels/base.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph-checkpoint@0.0.18_@langchain+core@0.3.61_@opentelemetry+api@1.9.0__a6099cbbd47045e82bada733957b498f/node_modules/@langchain/langgraph-checkpoint/index.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph-checkpoint@0.0.18_@langchain+core@0.3.61_@opentelemetry+api@1.9.0__a6099cbbd47045e82bada733957b498f/node_modules/@langchain/langgraph-checkpoint/dist/index.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph-checkpoint@0.0.18_@langchain+core@0.3.61_@opentelemetry+api@1.9.0__a6099cbbd47045e82bada733957b498f/node_modules/@langchain/langgraph-checkpoint/dist/memory.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph-checkpoint@0.0.18_@langchain+core@0.3.61_@opentelemetry+api@1.9.0__a6099cbbd47045e82bada733957b498f/node_modules/@langchain/langgraph-checkpoint/dist/base.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph-checkpoint@0.0.18_@langchain+core@0.3.61_@opentelemetry+api@1.9.0__a6099cbbd47045e82bada733957b498f/node_modules/@langchain/langgraph-checkpoint/dist/id.js
init_esm();
import { v5, v6 } from "uuid";
function uuid6(clockseq) {
  return v6({ clockseq });
}
function uuid5(name, namespace) {
  const namespaceBytes = namespace.replace(/-/g, "").match(/.{2}/g).map((byte) => parseInt(byte, 16));
  return v5(name, new Uint8Array(namespaceBytes));
}

// ../../../node_modules/.pnpm/@langchain+langgraph-checkpoint@0.0.18_@langchain+core@0.3.61_@opentelemetry+api@1.9.0__a6099cbbd47045e82bada733957b498f/node_modules/@langchain/langgraph-checkpoint/dist/serde/types.js
init_esm();
var ERROR2 = "__error__";
var SCHEDULED = "__scheduled__";
var INTERRUPT = "__interrupt__";
var RESUME = "__resume__";

// ../../../node_modules/.pnpm/@langchain+langgraph-checkpoint@0.0.18_@langchain+core@0.3.61_@opentelemetry+api@1.9.0__a6099cbbd47045e82bada733957b498f/node_modules/@langchain/langgraph-checkpoint/dist/serde/jsonplus.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/load.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/load/index.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/load/import_constants.js
init_esm();
var optionalImportEntrypoints = [];

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/load/import_map.js
var import_map_exports = {};
__export(import_map_exports, {
  agents: () => agents_exports,
  caches: () => base_exports3,
  callbacks__base: () => base_exports,
  callbacks__manager: () => manager_exports,
  callbacks__promises: () => promises_exports,
  chat_history: () => chat_history_exports,
  documents: () => documents_exports,
  embeddings: () => embeddings_exports,
  example_selectors: () => example_selectors_exports,
  language_models__base: () => base_exports4,
  language_models__chat_models: () => chat_models_exports,
  language_models__llms: () => llms_exports,
  load__serializable: () => serializable_exports,
  memory: () => memory_exports,
  messages: () => messages_exports,
  output_parsers: () => output_parsers_exports,
  outputs: () => outputs_exports,
  prompt_values: () => prompt_values_exports,
  prompts: () => prompts_exports,
  retrievers: () => retrievers_exports,
  runnables: () => runnables_exports,
  stores: () => stores_exports,
  tools: () => tools_exports,
  tracers__base: () => base_exports2,
  tracers__console: () => console_exports,
  tracers__initialize: () => initialize_exports,
  tracers__log_stream: () => log_stream_exports,
  tracers__run_collector: () => run_collector_exports,
  tracers__tracer_langchain: () => tracer_langchain_exports,
  tracers__tracer_langchain_v1: () => tracer_langchain_v1_exports,
  utils__async_caller: () => async_caller_exports,
  utils__chunk_array: () => chunk_array_exports,
  utils__env: () => env_exports,
  utils__function_calling: () => function_calling_exports,
  utils__hash: () => hash_exports,
  utils__json_patch: () => json_patch_exports,
  utils__json_schema: () => json_schema_exports,
  utils__math: () => math_exports,
  utils__stream: () => stream_exports,
  utils__testing: () => testing_exports,
  utils__tiktoken: () => tiktoken_exports,
  utils__types: () => types_exports,
  vectorstores: () => vectorstores_exports
});
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/agents.js
var agents_exports = {};
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/caches/base.js
var base_exports3 = {};
__export(base_exports3, {
  BaseCache: () => BaseCache,
  InMemoryCache: () => InMemoryCache,
  deserializeStoredGeneration: () => deserializeStoredGeneration,
  getCacheKey: () => getCacheKey,
  serializeGeneration: () => serializeGeneration
});
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/utils/hash.js
var hash_exports = {};
__export(hash_exports, {
  insecureHash: () => insecureHash,
  sha256: () => sha256
});
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/utils/js-sha1/hash.js
init_esm();
var root = typeof window === "object" ? window : {};
var HEX_CHARS = "0123456789abcdef".split("");
var EXTRA = [-2147483648, 8388608, 32768, 128];
var SHIFT = [24, 16, 8, 0];
var blocks = [];
function Sha1(sharedMemory) {
  if (sharedMemory) {
    blocks[0] = blocks[16] = blocks[1] = blocks[2] = blocks[3] = blocks[4] = blocks[5] = blocks[6] = blocks[7] = blocks[8] = blocks[9] = blocks[10] = blocks[11] = blocks[12] = blocks[13] = blocks[14] = blocks[15] = 0;
    this.blocks = blocks;
  } else {
    this.blocks = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];
  }
  this.h0 = 1732584193;
  this.h1 = 4023233417;
  this.h2 = 2562383102;
  this.h3 = 271733878;
  this.h4 = 3285377520;
  this.block = this.start = this.bytes = this.hBytes = 0;
  this.finalized = this.hashed = false;
  this.first = true;
}
Sha1.prototype.update = function(message) {
  if (this.finalized) {
    return;
  }
  var notString = typeof message !== "string";
  if (notString && message.constructor === root.ArrayBuffer) {
    message = new Uint8Array(message);
  }
  var code, index = 0, i2, length = message.length || 0, blocks3 = this.blocks;
  while (index < length) {
    if (this.hashed) {
      this.hashed = false;
      blocks3[0] = this.block;
      blocks3[16] = blocks3[1] = blocks3[2] = blocks3[3] = blocks3[4] = blocks3[5] = blocks3[6] = blocks3[7] = blocks3[8] = blocks3[9] = blocks3[10] = blocks3[11] = blocks3[12] = blocks3[13] = blocks3[14] = blocks3[15] = 0;
    }
    if (notString) {
      for (i2 = this.start; index < length && i2 < 64; ++index) {
        blocks3[i2 >> 2] |= message[index] << SHIFT[i2++ & 3];
      }
    } else {
      for (i2 = this.start; index < length && i2 < 64; ++index) {
        code = message.charCodeAt(index);
        if (code < 128) {
          blocks3[i2 >> 2] |= code << SHIFT[i2++ & 3];
        } else if (code < 2048) {
          blocks3[i2 >> 2] |= (192 | code >> 6) << SHIFT[i2++ & 3];
          blocks3[i2 >> 2] |= (128 | code & 63) << SHIFT[i2++ & 3];
        } else if (code < 55296 || code >= 57344) {
          blocks3[i2 >> 2] |= (224 | code >> 12) << SHIFT[i2++ & 3];
          blocks3[i2 >> 2] |= (128 | code >> 6 & 63) << SHIFT[i2++ & 3];
          blocks3[i2 >> 2] |= (128 | code & 63) << SHIFT[i2++ & 3];
        } else {
          code = 65536 + ((code & 1023) << 10 | message.charCodeAt(++index) & 1023);
          blocks3[i2 >> 2] |= (240 | code >> 18) << SHIFT[i2++ & 3];
          blocks3[i2 >> 2] |= (128 | code >> 12 & 63) << SHIFT[i2++ & 3];
          blocks3[i2 >> 2] |= (128 | code >> 6 & 63) << SHIFT[i2++ & 3];
          blocks3[i2 >> 2] |= (128 | code & 63) << SHIFT[i2++ & 3];
        }
      }
    }
    this.lastByteIndex = i2;
    this.bytes += i2 - this.start;
    if (i2 >= 64) {
      this.block = blocks3[16];
      this.start = i2 - 64;
      this.hash();
      this.hashed = true;
    } else {
      this.start = i2;
    }
  }
  if (this.bytes > 4294967295) {
    this.hBytes += this.bytes / 4294967296 << 0;
    this.bytes = this.bytes % 4294967296;
  }
  return this;
};
Sha1.prototype.finalize = function() {
  if (this.finalized) {
    return;
  }
  this.finalized = true;
  var blocks3 = this.blocks, i2 = this.lastByteIndex;
  blocks3[16] = this.block;
  blocks3[i2 >> 2] |= EXTRA[i2 & 3];
  this.block = blocks3[16];
  if (i2 >= 56) {
    if (!this.hashed) {
      this.hash();
    }
    blocks3[0] = this.block;
    blocks3[16] = blocks3[1] = blocks3[2] = blocks3[3] = blocks3[4] = blocks3[5] = blocks3[6] = blocks3[7] = blocks3[8] = blocks3[9] = blocks3[10] = blocks3[11] = blocks3[12] = blocks3[13] = blocks3[14] = blocks3[15] = 0;
  }
  blocks3[14] = this.hBytes << 3 | this.bytes >>> 29;
  blocks3[15] = this.bytes << 3;
  this.hash();
};
Sha1.prototype.hash = function() {
  var a = this.h0, b2 = this.h1, c2 = this.h2, d2 = this.h3, e2 = this.h4;
  var f, j2, t2, blocks3 = this.blocks;
  for (j2 = 16; j2 < 80; ++j2) {
    t2 = blocks3[j2 - 3] ^ blocks3[j2 - 8] ^ blocks3[j2 - 14] ^ blocks3[j2 - 16];
    blocks3[j2] = t2 << 1 | t2 >>> 31;
  }
  for (j2 = 0; j2 < 20; j2 += 5) {
    f = b2 & c2 | ~b2 & d2;
    t2 = a << 5 | a >>> 27;
    e2 = t2 + f + e2 + 1518500249 + blocks3[j2] << 0;
    b2 = b2 << 30 | b2 >>> 2;
    f = a & b2 | ~a & c2;
    t2 = e2 << 5 | e2 >>> 27;
    d2 = t2 + f + d2 + 1518500249 + blocks3[j2 + 1] << 0;
    a = a << 30 | a >>> 2;
    f = e2 & a | ~e2 & b2;
    t2 = d2 << 5 | d2 >>> 27;
    c2 = t2 + f + c2 + 1518500249 + blocks3[j2 + 2] << 0;
    e2 = e2 << 30 | e2 >>> 2;
    f = d2 & e2 | ~d2 & a;
    t2 = c2 << 5 | c2 >>> 27;
    b2 = t2 + f + b2 + 1518500249 + blocks3[j2 + 3] << 0;
    d2 = d2 << 30 | d2 >>> 2;
    f = c2 & d2 | ~c2 & e2;
    t2 = b2 << 5 | b2 >>> 27;
    a = t2 + f + a + 1518500249 + blocks3[j2 + 4] << 0;
    c2 = c2 << 30 | c2 >>> 2;
  }
  for (; j2 < 40; j2 += 5) {
    f = b2 ^ c2 ^ d2;
    t2 = a << 5 | a >>> 27;
    e2 = t2 + f + e2 + 1859775393 + blocks3[j2] << 0;
    b2 = b2 << 30 | b2 >>> 2;
    f = a ^ b2 ^ c2;
    t2 = e2 << 5 | e2 >>> 27;
    d2 = t2 + f + d2 + 1859775393 + blocks3[j2 + 1] << 0;
    a = a << 30 | a >>> 2;
    f = e2 ^ a ^ b2;
    t2 = d2 << 5 | d2 >>> 27;
    c2 = t2 + f + c2 + 1859775393 + blocks3[j2 + 2] << 0;
    e2 = e2 << 30 | e2 >>> 2;
    f = d2 ^ e2 ^ a;
    t2 = c2 << 5 | c2 >>> 27;
    b2 = t2 + f + b2 + 1859775393 + blocks3[j2 + 3] << 0;
    d2 = d2 << 30 | d2 >>> 2;
    f = c2 ^ d2 ^ e2;
    t2 = b2 << 5 | b2 >>> 27;
    a = t2 + f + a + 1859775393 + blocks3[j2 + 4] << 0;
    c2 = c2 << 30 | c2 >>> 2;
  }
  for (; j2 < 60; j2 += 5) {
    f = b2 & c2 | b2 & d2 | c2 & d2;
    t2 = a << 5 | a >>> 27;
    e2 = t2 + f + e2 - 1894007588 + blocks3[j2] << 0;
    b2 = b2 << 30 | b2 >>> 2;
    f = a & b2 | a & c2 | b2 & c2;
    t2 = e2 << 5 | e2 >>> 27;
    d2 = t2 + f + d2 - 1894007588 + blocks3[j2 + 1] << 0;
    a = a << 30 | a >>> 2;
    f = e2 & a | e2 & b2 | a & b2;
    t2 = d2 << 5 | d2 >>> 27;
    c2 = t2 + f + c2 - 1894007588 + blocks3[j2 + 2] << 0;
    e2 = e2 << 30 | e2 >>> 2;
    f = d2 & e2 | d2 & a | e2 & a;
    t2 = c2 << 5 | c2 >>> 27;
    b2 = t2 + f + b2 - 1894007588 + blocks3[j2 + 3] << 0;
    d2 = d2 << 30 | d2 >>> 2;
    f = c2 & d2 | c2 & e2 | d2 & e2;
    t2 = b2 << 5 | b2 >>> 27;
    a = t2 + f + a - 1894007588 + blocks3[j2 + 4] << 0;
    c2 = c2 << 30 | c2 >>> 2;
  }
  for (; j2 < 80; j2 += 5) {
    f = b2 ^ c2 ^ d2;
    t2 = a << 5 | a >>> 27;
    e2 = t2 + f + e2 - 899497514 + blocks3[j2] << 0;
    b2 = b2 << 30 | b2 >>> 2;
    f = a ^ b2 ^ c2;
    t2 = e2 << 5 | e2 >>> 27;
    d2 = t2 + f + d2 - 899497514 + blocks3[j2 + 1] << 0;
    a = a << 30 | a >>> 2;
    f = e2 ^ a ^ b2;
    t2 = d2 << 5 | d2 >>> 27;
    c2 = t2 + f + c2 - 899497514 + blocks3[j2 + 2] << 0;
    e2 = e2 << 30 | e2 >>> 2;
    f = d2 ^ e2 ^ a;
    t2 = c2 << 5 | c2 >>> 27;
    b2 = t2 + f + b2 - 899497514 + blocks3[j2 + 3] << 0;
    d2 = d2 << 30 | d2 >>> 2;
    f = c2 ^ d2 ^ e2;
    t2 = b2 << 5 | b2 >>> 27;
    a = t2 + f + a - 899497514 + blocks3[j2 + 4] << 0;
    c2 = c2 << 30 | c2 >>> 2;
  }
  this.h0 = this.h0 + a << 0;
  this.h1 = this.h1 + b2 << 0;
  this.h2 = this.h2 + c2 << 0;
  this.h3 = this.h3 + d2 << 0;
  this.h4 = this.h4 + e2 << 0;
};
Sha1.prototype.hex = function() {
  this.finalize();
  var h0 = this.h0, h1 = this.h1, h2 = this.h2, h3 = this.h3, h4 = this.h4;
  return HEX_CHARS[h0 >> 28 & 15] + HEX_CHARS[h0 >> 24 & 15] + HEX_CHARS[h0 >> 20 & 15] + HEX_CHARS[h0 >> 16 & 15] + HEX_CHARS[h0 >> 12 & 15] + HEX_CHARS[h0 >> 8 & 15] + HEX_CHARS[h0 >> 4 & 15] + HEX_CHARS[h0 & 15] + HEX_CHARS[h1 >> 28 & 15] + HEX_CHARS[h1 >> 24 & 15] + HEX_CHARS[h1 >> 20 & 15] + HEX_CHARS[h1 >> 16 & 15] + HEX_CHARS[h1 >> 12 & 15] + HEX_CHARS[h1 >> 8 & 15] + HEX_CHARS[h1 >> 4 & 15] + HEX_CHARS[h1 & 15] + HEX_CHARS[h2 >> 28 & 15] + HEX_CHARS[h2 >> 24 & 15] + HEX_CHARS[h2 >> 20 & 15] + HEX_CHARS[h2 >> 16 & 15] + HEX_CHARS[h2 >> 12 & 15] + HEX_CHARS[h2 >> 8 & 15] + HEX_CHARS[h2 >> 4 & 15] + HEX_CHARS[h2 & 15] + HEX_CHARS[h3 >> 28 & 15] + HEX_CHARS[h3 >> 24 & 15] + HEX_CHARS[h3 >> 20 & 15] + HEX_CHARS[h3 >> 16 & 15] + HEX_CHARS[h3 >> 12 & 15] + HEX_CHARS[h3 >> 8 & 15] + HEX_CHARS[h3 >> 4 & 15] + HEX_CHARS[h3 & 15] + HEX_CHARS[h4 >> 28 & 15] + HEX_CHARS[h4 >> 24 & 15] + HEX_CHARS[h4 >> 20 & 15] + HEX_CHARS[h4 >> 16 & 15] + HEX_CHARS[h4 >> 12 & 15] + HEX_CHARS[h4 >> 8 & 15] + HEX_CHARS[h4 >> 4 & 15] + HEX_CHARS[h4 & 15];
};
Sha1.prototype.toString = Sha1.prototype.hex;
Sha1.prototype.digest = function() {
  this.finalize();
  var h0 = this.h0, h1 = this.h1, h2 = this.h2, h3 = this.h3, h4 = this.h4;
  return [
    h0 >> 24 & 255,
    h0 >> 16 & 255,
    h0 >> 8 & 255,
    h0 & 255,
    h1 >> 24 & 255,
    h1 >> 16 & 255,
    h1 >> 8 & 255,
    h1 & 255,
    h2 >> 24 & 255,
    h2 >> 16 & 255,
    h2 >> 8 & 255,
    h2 & 255,
    h3 >> 24 & 255,
    h3 >> 16 & 255,
    h3 >> 8 & 255,
    h3 & 255,
    h4 >> 24 & 255,
    h4 >> 16 & 255,
    h4 >> 8 & 255,
    h4 & 255
  ];
};
Sha1.prototype.array = Sha1.prototype.digest;
Sha1.prototype.arrayBuffer = function() {
  this.finalize();
  var buffer = new ArrayBuffer(20);
  var dataView = new DataView(buffer);
  dataView.setUint32(0, this.h0);
  dataView.setUint32(4, this.h1);
  dataView.setUint32(8, this.h2);
  dataView.setUint32(12, this.h3);
  dataView.setUint32(16, this.h4);
  return buffer;
};
var hasLoggedWarning = false;
var insecureHash = (message) => {
  if (!hasLoggedWarning) {
    console.warn([
      `The default method for hashing keys is insecure and will be replaced in a future version,`,
      `but hasn't been replaced yet as to not break existing caches. It's recommended that you use`,
      `a more secure hashing algorithm to avoid cache poisoning.`,
      ``,
      `See this page for more information:`,
      `|`,
      `└> https://js.langchain.com/docs/troubleshooting/warnings/insecure-cache-algorithm`
    ].join("\n"));
    hasLoggedWarning = true;
  }
  return new Sha1(true).update(message)["hex"]();
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/utils/js-sha256/hash.js
init_esm();
var HEX_CHARS2 = "0123456789abcdef".split("");
var EXTRA2 = [-2147483648, 8388608, 32768, 128];
var SHIFT2 = [24, 16, 8, 0];
var K = [
  1116352408,
  1899447441,
  3049323471,
  3921009573,
  961987163,
  1508970993,
  2453635748,
  2870763221,
  3624381080,
  310598401,
  607225278,
  1426881987,
  1925078388,
  2162078206,
  2614888103,
  3248222580,
  3835390401,
  4022224774,
  264347078,
  604807628,
  770255983,
  1249150122,
  1555081692,
  1996064986,
  2554220882,
  2821834349,
  2952996808,
  3210313671,
  3336571891,
  3584528711,
  113926993,
  338241895,
  666307205,
  773529912,
  1294757372,
  1396182291,
  1695183700,
  1986661051,
  2177026350,
  2456956037,
  2730485921,
  2820302411,
  3259730800,
  3345764771,
  3516065817,
  3600352804,
  4094571909,
  275423344,
  430227734,
  506948616,
  659060556,
  883997877,
  958139571,
  1322822218,
  1537002063,
  1747873779,
  1955562222,
  2024104815,
  2227730452,
  2361852424,
  2428436474,
  2756734187,
  3204031479,
  3329325298
];
var blocks2 = [];
function Sha256(is224, sharedMemory) {
  if (sharedMemory) {
    blocks2[0] = blocks2[16] = blocks2[1] = blocks2[2] = blocks2[3] = blocks2[4] = blocks2[5] = blocks2[6] = blocks2[7] = blocks2[8] = blocks2[9] = blocks2[10] = blocks2[11] = blocks2[12] = blocks2[13] = blocks2[14] = blocks2[15] = 0;
    this.blocks = blocks2;
  } else {
    this.blocks = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];
  }
  if (is224) {
    this.h0 = 3238371032;
    this.h1 = 914150663;
    this.h2 = 812702999;
    this.h3 = 4144912697;
    this.h4 = 4290775857;
    this.h5 = 1750603025;
    this.h6 = 1694076839;
    this.h7 = 3204075428;
  } else {
    this.h0 = 1779033703;
    this.h1 = 3144134277;
    this.h2 = 1013904242;
    this.h3 = 2773480762;
    this.h4 = 1359893119;
    this.h5 = 2600822924;
    this.h6 = 528734635;
    this.h7 = 1541459225;
  }
  this.block = this.start = this.bytes = this.hBytes = 0;
  this.finalized = this.hashed = false;
  this.first = true;
  this.is224 = is224;
}
Sha256.prototype.update = function(message) {
  if (this.finalized) {
    return;
  }
  var notString, type = typeof message;
  if (type !== "string") {
    if (type === "object") {
      if (message === null) {
        throw new Error(ERROR);
      } else if (ARRAY_BUFFER && message.constructor === ArrayBuffer) {
        message = new Uint8Array(message);
      } else if (!Array.isArray(message)) {
        if (!ARRAY_BUFFER || !ArrayBuffer.isView(message)) {
          throw new Error(ERROR);
        }
      }
    } else {
      throw new Error(ERROR);
    }
    notString = true;
  }
  var code, index = 0, i2, length = message.length, blocks3 = this.blocks;
  while (index < length) {
    if (this.hashed) {
      this.hashed = false;
      blocks3[0] = this.block;
      this.block = blocks3[16] = blocks3[1] = blocks3[2] = blocks3[3] = blocks3[4] = blocks3[5] = blocks3[6] = blocks3[7] = blocks3[8] = blocks3[9] = blocks3[10] = blocks3[11] = blocks3[12] = blocks3[13] = blocks3[14] = blocks3[15] = 0;
    }
    if (notString) {
      for (i2 = this.start; index < length && i2 < 64; ++index) {
        blocks3[i2 >>> 2] |= message[index] << SHIFT2[i2++ & 3];
      }
    } else {
      for (i2 = this.start; index < length && i2 < 64; ++index) {
        code = message.charCodeAt(index);
        if (code < 128) {
          blocks3[i2 >>> 2] |= code << SHIFT2[i2++ & 3];
        } else if (code < 2048) {
          blocks3[i2 >>> 2] |= (192 | code >>> 6) << SHIFT2[i2++ & 3];
          blocks3[i2 >>> 2] |= (128 | code & 63) << SHIFT2[i2++ & 3];
        } else if (code < 55296 || code >= 57344) {
          blocks3[i2 >>> 2] |= (224 | code >>> 12) << SHIFT2[i2++ & 3];
          blocks3[i2 >>> 2] |= (128 | code >>> 6 & 63) << SHIFT2[i2++ & 3];
          blocks3[i2 >>> 2] |= (128 | code & 63) << SHIFT2[i2++ & 3];
        } else {
          code = 65536 + ((code & 1023) << 10 | message.charCodeAt(++index) & 1023);
          blocks3[i2 >>> 2] |= (240 | code >>> 18) << SHIFT2[i2++ & 3];
          blocks3[i2 >>> 2] |= (128 | code >>> 12 & 63) << SHIFT2[i2++ & 3];
          blocks3[i2 >>> 2] |= (128 | code >>> 6 & 63) << SHIFT2[i2++ & 3];
          blocks3[i2 >>> 2] |= (128 | code & 63) << SHIFT2[i2++ & 3];
        }
      }
    }
    this.lastByteIndex = i2;
    this.bytes += i2 - this.start;
    if (i2 >= 64) {
      this.block = blocks3[16];
      this.start = i2 - 64;
      this.hash();
      this.hashed = true;
    } else {
      this.start = i2;
    }
  }
  if (this.bytes > 4294967295) {
    this.hBytes += this.bytes / 4294967296 << 0;
    this.bytes = this.bytes % 4294967296;
  }
  return this;
};
Sha256.prototype.finalize = function() {
  if (this.finalized) {
    return;
  }
  this.finalized = true;
  var blocks3 = this.blocks, i2 = this.lastByteIndex;
  blocks3[16] = this.block;
  blocks3[i2 >>> 2] |= EXTRA2[i2 & 3];
  this.block = blocks3[16];
  if (i2 >= 56) {
    if (!this.hashed) {
      this.hash();
    }
    blocks3[0] = this.block;
    blocks3[16] = blocks3[1] = blocks3[2] = blocks3[3] = blocks3[4] = blocks3[5] = blocks3[6] = blocks3[7] = blocks3[8] = blocks3[9] = blocks3[10] = blocks3[11] = blocks3[12] = blocks3[13] = blocks3[14] = blocks3[15] = 0;
  }
  blocks3[14] = this.hBytes << 3 | this.bytes >>> 29;
  blocks3[15] = this.bytes << 3;
  this.hash();
};
Sha256.prototype.hash = function() {
  var a = this.h0, b2 = this.h1, c2 = this.h2, d2 = this.h3, e2 = this.h4, f = this.h5, g = this.h6, h2 = this.h7, blocks3 = this.blocks, j2, s0, s1, maj, t1, t2, ch, ab, da, cd, bc;
  for (j2 = 16; j2 < 64; ++j2) {
    t1 = blocks3[j2 - 15];
    s0 = (t1 >>> 7 | t1 << 25) ^ (t1 >>> 18 | t1 << 14) ^ t1 >>> 3;
    t1 = blocks3[j2 - 2];
    s1 = (t1 >>> 17 | t1 << 15) ^ (t1 >>> 19 | t1 << 13) ^ t1 >>> 10;
    blocks3[j2] = blocks3[j2 - 16] + s0 + blocks3[j2 - 7] + s1 << 0;
  }
  bc = b2 & c2;
  for (j2 = 0; j2 < 64; j2 += 4) {
    if (this.first) {
      if (this.is224) {
        ab = 300032;
        t1 = blocks3[0] - 1413257819;
        h2 = t1 - 150054599 << 0;
        d2 = t1 + 24177077 << 0;
      } else {
        ab = 704751109;
        t1 = blocks3[0] - 210244248;
        h2 = t1 - 1521486534 << 0;
        d2 = t1 + 143694565 << 0;
      }
      this.first = false;
    } else {
      s0 = (a >>> 2 | a << 30) ^ (a >>> 13 | a << 19) ^ (a >>> 22 | a << 10);
      s1 = (e2 >>> 6 | e2 << 26) ^ (e2 >>> 11 | e2 << 21) ^ (e2 >>> 25 | e2 << 7);
      ab = a & b2;
      maj = ab ^ a & c2 ^ bc;
      ch = e2 & f ^ ~e2 & g;
      t1 = h2 + s1 + ch + K[j2] + blocks3[j2];
      t2 = s0 + maj;
      h2 = d2 + t1 << 0;
      d2 = t1 + t2 << 0;
    }
    s0 = (d2 >>> 2 | d2 << 30) ^ (d2 >>> 13 | d2 << 19) ^ (d2 >>> 22 | d2 << 10);
    s1 = (h2 >>> 6 | h2 << 26) ^ (h2 >>> 11 | h2 << 21) ^ (h2 >>> 25 | h2 << 7);
    da = d2 & a;
    maj = da ^ d2 & b2 ^ ab;
    ch = g & h2 ^ ~g & e2;
    t1 = f + s1 + ch + K[j2 + 1] + blocks3[j2 + 1];
    t2 = s0 + maj;
    g = c2 + t1 << 0;
    c2 = t1 + t2 << 0;
    s0 = (c2 >>> 2 | c2 << 30) ^ (c2 >>> 13 | c2 << 19) ^ (c2 >>> 22 | c2 << 10);
    s1 = (g >>> 6 | g << 26) ^ (g >>> 11 | g << 21) ^ (g >>> 25 | g << 7);
    cd = c2 & d2;
    maj = cd ^ c2 & a ^ da;
    ch = f & g ^ ~f & h2;
    t1 = e2 + s1 + ch + K[j2 + 2] + blocks3[j2 + 2];
    t2 = s0 + maj;
    f = b2 + t1 << 0;
    b2 = t1 + t2 << 0;
    s0 = (b2 >>> 2 | b2 << 30) ^ (b2 >>> 13 | b2 << 19) ^ (b2 >>> 22 | b2 << 10);
    s1 = (f >>> 6 | f << 26) ^ (f >>> 11 | f << 21) ^ (f >>> 25 | f << 7);
    bc = b2 & c2;
    maj = bc ^ b2 & d2 ^ cd;
    ch = f & g ^ ~f & h2;
    t1 = e2 + s1 + ch + K[j2 + 3] + blocks3[j2 + 3];
    t2 = s0 + maj;
    e2 = a + t1 << 0;
    a = t1 + t2 << 0;
    this.chromeBugWorkAround = true;
  }
  this.h0 = this.h0 + a << 0;
  this.h1 = this.h1 + b2 << 0;
  this.h2 = this.h2 + c2 << 0;
  this.h3 = this.h3 + d2 << 0;
  this.h4 = this.h4 + e2 << 0;
  this.h5 = this.h5 + f << 0;
  this.h6 = this.h6 + g << 0;
  this.h7 = this.h7 + h2 << 0;
};
Sha256.prototype.hex = function() {
  this.finalize();
  var h0 = this.h0, h1 = this.h1, h2 = this.h2, h3 = this.h3, h4 = this.h4, h5 = this.h5, h6 = this.h6, h7 = this.h7;
  var hex = HEX_CHARS2[h0 >>> 28 & 15] + HEX_CHARS2[h0 >>> 24 & 15] + HEX_CHARS2[h0 >>> 20 & 15] + HEX_CHARS2[h0 >>> 16 & 15] + HEX_CHARS2[h0 >>> 12 & 15] + HEX_CHARS2[h0 >>> 8 & 15] + HEX_CHARS2[h0 >>> 4 & 15] + HEX_CHARS2[h0 & 15] + HEX_CHARS2[h1 >>> 28 & 15] + HEX_CHARS2[h1 >>> 24 & 15] + HEX_CHARS2[h1 >>> 20 & 15] + HEX_CHARS2[h1 >>> 16 & 15] + HEX_CHARS2[h1 >>> 12 & 15] + HEX_CHARS2[h1 >>> 8 & 15] + HEX_CHARS2[h1 >>> 4 & 15] + HEX_CHARS2[h1 & 15] + HEX_CHARS2[h2 >>> 28 & 15] + HEX_CHARS2[h2 >>> 24 & 15] + HEX_CHARS2[h2 >>> 20 & 15] + HEX_CHARS2[h2 >>> 16 & 15] + HEX_CHARS2[h2 >>> 12 & 15] + HEX_CHARS2[h2 >>> 8 & 15] + HEX_CHARS2[h2 >>> 4 & 15] + HEX_CHARS2[h2 & 15] + HEX_CHARS2[h3 >>> 28 & 15] + HEX_CHARS2[h3 >>> 24 & 15] + HEX_CHARS2[h3 >>> 20 & 15] + HEX_CHARS2[h3 >>> 16 & 15] + HEX_CHARS2[h3 >>> 12 & 15] + HEX_CHARS2[h3 >>> 8 & 15] + HEX_CHARS2[h3 >>> 4 & 15] + HEX_CHARS2[h3 & 15] + HEX_CHARS2[h4 >>> 28 & 15] + HEX_CHARS2[h4 >>> 24 & 15] + HEX_CHARS2[h4 >>> 20 & 15] + HEX_CHARS2[h4 >>> 16 & 15] + HEX_CHARS2[h4 >>> 12 & 15] + HEX_CHARS2[h4 >>> 8 & 15] + HEX_CHARS2[h4 >>> 4 & 15] + HEX_CHARS2[h4 & 15] + HEX_CHARS2[h5 >>> 28 & 15] + HEX_CHARS2[h5 >>> 24 & 15] + HEX_CHARS2[h5 >>> 20 & 15] + HEX_CHARS2[h5 >>> 16 & 15] + HEX_CHARS2[h5 >>> 12 & 15] + HEX_CHARS2[h5 >>> 8 & 15] + HEX_CHARS2[h5 >>> 4 & 15] + HEX_CHARS2[h5 & 15] + HEX_CHARS2[h6 >>> 28 & 15] + HEX_CHARS2[h6 >>> 24 & 15] + HEX_CHARS2[h6 >>> 20 & 15] + HEX_CHARS2[h6 >>> 16 & 15] + HEX_CHARS2[h6 >>> 12 & 15] + HEX_CHARS2[h6 >>> 8 & 15] + HEX_CHARS2[h6 >>> 4 & 15] + HEX_CHARS2[h6 & 15];
  if (!this.is224) {
    hex += HEX_CHARS2[h7 >>> 28 & 15] + HEX_CHARS2[h7 >>> 24 & 15] + HEX_CHARS2[h7 >>> 20 & 15] + HEX_CHARS2[h7 >>> 16 & 15] + HEX_CHARS2[h7 >>> 12 & 15] + HEX_CHARS2[h7 >>> 8 & 15] + HEX_CHARS2[h7 >>> 4 & 15] + HEX_CHARS2[h7 & 15];
  }
  return hex;
};
Sha256.prototype.toString = Sha256.prototype.hex;
Sha256.prototype.digest = function() {
  this.finalize();
  var h0 = this.h0, h1 = this.h1, h2 = this.h2, h3 = this.h3, h4 = this.h4, h5 = this.h5, h6 = this.h6, h7 = this.h7;
  var arr2 = [
    h0 >>> 24 & 255,
    h0 >>> 16 & 255,
    h0 >>> 8 & 255,
    h0 & 255,
    h1 >>> 24 & 255,
    h1 >>> 16 & 255,
    h1 >>> 8 & 255,
    h1 & 255,
    h2 >>> 24 & 255,
    h2 >>> 16 & 255,
    h2 >>> 8 & 255,
    h2 & 255,
    h3 >>> 24 & 255,
    h3 >>> 16 & 255,
    h3 >>> 8 & 255,
    h3 & 255,
    h4 >>> 24 & 255,
    h4 >>> 16 & 255,
    h4 >>> 8 & 255,
    h4 & 255,
    h5 >>> 24 & 255,
    h5 >>> 16 & 255,
    h5 >>> 8 & 255,
    h5 & 255,
    h6 >>> 24 & 255,
    h6 >>> 16 & 255,
    h6 >>> 8 & 255,
    h6 & 255
  ];
  if (!this.is224) {
    arr2.push(h7 >>> 24 & 255, h7 >>> 16 & 255, h7 >>> 8 & 255, h7 & 255);
  }
  return arr2;
};
Sha256.prototype.array = Sha256.prototype.digest;
Sha256.prototype.arrayBuffer = function() {
  this.finalize();
  var buffer = new ArrayBuffer(this.is224 ? 28 : 32);
  var dataView = new DataView(buffer);
  dataView.setUint32(0, this.h0);
  dataView.setUint32(4, this.h1);
  dataView.setUint32(8, this.h2);
  dataView.setUint32(12, this.h3);
  dataView.setUint32(16, this.h4);
  dataView.setUint32(20, this.h5);
  dataView.setUint32(24, this.h6);
  if (!this.is224) {
    dataView.setUint32(28, this.h7);
  }
  return buffer;
};
var sha256 = (...strings) => {
  return new Sha256(false, true).update(strings.join("")).hex();
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/caches/base.js
var getCacheKey = (...strings) => insecureHash(strings.join("_"));
function deserializeStoredGeneration(storedGeneration) {
  if (storedGeneration.message !== void 0) {
    return {
      text: storedGeneration.text,
      message: mapStoredMessageToChatMessage(storedGeneration.message)
    };
  } else {
    return { text: storedGeneration.text };
  }
}
function serializeGeneration(generation) {
  const serializedValue = {
    text: generation.text
  };
  if (generation.message !== void 0) {
    serializedValue.message = generation.message.toDict();
  }
  return serializedValue;
}
var BaseCache = class {
  constructor() {
    Object.defineProperty(this, "keyEncoder", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: getCacheKey
    });
  }
  /**
   * Sets a custom key encoder function for the cache.
   * This function should take a prompt and an LLM key and return a string
   * that will be used as the cache key.
   * @param keyEncoderFn The custom key encoder function.
   */
  makeDefaultKeyEncoder(keyEncoderFn) {
    this.keyEncoder = keyEncoderFn;
  }
};
var GLOBAL_MAP = /* @__PURE__ */ new Map();
var InMemoryCache = class _InMemoryCache extends BaseCache {
  constructor(map) {
    super();
    Object.defineProperty(this, "cache", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.cache = map ?? /* @__PURE__ */ new Map();
  }
  /**
   * Retrieves data from the cache using a prompt and an LLM key. If the
   * data is not found, it returns null.
   * @param prompt The prompt used to find the data.
   * @param llmKey The LLM key used to find the data.
   * @returns The data corresponding to the prompt and LLM key, or null if not found.
   */
  lookup(prompt, llmKey) {
    return Promise.resolve(this.cache.get(this.keyEncoder(prompt, llmKey)) ?? null);
  }
  /**
   * Updates the cache with new data using a prompt and an LLM key.
   * @param prompt The prompt used to store the data.
   * @param llmKey The LLM key used to store the data.
   * @param value The data to be stored.
   */
  async update(prompt, llmKey, value) {
    this.cache.set(this.keyEncoder(prompt, llmKey), value);
  }
  /**
   * Returns a global instance of InMemoryCache using a predefined global
   * map as the initial cache.
   * @returns A global instance of InMemoryCache.
   */
  static global() {
    return new _InMemoryCache(GLOBAL_MAP);
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/chat_history.js
var chat_history_exports = {};
__export(chat_history_exports, {
  BaseChatMessageHistory: () => BaseChatMessageHistory,
  BaseListChatMessageHistory: () => BaseListChatMessageHistory,
  InMemoryChatMessageHistory: () => InMemoryChatMessageHistory
});
init_esm();
var BaseChatMessageHistory = class extends Serializable {
  /**
   * Add a list of messages.
   *
   * Implementations should override this method to handle bulk addition of messages
   * in an efficient manner to avoid unnecessary round-trips to the underlying store.
   *
   * @param messages - A list of BaseMessage objects to store.
   */
  async addMessages(messages) {
    for (const message of messages) {
      await this.addMessage(message);
    }
  }
};
var BaseListChatMessageHistory = class extends Serializable {
  /**
   * This is a convenience method for adding a human message string to the store.
   * Please note that this is a convenience method. Code should favor the
   * bulk addMessages interface instead to save on round-trips to the underlying
   * persistence layer.
   * This method may be deprecated in a future release.
   */
  addUserMessage(message) {
    return this.addMessage(new HumanMessage(message));
  }
  /** @deprecated Use addAIMessage instead */
  addAIChatMessage(message) {
    return this.addMessage(new AIMessage(message));
  }
  /**
   * This is a convenience method for adding an AI message string to the store.
   * Please note that this is a convenience method. Code should favor the bulk
   * addMessages interface instead to save on round-trips to the underlying
   * persistence layer.
   * This method may be deprecated in a future release.
   */
  addAIMessage(message) {
    return this.addMessage(new AIMessage(message));
  }
  /**
   * Add a list of messages.
   *
   * Implementations should override this method to handle bulk addition of messages
   * in an efficient manner to avoid unnecessary round-trips to the underlying store.
   *
   * @param messages - A list of BaseMessage objects to store.
   */
  async addMessages(messages) {
    for (const message of messages) {
      await this.addMessage(message);
    }
  }
  /**
   * Remove all messages from the store.
   */
  clear() {
    throw new Error("Not implemented.");
  }
};
var InMemoryChatMessageHistory = class extends BaseListChatMessageHistory {
  constructor(messages) {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain", "stores", "message", "in_memory"]
    });
    Object.defineProperty(this, "messages", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    this.messages = messages ?? [];
  }
  /**
   * Method to get all the messages stored in the ChatMessageHistory
   * instance.
   * @returns Array of stored BaseMessage instances.
   */
  async getMessages() {
    return this.messages;
  }
  /**
   * Method to add a new message to the ChatMessageHistory instance.
   * @param message The BaseMessage instance to add.
   * @returns A promise that resolves when the message has been added.
   */
  async addMessage(message) {
    this.messages.push(message);
  }
  /**
   * Method to clear all the messages from the ChatMessageHistory instance.
   * @returns A promise that resolves when all messages have been cleared.
   */
  async clear() {
    this.messages = [];
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/documents/index.js
var documents_exports = {};
__export(documents_exports, {
  BaseDocumentTransformer: () => BaseDocumentTransformer,
  Document: () => Document,
  MappingDocumentTransformer: () => MappingDocumentTransformer
});
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/documents/document.js
init_esm();
var Document = class {
  constructor(fields) {
    Object.defineProperty(this, "pageContent", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "metadata", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "id", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.pageContent = fields.pageContent !== void 0 ? fields.pageContent.toString() : "";
    this.metadata = fields.metadata ?? {};
    this.id = fields.id;
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/documents/transformers.js
init_esm();
var BaseDocumentTransformer = class extends Runnable {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "documents", "transformers"]
    });
  }
  /**
   * Method to invoke the document transformation. This method calls the
   * transformDocuments method with the provided input.
   * @param input The input documents to be transformed.
   * @param _options Optional configuration object to customize the behavior of callbacks.
   * @returns A Promise that resolves to the transformed documents.
   */
  invoke(input, _options) {
    return this.transformDocuments(input);
  }
};
var MappingDocumentTransformer = class extends BaseDocumentTransformer {
  async transformDocuments(documents) {
    const newDocuments = [];
    for (const document2 of documents) {
      const transformedDocument = await this._transformDocument(document2);
      newDocuments.push(transformedDocument);
    }
    return newDocuments;
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/embeddings.js
var embeddings_exports = {};
__export(embeddings_exports, {
  Embeddings: () => Embeddings
});
init_esm();
var Embeddings = class {
  constructor(params) {
    Object.defineProperty(this, "caller", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.caller = new AsyncCaller(params ?? {});
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/example_selectors/index.js
var example_selectors_exports = {};
__export(example_selectors_exports, {
  BaseExampleSelector: () => BaseExampleSelector,
  BasePromptSelector: () => BasePromptSelector,
  ConditionalPromptSelector: () => ConditionalPromptSelector,
  LengthBasedExampleSelector: () => LengthBasedExampleSelector,
  SemanticSimilarityExampleSelector: () => SemanticSimilarityExampleSelector,
  isChatModel: () => isChatModel,
  isLLM: () => isLLM
});
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/example_selectors/base.js
init_esm();
var BaseExampleSelector = class extends Serializable {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "example_selectors", "base"]
    });
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/example_selectors/conditional.js
init_esm();
var BasePromptSelector = class {
  /**
   * Asynchronous version of `getPrompt` that also accepts an options object
   * for partial variables.
   * @param llm The language model for which to get a prompt.
   * @param options Optional object for partial variables.
   * @returns A Promise that resolves to a prompt template.
   */
  async getPromptAsync(llm, options) {
    const prompt = this.getPrompt(llm);
    return prompt.partial(options?.partialVariables ?? {});
  }
};
var ConditionalPromptSelector = class extends BasePromptSelector {
  constructor(default_prompt, conditionals = []) {
    super();
    Object.defineProperty(this, "defaultPrompt", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "conditionals", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.defaultPrompt = default_prompt;
    this.conditionals = conditionals;
  }
  /**
   * Method that selects a prompt based on a set of conditions. If none of
   * the conditions are met, it returns the default prompt.
   * @param llm The language model for which to get a prompt.
   * @returns A prompt template.
   */
  getPrompt(llm) {
    for (const [condition, prompt] of this.conditionals) {
      if (condition(llm)) {
        return prompt;
      }
    }
    return this.defaultPrompt;
  }
};
function isLLM(llm) {
  return llm._modelType() === "base_llm";
}
function isChatModel(llm) {
  return llm._modelType() === "base_chat_model";
}

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/example_selectors/length_based.js
init_esm();
function getLengthBased(text) {
  return text.split(/\n| /).length;
}
var LengthBasedExampleSelector = class _LengthBasedExampleSelector extends BaseExampleSelector {
  constructor(data) {
    super(data);
    Object.defineProperty(this, "examples", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    Object.defineProperty(this, "examplePrompt", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "getTextLength", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: getLengthBased
    });
    Object.defineProperty(this, "maxLength", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: 2048
    });
    Object.defineProperty(this, "exampleTextLengths", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    this.examplePrompt = data.examplePrompt;
    this.maxLength = data.maxLength ?? 2048;
    this.getTextLength = data.getTextLength ?? getLengthBased;
  }
  /**
   * Adds an example to the list of examples and calculates its length.
   * @param example The example to be added.
   * @returns Promise that resolves when the example has been added and its length calculated.
   */
  async addExample(example) {
    this.examples.push(example);
    const stringExample = await this.examplePrompt.format(example);
    this.exampleTextLengths.push(this.getTextLength(stringExample));
  }
  /**
   * Calculates the lengths of the examples.
   * @param v Array of lengths of the examples.
   * @param values Instance of LengthBasedExampleSelector.
   * @returns Promise that resolves with an array of lengths of the examples.
   */
  async calculateExampleTextLengths(v2, values) {
    if (v2.length > 0) {
      return v2;
    }
    const { examples, examplePrompt } = values;
    const stringExamples = await Promise.all(examples.map((eg) => examplePrompt.format(eg)));
    return stringExamples.map((eg) => this.getTextLength(eg));
  }
  /**
   * Selects examples until the total length of the selected examples
   * reaches the maxLength.
   * @param inputVariables The input variables for the examples.
   * @returns Promise that resolves with an array of selected examples.
   */
  async selectExamples(inputVariables) {
    const inputs = Object.values(inputVariables).join(" ");
    let remainingLength = this.maxLength - this.getTextLength(inputs);
    let i2 = 0;
    const examples = [];
    while (remainingLength > 0 && i2 < this.examples.length) {
      const newLength = remainingLength - this.exampleTextLengths[i2];
      if (newLength < 0) {
        break;
      } else {
        examples.push(this.examples[i2]);
        remainingLength = newLength;
      }
      i2 += 1;
    }
    return examples;
  }
  /**
   * Creates a new instance of LengthBasedExampleSelector and adds a list of
   * examples to it.
   * @param examples Array of examples to be added.
   * @param args Input parameters for the LengthBasedExampleSelector.
   * @returns Promise that resolves with a new instance of LengthBasedExampleSelector with the examples added.
   */
  static async fromExamples(examples, args) {
    const selector = new _LengthBasedExampleSelector(args);
    await Promise.all(examples.map((eg) => selector.addExample(eg)));
    return selector;
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/example_selectors/semantic_similarity.js
init_esm();
function sortedValues(values) {
  return Object.keys(values).sort().map((key) => values[key]);
}
var SemanticSimilarityExampleSelector = class _SemanticSimilarityExampleSelector extends BaseExampleSelector {
  constructor(data) {
    super(data);
    Object.defineProperty(this, "vectorStoreRetriever", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "exampleKeys", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "inputKeys", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.exampleKeys = data.exampleKeys;
    this.inputKeys = data.inputKeys;
    if (data.vectorStore !== void 0) {
      this.vectorStoreRetriever = data.vectorStore.asRetriever({
        k: data.k ?? 4,
        filter: data.filter
      });
    } else if (data.vectorStoreRetriever) {
      this.vectorStoreRetriever = data.vectorStoreRetriever;
    } else {
      throw new Error(`You must specify one of "vectorStore" and "vectorStoreRetriever".`);
    }
  }
  /**
   * Method that adds a new example to the vectorStore. The example is
   * converted to a string and added to the vectorStore as a document.
   * @param example The example to be added to the vectorStore.
   * @returns Promise that resolves when the example has been added to the vectorStore.
   */
  async addExample(example) {
    const inputKeys = this.inputKeys ?? Object.keys(example);
    const stringExample = sortedValues(inputKeys.reduce((acc, key) => ({ ...acc, [key]: example[key] }), {})).join(" ");
    await this.vectorStoreRetriever.addDocuments([
      new Document({
        pageContent: stringExample,
        metadata: example
      })
    ]);
  }
  /**
   * Method that selects which examples to use based on semantic similarity.
   * It performs a similarity search in the vectorStore using the input
   * variables and returns the examples with the highest similarity.
   * @param inputVariables The input variables used for the similarity search.
   * @returns Promise that resolves with an array of the selected examples.
   */
  async selectExamples(inputVariables) {
    const inputKeys = this.inputKeys ?? Object.keys(inputVariables);
    const query = sortedValues(inputKeys.reduce((acc, key) => ({ ...acc, [key]: inputVariables[key] }), {})).join(" ");
    const exampleDocs = await this.vectorStoreRetriever.invoke(query);
    const examples = exampleDocs.map((doc) => doc.metadata);
    if (this.exampleKeys) {
      return examples.map((example) => this.exampleKeys.reduce((acc, key) => ({ ...acc, [key]: example[key] }), {}));
    }
    return examples;
  }
  /**
   * Static method that creates a new instance of
   * SemanticSimilarityExampleSelector. It takes a list of examples, an
   * instance of Embeddings, a VectorStore class, and an options object as
   * parameters. It converts the examples to strings, creates a VectorStore
   * from the strings and the embeddings, and returns a new
   * SemanticSimilarityExampleSelector with the created VectorStore and the
   * options provided.
   * @param examples The list of examples to be used.
   * @param embeddings The instance of Embeddings to be used.
   * @param vectorStoreCls The VectorStore class to be used.
   * @param options The options object for the SemanticSimilarityExampleSelector.
   * @returns Promise that resolves with a new instance of SemanticSimilarityExampleSelector.
   */
  static async fromExamples(examples, embeddings, vectorStoreCls, options = {}) {
    const inputKeys = options.inputKeys ?? null;
    const stringExamples = examples.map((example) => sortedValues(inputKeys ? inputKeys.reduce((acc, key) => ({ ...acc, [key]: example[key] }), {}) : example).join(" "));
    const vectorStore = await vectorStoreCls.fromTexts(
      stringExamples,
      examples,
      // metadatas
      embeddings,
      options
    );
    return new _SemanticSimilarityExampleSelector({
      vectorStore,
      k: options.k ?? 4,
      exampleKeys: options.exampleKeys,
      inputKeys: options.inputKeys
    });
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/language_models/base.js
var base_exports4 = {};
__export(base_exports4, {
  BaseLangChain: () => BaseLangChain,
  BaseLanguageModel: () => BaseLanguageModel,
  calculateMaxTokens: () => calculateMaxTokens,
  getEmbeddingContextSize: () => getEmbeddingContextSize,
  getModelContextSize: () => getModelContextSize,
  getModelNameForTiktoken: () => getModelNameForTiktoken,
  isOpenAITool: () => isOpenAITool
});
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/utils/tiktoken.js
var tiktoken_exports = {};
__export(tiktoken_exports, {
  encodingForModel: () => encodingForModel,
  getEncoding: () => getEncoding
});
init_esm();
var cache = {};
var caller = /* @__PURE__ */ new AsyncCaller({});
async function getEncoding(encoding) {
  if (!(encoding in cache)) {
    cache[encoding] = caller.fetch(`https://tiktoken.pages.dev/js/${encoding}.json`).then((res) => res.json()).then((data) => new Tiktoken(data)).catch((e2) => {
      delete cache[encoding];
      throw e2;
    });
  }
  return await cache[encoding];
}
async function encodingForModel(model) {
  return getEncoding(getEncodingNameForModel(model));
}

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/language_models/base.js
var getModelNameForTiktoken = (modelName) => {
  if (modelName.startsWith("gpt-3.5-turbo-16k")) {
    return "gpt-3.5-turbo-16k";
  }
  if (modelName.startsWith("gpt-3.5-turbo-")) {
    return "gpt-3.5-turbo";
  }
  if (modelName.startsWith("gpt-4-32k")) {
    return "gpt-4-32k";
  }
  if (modelName.startsWith("gpt-4-")) {
    return "gpt-4";
  }
  if (modelName.startsWith("gpt-4o")) {
    return "gpt-4o";
  }
  return modelName;
};
var getEmbeddingContextSize = (modelName) => {
  switch (modelName) {
    case "text-embedding-ada-002":
      return 8191;
    default:
      return 2046;
  }
};
var getModelContextSize = (modelName) => {
  switch (getModelNameForTiktoken(modelName)) {
    case "gpt-3.5-turbo-16k":
      return 16384;
    case "gpt-3.5-turbo":
      return 4096;
    case "gpt-4-32k":
      return 32768;
    case "gpt-4":
      return 8192;
    case "text-davinci-003":
      return 4097;
    case "text-curie-001":
      return 2048;
    case "text-babbage-001":
      return 2048;
    case "text-ada-001":
      return 2048;
    case "code-davinci-002":
      return 8e3;
    case "code-cushman-001":
      return 2048;
    default:
      return 4097;
  }
};
function isOpenAITool(tool2) {
  if (typeof tool2 !== "object" || !tool2)
    return false;
  if ("type" in tool2 && tool2.type === "function" && "function" in tool2 && typeof tool2.function === "object" && tool2.function && "name" in tool2.function && "parameters" in tool2.function) {
    return true;
  }
  return false;
}
var calculateMaxTokens = async ({ prompt, modelName }) => {
  let numTokens;
  try {
    numTokens = (await encodingForModel(getModelNameForTiktoken(modelName))).encode(prompt).length;
  } catch (error) {
    console.warn("Failed to calculate number of tokens, falling back to approximate count");
    numTokens = Math.ceil(prompt.length / 4);
  }
  const maxTokens = getModelContextSize(modelName);
  return maxTokens - numTokens;
};
var getVerbosity = () => false;
var BaseLangChain = class extends Runnable {
  get lc_attributes() {
    return {
      callbacks: void 0,
      verbose: void 0
    };
  }
  constructor(params) {
    super(params);
    Object.defineProperty(this, "verbose", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "callbacks", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "tags", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "metadata", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.verbose = params.verbose ?? getVerbosity();
    this.callbacks = params.callbacks;
    this.tags = params.tags ?? [];
    this.metadata = params.metadata ?? {};
  }
};
var BaseLanguageModel = class extends BaseLangChain {
  /**
   * Keys that the language model accepts as call options.
   */
  get callKeys() {
    return ["stop", "timeout", "signal", "tags", "metadata", "callbacks"];
  }
  constructor({ callbacks, callbackManager, ...params }) {
    const { cache: cache2, ...rest } = params;
    super({
      callbacks: callbacks ?? callbackManager,
      ...rest
    });
    Object.defineProperty(this, "caller", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "cache", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "_encoding", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    if (typeof cache2 === "object") {
      this.cache = cache2;
    } else if (cache2) {
      this.cache = InMemoryCache.global();
    } else {
      this.cache = void 0;
    }
    this.caller = new AsyncCaller(params ?? {});
  }
  /**
   * Get the number of tokens in the content.
   * @param content The content to get the number of tokens for.
   * @returns The number of tokens in the content.
   */
  async getNumTokens(content) {
    let textContent;
    if (typeof content === "string") {
      textContent = content;
    } else {
      textContent = content.map((item) => {
        if (typeof item === "string")
          return item;
        if (item.type === "text" && "text" in item)
          return item.text;
        return "";
      }).join("");
    }
    let numTokens = Math.ceil(textContent.length / 4);
    if (!this._encoding) {
      try {
        this._encoding = await encodingForModel("modelName" in this ? getModelNameForTiktoken(this.modelName) : "gpt2");
      } catch (error) {
        console.warn("Failed to calculate number of tokens, falling back to approximate count", error);
      }
    }
    if (this._encoding) {
      try {
        numTokens = this._encoding.encode(textContent).length;
      } catch (error) {
        console.warn("Failed to calculate number of tokens, falling back to approximate count", error);
      }
    }
    return numTokens;
  }
  static _convertInputToPromptValue(input) {
    if (typeof input === "string") {
      return new StringPromptValue(input);
    } else if (Array.isArray(input)) {
      return new ChatPromptValue(input.map(coerceMessageLikeToMessage));
    } else {
      return input;
    }
  }
  /**
   * Get the identifying parameters of the LLM.
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  _identifyingParams() {
    return {};
  }
  /**
   * Create a unique cache key for a specific call to a specific language model.
   * @param callOptions Call options for the model
   * @returns A unique cache key.
   */
  _getSerializedCacheKeyParametersForCall({ config, ...callOptions }) {
    const params = {
      ...this._identifyingParams(),
      ...callOptions,
      _type: this._llmType(),
      _model: this._modelType()
    };
    const filteredEntries = Object.entries(params).filter(([_2, value]) => value !== void 0);
    const serializedEntries = filteredEntries.map(([key, value]) => `${key}:${JSON.stringify(value)}`).sort().join(",");
    return serializedEntries;
  }
  /**
   * @deprecated
   * Return a json-like object representing this LLM.
   */
  serialize() {
    return {
      ...this._identifyingParams(),
      _type: this._llmType(),
      _model: this._modelType()
    };
  }
  /**
   * @deprecated
   * Load an LLM from a json-like object describing it.
   */
  static async deserialize(_data) {
    throw new Error("Use .toJSON() instead");
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/language_models/chat_models.js
var chat_models_exports = {};
__export(chat_models_exports, {
  BaseChatModel: () => BaseChatModel,
  SimpleChatModel: () => SimpleChatModel,
  createChatMessageChunkEncoderStream: () => createChatMessageChunkEncoderStream
});
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/runnables/passthrough.js
init_esm();
var RunnablePassthrough = class extends Runnable {
  static lc_name() {
    return "RunnablePassthrough";
  }
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "runnables"]
    });
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "func", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    if (fields) {
      this.func = fields.func;
    }
  }
  async invoke(input, options) {
    const config = ensureConfig(options);
    if (this.func) {
      await this.func(input, config);
    }
    return this._callWithConfig((input2) => Promise.resolve(input2), input, config);
  }
  async *transform(generator, options) {
    const config = ensureConfig(options);
    let finalOutput;
    let finalOutputSupported = true;
    for await (const chunk of this._transformStreamWithConfig(generator, (input) => input, config)) {
      yield chunk;
      if (finalOutputSupported) {
        if (finalOutput === void 0) {
          finalOutput = chunk;
        } else {
          try {
            finalOutput = concat(finalOutput, chunk);
          } catch {
            finalOutput = void 0;
            finalOutputSupported = false;
          }
        }
      }
    }
    if (this.func && finalOutput !== void 0) {
      await this.func(finalOutput, config);
    }
  }
  /**
   * A runnable that assigns key-value pairs to the input.
   *
   * The example below shows how you could use it with an inline function.
   *
   * @example
   * ```typescript
   * const prompt =
   *   PromptTemplate.fromTemplate(`Write a SQL query to answer the question using the following schema: {schema}
   * Question: {question}
   * SQL Query:`);
   *
   * // The `RunnablePassthrough.assign()` is used here to passthrough the input from the `.invoke()`
   * // call (in this example it's the question), along with any inputs passed to the `.assign()` method.
   * // In this case, we're passing the schema.
   * const sqlQueryGeneratorChain = RunnableSequence.from([
   *   RunnablePassthrough.assign({
   *     schema: async () => db.getTableInfo(),
   *   }),
   *   prompt,
   *   new ChatOpenAI({}).withConfig({ stop: ["\nSQLResult:"] }),
   *   new StringOutputParser(),
   * ]);
   * const result = await sqlQueryGeneratorChain.invoke({
   *   question: "How many employees are there?",
   * });
   * ```
   */
  static assign(mapping) {
    return new RunnableAssign(new RunnableMap({ steps: mapping }));
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/language_models/chat_models.js
function createChatMessageChunkEncoderStream() {
  const textEncoder = new TextEncoder();
  return new TransformStream({
    transform(chunk, controller) {
      controller.enqueue(textEncoder.encode(typeof chunk.content === "string" ? chunk.content : JSON.stringify(chunk.content)));
    }
  });
}
function _formatForTracing(messages) {
  const messagesToTrace = [];
  for (const message of messages) {
    let messageToTrace = message;
    if (Array.isArray(message.content)) {
      for (let idx = 0; idx < message.content.length; idx++) {
        const block = message.content[idx];
        if (isURLContentBlock(block) || isBase64ContentBlock(block)) {
          if (messageToTrace === message) {
            messageToTrace = new message.constructor({
              ...messageToTrace,
              content: [
                ...message.content.slice(0, idx),
                convertToOpenAIImageBlock(block),
                ...message.content.slice(idx + 1)
              ]
            });
          }
        }
      }
    }
    messagesToTrace.push(messageToTrace);
  }
  return messagesToTrace;
}
var BaseChatModel = class _BaseChatModel extends BaseLanguageModel {
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain", "chat_models", this._llmType()]
    });
    Object.defineProperty(this, "disableStreaming", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
  }
  _separateRunnableConfigFromCallOptionsCompat(options) {
    const [runnableConfig, callOptions] = super._separateRunnableConfigFromCallOptions(options);
    callOptions.signal = runnableConfig.signal;
    return [runnableConfig, callOptions];
  }
  /**
   * Invokes the chat model with a single input.
   * @param input The input for the language model.
   * @param options The call options.
   * @returns A Promise that resolves to a BaseMessageChunk.
   */
  async invoke(input, options) {
    const promptValue = _BaseChatModel._convertInputToPromptValue(input);
    const result = await this.generatePrompt([promptValue], options, options?.callbacks);
    const chatGeneration = result.generations[0][0];
    return chatGeneration.message;
  }
  // eslint-disable-next-line require-yield
  async *_streamResponseChunks(_messages, _options, _runManager) {
    throw new Error("Not implemented.");
  }
  async *_streamIterator(input, options) {
    if (this._streamResponseChunks === _BaseChatModel.prototype._streamResponseChunks || this.disableStreaming) {
      yield this.invoke(input, options);
    } else {
      const prompt = _BaseChatModel._convertInputToPromptValue(input);
      const messages = prompt.toChatMessages();
      const [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptionsCompat(options);
      const inheritableMetadata = {
        ...runnableConfig.metadata,
        ...this.getLsParams(callOptions)
      };
      const callbackManager_ = await CallbackManager.configure(runnableConfig.callbacks, this.callbacks, runnableConfig.tags, this.tags, inheritableMetadata, this.metadata, { verbose: this.verbose });
      const extra = {
        options: callOptions,
        invocation_params: this?.invocationParams(callOptions),
        batch_size: 1
      };
      const runManagers = await callbackManager_?.handleChatModelStart(this.toJSON(), [_formatForTracing(messages)], runnableConfig.runId, void 0, extra, void 0, void 0, runnableConfig.runName);
      let generationChunk;
      let llmOutput;
      try {
        for await (const chunk of this._streamResponseChunks(messages, callOptions, runManagers?.[0])) {
          if (chunk.message.id == null) {
            const runId = runManagers?.at(0)?.runId;
            if (runId != null)
              chunk.message._updateId(`run-${runId}`);
          }
          chunk.message.response_metadata = {
            ...chunk.generationInfo,
            ...chunk.message.response_metadata
          };
          yield chunk.message;
          if (!generationChunk) {
            generationChunk = chunk;
          } else {
            generationChunk = generationChunk.concat(chunk);
          }
          if (isAIMessageChunk(chunk.message) && chunk.message.usage_metadata !== void 0) {
            llmOutput = {
              tokenUsage: {
                promptTokens: chunk.message.usage_metadata.input_tokens,
                completionTokens: chunk.message.usage_metadata.output_tokens,
                totalTokens: chunk.message.usage_metadata.total_tokens
              }
            };
          }
        }
      } catch (err3) {
        await Promise.all((runManagers ?? []).map((runManager) => runManager?.handleLLMError(err3)));
        throw err3;
      }
      await Promise.all((runManagers ?? []).map((runManager) => runManager?.handleLLMEnd({
        // TODO: Remove cast after figuring out inheritance
        generations: [[generationChunk]],
        llmOutput
      })));
    }
  }
  getLsParams(options) {
    const providerName = this.getName().startsWith("Chat") ? this.getName().replace("Chat", "") : this.getName();
    return {
      ls_model_type: "chat",
      ls_stop: options.stop,
      ls_provider: providerName
    };
  }
  /** @ignore */
  async _generateUncached(messages, parsedOptions, handledOptions, startedRunManagers) {
    const baseMessages = messages.map((messageList) => messageList.map(coerceMessageLikeToMessage));
    let runManagers;
    if (startedRunManagers !== void 0 && startedRunManagers.length === baseMessages.length) {
      runManagers = startedRunManagers;
    } else {
      const inheritableMetadata = {
        ...handledOptions.metadata,
        ...this.getLsParams(parsedOptions)
      };
      const callbackManager_ = await CallbackManager.configure(handledOptions.callbacks, this.callbacks, handledOptions.tags, this.tags, inheritableMetadata, this.metadata, { verbose: this.verbose });
      const extra = {
        options: parsedOptions,
        invocation_params: this?.invocationParams(parsedOptions),
        batch_size: 1
      };
      runManagers = await callbackManager_?.handleChatModelStart(this.toJSON(), baseMessages.map(_formatForTracing), handledOptions.runId, void 0, extra, void 0, void 0, handledOptions.runName);
    }
    const generations = [];
    const llmOutputs = [];
    const hasStreamingHandler = !!runManagers?.[0].handlers.find(callbackHandlerPrefersStreaming);
    if (hasStreamingHandler && !this.disableStreaming && baseMessages.length === 1 && this._streamResponseChunks !== _BaseChatModel.prototype._streamResponseChunks) {
      try {
        const stream = await this._streamResponseChunks(baseMessages[0], parsedOptions, runManagers?.[0]);
        let aggregated;
        let llmOutput;
        for await (const chunk of stream) {
          if (chunk.message.id == null) {
            const runId = runManagers?.at(0)?.runId;
            if (runId != null)
              chunk.message._updateId(`run-${runId}`);
          }
          if (aggregated === void 0) {
            aggregated = chunk;
          } else {
            aggregated = concat(aggregated, chunk);
          }
          if (isAIMessageChunk(chunk.message) && chunk.message.usage_metadata !== void 0) {
            llmOutput = {
              tokenUsage: {
                promptTokens: chunk.message.usage_metadata.input_tokens,
                completionTokens: chunk.message.usage_metadata.output_tokens,
                totalTokens: chunk.message.usage_metadata.total_tokens
              }
            };
          }
        }
        if (aggregated === void 0) {
          throw new Error("Received empty response from chat model call.");
        }
        generations.push([aggregated]);
        await runManagers?.[0].handleLLMEnd({
          generations,
          llmOutput
        });
      } catch (e2) {
        await runManagers?.[0].handleLLMError(e2);
        throw e2;
      }
    } else {
      const results = await Promise.allSettled(baseMessages.map((messageList, i2) => this._generate(messageList, { ...parsedOptions, promptIndex: i2 }, runManagers?.[i2])));
      await Promise.all(results.map(async (pResult, i2) => {
        if (pResult.status === "fulfilled") {
          const result = pResult.value;
          for (const generation of result.generations) {
            if (generation.message.id == null) {
              const runId = runManagers?.at(0)?.runId;
              if (runId != null)
                generation.message._updateId(`run-${runId}`);
            }
            generation.message.response_metadata = {
              ...generation.generationInfo,
              ...generation.message.response_metadata
            };
          }
          if (result.generations.length === 1) {
            result.generations[0].message.response_metadata = {
              ...result.llmOutput,
              ...result.generations[0].message.response_metadata
            };
          }
          generations[i2] = result.generations;
          llmOutputs[i2] = result.llmOutput;
          return runManagers?.[i2]?.handleLLMEnd({
            generations: [result.generations],
            llmOutput: result.llmOutput
          });
        } else {
          await runManagers?.[i2]?.handleLLMError(pResult.reason);
          return Promise.reject(pResult.reason);
        }
      }));
    }
    const output = {
      generations,
      llmOutput: llmOutputs.length ? this._combineLLMOutput?.(...llmOutputs) : void 0
    };
    Object.defineProperty(output, RUN_KEY, {
      value: runManagers ? { runIds: runManagers?.map((manager2) => manager2.runId) } : void 0,
      configurable: true
    });
    return output;
  }
  async _generateCached({ messages, cache: cache2, llmStringKey, parsedOptions, handledOptions }) {
    const baseMessages = messages.map((messageList) => messageList.map(coerceMessageLikeToMessage));
    const inheritableMetadata = {
      ...handledOptions.metadata,
      ...this.getLsParams(parsedOptions)
    };
    const callbackManager_ = await CallbackManager.configure(handledOptions.callbacks, this.callbacks, handledOptions.tags, this.tags, inheritableMetadata, this.metadata, { verbose: this.verbose });
    const extra = {
      options: parsedOptions,
      invocation_params: this?.invocationParams(parsedOptions),
      batch_size: 1
    };
    const runManagers = await callbackManager_?.handleChatModelStart(this.toJSON(), baseMessages.map(_formatForTracing), handledOptions.runId, void 0, extra, void 0, void 0, handledOptions.runName);
    const missingPromptIndices = [];
    const results = await Promise.allSettled(baseMessages.map(async (baseMessage, index) => {
      const prompt = _BaseChatModel._convertInputToPromptValue(baseMessage).toString();
      const result = await cache2.lookup(prompt, llmStringKey);
      if (result == null) {
        missingPromptIndices.push(index);
      }
      return result;
    }));
    const cachedResults = results.map((result, index) => ({ result, runManager: runManagers?.[index] })).filter(({ result }) => result.status === "fulfilled" && result.value != null || result.status === "rejected");
    const generations = [];
    await Promise.all(cachedResults.map(async ({ result: promiseResult, runManager }, i2) => {
      if (promiseResult.status === "fulfilled") {
        const result = promiseResult.value;
        generations[i2] = result.map((result2) => {
          if ("message" in result2 && isBaseMessage(result2.message) && isAIMessage(result2.message)) {
            result2.message.usage_metadata = {
              input_tokens: 0,
              output_tokens: 0,
              total_tokens: 0
            };
          }
          result2.generationInfo = {
            ...result2.generationInfo,
            tokenUsage: {}
          };
          return result2;
        });
        if (result.length) {
          await runManager?.handleLLMNewToken(result[0].text);
        }
        return runManager?.handleLLMEnd({
          generations: [result]
        }, void 0, void 0, void 0, {
          cached: true
        });
      } else {
        await runManager?.handleLLMError(promiseResult.reason, void 0, void 0, void 0, {
          cached: true
        });
        return Promise.reject(promiseResult.reason);
      }
    }));
    const output = {
      generations,
      missingPromptIndices,
      startedRunManagers: runManagers
    };
    Object.defineProperty(output, RUN_KEY, {
      value: runManagers ? { runIds: runManagers?.map((manager2) => manager2.runId) } : void 0,
      configurable: true
    });
    return output;
  }
  /**
   * Generates chat based on the input messages.
   * @param messages An array of arrays of BaseMessage instances.
   * @param options The call options or an array of stop sequences.
   * @param callbacks The callbacks for the language model.
   * @returns A Promise that resolves to an LLMResult.
   */
  async generate(messages, options, callbacks) {
    let parsedOptions;
    if (Array.isArray(options)) {
      parsedOptions = { stop: options };
    } else {
      parsedOptions = options;
    }
    const baseMessages = messages.map((messageList) => messageList.map(coerceMessageLikeToMessage));
    const [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptionsCompat(parsedOptions);
    runnableConfig.callbacks = runnableConfig.callbacks ?? callbacks;
    if (!this.cache) {
      return this._generateUncached(baseMessages, callOptions, runnableConfig);
    }
    const { cache: cache2 } = this;
    const llmStringKey = this._getSerializedCacheKeyParametersForCall(callOptions);
    const { generations, missingPromptIndices, startedRunManagers } = await this._generateCached({
      messages: baseMessages,
      cache: cache2,
      llmStringKey,
      parsedOptions: callOptions,
      handledOptions: runnableConfig
    });
    let llmOutput = {};
    if (missingPromptIndices.length > 0) {
      const results = await this._generateUncached(missingPromptIndices.map((i2) => baseMessages[i2]), callOptions, runnableConfig, startedRunManagers !== void 0 ? missingPromptIndices.map((i2) => startedRunManagers?.[i2]) : void 0);
      await Promise.all(results.generations.map(async (generation, index) => {
        const promptIndex = missingPromptIndices[index];
        generations[promptIndex] = generation;
        const prompt = _BaseChatModel._convertInputToPromptValue(baseMessages[promptIndex]).toString();
        return cache2.update(prompt, llmStringKey, generation);
      }));
      llmOutput = results.llmOutput ?? {};
    }
    return { generations, llmOutput };
  }
  /**
   * Get the parameters used to invoke the model
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  invocationParams(_options) {
    return {};
  }
  _modelType() {
    return "base_chat_model";
  }
  /**
   * @deprecated
   * Return a json-like object representing this LLM.
   */
  serialize() {
    return {
      ...this.invocationParams(),
      _type: this._llmType(),
      _model: this._modelType()
    };
  }
  /**
   * Generates a prompt based on the input prompt values.
   * @param promptValues An array of BasePromptValue instances.
   * @param options The call options or an array of stop sequences.
   * @param callbacks The callbacks for the language model.
   * @returns A Promise that resolves to an LLMResult.
   */
  async generatePrompt(promptValues, options, callbacks) {
    const promptMessages = promptValues.map((promptValue) => promptValue.toChatMessages());
    return this.generate(promptMessages, options, callbacks);
  }
  /**
   * @deprecated Use .invoke() instead. Will be removed in 0.2.0.
   *
   * Makes a single call to the chat model.
   * @param messages An array of BaseMessage instances.
   * @param options The call options or an array of stop sequences.
   * @param callbacks The callbacks for the language model.
   * @returns A Promise that resolves to a BaseMessage.
   */
  async call(messages, options, callbacks) {
    const result = await this.generate([messages.map(coerceMessageLikeToMessage)], options, callbacks);
    const generations = result.generations;
    return generations[0][0].message;
  }
  /**
   * @deprecated Use .invoke() instead. Will be removed in 0.2.0.
   *
   * Makes a single call to the chat model with a prompt value.
   * @param promptValue The value of the prompt.
   * @param options The call options or an array of stop sequences.
   * @param callbacks The callbacks for the language model.
   * @returns A Promise that resolves to a BaseMessage.
   */
  async callPrompt(promptValue, options, callbacks) {
    const promptMessages = promptValue.toChatMessages();
    return this.call(promptMessages, options, callbacks);
  }
  /**
   * @deprecated Use .invoke() instead. Will be removed in 0.2.0.
   *
   * Predicts the next message based on the input messages.
   * @param messages An array of BaseMessage instances.
   * @param options The call options or an array of stop sequences.
   * @param callbacks The callbacks for the language model.
   * @returns A Promise that resolves to a BaseMessage.
   */
  async predictMessages(messages, options, callbacks) {
    return this.call(messages, options, callbacks);
  }
  /**
   * @deprecated Use .invoke() instead. Will be removed in 0.2.0.
   *
   * Predicts the next message based on a text input.
   * @param text The text input.
   * @param options The call options or an array of stop sequences.
   * @param callbacks The callbacks for the language model.
   * @returns A Promise that resolves to a string.
   */
  async predict(text, options, callbacks) {
    const message = new HumanMessage(text);
    const result = await this.call([message], options, callbacks);
    if (typeof result.content !== "string") {
      throw new Error("Cannot use predict when output is not a string.");
    }
    return result.content;
  }
  withStructuredOutput(outputSchema, config) {
    if (typeof this.bindTools !== "function") {
      throw new Error(`Chat model must implement ".bindTools()" to use withStructuredOutput.`);
    }
    if (config?.strict) {
      throw new Error(`"strict" mode is not supported for this model by default.`);
    }
    const schema = outputSchema;
    const name = config?.name;
    const description = getSchemaDescription(schema) ?? "A function available to call.";
    const method = config?.method;
    const includeRaw = config?.includeRaw;
    if (method === "jsonMode") {
      throw new Error(`Base withStructuredOutput implementation only supports "functionCalling" as a method.`);
    }
    let functionName = name ?? "extract";
    let tools;
    if (isInteropZodSchema(schema)) {
      tools = [
        {
          type: "function",
          function: {
            name: functionName,
            description,
            parameters: toJsonSchema(schema)
          }
        }
      ];
    } else {
      if ("name" in schema) {
        functionName = schema.name;
      }
      tools = [
        {
          type: "function",
          function: {
            name: functionName,
            description,
            parameters: schema
          }
        }
      ];
    }
    const llm = this.bindTools(tools);
    const outputParser = RunnableLambda.from((input) => {
      if (!input.tool_calls || input.tool_calls.length === 0) {
        throw new Error("No tool calls found in the response.");
      }
      const toolCall = input.tool_calls.find((tc) => tc.name === functionName);
      if (!toolCall) {
        throw new Error(`No tool call found with name ${functionName}.`);
      }
      return toolCall.args;
    });
    if (!includeRaw) {
      return llm.pipe(outputParser).withConfig({
        runName: "StructuredOutput"
      });
    }
    const parserAssign = RunnablePassthrough.assign({
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      parsed: (input, config2) => outputParser.invoke(input.raw, config2)
    });
    const parserNone = RunnablePassthrough.assign({
      parsed: () => null
    });
    const parsedWithFallback = parserAssign.withFallbacks({
      fallbacks: [parserNone]
    });
    return RunnableSequence.from([
      {
        raw: llm
      },
      parsedWithFallback
    ]).withConfig({
      runName: "StructuredOutputRunnable"
    });
  }
};
var SimpleChatModel = class extends BaseChatModel {
  async _generate(messages, options, runManager) {
    const text = await this._call(messages, options, runManager);
    const message = new AIMessage(text);
    if (typeof message.content !== "string") {
      throw new Error("Cannot generate with a simple chat model when output is not a string.");
    }
    return {
      generations: [
        {
          text: message.content,
          message
        }
      ]
    };
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/language_models/llms.js
var llms_exports = {};
__export(llms_exports, {
  BaseLLM: () => BaseLLM,
  LLM: () => LLM
});
init_esm();
var BaseLLM = class _BaseLLM extends BaseLanguageModel {
  constructor({ concurrency, ...rest }) {
    super(concurrency ? { maxConcurrency: concurrency, ...rest } : rest);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain", "llms", this._llmType()]
    });
  }
  /**
   * This method takes an input and options, and returns a string. It
   * converts the input to a prompt value and generates a result based on
   * the prompt.
   * @param input Input for the LLM.
   * @param options Options for the LLM call.
   * @returns A string result based on the prompt.
   */
  async invoke(input, options) {
    const promptValue = _BaseLLM._convertInputToPromptValue(input);
    const result = await this.generatePrompt([promptValue], options, options?.callbacks);
    return result.generations[0][0].text;
  }
  // eslint-disable-next-line require-yield
  async *_streamResponseChunks(_input, _options, _runManager) {
    throw new Error("Not implemented.");
  }
  _separateRunnableConfigFromCallOptionsCompat(options) {
    const [runnableConfig, callOptions] = super._separateRunnableConfigFromCallOptions(options);
    callOptions.signal = runnableConfig.signal;
    return [runnableConfig, callOptions];
  }
  async *_streamIterator(input, options) {
    if (this._streamResponseChunks === _BaseLLM.prototype._streamResponseChunks) {
      yield this.invoke(input, options);
    } else {
      const prompt = _BaseLLM._convertInputToPromptValue(input);
      const [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptionsCompat(options);
      const callbackManager_ = await CallbackManager.configure(runnableConfig.callbacks, this.callbacks, runnableConfig.tags, this.tags, runnableConfig.metadata, this.metadata, { verbose: this.verbose });
      const extra = {
        options: callOptions,
        invocation_params: this?.invocationParams(callOptions),
        batch_size: 1
      };
      const runManagers = await callbackManager_?.handleLLMStart(this.toJSON(), [prompt.toString()], runnableConfig.runId, void 0, extra, void 0, void 0, runnableConfig.runName);
      let generation = new GenerationChunk({
        text: ""
      });
      try {
        for await (const chunk of this._streamResponseChunks(prompt.toString(), callOptions, runManagers?.[0])) {
          if (!generation) {
            generation = chunk;
          } else {
            generation = generation.concat(chunk);
          }
          if (typeof chunk.text === "string") {
            yield chunk.text;
          }
        }
      } catch (err3) {
        await Promise.all((runManagers ?? []).map((runManager) => runManager?.handleLLMError(err3)));
        throw err3;
      }
      await Promise.all((runManagers ?? []).map((runManager) => runManager?.handleLLMEnd({
        generations: [[generation]]
      })));
    }
  }
  /**
   * This method takes prompt values, options, and callbacks, and generates
   * a result based on the prompts.
   * @param promptValues Prompt values for the LLM.
   * @param options Options for the LLM call.
   * @param callbacks Callbacks for the LLM call.
   * @returns An LLMResult based on the prompts.
   */
  async generatePrompt(promptValues, options, callbacks) {
    const prompts = promptValues.map((promptValue) => promptValue.toString());
    return this.generate(prompts, options, callbacks);
  }
  /**
   * Get the parameters used to invoke the model
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  invocationParams(_options) {
    return {};
  }
  _flattenLLMResult(llmResult) {
    const llmResults = [];
    for (let i2 = 0; i2 < llmResult.generations.length; i2 += 1) {
      const genList = llmResult.generations[i2];
      if (i2 === 0) {
        llmResults.push({
          generations: [genList],
          llmOutput: llmResult.llmOutput
        });
      } else {
        const llmOutput = llmResult.llmOutput ? { ...llmResult.llmOutput, tokenUsage: {} } : void 0;
        llmResults.push({
          generations: [genList],
          llmOutput
        });
      }
    }
    return llmResults;
  }
  /** @ignore */
  async _generateUncached(prompts, parsedOptions, handledOptions, startedRunManagers) {
    let runManagers;
    if (startedRunManagers !== void 0 && startedRunManagers.length === prompts.length) {
      runManagers = startedRunManagers;
    } else {
      const callbackManager_ = await CallbackManager.configure(handledOptions.callbacks, this.callbacks, handledOptions.tags, this.tags, handledOptions.metadata, this.metadata, { verbose: this.verbose });
      const extra = {
        options: parsedOptions,
        invocation_params: this?.invocationParams(parsedOptions),
        batch_size: prompts.length
      };
      runManagers = await callbackManager_?.handleLLMStart(this.toJSON(), prompts, handledOptions.runId, void 0, extra, void 0, void 0, handledOptions?.runName);
    }
    const hasStreamingHandler = !!runManagers?.[0].handlers.find(callbackHandlerPrefersStreaming);
    let output;
    if (hasStreamingHandler && prompts.length === 1 && this._streamResponseChunks !== _BaseLLM.prototype._streamResponseChunks) {
      try {
        const stream = await this._streamResponseChunks(prompts[0], parsedOptions, runManagers?.[0]);
        let aggregated;
        for await (const chunk of stream) {
          if (aggregated === void 0) {
            aggregated = chunk;
          } else {
            aggregated = concat(aggregated, chunk);
          }
        }
        if (aggregated === void 0) {
          throw new Error("Received empty response from chat model call.");
        }
        output = { generations: [[aggregated]], llmOutput: {} };
        await runManagers?.[0].handleLLMEnd(output);
      } catch (e2) {
        await runManagers?.[0].handleLLMError(e2);
        throw e2;
      }
    } else {
      try {
        output = await this._generate(prompts, parsedOptions, runManagers?.[0]);
      } catch (err3) {
        await Promise.all((runManagers ?? []).map((runManager) => runManager?.handleLLMError(err3)));
        throw err3;
      }
      const flattenedOutputs = this._flattenLLMResult(output);
      await Promise.all((runManagers ?? []).map((runManager, i2) => runManager?.handleLLMEnd(flattenedOutputs[i2])));
    }
    const runIds = runManagers?.map((manager2) => manager2.runId) || void 0;
    Object.defineProperty(output, RUN_KEY, {
      value: runIds ? { runIds } : void 0,
      configurable: true
    });
    return output;
  }
  async _generateCached({ prompts, cache: cache2, llmStringKey, parsedOptions, handledOptions, runId }) {
    const callbackManager_ = await CallbackManager.configure(handledOptions.callbacks, this.callbacks, handledOptions.tags, this.tags, handledOptions.metadata, this.metadata, { verbose: this.verbose });
    const extra = {
      options: parsedOptions,
      invocation_params: this?.invocationParams(parsedOptions),
      batch_size: prompts.length
    };
    const runManagers = await callbackManager_?.handleLLMStart(this.toJSON(), prompts, runId, void 0, extra, void 0, void 0, handledOptions?.runName);
    const missingPromptIndices = [];
    const results = await Promise.allSettled(prompts.map(async (prompt, index) => {
      const result = await cache2.lookup(prompt, llmStringKey);
      if (result == null) {
        missingPromptIndices.push(index);
      }
      return result;
    }));
    const cachedResults = results.map((result, index) => ({ result, runManager: runManagers?.[index] })).filter(({ result }) => result.status === "fulfilled" && result.value != null || result.status === "rejected");
    const generations = [];
    await Promise.all(cachedResults.map(async ({ result: promiseResult, runManager }, i2) => {
      if (promiseResult.status === "fulfilled") {
        const result = promiseResult.value;
        generations[i2] = result.map((result2) => {
          result2.generationInfo = {
            ...result2.generationInfo,
            tokenUsage: {}
          };
          return result2;
        });
        if (result.length) {
          await runManager?.handleLLMNewToken(result[0].text);
        }
        return runManager?.handleLLMEnd({
          generations: [result]
        }, void 0, void 0, void 0, {
          cached: true
        });
      } else {
        await runManager?.handleLLMError(promiseResult.reason, void 0, void 0, void 0, {
          cached: true
        });
        return Promise.reject(promiseResult.reason);
      }
    }));
    const output = {
      generations,
      missingPromptIndices,
      startedRunManagers: runManagers
    };
    Object.defineProperty(output, RUN_KEY, {
      value: runManagers ? { runIds: runManagers?.map((manager2) => manager2.runId) } : void 0,
      configurable: true
    });
    return output;
  }
  /**
   * Run the LLM on the given prompts and input, handling caching.
   */
  async generate(prompts, options, callbacks) {
    if (!Array.isArray(prompts)) {
      throw new Error("Argument 'prompts' is expected to be a string[]");
    }
    let parsedOptions;
    if (Array.isArray(options)) {
      parsedOptions = { stop: options };
    } else {
      parsedOptions = options;
    }
    const [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptionsCompat(parsedOptions);
    runnableConfig.callbacks = runnableConfig.callbacks ?? callbacks;
    if (!this.cache) {
      return this._generateUncached(prompts, callOptions, runnableConfig);
    }
    const { cache: cache2 } = this;
    const llmStringKey = this._getSerializedCacheKeyParametersForCall(callOptions);
    const { generations, missingPromptIndices, startedRunManagers } = await this._generateCached({
      prompts,
      cache: cache2,
      llmStringKey,
      parsedOptions: callOptions,
      handledOptions: runnableConfig,
      runId: runnableConfig.runId
    });
    let llmOutput = {};
    if (missingPromptIndices.length > 0) {
      const results = await this._generateUncached(missingPromptIndices.map((i2) => prompts[i2]), callOptions, runnableConfig, startedRunManagers !== void 0 ? missingPromptIndices.map((i2) => startedRunManagers?.[i2]) : void 0);
      await Promise.all(results.generations.map(async (generation, index) => {
        const promptIndex = missingPromptIndices[index];
        generations[promptIndex] = generation;
        return cache2.update(prompts[promptIndex], llmStringKey, generation);
      }));
      llmOutput = results.llmOutput ?? {};
    }
    return { generations, llmOutput };
  }
  /**
   * @deprecated Use .invoke() instead. Will be removed in 0.2.0.
   * Convenience wrapper for {@link generate} that takes in a single string prompt and returns a single string output.
   */
  async call(prompt, options, callbacks) {
    const { generations } = await this.generate([prompt], options, callbacks);
    return generations[0][0].text;
  }
  /**
   * @deprecated Use .invoke() instead. Will be removed in 0.2.0.
   *
   * This method is similar to `call`, but it's used for making predictions
   * based on the input text.
   * @param text Input text for the prediction.
   * @param options Options for the LLM call.
   * @param callbacks Callbacks for the LLM call.
   * @returns A prediction based on the input text.
   */
  async predict(text, options, callbacks) {
    return this.call(text, options, callbacks);
  }
  /**
   * @deprecated Use .invoke() instead. Will be removed in 0.2.0.
   *
   * This method takes a list of messages, options, and callbacks, and
   * returns a predicted message.
   * @param messages A list of messages for the prediction.
   * @param options Options for the LLM call.
   * @param callbacks Callbacks for the LLM call.
   * @returns A predicted message based on the list of messages.
   */
  async predictMessages(messages, options, callbacks) {
    const text = getBufferString(messages);
    const prediction = await this.call(text, options, callbacks);
    return new AIMessage(prediction);
  }
  /**
   * Get the identifying parameters of the LLM.
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  _identifyingParams() {
    return {};
  }
  /**
   * @deprecated
   * Return a json-like object representing this LLM.
   */
  serialize() {
    return {
      ...this._identifyingParams(),
      _type: this._llmType(),
      _model: this._modelType()
    };
  }
  _modelType() {
    return "base_llm";
  }
};
var LLM = class extends BaseLLM {
  async _generate(prompts, options, runManager) {
    const generations = await Promise.all(prompts.map((prompt, promptIndex) => this._call(prompt, { ...options, promptIndex }, runManager).then((text) => [{ text }])));
    return { generations };
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/memory.js
var memory_exports = {};
__export(memory_exports, {
  BaseMemory: () => BaseMemory,
  getInputValue: () => getInputValue,
  getOutputValue: () => getOutputValue,
  getPromptInputKey: () => getPromptInputKey
});
init_esm();
var BaseMemory = class {
};
var getValue = (values, key) => {
  if (key !== void 0) {
    return values[key];
  }
  const keys = Object.keys(values);
  if (keys.length === 1) {
    return values[keys[0]];
  }
};
var getInputValue = (inputValues, inputKey) => {
  const value = getValue(inputValues, inputKey);
  if (!value) {
    const keys = Object.keys(inputValues);
    throw new Error(`input values have ${keys.length} keys, you must specify an input key or pass only 1 key as input`);
  }
  return value;
};
var getOutputValue = (outputValues, outputKey) => {
  const value = getValue(outputValues, outputKey);
  if (!value && value !== "") {
    const keys = Object.keys(outputValues);
    throw new Error(`output values have ${keys.length} keys, you must specify an output key or pass only 1 key as output`);
  }
  return value;
};
function getPromptInputKey(inputs, memoryVariables) {
  const promptInputKeys = Object.keys(inputs).filter((key) => !memoryVariables.includes(key) && key !== "stop");
  if (promptInputKeys.length !== 1) {
    throw new Error(`One input key expected, but got ${promptInputKeys.length}`);
  }
  return promptInputKeys[0];
}

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/output_parsers/index.js
var output_parsers_exports = {};
__export(output_parsers_exports, {
  AsymmetricStructuredOutputParser: () => AsymmetricStructuredOutputParser,
  BaseCumulativeTransformOutputParser: () => BaseCumulativeTransformOutputParser,
  BaseLLMOutputParser: () => BaseLLMOutputParser,
  BaseOutputParser: () => BaseOutputParser,
  BaseTransformOutputParser: () => BaseTransformOutputParser,
  BytesOutputParser: () => BytesOutputParser,
  CommaSeparatedListOutputParser: () => CommaSeparatedListOutputParser,
  CustomListOutputParser: () => CustomListOutputParser,
  JsonMarkdownStructuredOutputParser: () => JsonMarkdownStructuredOutputParser,
  JsonOutputParser: () => JsonOutputParser,
  ListOutputParser: () => ListOutputParser,
  MarkdownListOutputParser: () => MarkdownListOutputParser,
  NumberedListOutputParser: () => NumberedListOutputParser,
  OutputParserException: () => OutputParserException,
  StringOutputParser: () => StringOutputParser,
  StructuredOutputParser: () => StructuredOutputParser,
  XMLOutputParser: () => XMLOutputParser,
  XML_FORMAT_INSTRUCTIONS: () => XML_FORMAT_INSTRUCTIONS,
  parseJsonMarkdown: () => parseJsonMarkdown,
  parsePartialJson: () => parsePartialJson,
  parseXMLMarkdown: () => parseXMLMarkdown
});
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/output_parsers/base.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/runnables/index.js
var runnables_exports = {};
__export(runnables_exports, {
  RouterRunnable: () => RouterRunnable,
  Runnable: () => Runnable,
  RunnableAssign: () => RunnableAssign,
  RunnableBinding: () => RunnableBinding,
  RunnableBranch: () => RunnableBranch,
  RunnableEach: () => RunnableEach,
  RunnableLambda: () => RunnableLambda,
  RunnableMap: () => RunnableMap,
  RunnableParallel: () => RunnableParallel,
  RunnablePassthrough: () => RunnablePassthrough,
  RunnablePick: () => RunnablePick,
  RunnableRetry: () => RunnableRetry,
  RunnableSequence: () => RunnableSequence,
  RunnableToolLike: () => RunnableToolLike,
  RunnableWithFallbacks: () => RunnableWithFallbacks,
  RunnableWithMessageHistory: () => RunnableWithMessageHistory,
  _coerceToRunnable: () => _coerceToRunnable,
  ensureConfig: () => ensureConfig,
  getCallbackManagerForConfig: () => getCallbackManagerForConfig,
  mergeConfigs: () => mergeConfigs,
  patchConfig: () => patchConfig,
  pickRunnableConfigKeys: () => pickRunnableConfigKeys
});
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/runnables/router.js
init_esm();
var RouterRunnable = class extends Runnable {
  static lc_name() {
    return "RouterRunnable";
  }
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "runnables"]
    });
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "runnables", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.runnables = fields.runnables;
  }
  async invoke(input, options) {
    const { key, input: actualInput } = input;
    const runnable = this.runnables[key];
    if (runnable === void 0) {
      throw new Error(`No runnable associated with key "${key}".`);
    }
    return runnable.invoke(actualInput, ensureConfig(options));
  }
  async batch(inputs, options, batchOptions) {
    const keys = inputs.map((input) => input.key);
    const actualInputs = inputs.map((input) => input.input);
    const missingKey = keys.find((key) => this.runnables[key] === void 0);
    if (missingKey !== void 0) {
      throw new Error(`One or more keys do not have a corresponding runnable.`);
    }
    const runnables = keys.map((key) => this.runnables[key]);
    const optionsList = this._getOptionsList(options ?? {}, inputs.length);
    const maxConcurrency = optionsList[0]?.maxConcurrency ?? batchOptions?.maxConcurrency;
    const batchSize = maxConcurrency && maxConcurrency > 0 ? maxConcurrency : inputs.length;
    const batchResults = [];
    for (let i2 = 0; i2 < actualInputs.length; i2 += batchSize) {
      const batchPromises = actualInputs.slice(i2, i2 + batchSize).map((actualInput, i3) => runnables[i3].invoke(actualInput, optionsList[i3]));
      const batchResult = await Promise.all(batchPromises);
      batchResults.push(batchResult);
    }
    return batchResults.flat();
  }
  async stream(input, options) {
    const { key, input: actualInput } = input;
    const runnable = this.runnables[key];
    if (runnable === void 0) {
      throw new Error(`No runnable associated with key "${key}".`);
    }
    return runnable.stream(actualInput, options);
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/runnables/branch.js
init_esm();
var RunnableBranch = class extends Runnable {
  static lc_name() {
    return "RunnableBranch";
  }
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "runnables"]
    });
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "default", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "branches", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.branches = fields.branches;
    this.default = fields.default;
  }
  /**
   * Convenience method for instantiating a RunnableBranch from
   * RunnableLikes (objects, functions, or Runnables).
   *
   * Each item in the input except for the last one should be a
   * tuple with two items. The first is a "condition" RunnableLike that
   * returns "true" if the second RunnableLike in the tuple should run.
   *
   * The final item in the input should be a RunnableLike that acts as a
   * default branch if no other branches match.
   *
   * @example
   * ```ts
   * import { RunnableBranch } from "@langchain/core/runnables";
   *
   * const branch = RunnableBranch.from([
   *   [(x: number) => x > 0, (x: number) => x + 1],
   *   [(x: number) => x < 0, (x: number) => x - 1],
   *   (x: number) => x
   * ]);
   * ```
   * @param branches An array where the every item except the last is a tuple of [condition, runnable]
   *   pairs. The last item is a default runnable which is invoked if no other condition matches.
   * @returns A new RunnableBranch.
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  static from(branches) {
    if (branches.length < 1) {
      throw new Error("RunnableBranch requires at least one branch");
    }
    const branchLikes = branches.slice(0, -1);
    const coercedBranches = branchLikes.map(([condition, runnable]) => [
      _coerceToRunnable(condition),
      _coerceToRunnable(runnable)
    ]);
    const defaultBranch = _coerceToRunnable(branches[branches.length - 1]);
    return new this({
      branches: coercedBranches,
      default: defaultBranch
    });
  }
  async _invoke(input, config, runManager) {
    let result;
    for (let i2 = 0; i2 < this.branches.length; i2 += 1) {
      const [condition, branchRunnable] = this.branches[i2];
      const conditionValue = await condition.invoke(input, patchConfig(config, {
        callbacks: runManager?.getChild(`condition:${i2 + 1}`)
      }));
      if (conditionValue) {
        result = await branchRunnable.invoke(input, patchConfig(config, {
          callbacks: runManager?.getChild(`branch:${i2 + 1}`)
        }));
        break;
      }
    }
    if (!result) {
      result = await this.default.invoke(input, patchConfig(config, {
        callbacks: runManager?.getChild("branch:default")
      }));
    }
    return result;
  }
  async invoke(input, config = {}) {
    return this._callWithConfig(this._invoke, input, config);
  }
  async *_streamIterator(input, config) {
    const callbackManager_ = await getCallbackManagerForConfig(config);
    const runManager = await callbackManager_?.handleChainStart(this.toJSON(), _coerceToDict(input, "input"), config?.runId, void 0, void 0, void 0, config?.runName);
    let finalOutput;
    let finalOutputSupported = true;
    let stream;
    try {
      for (let i2 = 0; i2 < this.branches.length; i2 += 1) {
        const [condition, branchRunnable] = this.branches[i2];
        const conditionValue = await condition.invoke(input, patchConfig(config, {
          callbacks: runManager?.getChild(`condition:${i2 + 1}`)
        }));
        if (conditionValue) {
          stream = await branchRunnable.stream(input, patchConfig(config, {
            callbacks: runManager?.getChild(`branch:${i2 + 1}`)
          }));
          for await (const chunk of stream) {
            yield chunk;
            if (finalOutputSupported) {
              if (finalOutput === void 0) {
                finalOutput = chunk;
              } else {
                try {
                  finalOutput = concat(finalOutput, chunk);
                } catch (e2) {
                  finalOutput = void 0;
                  finalOutputSupported = false;
                }
              }
            }
          }
          break;
        }
      }
      if (stream === void 0) {
        stream = await this.default.stream(input, patchConfig(config, {
          callbacks: runManager?.getChild("branch:default")
        }));
        for await (const chunk of stream) {
          yield chunk;
          if (finalOutputSupported) {
            if (finalOutput === void 0) {
              finalOutput = chunk;
            } else {
              try {
                finalOutput = concat(finalOutput, chunk);
              } catch (e2) {
                finalOutput = void 0;
                finalOutputSupported = false;
              }
            }
          }
        }
      }
    } catch (e2) {
      await runManager?.handleChainError(e2);
      throw e2;
    }
    await runManager?.handleChainEnd(finalOutput ?? {});
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/runnables/history.js
init_esm();
var RunnableWithMessageHistory = class extends RunnableBinding {
  constructor(fields) {
    let historyChain = RunnableLambda.from((input, options) => this._enterHistory(input, options ?? {})).withConfig({ runName: "loadHistory" });
    const messagesKey = fields.historyMessagesKey ?? fields.inputMessagesKey;
    if (messagesKey) {
      historyChain = RunnablePassthrough.assign({
        [messagesKey]: historyChain
      }).withConfig({ runName: "insertHistory" });
    }
    const bound = historyChain.pipe(fields.runnable.withListeners({
      onEnd: (run, config2) => this._exitHistory(run, config2 ?? {})
    })).withConfig({ runName: "RunnableWithMessageHistory" });
    const config = fields.config ?? {};
    super({
      ...fields,
      config,
      bound
    });
    Object.defineProperty(this, "runnable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "inputMessagesKey", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "outputMessagesKey", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "historyMessagesKey", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "getMessageHistory", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.runnable = fields.runnable;
    this.getMessageHistory = fields.getMessageHistory;
    this.inputMessagesKey = fields.inputMessagesKey;
    this.outputMessagesKey = fields.outputMessagesKey;
    this.historyMessagesKey = fields.historyMessagesKey;
  }
  _getInputMessages(inputValue) {
    let parsedInputValue;
    if (typeof inputValue === "object" && !Array.isArray(inputValue) && !isBaseMessage(inputValue)) {
      let key;
      if (this.inputMessagesKey) {
        key = this.inputMessagesKey;
      } else if (Object.keys(inputValue).length === 1) {
        key = Object.keys(inputValue)[0];
      } else {
        key = "input";
      }
      if (Array.isArray(inputValue[key]) && Array.isArray(inputValue[key][0])) {
        parsedInputValue = inputValue[key][0];
      } else {
        parsedInputValue = inputValue[key];
      }
    } else {
      parsedInputValue = inputValue;
    }
    if (typeof parsedInputValue === "string") {
      return [new HumanMessage(parsedInputValue)];
    } else if (Array.isArray(parsedInputValue)) {
      return parsedInputValue;
    } else if (isBaseMessage(parsedInputValue)) {
      return [parsedInputValue];
    } else {
      throw new Error(`Expected a string, BaseMessage, or array of BaseMessages.
Got ${JSON.stringify(parsedInputValue, null, 2)}`);
    }
  }
  _getOutputMessages(outputValue) {
    let parsedOutputValue;
    if (!Array.isArray(outputValue) && !isBaseMessage(outputValue) && typeof outputValue !== "string") {
      let key;
      if (this.outputMessagesKey !== void 0) {
        key = this.outputMessagesKey;
      } else if (Object.keys(outputValue).length === 1) {
        key = Object.keys(outputValue)[0];
      } else {
        key = "output";
      }
      if (outputValue.generations !== void 0) {
        parsedOutputValue = outputValue.generations[0][0].message;
      } else {
        parsedOutputValue = outputValue[key];
      }
    } else {
      parsedOutputValue = outputValue;
    }
    if (typeof parsedOutputValue === "string") {
      return [new AIMessage(parsedOutputValue)];
    } else if (Array.isArray(parsedOutputValue)) {
      return parsedOutputValue;
    } else if (isBaseMessage(parsedOutputValue)) {
      return [parsedOutputValue];
    } else {
      throw new Error(`Expected a string, BaseMessage, or array of BaseMessages. Received: ${JSON.stringify(parsedOutputValue, null, 2)}`);
    }
  }
  async _enterHistory(input, kwargs) {
    const history = kwargs?.configurable?.messageHistory;
    const messages = await history.getMessages();
    if (this.historyMessagesKey === void 0) {
      return messages.concat(this._getInputMessages(input));
    }
    return messages;
  }
  async _exitHistory(run, config) {
    const history = config.configurable?.messageHistory;
    let inputs;
    if (Array.isArray(run.inputs) && Array.isArray(run.inputs[0])) {
      inputs = run.inputs[0];
    } else {
      inputs = run.inputs;
    }
    let inputMessages = this._getInputMessages(inputs);
    if (this.historyMessagesKey === void 0) {
      const existingMessages = await history.getMessages();
      inputMessages = inputMessages.slice(existingMessages.length);
    }
    const outputValue = run.outputs;
    if (!outputValue) {
      throw new Error(`Output values from 'Run' undefined. Run: ${JSON.stringify(run, null, 2)}`);
    }
    const outputMessages = this._getOutputMessages(outputValue);
    await history.addMessages([...inputMessages, ...outputMessages]);
  }
  async _mergeConfig(...configs) {
    const config = await super._mergeConfig(...configs);
    if (!config.configurable || !config.configurable.sessionId) {
      const exampleInput = {
        [this.inputMessagesKey ?? "input"]: "foo"
      };
      const exampleConfig = { configurable: { sessionId: "123" } };
      throw new Error(`sessionId is required. Pass it in as part of the config argument to .invoke() or .stream()
eg. chain.invoke(${JSON.stringify(exampleInput)}, ${JSON.stringify(exampleConfig)})`);
    }
    const { sessionId } = config.configurable;
    config.configurable.messageHistory = await this.getMessageHistory(sessionId);
    return config;
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/output_parsers/base.js
var BaseLLMOutputParser = class extends Runnable {
  /**
   * Parses the result of an LLM call with a given prompt. By default, it
   * simply calls `parseResult`.
   * @param generations The generations from an LLM call.
   * @param _prompt The prompt used in the LLM call.
   * @param callbacks Optional callbacks.
   * @returns A promise of the parsed output.
   */
  parseResultWithPrompt(generations, _prompt, callbacks) {
    return this.parseResult(generations, callbacks);
  }
  _baseMessageToString(message) {
    return typeof message.content === "string" ? message.content : this._baseMessageContentToString(message.content);
  }
  _baseMessageContentToString(content) {
    return JSON.stringify(content);
  }
  /**
   * Calls the parser with a given input and optional configuration options.
   * If the input is a string, it creates a generation with the input as
   * text and calls `parseResult`. If the input is a `BaseMessage`, it
   * creates a generation with the input as a message and the content of the
   * input as text, and then calls `parseResult`.
   * @param input The input to the parser, which can be a string or a `BaseMessage`.
   * @param options Optional configuration options.
   * @returns A promise of the parsed output.
   */
  async invoke(input, options) {
    if (typeof input === "string") {
      return this._callWithConfig(async (input2, options2) => this.parseResult([{ text: input2 }], options2?.callbacks), input, { ...options, runType: "parser" });
    } else {
      return this._callWithConfig(async (input2, options2) => this.parseResult([
        {
          message: input2,
          text: this._baseMessageToString(input2)
        }
      ], options2?.callbacks), input, { ...options, runType: "parser" });
    }
  }
};
var BaseOutputParser = class extends BaseLLMOutputParser {
  parseResult(generations, callbacks) {
    return this.parse(generations[0].text, callbacks);
  }
  async parseWithPrompt(text, _prompt, callbacks) {
    return this.parse(text, callbacks);
  }
  /**
   * Return the string type key uniquely identifying this class of parser
   */
  _type() {
    throw new Error("_type not implemented");
  }
};
var OutputParserException = class extends Error {
  constructor(message, llmOutput, observation, sendToLLM = false) {
    super(message);
    Object.defineProperty(this, "llmOutput", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "observation", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "sendToLLM", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.llmOutput = llmOutput;
    this.observation = observation;
    this.sendToLLM = sendToLLM;
    if (sendToLLM) {
      if (observation === void 0 || llmOutput === void 0) {
        throw new Error("Arguments 'observation' & 'llmOutput' are required if 'sendToLlm' is true");
      }
    }
    addLangChainErrorFields(this, "OUTPUT_PARSING_FAILURE");
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/output_parsers/bytes.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/output_parsers/transform.js
init_esm();
var BaseTransformOutputParser = class extends BaseOutputParser {
  async *_transform(inputGenerator) {
    for await (const chunk of inputGenerator) {
      if (typeof chunk === "string") {
        yield this.parseResult([{ text: chunk }]);
      } else {
        yield this.parseResult([
          {
            message: chunk,
            text: this._baseMessageToString(chunk)
          }
        ]);
      }
    }
  }
  /**
   * Transforms an asynchronous generator of input into an asynchronous
   * generator of parsed output.
   * @param inputGenerator An asynchronous generator of input.
   * @param options A configuration object.
   * @returns An asynchronous generator of parsed output.
   */
  async *transform(inputGenerator, options) {
    yield* this._transformStreamWithConfig(inputGenerator, this._transform.bind(this), {
      ...options,
      runType: "parser"
    });
  }
};
var BaseCumulativeTransformOutputParser = class extends BaseTransformOutputParser {
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "diff", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    this.diff = fields?.diff ?? this.diff;
  }
  async *_transform(inputGenerator) {
    let prevParsed;
    let accGen;
    for await (const chunk of inputGenerator) {
      if (typeof chunk !== "string" && typeof chunk.content !== "string") {
        throw new Error("Cannot handle non-string output.");
      }
      let chunkGen;
      if (isBaseMessageChunk(chunk)) {
        if (typeof chunk.content !== "string") {
          throw new Error("Cannot handle non-string message output.");
        }
        chunkGen = new ChatGenerationChunk({
          message: chunk,
          text: chunk.content
        });
      } else if (isBaseMessage(chunk)) {
        if (typeof chunk.content !== "string") {
          throw new Error("Cannot handle non-string message output.");
        }
        chunkGen = new ChatGenerationChunk({
          message: convertToChunk(chunk),
          text: chunk.content
        });
      } else {
        chunkGen = new GenerationChunk({ text: chunk });
      }
      if (accGen === void 0) {
        accGen = chunkGen;
      } else {
        accGen = accGen.concat(chunkGen);
      }
      const parsed = await this.parsePartialResult([accGen]);
      if (parsed !== void 0 && parsed !== null && !deepCompareStrict(parsed, prevParsed)) {
        if (this.diff) {
          yield this._diff(prevParsed, parsed);
        } else {
          yield parsed;
        }
        prevParsed = parsed;
      }
    }
  }
  getFormatInstructions() {
    return "";
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/output_parsers/bytes.js
var BytesOutputParser = class extends BaseTransformOutputParser {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "output_parsers", "bytes"]
    });
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "textEncoder", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: new TextEncoder()
    });
  }
  static lc_name() {
    return "BytesOutputParser";
  }
  parse(text) {
    return Promise.resolve(this.textEncoder.encode(text));
  }
  getFormatInstructions() {
    return "";
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/output_parsers/list.js
init_esm();
var ListOutputParser = class extends BaseTransformOutputParser {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "re", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
  }
  async *_transform(inputGenerator) {
    let buffer = "";
    for await (const input of inputGenerator) {
      if (typeof input === "string") {
        buffer += input;
      } else {
        buffer += input.content;
      }
      if (!this.re) {
        const parts = await this.parse(buffer);
        if (parts.length > 1) {
          for (const part of parts.slice(0, -1)) {
            yield [part];
          }
          buffer = parts[parts.length - 1];
        }
      } else {
        const matches = [...buffer.matchAll(this.re)];
        if (matches.length > 1) {
          let doneIdx = 0;
          for (const match of matches.slice(0, -1)) {
            yield [match[1]];
            doneIdx += (match.index ?? 0) + match[0].length;
          }
          buffer = buffer.slice(doneIdx);
        }
      }
    }
    for (const part of await this.parse(buffer)) {
      yield [part];
    }
  }
};
var CommaSeparatedListOutputParser = class extends ListOutputParser {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "output_parsers", "list"]
    });
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
  }
  static lc_name() {
    return "CommaSeparatedListOutputParser";
  }
  /**
   * Parses the given text into an array of strings, using a comma as the
   * separator. If the parsing fails, throws an OutputParserException.
   * @param text The text to parse.
   * @returns An array of strings obtained by splitting the input text at each comma.
   */
  async parse(text) {
    try {
      return text.trim().split(",").map((s2) => s2.trim());
    } catch (e2) {
      throw new OutputParserException(`Could not parse output: ${text}`, text);
    }
  }
  /**
   * Provides instructions on the expected format of the response for the
   * CommaSeparatedListOutputParser.
   * @returns A string containing instructions on the expected format of the response.
   */
  getFormatInstructions() {
    return `Your response should be a list of comma separated values, eg: \`foo, bar, baz\``;
  }
};
var CustomListOutputParser = class extends ListOutputParser {
  constructor({ length, separator }) {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "output_parsers", "list"]
    });
    Object.defineProperty(this, "length", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "separator", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.length = length;
    this.separator = separator || ",";
  }
  /**
   * Parses the given text into an array of strings, using the specified
   * separator. If the parsing fails or the number of items in the list
   * doesn't match the expected length, throws an OutputParserException.
   * @param text The text to parse.
   * @returns An array of strings obtained by splitting the input text at each occurrence of the specified separator.
   */
  async parse(text) {
    try {
      const items = text.trim().split(this.separator).map((s2) => s2.trim());
      if (this.length !== void 0 && items.length !== this.length) {
        throw new OutputParserException(`Incorrect number of items. Expected ${this.length}, got ${items.length}.`);
      }
      return items;
    } catch (e2) {
      if (Object.getPrototypeOf(e2) === OutputParserException.prototype) {
        throw e2;
      }
      throw new OutputParserException(`Could not parse output: ${text}`);
    }
  }
  /**
   * Provides instructions on the expected format of the response for the
   * CustomListOutputParser, including the number of items and the
   * separator.
   * @returns A string containing instructions on the expected format of the response.
   */
  getFormatInstructions() {
    return `Your response should be a list of ${this.length === void 0 ? "" : `${this.length} `}items separated by "${this.separator}" (eg: \`foo${this.separator} bar${this.separator} baz\`)`;
  }
};
var NumberedListOutputParser = class extends ListOutputParser {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "output_parsers", "list"]
    });
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "re", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: /\d+\.\s([^\n]+)/g
    });
  }
  static lc_name() {
    return "NumberedListOutputParser";
  }
  getFormatInstructions() {
    return `Your response should be a numbered list with each item on a new line. For example: 

1. foo

2. bar

3. baz`;
  }
  async parse(text) {
    return [...text.matchAll(this.re) ?? []].map((m2) => m2[1]);
  }
};
var MarkdownListOutputParser = class extends ListOutputParser {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "output_parsers", "list"]
    });
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "re", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: /^\s*[-*]\s([^\n]+)$/gm
    });
  }
  static lc_name() {
    return "NumberedListOutputParser";
  }
  getFormatInstructions() {
    return `Your response should be a numbered list with each item on a new line. For example: 

1. foo

2. bar

3. baz`;
  }
  async parse(text) {
    return [...text.matchAll(this.re) ?? []].map((m2) => m2[1]);
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/output_parsers/string.js
init_esm();
var StringOutputParser = class extends BaseTransformOutputParser {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "output_parsers", "string"]
    });
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
  }
  static lc_name() {
    return "StrOutputParser";
  }
  /**
   * Parses a string output from an LLM call. This method is meant to be
   * implemented by subclasses to define how a string output from an LLM
   * should be parsed.
   * @param text The string output from an LLM call.
   * @param callbacks Optional callbacks.
   * @returns A promise of the parsed output.
   */
  parse(text) {
    return Promise.resolve(text);
  }
  getFormatInstructions() {
    return "";
  }
  _textContentToString(content) {
    return content.text;
  }
  _imageUrlContentToString(_content) {
    throw new Error(`Cannot coerce a multimodal "image_url" message part into a string.`);
  }
  _messageContentComplexToString(content) {
    switch (content.type) {
      case "text":
      case "text_delta":
        if ("text" in content) {
          return this._textContentToString(content);
        }
        break;
      case "image_url":
        if ("image_url" in content) {
          return this._imageUrlContentToString(content);
        }
        break;
      default:
        throw new Error(`Cannot coerce "${content.type}" message part into a string.`);
    }
    throw new Error(`Invalid content type: ${content.type}`);
  }
  _baseMessageContentToString(content) {
    return content.reduce((acc, item) => acc + this._messageContentComplexToString(item), "");
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/output_parsers/structured.js
init_esm();
var StructuredOutputParser = class extends BaseOutputParser {
  static lc_name() {
    return "StructuredOutputParser";
  }
  toJSON() {
    return this.toJSONNotImplemented();
  }
  constructor(schema) {
    super(schema);
    Object.defineProperty(this, "schema", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: schema
    });
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain", "output_parsers", "structured"]
    });
  }
  /**
   * Creates a new StructuredOutputParser from a Zod schema.
   * @param schema The Zod schema which the output should match
   * @returns A new instance of StructuredOutputParser.
   */
  static fromZodSchema(schema) {
    return new this(schema);
  }
  /**
   * Creates a new StructuredOutputParser from a set of names and
   * descriptions.
   * @param schemas An object where each key is a name and each value is a description
   * @returns A new instance of StructuredOutputParser.
   */
  static fromNamesAndDescriptions(schemas) {
    const zodSchema = external_exports.object(Object.fromEntries(Object.entries(schemas).map(([name, description]) => [name, external_exports.string().describe(description)])));
    return new this(zodSchema);
  }
  /**
   * Returns a markdown code snippet with a JSON object formatted according
   * to the schema.
   * @param options Optional. The options for formatting the instructions
   * @returns A markdown code snippet with a JSON object formatted according to the schema.
   */
  getFormatInstructions() {
    return `You must format your output as a JSON value that adheres to a given "JSON Schema" instance.

"JSON Schema" is a declarative language that allows you to annotate and validate JSON documents.

For example, the example "JSON Schema" instance {{"properties": {{"foo": {{"description": "a list of test words", "type": "array", "items": {{"type": "string"}}}}}}, "required": ["foo"]}}
would match an object with one required property, "foo". The "type" property specifies "foo" must be an "array", and the "description" property semantically describes it as "a list of test words". The items within "foo" must be strings.
Thus, the object {{"foo": ["bar", "baz"]}} is a well-formatted instance of this example "JSON Schema". The object {{"properties": {{"foo": ["bar", "baz"]}}}} is not well-formatted.

Your output will be parsed and type-checked according to the provided schema instance, so make sure all fields in your output match the schema exactly and there are no trailing commas!

Here is the JSON Schema instance your output must adhere to. Include the enclosing markdown codeblock:
\`\`\`json
${JSON.stringify(toJsonSchema(this.schema))}
\`\`\`
`;
  }
  /**
   * Parses the given text according to the schema.
   * @param text The text to parse
   * @returns The parsed output.
   */
  async parse(text) {
    try {
      const json = text.includes("```") ? text.trim().split(/```(?:json)?/)[1] : text.trim();
      const escapedJson = json.replace(/"([^"\\]*(\\.[^"\\]*)*)"/g, (_match, capturedGroup) => {
        const escapedInsideQuotes = capturedGroup.replace(/\n/g, "\\n");
        return `"${escapedInsideQuotes}"`;
      }).replace(/\n/g, "");
      return await interopParseAsync(this.schema, JSON.parse(escapedJson));
    } catch (e2) {
      throw new OutputParserException(`Failed to parse. Text: "${text}". Error: ${e2}`, text);
    }
  }
};
var JsonMarkdownStructuredOutputParser = class extends StructuredOutputParser {
  static lc_name() {
    return "JsonMarkdownStructuredOutputParser";
  }
  getFormatInstructions(options) {
    const interpolationDepth = options?.interpolationDepth ?? 1;
    if (interpolationDepth < 1) {
      throw new Error("f string interpolation depth must be at least 1");
    }
    return `Return a markdown code snippet with a JSON object formatted to look like:
\`\`\`json
${this._schemaToInstruction(toJsonSchema(this.schema)).replaceAll("{", "{".repeat(interpolationDepth)).replaceAll("}", "}".repeat(interpolationDepth))}
\`\`\``;
  }
  _schemaToInstruction(schemaInput, indent = 2) {
    const schema = schemaInput;
    if ("type" in schema) {
      let nullable2 = false;
      let type;
      if (Array.isArray(schema.type)) {
        const nullIdx = schema.type.findIndex((type2) => type2 === "null");
        if (nullIdx !== -1) {
          nullable2 = true;
          schema.type.splice(nullIdx, 1);
        }
        type = schema.type.join(" | ");
      } else {
        type = schema.type;
      }
      if (schema.type === "object" && schema.properties) {
        const description2 = schema.description ? ` // ${schema.description}` : "";
        const properties = Object.entries(schema.properties).map(([key, value]) => {
          const isOptional = schema.required?.includes(key) ? "" : " (optional)";
          return `${" ".repeat(indent)}"${key}": ${this._schemaToInstruction(value, indent + 2)}${isOptional}`;
        }).join("\n");
        return `{
${properties}
${" ".repeat(indent - 2)}}${description2}`;
      }
      if (schema.type === "array" && schema.items) {
        const description2 = schema.description ? ` // ${schema.description}` : "";
        return `array[
${" ".repeat(indent)}${this._schemaToInstruction(schema.items, indent + 2)}
${" ".repeat(indent - 2)}] ${description2}`;
      }
      const isNullable = nullable2 ? " (nullable)" : "";
      const description = schema.description ? ` // ${schema.description}` : "";
      return `${type}${description}${isNullable}`;
    }
    if ("anyOf" in schema) {
      return schema.anyOf.map((s2) => this._schemaToInstruction(s2, indent)).join(`
${" ".repeat(indent - 2)}`);
    }
    throw new Error("unsupported schema type");
  }
  static fromZodSchema(schema) {
    return new this(schema);
  }
  static fromNamesAndDescriptions(schemas) {
    const zodSchema = external_exports.object(Object.fromEntries(Object.entries(schemas).map(([name, description]) => [name, external_exports.string().describe(description)])));
    return new this(zodSchema);
  }
};
var AsymmetricStructuredOutputParser = class extends BaseOutputParser {
  constructor({ inputSchema }) {
    super(...arguments);
    Object.defineProperty(this, "structuredInputParser", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.structuredInputParser = new JsonMarkdownStructuredOutputParser(inputSchema);
  }
  async parse(text) {
    let parsedInput;
    try {
      parsedInput = await this.structuredInputParser.parse(text);
    } catch (e2) {
      throw new OutputParserException(`Failed to parse. Text: "${text}". Error: ${e2}`, text);
    }
    return this.outputProcessor(parsedInput);
  }
  getFormatInstructions() {
    return this.structuredInputParser.getFormatInstructions();
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/output_parsers/json.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/utils/json_patch.js
var json_patch_exports = {};
__export(json_patch_exports, {
  applyPatch: () => applyPatch,
  compare: () => compare
});
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/output_parsers/json.js
var JsonOutputParser = class extends BaseCumulativeTransformOutputParser {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "output_parsers"]
    });
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
  }
  static lc_name() {
    return "JsonOutputParser";
  }
  _diff(prev, next) {
    if (!next) {
      return void 0;
    }
    if (!prev) {
      return [{ op: "replace", path: "", value: next }];
    }
    return compare(prev, next);
  }
  // This should actually return Partial<T>, but there's no way
  // to specify emitted chunks as instances separate from the main output type.
  async parsePartialResult(generations) {
    return parseJsonMarkdown(generations[0].text);
  }
  async parse(text) {
    return parseJsonMarkdown(text, JSON.parse);
  }
  getFormatInstructions() {
    return "";
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/output_parsers/xml.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/utils/sax-js/sax.js
init_esm();
var initializeSax = function() {
  const sax2 = {};
  sax2.parser = function(strict, opt) {
    return new SAXParser(strict, opt);
  };
  sax2.SAXParser = SAXParser;
  sax2.SAXStream = SAXStream;
  sax2.createStream = createStream;
  sax2.MAX_BUFFER_LENGTH = 64 * 1024;
  const buffers = [
    "comment",
    "sgmlDecl",
    "textNode",
    "tagName",
    "doctype",
    "procInstName",
    "procInstBody",
    "entity",
    "attribName",
    "attribValue",
    "cdata",
    "script"
  ];
  sax2.EVENTS = [
    "text",
    "processinginstruction",
    "sgmldeclaration",
    "doctype",
    "comment",
    "opentagstart",
    "attribute",
    "opentag",
    "closetag",
    "opencdata",
    "cdata",
    "closecdata",
    "error",
    "end",
    "ready",
    "script",
    "opennamespace",
    "closenamespace"
  ];
  function SAXParser(strict, opt) {
    if (!(this instanceof SAXParser)) {
      return new SAXParser(strict, opt);
    }
    var parser = this;
    clearBuffers(parser);
    parser.q = parser.c = "";
    parser.bufferCheckPosition = sax2.MAX_BUFFER_LENGTH;
    parser.opt = opt || {};
    parser.opt.lowercase = parser.opt.lowercase || parser.opt.lowercasetags;
    parser.looseCase = parser.opt.lowercase ? "toLowerCase" : "toUpperCase";
    parser.tags = [];
    parser.closed = parser.closedRoot = parser.sawRoot = false;
    parser.tag = parser.error = null;
    parser.strict = !!strict;
    parser.noscript = !!(strict || parser.opt.noscript);
    parser.state = S2.BEGIN;
    parser.strictEntities = parser.opt.strictEntities;
    parser.ENTITIES = parser.strictEntities ? Object.create(sax2.XML_ENTITIES) : Object.create(sax2.ENTITIES);
    parser.attribList = [];
    if (parser.opt.xmlns) {
      parser.ns = Object.create(rootNS);
    }
    parser.trackPosition = parser.opt.position !== false;
    if (parser.trackPosition) {
      parser.position = parser.line = parser.column = 0;
    }
    emit(parser, "onready");
  }
  if (!Object.create) {
    Object.create = function(o2) {
      function F() {
      }
      F.prototype = o2;
      var newf = new F();
      return newf;
    };
  }
  if (!Object.keys) {
    Object.keys = function(o2) {
      var a = [];
      for (var i2 in o2)
        if (o2.hasOwnProperty(i2))
          a.push(i2);
      return a;
    };
  }
  function checkBufferLength(parser) {
    var maxAllowed = Math.max(sax2.MAX_BUFFER_LENGTH, 10);
    var maxActual = 0;
    for (var i2 = 0, l = buffers.length; i2 < l; i2++) {
      var len = parser[buffers[i2]].length;
      if (len > maxAllowed) {
        switch (buffers[i2]) {
          case "textNode":
            closeText(parser);
            break;
          case "cdata":
            emitNode(parser, "oncdata", parser.cdata);
            parser.cdata = "";
            break;
          case "script":
            emitNode(parser, "onscript", parser.script);
            parser.script = "";
            break;
          default:
            error(parser, "Max buffer length exceeded: " + buffers[i2]);
        }
      }
      maxActual = Math.max(maxActual, len);
    }
    var m2 = sax2.MAX_BUFFER_LENGTH - maxActual;
    parser.bufferCheckPosition = m2 + parser.position;
  }
  function clearBuffers(parser) {
    for (var i2 = 0, l = buffers.length; i2 < l; i2++) {
      parser[buffers[i2]] = "";
    }
  }
  function flushBuffers(parser) {
    closeText(parser);
    if (parser.cdata !== "") {
      emitNode(parser, "oncdata", parser.cdata);
      parser.cdata = "";
    }
    if (parser.script !== "") {
      emitNode(parser, "onscript", parser.script);
      parser.script = "";
    }
  }
  SAXParser.prototype = {
    end: function() {
      end(this);
    },
    write,
    resume: function() {
      this.error = null;
      return this;
    },
    close: function() {
      return this.write(null);
    },
    flush: function() {
      flushBuffers(this);
    }
  };
  var Stream = ReadableStream;
  if (!Stream)
    Stream = function() {
    };
  var streamWraps = sax2.EVENTS.filter(function(ev) {
    return ev !== "error" && ev !== "end";
  });
  function createStream(strict, opt) {
    return new SAXStream(strict, opt);
  }
  function SAXStream(strict, opt) {
    if (!(this instanceof SAXStream)) {
      return new SAXStream(strict, opt);
    }
    Stream.apply(this);
    this._parser = new SAXParser(strict, opt);
    this.writable = true;
    this.readable = true;
    var me = this;
    this._parser.onend = function() {
      me.emit("end");
    };
    this._parser.onerror = function(er) {
      me.emit("error", er);
      me._parser.error = null;
    };
    this._decoder = null;
    streamWraps.forEach(function(ev) {
      Object.defineProperty(me, "on" + ev, {
        get: function() {
          return me._parser["on" + ev];
        },
        set: function(h2) {
          if (!h2) {
            me.removeAllListeners(ev);
            me._parser["on" + ev] = h2;
            return h2;
          }
          me.on(ev, h2);
        },
        enumerable: true,
        configurable: false
      });
    });
  }
  SAXStream.prototype = Object.create(Stream.prototype, {
    constructor: {
      value: SAXStream
    }
  });
  SAXStream.prototype.write = function(data) {
    this._parser.write(data.toString());
    this.emit("data", data);
    return true;
  };
  SAXStream.prototype.end = function(chunk) {
    if (chunk && chunk.length) {
      this.write(chunk);
    }
    this._parser.end();
    return true;
  };
  SAXStream.prototype.on = function(ev, handler) {
    var me = this;
    if (!me._parser["on" + ev] && streamWraps.indexOf(ev) !== -1) {
      me._parser["on" + ev] = function() {
        var args = arguments.length === 1 ? [arguments[0]] : Array.apply(null, arguments);
        args.splice(0, 0, ev);
        me.emit.apply(me, args);
      };
    }
    return Stream.prototype.on.call(me, ev, handler);
  };
  var CDATA = "[CDATA[";
  var DOCTYPE = "DOCTYPE";
  var XML_NAMESPACE = "http://www.w3.org/XML/1998/namespace";
  var XMLNS_NAMESPACE = "http://www.w3.org/2000/xmlns/";
  var rootNS = { xml: XML_NAMESPACE, xmlns: XMLNS_NAMESPACE };
  var nameStart = /[:_A-Za-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD]/;
  var nameBody = /[:_A-Za-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD\u00B7\u0300-\u036F\u203F-\u2040.\d-]/;
  var entityStart = /[#:_A-Za-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD]/;
  var entityBody = /[#:_A-Za-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD\u00B7\u0300-\u036F\u203F-\u2040.\d-]/;
  function isWhitespace(c2) {
    return c2 === " " || c2 === "\n" || c2 === "\r" || c2 === "	";
  }
  function isQuote(c2) {
    return c2 === '"' || c2 === "'";
  }
  function isAttribEnd(c2) {
    return c2 === ">" || isWhitespace(c2);
  }
  function isMatch(regex2, c2) {
    return regex2.test(c2);
  }
  function notMatch(regex2, c2) {
    return !isMatch(regex2, c2);
  }
  var S2 = 0;
  sax2.STATE = {
    BEGIN: S2++,
    // leading byte order mark or whitespace
    BEGIN_WHITESPACE: S2++,
    // leading whitespace
    TEXT: S2++,
    // general stuff
    TEXT_ENTITY: S2++,
    // &amp and such.
    OPEN_WAKA: S2++,
    // <
    SGML_DECL: S2++,
    // <!BLARG
    SGML_DECL_QUOTED: S2++,
    // <!BLARG foo "bar
    DOCTYPE: S2++,
    // <!DOCTYPE
    DOCTYPE_QUOTED: S2++,
    // <!DOCTYPE "//blah
    DOCTYPE_DTD: S2++,
    // <!DOCTYPE "//blah" [ ...
    DOCTYPE_DTD_QUOTED: S2++,
    // <!DOCTYPE "//blah" [ "foo
    COMMENT_STARTING: S2++,
    // <!-
    COMMENT: S2++,
    // <!--
    COMMENT_ENDING: S2++,
    // <!-- blah -
    COMMENT_ENDED: S2++,
    // <!-- blah --
    CDATA: S2++,
    // <![CDATA[ something
    CDATA_ENDING: S2++,
    // ]
    CDATA_ENDING_2: S2++,
    // ]]
    PROC_INST: S2++,
    // <?hi
    PROC_INST_BODY: S2++,
    // <?hi there
    PROC_INST_ENDING: S2++,
    // <?hi "there" ?
    OPEN_TAG: S2++,
    // <strong
    OPEN_TAG_SLASH: S2++,
    // <strong /
    ATTRIB: S2++,
    // <a
    ATTRIB_NAME: S2++,
    // <a foo
    ATTRIB_NAME_SAW_WHITE: S2++,
    // <a foo _
    ATTRIB_VALUE: S2++,
    // <a foo=
    ATTRIB_VALUE_QUOTED: S2++,
    // <a foo="bar
    ATTRIB_VALUE_CLOSED: S2++,
    // <a foo="bar"
    ATTRIB_VALUE_UNQUOTED: S2++,
    // <a foo=bar
    ATTRIB_VALUE_ENTITY_Q: S2++,
    // <foo bar="&quot;"
    ATTRIB_VALUE_ENTITY_U: S2++,
    // <foo bar=&quot
    CLOSE_TAG: S2++,
    // </a
    CLOSE_TAG_SAW_WHITE: S2++,
    // </a   >
    SCRIPT: S2++,
    // <script> ...
    SCRIPT_ENDING: S2++
    // <script> ... <
  };
  sax2.XML_ENTITIES = {
    amp: "&",
    gt: ">",
    lt: "<",
    quot: '"',
    apos: "'"
  };
  sax2.ENTITIES = {
    amp: "&",
    gt: ">",
    lt: "<",
    quot: '"',
    apos: "'",
    AElig: 198,
    Aacute: 193,
    Acirc: 194,
    Agrave: 192,
    Aring: 197,
    Atilde: 195,
    Auml: 196,
    Ccedil: 199,
    ETH: 208,
    Eacute: 201,
    Ecirc: 202,
    Egrave: 200,
    Euml: 203,
    Iacute: 205,
    Icirc: 206,
    Igrave: 204,
    Iuml: 207,
    Ntilde: 209,
    Oacute: 211,
    Ocirc: 212,
    Ograve: 210,
    Oslash: 216,
    Otilde: 213,
    Ouml: 214,
    THORN: 222,
    Uacute: 218,
    Ucirc: 219,
    Ugrave: 217,
    Uuml: 220,
    Yacute: 221,
    aacute: 225,
    acirc: 226,
    aelig: 230,
    agrave: 224,
    aring: 229,
    atilde: 227,
    auml: 228,
    ccedil: 231,
    eacute: 233,
    ecirc: 234,
    egrave: 232,
    eth: 240,
    euml: 235,
    iacute: 237,
    icirc: 238,
    igrave: 236,
    iuml: 239,
    ntilde: 241,
    oacute: 243,
    ocirc: 244,
    ograve: 242,
    oslash: 248,
    otilde: 245,
    ouml: 246,
    szlig: 223,
    thorn: 254,
    uacute: 250,
    ucirc: 251,
    ugrave: 249,
    uuml: 252,
    yacute: 253,
    yuml: 255,
    copy: 169,
    reg: 174,
    nbsp: 160,
    iexcl: 161,
    cent: 162,
    pound: 163,
    curren: 164,
    yen: 165,
    brvbar: 166,
    sect: 167,
    uml: 168,
    ordf: 170,
    laquo: 171,
    not: 172,
    shy: 173,
    macr: 175,
    deg: 176,
    plusmn: 177,
    sup1: 185,
    sup2: 178,
    sup3: 179,
    acute: 180,
    micro: 181,
    para: 182,
    middot: 183,
    cedil: 184,
    ordm: 186,
    raquo: 187,
    frac14: 188,
    frac12: 189,
    frac34: 190,
    iquest: 191,
    times: 215,
    divide: 247,
    OElig: 338,
    oelig: 339,
    Scaron: 352,
    scaron: 353,
    Yuml: 376,
    fnof: 402,
    circ: 710,
    tilde: 732,
    Alpha: 913,
    Beta: 914,
    Gamma: 915,
    Delta: 916,
    Epsilon: 917,
    Zeta: 918,
    Eta: 919,
    Theta: 920,
    Iota: 921,
    Kappa: 922,
    Lambda: 923,
    Mu: 924,
    Nu: 925,
    Xi: 926,
    Omicron: 927,
    Pi: 928,
    Rho: 929,
    Sigma: 931,
    Tau: 932,
    Upsilon: 933,
    Phi: 934,
    Chi: 935,
    Psi: 936,
    Omega: 937,
    alpha: 945,
    beta: 946,
    gamma: 947,
    delta: 948,
    epsilon: 949,
    zeta: 950,
    eta: 951,
    theta: 952,
    iota: 953,
    kappa: 954,
    lambda: 955,
    mu: 956,
    nu: 957,
    xi: 958,
    omicron: 959,
    pi: 960,
    rho: 961,
    sigmaf: 962,
    sigma: 963,
    tau: 964,
    upsilon: 965,
    phi: 966,
    chi: 967,
    psi: 968,
    omega: 969,
    thetasym: 977,
    upsih: 978,
    piv: 982,
    ensp: 8194,
    emsp: 8195,
    thinsp: 8201,
    zwnj: 8204,
    zwj: 8205,
    lrm: 8206,
    rlm: 8207,
    ndash: 8211,
    mdash: 8212,
    lsquo: 8216,
    rsquo: 8217,
    sbquo: 8218,
    ldquo: 8220,
    rdquo: 8221,
    bdquo: 8222,
    dagger: 8224,
    Dagger: 8225,
    bull: 8226,
    hellip: 8230,
    permil: 8240,
    prime: 8242,
    Prime: 8243,
    lsaquo: 8249,
    rsaquo: 8250,
    oline: 8254,
    frasl: 8260,
    euro: 8364,
    image: 8465,
    weierp: 8472,
    real: 8476,
    trade: 8482,
    alefsym: 8501,
    larr: 8592,
    uarr: 8593,
    rarr: 8594,
    darr: 8595,
    harr: 8596,
    crarr: 8629,
    lArr: 8656,
    uArr: 8657,
    rArr: 8658,
    dArr: 8659,
    hArr: 8660,
    forall: 8704,
    part: 8706,
    exist: 8707,
    empty: 8709,
    nabla: 8711,
    isin: 8712,
    notin: 8713,
    ni: 8715,
    prod: 8719,
    sum: 8721,
    minus: 8722,
    lowast: 8727,
    radic: 8730,
    prop: 8733,
    infin: 8734,
    ang: 8736,
    and: 8743,
    or: 8744,
    cap: 8745,
    cup: 8746,
    int: 8747,
    there4: 8756,
    sim: 8764,
    cong: 8773,
    asymp: 8776,
    ne: 8800,
    equiv: 8801,
    le: 8804,
    ge: 8805,
    sub: 8834,
    sup: 8835,
    nsub: 8836,
    sube: 8838,
    supe: 8839,
    oplus: 8853,
    otimes: 8855,
    perp: 8869,
    sdot: 8901,
    lceil: 8968,
    rceil: 8969,
    lfloor: 8970,
    rfloor: 8971,
    lang: 9001,
    rang: 9002,
    loz: 9674,
    spades: 9824,
    clubs: 9827,
    hearts: 9829,
    diams: 9830
  };
  Object.keys(sax2.ENTITIES).forEach(function(key) {
    var e2 = sax2.ENTITIES[key];
    var s3 = typeof e2 === "number" ? String.fromCharCode(e2) : e2;
    sax2.ENTITIES[key] = s3;
  });
  for (var s2 in sax2.STATE) {
    sax2.STATE[sax2.STATE[s2]] = s2;
  }
  S2 = sax2.STATE;
  function emit(parser, event, data) {
    parser[event] && parser[event](data);
  }
  function emitNode(parser, nodeType, data) {
    if (parser.textNode)
      closeText(parser);
    emit(parser, nodeType, data);
  }
  function closeText(parser) {
    parser.textNode = textopts(parser.opt, parser.textNode);
    if (parser.textNode)
      emit(parser, "ontext", parser.textNode);
    parser.textNode = "";
  }
  function textopts(opt, text) {
    if (opt.trim)
      text = text.trim();
    if (opt.normalize)
      text = text.replace(/\s+/g, " ");
    return text;
  }
  function error(parser, er) {
    closeText(parser);
    if (parser.trackPosition) {
      er += "\nLine: " + parser.line + "\nColumn: " + parser.column + "\nChar: " + parser.c;
    }
    er = new Error(er);
    parser.error = er;
    emit(parser, "onerror", er);
    return parser;
  }
  function end(parser) {
    if (parser.sawRoot && !parser.closedRoot)
      strictFail(parser, "Unclosed root tag");
    if (parser.state !== S2.BEGIN && parser.state !== S2.BEGIN_WHITESPACE && parser.state !== S2.TEXT) {
      error(parser, "Unexpected end");
    }
    closeText(parser);
    parser.c = "";
    parser.closed = true;
    emit(parser, "onend");
    SAXParser.call(parser, parser.strict, parser.opt);
    return parser;
  }
  function strictFail(parser, message) {
    if (typeof parser !== "object" || !(parser instanceof SAXParser)) {
      throw new Error("bad call to strictFail");
    }
    if (parser.strict) {
      error(parser, message);
    }
  }
  function newTag(parser) {
    if (!parser.strict)
      parser.tagName = parser.tagName[parser.looseCase]();
    var parent = parser.tags[parser.tags.length - 1] || parser;
    var tag = parser.tag = { name: parser.tagName, attributes: {} };
    if (parser.opt.xmlns) {
      tag.ns = parent.ns;
    }
    parser.attribList.length = 0;
    emitNode(parser, "onopentagstart", tag);
  }
  function qname(name, attribute) {
    var i2 = name.indexOf(":");
    var qualName = i2 < 0 ? ["", name] : name.split(":");
    var prefix = qualName[0];
    var local = qualName[1];
    if (attribute && name === "xmlns") {
      prefix = "xmlns";
      local = "";
    }
    return { prefix, local };
  }
  function attrib(parser) {
    if (!parser.strict) {
      parser.attribName = parser.attribName[parser.looseCase]();
    }
    if (parser.attribList.indexOf(parser.attribName) !== -1 || parser.tag.attributes.hasOwnProperty(parser.attribName)) {
      parser.attribName = parser.attribValue = "";
      return;
    }
    if (parser.opt.xmlns) {
      var qn = qname(parser.attribName, true);
      var prefix = qn.prefix;
      var local = qn.local;
      if (prefix === "xmlns") {
        if (local === "xml" && parser.attribValue !== XML_NAMESPACE) {
          strictFail(parser, "xml: prefix must be bound to " + XML_NAMESPACE + "\nActual: " + parser.attribValue);
        } else if (local === "xmlns" && parser.attribValue !== XMLNS_NAMESPACE) {
          strictFail(parser, "xmlns: prefix must be bound to " + XMLNS_NAMESPACE + "\nActual: " + parser.attribValue);
        } else {
          var tag = parser.tag;
          var parent = parser.tags[parser.tags.length - 1] || parser;
          if (tag.ns === parent.ns) {
            tag.ns = Object.create(parent.ns);
          }
          tag.ns[local] = parser.attribValue;
        }
      }
      parser.attribList.push([parser.attribName, parser.attribValue]);
    } else {
      parser.tag.attributes[parser.attribName] = parser.attribValue;
      emitNode(parser, "onattribute", {
        name: parser.attribName,
        value: parser.attribValue
      });
    }
    parser.attribName = parser.attribValue = "";
  }
  function openTag(parser, selfClosing) {
    if (parser.opt.xmlns) {
      var tag = parser.tag;
      var qn = qname(parser.tagName);
      tag.prefix = qn.prefix;
      tag.local = qn.local;
      tag.uri = tag.ns[qn.prefix] || "";
      if (tag.prefix && !tag.uri) {
        strictFail(parser, "Unbound namespace prefix: " + JSON.stringify(parser.tagName));
        tag.uri = qn.prefix;
      }
      var parent = parser.tags[parser.tags.length - 1] || parser;
      if (tag.ns && parent.ns !== tag.ns) {
        Object.keys(tag.ns).forEach(function(p2) {
          emitNode(parser, "onopennamespace", {
            prefix: p2,
            uri: tag.ns[p2]
          });
        });
      }
      for (var i2 = 0, l = parser.attribList.length; i2 < l; i2++) {
        var nv = parser.attribList[i2];
        var name = nv[0];
        var value = nv[1];
        var qualName = qname(name, true);
        var prefix = qualName.prefix;
        var local = qualName.local;
        var uri = prefix === "" ? "" : tag.ns[prefix] || "";
        var a = {
          name,
          value,
          prefix,
          local,
          uri
        };
        if (prefix && prefix !== "xmlns" && !uri) {
          strictFail(parser, "Unbound namespace prefix: " + JSON.stringify(prefix));
          a.uri = prefix;
        }
        parser.tag.attributes[name] = a;
        emitNode(parser, "onattribute", a);
      }
      parser.attribList.length = 0;
    }
    parser.tag.isSelfClosing = !!selfClosing;
    parser.sawRoot = true;
    parser.tags.push(parser.tag);
    emitNode(parser, "onopentag", parser.tag);
    if (!selfClosing) {
      if (!parser.noscript && parser.tagName.toLowerCase() === "script") {
        parser.state = S2.SCRIPT;
      } else {
        parser.state = S2.TEXT;
      }
      parser.tag = null;
      parser.tagName = "";
    }
    parser.attribName = parser.attribValue = "";
    parser.attribList.length = 0;
  }
  function closeTag(parser) {
    if (!parser.tagName) {
      strictFail(parser, "Weird empty close tag.");
      parser.textNode += "</>";
      parser.state = S2.TEXT;
      return;
    }
    if (parser.script) {
      if (parser.tagName !== "script") {
        parser.script += "</" + parser.tagName + ">";
        parser.tagName = "";
        parser.state = S2.SCRIPT;
        return;
      }
      emitNode(parser, "onscript", parser.script);
      parser.script = "";
    }
    var t2 = parser.tags.length;
    var tagName = parser.tagName;
    if (!parser.strict) {
      tagName = tagName[parser.looseCase]();
    }
    var closeTo = tagName;
    while (t2--) {
      var close = parser.tags[t2];
      if (close.name !== closeTo) {
        strictFail(parser, "Unexpected close tag");
      } else {
        break;
      }
    }
    if (t2 < 0) {
      strictFail(parser, "Unmatched closing tag: " + parser.tagName);
      parser.textNode += "</" + parser.tagName + ">";
      parser.state = S2.TEXT;
      return;
    }
    parser.tagName = tagName;
    var s3 = parser.tags.length;
    while (s3-- > t2) {
      var tag = parser.tag = parser.tags.pop();
      parser.tagName = parser.tag.name;
      emitNode(parser, "onclosetag", parser.tagName);
      var x2 = {};
      for (var i2 in tag.ns) {
        x2[i2] = tag.ns[i2];
      }
      var parent = parser.tags[parser.tags.length - 1] || parser;
      if (parser.opt.xmlns && tag.ns !== parent.ns) {
        Object.keys(tag.ns).forEach(function(p2) {
          var n2 = tag.ns[p2];
          emitNode(parser, "onclosenamespace", { prefix: p2, uri: n2 });
        });
      }
    }
    if (t2 === 0)
      parser.closedRoot = true;
    parser.tagName = parser.attribValue = parser.attribName = "";
    parser.attribList.length = 0;
    parser.state = S2.TEXT;
  }
  function parseEntity(parser) {
    var entity = parser.entity;
    var entityLC = entity.toLowerCase();
    var num;
    var numStr = "";
    if (parser.ENTITIES[entity]) {
      return parser.ENTITIES[entity];
    }
    if (parser.ENTITIES[entityLC]) {
      return parser.ENTITIES[entityLC];
    }
    entity = entityLC;
    if (entity.charAt(0) === "#") {
      if (entity.charAt(1) === "x") {
        entity = entity.slice(2);
        num = parseInt(entity, 16);
        numStr = num.toString(16);
      } else {
        entity = entity.slice(1);
        num = parseInt(entity, 10);
        numStr = num.toString(10);
      }
    }
    entity = entity.replace(/^0+/, "");
    if (isNaN(num) || numStr.toLowerCase() !== entity) {
      strictFail(parser, "Invalid character entity");
      return "&" + parser.entity + ";";
    }
    return String.fromCodePoint(num);
  }
  function beginWhiteSpace(parser, c2) {
    if (c2 === "<") {
      parser.state = S2.OPEN_WAKA;
      parser.startTagPosition = parser.position;
    } else if (!isWhitespace(c2)) {
      strictFail(parser, "Non-whitespace before first tag.");
      parser.textNode = c2;
      parser.state = S2.TEXT;
    }
  }
  function charAt(chunk, i2) {
    var result = "";
    if (i2 < chunk.length) {
      result = chunk.charAt(i2);
    }
    return result;
  }
  function write(chunk) {
    var parser = this;
    if (this.error) {
      throw this.error;
    }
    if (parser.closed) {
      return error(parser, "Cannot write after close. Assign an onready handler.");
    }
    if (chunk === null) {
      return end(parser);
    }
    if (typeof chunk === "object") {
      chunk = chunk.toString();
    }
    var i2 = 0;
    var c2 = "";
    while (true) {
      c2 = charAt(chunk, i2++);
      parser.c = c2;
      if (!c2) {
        break;
      }
      if (parser.trackPosition) {
        parser.position++;
        if (c2 === "\n") {
          parser.line++;
          parser.column = 0;
        } else {
          parser.column++;
        }
      }
      switch (parser.state) {
        case S2.BEGIN:
          parser.state = S2.BEGIN_WHITESPACE;
          if (c2 === "\uFEFF") {
            continue;
          }
          beginWhiteSpace(parser, c2);
          continue;
        case S2.BEGIN_WHITESPACE:
          beginWhiteSpace(parser, c2);
          continue;
        case S2.TEXT:
          if (parser.sawRoot && !parser.closedRoot) {
            var starti = i2 - 1;
            while (c2 && c2 !== "<" && c2 !== "&") {
              c2 = charAt(chunk, i2++);
              if (c2 && parser.trackPosition) {
                parser.position++;
                if (c2 === "\n") {
                  parser.line++;
                  parser.column = 0;
                } else {
                  parser.column++;
                }
              }
            }
            parser.textNode += chunk.substring(starti, i2 - 1);
          }
          if (c2 === "<" && !(parser.sawRoot && parser.closedRoot && !parser.strict)) {
            parser.state = S2.OPEN_WAKA;
            parser.startTagPosition = parser.position;
          } else {
            if (!isWhitespace(c2) && (!parser.sawRoot || parser.closedRoot)) {
              strictFail(parser, "Text data outside of root node.");
            }
            if (c2 === "&") {
              parser.state = S2.TEXT_ENTITY;
            } else {
              parser.textNode += c2;
            }
          }
          continue;
        case S2.SCRIPT:
          if (c2 === "<") {
            parser.state = S2.SCRIPT_ENDING;
          } else {
            parser.script += c2;
          }
          continue;
        case S2.SCRIPT_ENDING:
          if (c2 === "/") {
            parser.state = S2.CLOSE_TAG;
          } else {
            parser.script += "<" + c2;
            parser.state = S2.SCRIPT;
          }
          continue;
        case S2.OPEN_WAKA:
          if (c2 === "!") {
            parser.state = S2.SGML_DECL;
            parser.sgmlDecl = "";
          } else if (isWhitespace(c2)) {
          } else if (isMatch(nameStart, c2)) {
            parser.state = S2.OPEN_TAG;
            parser.tagName = c2;
          } else if (c2 === "/") {
            parser.state = S2.CLOSE_TAG;
            parser.tagName = "";
          } else if (c2 === "?") {
            parser.state = S2.PROC_INST;
            parser.procInstName = parser.procInstBody = "";
          } else {
            strictFail(parser, "Unencoded <");
            if (parser.startTagPosition + 1 < parser.position) {
              var pad = parser.position - parser.startTagPosition;
              c2 = new Array(pad).join(" ") + c2;
            }
            parser.textNode += "<" + c2;
            parser.state = S2.TEXT;
          }
          continue;
        case S2.SGML_DECL:
          if ((parser.sgmlDecl + c2).toUpperCase() === CDATA) {
            emitNode(parser, "onopencdata");
            parser.state = S2.CDATA;
            parser.sgmlDecl = "";
            parser.cdata = "";
          } else if (parser.sgmlDecl + c2 === "--") {
            parser.state = S2.COMMENT;
            parser.comment = "";
            parser.sgmlDecl = "";
          } else if ((parser.sgmlDecl + c2).toUpperCase() === DOCTYPE) {
            parser.state = S2.DOCTYPE;
            if (parser.doctype || parser.sawRoot) {
              strictFail(parser, "Inappropriately located doctype declaration");
            }
            parser.doctype = "";
            parser.sgmlDecl = "";
          } else if (c2 === ">") {
            emitNode(parser, "onsgmldeclaration", parser.sgmlDecl);
            parser.sgmlDecl = "";
            parser.state = S2.TEXT;
          } else if (isQuote(c2)) {
            parser.state = S2.SGML_DECL_QUOTED;
            parser.sgmlDecl += c2;
          } else {
            parser.sgmlDecl += c2;
          }
          continue;
        case S2.SGML_DECL_QUOTED:
          if (c2 === parser.q) {
            parser.state = S2.SGML_DECL;
            parser.q = "";
          }
          parser.sgmlDecl += c2;
          continue;
        case S2.DOCTYPE:
          if (c2 === ">") {
            parser.state = S2.TEXT;
            emitNode(parser, "ondoctype", parser.doctype);
            parser.doctype = true;
          } else {
            parser.doctype += c2;
            if (c2 === "[") {
              parser.state = S2.DOCTYPE_DTD;
            } else if (isQuote(c2)) {
              parser.state = S2.DOCTYPE_QUOTED;
              parser.q = c2;
            }
          }
          continue;
        case S2.DOCTYPE_QUOTED:
          parser.doctype += c2;
          if (c2 === parser.q) {
            parser.q = "";
            parser.state = S2.DOCTYPE;
          }
          continue;
        case S2.DOCTYPE_DTD:
          parser.doctype += c2;
          if (c2 === "]") {
            parser.state = S2.DOCTYPE;
          } else if (isQuote(c2)) {
            parser.state = S2.DOCTYPE_DTD_QUOTED;
            parser.q = c2;
          }
          continue;
        case S2.DOCTYPE_DTD_QUOTED:
          parser.doctype += c2;
          if (c2 === parser.q) {
            parser.state = S2.DOCTYPE_DTD;
            parser.q = "";
          }
          continue;
        case S2.COMMENT:
          if (c2 === "-") {
            parser.state = S2.COMMENT_ENDING;
          } else {
            parser.comment += c2;
          }
          continue;
        case S2.COMMENT_ENDING:
          if (c2 === "-") {
            parser.state = S2.COMMENT_ENDED;
            parser.comment = textopts(parser.opt, parser.comment);
            if (parser.comment) {
              emitNode(parser, "oncomment", parser.comment);
            }
            parser.comment = "";
          } else {
            parser.comment += "-" + c2;
            parser.state = S2.COMMENT;
          }
          continue;
        case S2.COMMENT_ENDED:
          if (c2 !== ">") {
            strictFail(parser, "Malformed comment");
            parser.comment += "--" + c2;
            parser.state = S2.COMMENT;
          } else {
            parser.state = S2.TEXT;
          }
          continue;
        case S2.CDATA:
          if (c2 === "]") {
            parser.state = S2.CDATA_ENDING;
          } else {
            parser.cdata += c2;
          }
          continue;
        case S2.CDATA_ENDING:
          if (c2 === "]") {
            parser.state = S2.CDATA_ENDING_2;
          } else {
            parser.cdata += "]" + c2;
            parser.state = S2.CDATA;
          }
          continue;
        case S2.CDATA_ENDING_2:
          if (c2 === ">") {
            if (parser.cdata) {
              emitNode(parser, "oncdata", parser.cdata);
            }
            emitNode(parser, "onclosecdata");
            parser.cdata = "";
            parser.state = S2.TEXT;
          } else if (c2 === "]") {
            parser.cdata += "]";
          } else {
            parser.cdata += "]]" + c2;
            parser.state = S2.CDATA;
          }
          continue;
        case S2.PROC_INST:
          if (c2 === "?") {
            parser.state = S2.PROC_INST_ENDING;
          } else if (isWhitespace(c2)) {
            parser.state = S2.PROC_INST_BODY;
          } else {
            parser.procInstName += c2;
          }
          continue;
        case S2.PROC_INST_BODY:
          if (!parser.procInstBody && isWhitespace(c2)) {
            continue;
          } else if (c2 === "?") {
            parser.state = S2.PROC_INST_ENDING;
          } else {
            parser.procInstBody += c2;
          }
          continue;
        case S2.PROC_INST_ENDING:
          if (c2 === ">") {
            emitNode(parser, "onprocessinginstruction", {
              name: parser.procInstName,
              body: parser.procInstBody
            });
            parser.procInstName = parser.procInstBody = "";
            parser.state = S2.TEXT;
          } else {
            parser.procInstBody += "?" + c2;
            parser.state = S2.PROC_INST_BODY;
          }
          continue;
        case S2.OPEN_TAG:
          if (isMatch(nameBody, c2)) {
            parser.tagName += c2;
          } else {
            newTag(parser);
            if (c2 === ">") {
              openTag(parser);
            } else if (c2 === "/") {
              parser.state = S2.OPEN_TAG_SLASH;
            } else {
              if (!isWhitespace(c2)) {
                strictFail(parser, "Invalid character in tag name");
              }
              parser.state = S2.ATTRIB;
            }
          }
          continue;
        case S2.OPEN_TAG_SLASH:
          if (c2 === ">") {
            openTag(parser, true);
            closeTag(parser);
          } else {
            strictFail(parser, "Forward-slash in opening tag not followed by >");
            parser.state = S2.ATTRIB;
          }
          continue;
        case S2.ATTRIB:
          if (isWhitespace(c2)) {
            continue;
          } else if (c2 === ">") {
            openTag(parser);
          } else if (c2 === "/") {
            parser.state = S2.OPEN_TAG_SLASH;
          } else if (isMatch(nameStart, c2)) {
            parser.attribName = c2;
            parser.attribValue = "";
            parser.state = S2.ATTRIB_NAME;
          } else {
            strictFail(parser, "Invalid attribute name");
          }
          continue;
        case S2.ATTRIB_NAME:
          if (c2 === "=") {
            parser.state = S2.ATTRIB_VALUE;
          } else if (c2 === ">") {
            strictFail(parser, "Attribute without value");
            parser.attribValue = parser.attribName;
            attrib(parser);
            openTag(parser);
          } else if (isWhitespace(c2)) {
            parser.state = S2.ATTRIB_NAME_SAW_WHITE;
          } else if (isMatch(nameBody, c2)) {
            parser.attribName += c2;
          } else {
            strictFail(parser, "Invalid attribute name");
          }
          continue;
        case S2.ATTRIB_NAME_SAW_WHITE:
          if (c2 === "=") {
            parser.state = S2.ATTRIB_VALUE;
          } else if (isWhitespace(c2)) {
            continue;
          } else {
            strictFail(parser, "Attribute without value");
            parser.tag.attributes[parser.attribName] = "";
            parser.attribValue = "";
            emitNode(parser, "onattribute", {
              name: parser.attribName,
              value: ""
            });
            parser.attribName = "";
            if (c2 === ">") {
              openTag(parser);
            } else if (isMatch(nameStart, c2)) {
              parser.attribName = c2;
              parser.state = S2.ATTRIB_NAME;
            } else {
              strictFail(parser, "Invalid attribute name");
              parser.state = S2.ATTRIB;
            }
          }
          continue;
        case S2.ATTRIB_VALUE:
          if (isWhitespace(c2)) {
            continue;
          } else if (isQuote(c2)) {
            parser.q = c2;
            parser.state = S2.ATTRIB_VALUE_QUOTED;
          } else {
            strictFail(parser, "Unquoted attribute value");
            parser.state = S2.ATTRIB_VALUE_UNQUOTED;
            parser.attribValue = c2;
          }
          continue;
        case S2.ATTRIB_VALUE_QUOTED:
          if (c2 !== parser.q) {
            if (c2 === "&") {
              parser.state = S2.ATTRIB_VALUE_ENTITY_Q;
            } else {
              parser.attribValue += c2;
            }
            continue;
          }
          attrib(parser);
          parser.q = "";
          parser.state = S2.ATTRIB_VALUE_CLOSED;
          continue;
        case S2.ATTRIB_VALUE_CLOSED:
          if (isWhitespace(c2)) {
            parser.state = S2.ATTRIB;
          } else if (c2 === ">") {
            openTag(parser);
          } else if (c2 === "/") {
            parser.state = S2.OPEN_TAG_SLASH;
          } else if (isMatch(nameStart, c2)) {
            strictFail(parser, "No whitespace between attributes");
            parser.attribName = c2;
            parser.attribValue = "";
            parser.state = S2.ATTRIB_NAME;
          } else {
            strictFail(parser, "Invalid attribute name");
          }
          continue;
        case S2.ATTRIB_VALUE_UNQUOTED:
          if (!isAttribEnd(c2)) {
            if (c2 === "&") {
              parser.state = S2.ATTRIB_VALUE_ENTITY_U;
            } else {
              parser.attribValue += c2;
            }
            continue;
          }
          attrib(parser);
          if (c2 === ">") {
            openTag(parser);
          } else {
            parser.state = S2.ATTRIB;
          }
          continue;
        case S2.CLOSE_TAG:
          if (!parser.tagName) {
            if (isWhitespace(c2)) {
              continue;
            } else if (notMatch(nameStart, c2)) {
              if (parser.script) {
                parser.script += "</" + c2;
                parser.state = S2.SCRIPT;
              } else {
                strictFail(parser, "Invalid tagname in closing tag.");
              }
            } else {
              parser.tagName = c2;
            }
          } else if (c2 === ">") {
            closeTag(parser);
          } else if (isMatch(nameBody, c2)) {
            parser.tagName += c2;
          } else if (parser.script) {
            parser.script += "</" + parser.tagName;
            parser.tagName = "";
            parser.state = S2.SCRIPT;
          } else {
            if (!isWhitespace(c2)) {
              strictFail(parser, "Invalid tagname in closing tag");
            }
            parser.state = S2.CLOSE_TAG_SAW_WHITE;
          }
          continue;
        case S2.CLOSE_TAG_SAW_WHITE:
          if (isWhitespace(c2)) {
            continue;
          }
          if (c2 === ">") {
            closeTag(parser);
          } else {
            strictFail(parser, "Invalid characters in closing tag");
          }
          continue;
        case S2.TEXT_ENTITY:
        case S2.ATTRIB_VALUE_ENTITY_Q:
        case S2.ATTRIB_VALUE_ENTITY_U:
          var returnState;
          var buffer;
          switch (parser.state) {
            case S2.TEXT_ENTITY:
              returnState = S2.TEXT;
              buffer = "textNode";
              break;
            case S2.ATTRIB_VALUE_ENTITY_Q:
              returnState = S2.ATTRIB_VALUE_QUOTED;
              buffer = "attribValue";
              break;
            case S2.ATTRIB_VALUE_ENTITY_U:
              returnState = S2.ATTRIB_VALUE_UNQUOTED;
              buffer = "attribValue";
              break;
          }
          if (c2 === ";") {
            if (parser.opt.unparsedEntities) {
              var parsedEntity = parseEntity(parser);
              parser.entity = "";
              parser.state = returnState;
              parser.write(parsedEntity);
            } else {
              parser[buffer] += parseEntity(parser);
              parser.entity = "";
              parser.state = returnState;
            }
          } else if (isMatch(parser.entity.length ? entityBody : entityStart, c2)) {
            parser.entity += c2;
          } else {
            strictFail(parser, "Invalid character in entity name");
            parser[buffer] += "&" + parser.entity + c2;
            parser.entity = "";
            parser.state = returnState;
          }
          continue;
        default: {
          throw new Error(parser, "Unknown state: " + parser.state);
        }
      }
    }
    if (parser.position >= parser.bufferCheckPosition) {
      checkBufferLength(parser);
    }
    return parser;
  }
  if (!String.fromCodePoint) {
    (function() {
      var stringFromCharCode = String.fromCharCode;
      var floor = Math.floor;
      var fromCodePoint = function() {
        var MAX_SIZE = 16384;
        var codeUnits = [];
        var highSurrogate;
        var lowSurrogate;
        var index = -1;
        var length = arguments.length;
        if (!length) {
          return "";
        }
        var result = "";
        while (++index < length) {
          var codePoint = Number(arguments[index]);
          if (!isFinite(codePoint) || // `NaN`, `+Infinity`, or `-Infinity`
          codePoint < 0 || // not a valid Unicode code point
          codePoint > 1114111 || // not a valid Unicode code point
          floor(codePoint) !== codePoint) {
            throw RangeError("Invalid code point: " + codePoint);
          }
          if (codePoint <= 65535) {
            codeUnits.push(codePoint);
          } else {
            codePoint -= 65536;
            highSurrogate = (codePoint >> 10) + 55296;
            lowSurrogate = codePoint % 1024 + 56320;
            codeUnits.push(highSurrogate, lowSurrogate);
          }
          if (index + 1 === length || codeUnits.length > MAX_SIZE) {
            result += stringFromCharCode.apply(null, codeUnits);
            codeUnits.length = 0;
          }
        }
        return result;
      };
      if (Object.defineProperty) {
        Object.defineProperty(String, "fromCodePoint", {
          value: fromCodePoint,
          configurable: true,
          writable: true
        });
      } else {
        String.fromCodePoint = fromCodePoint;
      }
    })();
  }
  return sax2;
};
var sax = /* @__PURE__ */ initializeSax();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/output_parsers/xml.js
var XML_FORMAT_INSTRUCTIONS = `The output should be formatted as a XML file.
1. Output should conform to the tags below. 
2. If tags are not given, make them on your own.
3. Remember to always open and close all the tags.

As an example, for the tags ["foo", "bar", "baz"]:
1. String "<foo>
   <bar>
      <baz></baz>
   </bar>
</foo>" is a well-formatted instance of the schema. 
2. String "<foo>
   <bar>
   </foo>" is a badly-formatted instance.
3. String "<foo>
   <tag>
   </tag>
</foo>" is a badly-formatted instance.

Here are the output tags:
\`\`\`
{tags}
\`\`\``;
var XMLOutputParser = class extends BaseCumulativeTransformOutputParser {
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "tags", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "output_parsers"]
    });
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    this.tags = fields?.tags;
  }
  static lc_name() {
    return "XMLOutputParser";
  }
  _diff(prev, next) {
    if (!next) {
      return void 0;
    }
    if (!prev) {
      return [{ op: "replace", path: "", value: next }];
    }
    return compare(prev, next);
  }
  async parsePartialResult(generations) {
    return parseXMLMarkdown(generations[0].text);
  }
  async parse(text) {
    return parseXMLMarkdown(text);
  }
  getFormatInstructions() {
    const withTags = !!(this.tags && this.tags.length > 0);
    return withTags ? XML_FORMAT_INSTRUCTIONS.replace("{tags}", this.tags?.join(", ") ?? "") : XML_FORMAT_INSTRUCTIONS;
  }
};
var strip = (text) => text.split("\n").map((line) => line.replace(/^\s+/, "")).join("\n").trim();
var parseParsedResult = (input) => {
  if (Object.keys(input).length === 0) {
    return {};
  }
  const result = {};
  if (input.children.length > 0) {
    result[input.name] = input.children.map(parseParsedResult);
    return result;
  } else {
    result[input.name] = input.text ?? void 0;
    return result;
  }
};
function parseXMLMarkdown(s2) {
  const cleanedString = strip(s2);
  const parser = sax.parser(true);
  let parsedResult = {};
  const elementStack = [];
  parser.onopentag = (node) => {
    const element = {
      name: node.name,
      attributes: node.attributes,
      children: [],
      text: "",
      isSelfClosing: node.isSelfClosing
    };
    if (elementStack.length > 0) {
      const parentElement = elementStack[elementStack.length - 1];
      parentElement.children.push(element);
    } else {
      parsedResult = element;
    }
    if (!node.isSelfClosing) {
      elementStack.push(element);
    }
  };
  parser.onclosetag = () => {
    if (elementStack.length > 0) {
      const lastElement = elementStack.pop();
      if (elementStack.length === 0 && lastElement) {
        parsedResult = lastElement;
      }
    }
  };
  parser.ontext = (text) => {
    if (elementStack.length > 0) {
      const currentElement = elementStack[elementStack.length - 1];
      currentElement.text += text;
    }
  };
  parser.onattribute = (attr) => {
    if (elementStack.length > 0) {
      const currentElement = elementStack[elementStack.length - 1];
      currentElement.attributes[attr.name] = attr.value;
    }
  };
  const match = /```(xml)?(.*)```/s.exec(cleanedString);
  const xmlString = match ? match[2] : cleanedString;
  parser.write(xmlString).close();
  if (parsedResult && parsedResult.name === "?xml") {
    parsedResult = parsedResult.children[0];
  }
  return parseParsedResult(parsedResult);
}

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/prompts/index.js
var prompts_exports = {};
__export(prompts_exports, {
  AIMessagePromptTemplate: () => AIMessagePromptTemplate,
  BaseChatPromptTemplate: () => BaseChatPromptTemplate,
  BaseMessagePromptTemplate: () => BaseMessagePromptTemplate,
  BaseMessageStringPromptTemplate: () => BaseMessageStringPromptTemplate,
  BasePromptTemplate: () => BasePromptTemplate,
  BaseStringPromptTemplate: () => BaseStringPromptTemplate,
  ChatMessagePromptTemplate: () => ChatMessagePromptTemplate,
  ChatPromptTemplate: () => ChatPromptTemplate,
  DEFAULT_FORMATTER_MAPPING: () => DEFAULT_FORMATTER_MAPPING,
  DEFAULT_PARSER_MAPPING: () => DEFAULT_PARSER_MAPPING,
  DictPromptTemplate: () => DictPromptTemplate,
  FewShotChatMessagePromptTemplate: () => FewShotChatMessagePromptTemplate,
  FewShotPromptTemplate: () => FewShotPromptTemplate,
  HumanMessagePromptTemplate: () => HumanMessagePromptTemplate,
  ImagePromptTemplate: () => ImagePromptTemplate,
  MessagesPlaceholder: () => MessagesPlaceholder,
  PipelinePromptTemplate: () => PipelinePromptTemplate,
  PromptTemplate: () => PromptTemplate,
  StructuredPrompt: () => StructuredPrompt,
  SystemMessagePromptTemplate: () => SystemMessagePromptTemplate,
  checkValidTemplate: () => checkValidTemplate,
  interpolateFString: () => interpolateFString,
  interpolateMustache: () => interpolateMustache,
  parseFString: () => parseFString,
  parseMustache: () => parseMustache,
  parseTemplate: () => parseTemplate,
  renderTemplate: () => renderTemplate
});
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/prompts/pipeline.js
init_esm();
var PipelinePromptTemplate = class _PipelinePromptTemplate extends BasePromptTemplate {
  static lc_name() {
    return "PipelinePromptTemplate";
  }
  constructor(input) {
    super({ ...input, inputVariables: [] });
    Object.defineProperty(this, "pipelinePrompts", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "finalPrompt", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.pipelinePrompts = input.pipelinePrompts;
    this.finalPrompt = input.finalPrompt;
    this.inputVariables = this.computeInputValues();
  }
  /**
   * Computes the input values required by the pipeline prompts.
   * @returns Array of input values required by the pipeline prompts.
   */
  computeInputValues() {
    const intermediateValues = this.pipelinePrompts.map((pipelinePrompt) => pipelinePrompt.name);
    const inputValues = this.pipelinePrompts.map((pipelinePrompt) => pipelinePrompt.prompt.inputVariables.filter((inputValue) => !intermediateValues.includes(inputValue))).flat();
    return [...new Set(inputValues)];
  }
  static extractRequiredInputValues(allValues, requiredValueNames) {
    return requiredValueNames.reduce((requiredValues, valueName) => {
      requiredValues[valueName] = allValues[valueName];
      return requiredValues;
    }, {});
  }
  /**
   * Formats the pipeline prompts based on the provided input values.
   * @param values Input values to format the pipeline prompts.
   * @returns Promise that resolves with the formatted input values.
   */
  async formatPipelinePrompts(values) {
    const allValues = await this.mergePartialAndUserVariables(values);
    for (const { name: pipelinePromptName, prompt: pipelinePrompt } of this.pipelinePrompts) {
      const pipelinePromptInputValues = _PipelinePromptTemplate.extractRequiredInputValues(allValues, pipelinePrompt.inputVariables);
      if (pipelinePrompt instanceof ChatPromptTemplate) {
        allValues[pipelinePromptName] = await pipelinePrompt.formatMessages(pipelinePromptInputValues);
      } else {
        allValues[pipelinePromptName] = await pipelinePrompt.format(pipelinePromptInputValues);
      }
    }
    return _PipelinePromptTemplate.extractRequiredInputValues(allValues, this.finalPrompt.inputVariables);
  }
  /**
   * Formats the final prompt value based on the provided input values.
   * @param values Input values to format the final prompt value.
   * @returns Promise that resolves with the formatted final prompt value.
   */
  async formatPromptValue(values) {
    return this.finalPrompt.formatPromptValue(await this.formatPipelinePrompts(values));
  }
  async format(values) {
    return this.finalPrompt.format(await this.formatPipelinePrompts(values));
  }
  /**
   * Handles partial prompts, which are prompts that have been partially
   * filled with input values.
   * @param values Partial input values.
   * @returns Promise that resolves with a new PipelinePromptTemplate instance with updated input variables.
   */
  async partial(values) {
    const promptDict = { ...this };
    promptDict.inputVariables = this.inputVariables.filter((iv) => !(iv in values));
    promptDict.partialVariables = {
      ...this.partialVariables ?? {},
      ...values
    };
    return new _PipelinePromptTemplate(promptDict);
  }
  serialize() {
    throw new Error("Not implemented.");
  }
  _getPromptType() {
    return "pipeline";
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/prompts/serde.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/prompts/structured.js
init_esm();
function isWithStructuredOutput(x2) {
  return typeof x2 === "object" && x2 != null && "withStructuredOutput" in x2 && typeof x2.withStructuredOutput === "function";
}
function isRunnableBinding(x2) {
  return typeof x2 === "object" && x2 != null && "lc_id" in x2 && Array.isArray(x2.lc_id) && x2.lc_id.join("/") === "langchain_core/runnables/RunnableBinding";
}
var StructuredPrompt = class _StructuredPrompt extends ChatPromptTemplate {
  get lc_aliases() {
    return {
      ...super.lc_aliases,
      schema: "schema_"
    };
  }
  constructor(input) {
    super(input);
    Object.defineProperty(this, "schema", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "method", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "prompts", "structured"]
    });
    this.schema = input.schema;
    this.method = input.method;
  }
  pipe(coerceable) {
    if (isWithStructuredOutput(coerceable)) {
      return super.pipe(coerceable.withStructuredOutput(this.schema));
    }
    if (isRunnableBinding(coerceable) && isWithStructuredOutput(coerceable.bound)) {
      return super.pipe(new RunnableBinding({
        bound: coerceable.bound.withStructuredOutput(this.schema, ...this.method ? [{ method: this.method }] : []),
        kwargs: coerceable.kwargs ?? {},
        config: coerceable.config,
        configFactories: coerceable.configFactories
      }));
    }
    throw new Error(`Structured prompts need to be piped to a language model that supports the "withStructuredOutput()" method.`);
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  static fromMessagesAndSchema(promptMessages, schema, method) {
    return _StructuredPrompt.fromMessages(promptMessages, { schema, method });
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/retrievers/index.js
var retrievers_exports = {};
__export(retrievers_exports, {
  BaseRetriever: () => BaseRetriever
});
init_esm();
var BaseRetriever = class extends Runnable {
  /**
   * Constructs a new `BaseRetriever` instance with optional configuration fields.
   *
   * @param fields - Optional input configuration that can include `callbacks`,
   *                 `tags`, `metadata`, and `verbose` settings for custom retriever behavior.
   */
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "callbacks", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "tags", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "metadata", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "verbose", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.callbacks = fields?.callbacks;
    this.tags = fields?.tags ?? [];
    this.metadata = fields?.metadata ?? {};
    this.verbose = fields?.verbose ?? false;
  }
  /**
   * TODO: This should be an abstract method, but we'd like to avoid breaking
   * changes to people currently using subclassed custom retrievers.
   * Change it on next major release.
   */
  /**
   * Placeholder method for retrieving relevant documents based on a query.
   *
   * This method is intended to be implemented by subclasses and will be
   * converted to an abstract method in the next major release. Currently, it
   * throws an error if not implemented, ensuring that custom retrievers define
   * the specific retrieval logic.
   *
   * @param _query - The query string used to search for relevant documents.
   * @param _callbacks - (optional) Callback manager for managing callbacks
   *                     during retrieval.
   * @returns A promise resolving to an array of `DocumentInterface` instances relevant to the query.
   * @throws {Error} Throws an error indicating the method is not implemented.
   */
  _getRelevantDocuments(_query, _callbacks) {
    throw new Error("Not implemented!");
  }
  /**
   * Executes a retrieval operation.
   *
   * @param input - The query string used to search for relevant documents.
   * @param options - (optional) Configuration options for the retrieval run,
   *                  which may include callbacks, tags, and metadata.
   * @returns A promise that resolves to an array of `DocumentInterface` instances
   *          representing the most relevant documents to the query.
   */
  async invoke(input, options) {
    return this.getRelevantDocuments(input, ensureConfig(options));
  }
  /**
   * @deprecated Use .invoke() instead. Will be removed in 0.3.0.
   *
   * Main method used to retrieve relevant documents. It takes a query
   * string and an optional configuration object, and returns a promise that
   * resolves to an array of `Document` objects. This method handles the
   * retrieval process, including starting and ending callbacks, and error
   * handling.
   * @param query The query string to retrieve relevant documents for.
   * @param config Optional configuration object for the retrieval process.
   * @returns A promise that resolves to an array of `Document` objects.
   */
  async getRelevantDocuments(query, config) {
    const parsedConfig = ensureConfig(parseCallbackConfigArg(config));
    const callbackManager_ = await CallbackManager.configure(parsedConfig.callbacks, this.callbacks, parsedConfig.tags, this.tags, parsedConfig.metadata, this.metadata, { verbose: this.verbose });
    const runManager = await callbackManager_?.handleRetrieverStart(this.toJSON(), query, parsedConfig.runId, void 0, void 0, void 0, parsedConfig.runName);
    try {
      const results = await this._getRelevantDocuments(query, runManager);
      await runManager?.handleRetrieverEnd(results);
      return results;
    } catch (error) {
      await runManager?.handleRetrieverError(error);
      throw error;
    }
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/stores.js
var stores_exports = {};
__export(stores_exports, {
  BaseStore: () => BaseStore,
  InMemoryStore: () => InMemoryStore
});
init_esm();
var BaseStore = class extends Serializable {
};
var InMemoryStore = class extends BaseStore {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain", "storage"]
    });
    Object.defineProperty(this, "store", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {}
    });
  }
  /**
   * Retrieves the values associated with the given keys from the store.
   * @param keys Keys to retrieve values for.
   * @returns Array of values associated with the given keys.
   */
  async mget(keys) {
    return keys.map((key) => this.store[key]);
  }
  /**
   * Sets the values for the given keys in the store.
   * @param keyValuePairs Array of key-value pairs to set in the store.
   * @returns Promise that resolves when all key-value pairs have been set.
   */
  async mset(keyValuePairs) {
    for (const [key, value] of keyValuePairs) {
      this.store[key] = value;
    }
  }
  /**
   * Deletes the given keys and their associated values from the store.
   * @param keys Keys to delete from the store.
   * @returns Promise that resolves when all keys have been deleted.
   */
  async mdelete(keys) {
    for (const key of keys) {
      delete this.store[key];
    }
  }
  /**
   * Asynchronous generator that yields keys from the store. If a prefix is
   * provided, it only yields keys that start with the prefix.
   * @param prefix Optional prefix to filter keys.
   * @returns AsyncGenerator that yields keys from the store.
   */
  async *yieldKeys(prefix) {
    const keys = Object.keys(this.store);
    for (const key of keys) {
      if (prefix === void 0 || key.startsWith(prefix)) {
        yield key;
      }
    }
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/tools/index.js
var tools_exports = {};
__export(tools_exports, {
  BaseToolkit: () => BaseToolkit,
  DynamicStructuredTool: () => DynamicStructuredTool,
  DynamicTool: () => DynamicTool,
  StructuredTool: () => StructuredTool,
  Tool: () => Tool,
  ToolInputParsingException: () => ToolInputParsingException,
  isLangChainTool: () => isLangChainTool,
  isRunnableToolLike: () => isRunnableToolLike,
  isStructuredTool: () => isStructuredTool,
  isStructuredToolParams: () => isStructuredToolParams,
  tool: () => tool
});
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/tools/types.js
init_esm();
function isStructuredTool(tool2) {
  return tool2 !== void 0 && Array.isArray(tool2.lc_namespace);
}
function isRunnableToolLike(tool2) {
  return tool2 !== void 0 && Runnable.isRunnable(tool2) && "lc_name" in tool2.constructor && typeof tool2.constructor.lc_name === "function" && tool2.constructor.lc_name() === "RunnableToolLike";
}
function isStructuredToolParams(tool2) {
  return !!tool2 && typeof tool2 === "object" && "name" in tool2 && "schema" in tool2 && // eslint-disable-next-line @typescript-eslint/no-explicit-any
  (isInteropZodSchema(tool2.schema) || tool2.schema != null && typeof tool2.schema === "object" && "type" in tool2.schema && typeof tool2.schema.type === "string" && ["null", "boolean", "object", "array", "number", "string"].includes(tool2.schema.type));
}
function isLangChainTool(tool2) {
  return isStructuredToolParams(tool2) || isRunnableToolLike(tool2) || // eslint-disable-next-line @typescript-eslint/no-explicit-any
  isStructuredTool(tool2);
}

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/tools/index.js
var StructuredTool = class extends BaseLangChain {
  get lc_namespace() {
    return ["langchain", "tools"];
  }
  constructor(fields) {
    super(fields ?? {});
    Object.defineProperty(this, "returnDirect", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    Object.defineProperty(this, "verboseParsingErrors", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    Object.defineProperty(this, "responseFormat", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "content"
    });
    this.verboseParsingErrors = fields?.verboseParsingErrors ?? this.verboseParsingErrors;
    this.responseFormat = fields?.responseFormat ?? this.responseFormat;
  }
  /**
   * Invokes the tool with the provided input and configuration.
   * @param input The input for the tool.
   * @param config Optional configuration for the tool.
   * @returns A Promise that resolves with the tool's output.
   */
  async invoke(input, config) {
    let toolInput;
    let enrichedConfig = ensureConfig(config);
    if (_isToolCall(input)) {
      toolInput = input.args;
      enrichedConfig = {
        ...enrichedConfig,
        toolCall: input
      };
    } else {
      toolInput = input;
    }
    return this.call(toolInput, enrichedConfig);
  }
  /**
   * @deprecated Use .invoke() instead. Will be removed in 0.3.0.
   *
   * Calls the tool with the provided argument, configuration, and tags. It
   * parses the input according to the schema, handles any errors, and
   * manages callbacks.
   * @param arg The input argument for the tool.
   * @param configArg Optional configuration or callbacks for the tool.
   * @param tags Optional tags for the tool.
   * @returns A Promise that resolves with a string.
   */
  async call(arg, configArg, tags) {
    const inputForValidation = _isToolCall(arg) ? arg.args : arg;
    let parsed;
    if (isInteropZodSchema(this.schema)) {
      try {
        parsed = await interopParseAsync(this.schema, inputForValidation);
      } catch (e2) {
        let message = `Received tool input did not match expected schema`;
        if (this.verboseParsingErrors) {
          message = `${message}
Details: ${e2.message}`;
        }
        throw new ToolInputParsingException(message, JSON.stringify(arg));
      }
    } else {
      const result2 = validate(inputForValidation, this.schema);
      if (!result2.valid) {
        let message = `Received tool input did not match expected schema`;
        if (this.verboseParsingErrors) {
          message = `${message}
Details: ${result2.errors.map((e2) => `${e2.keywordLocation}: ${e2.error}`).join("\n")}`;
        }
        throw new ToolInputParsingException(message, JSON.stringify(arg));
      }
      parsed = inputForValidation;
    }
    const config = parseCallbackConfigArg(configArg);
    const callbackManager_ = CallbackManager.configure(config.callbacks, this.callbacks, config.tags || tags, this.tags, config.metadata, this.metadata, { verbose: this.verbose });
    const runManager = await callbackManager_?.handleToolStart(
      this.toJSON(),
      // Log the original raw input arg
      typeof arg === "string" ? arg : JSON.stringify(arg),
      config.runId,
      void 0,
      void 0,
      void 0,
      config.runName
    );
    delete config.runId;
    let result;
    try {
      result = await this._call(parsed, runManager, config);
    } catch (e2) {
      await runManager?.handleToolError(e2);
      throw e2;
    }
    let content;
    let artifact;
    if (this.responseFormat === "content_and_artifact") {
      if (Array.isArray(result) && result.length === 2) {
        [content, artifact] = result;
      } else {
        throw new Error(`Tool response format is "content_and_artifact" but the output was not a two-tuple.
Result: ${JSON.stringify(result)}`);
      }
    } else {
      content = result;
    }
    let toolCallId;
    if (_isToolCall(arg)) {
      toolCallId = arg.id;
    }
    if (!toolCallId && _configHasToolCallId(config)) {
      toolCallId = config.toolCall.id;
    }
    const formattedOutput = _formatToolOutput({
      content,
      artifact,
      toolCallId,
      name: this.name
    });
    await runManager?.handleToolEnd(formattedOutput);
    return formattedOutput;
  }
};
var Tool = class extends StructuredTool {
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "schema", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: external_exports.object({ input: external_exports.string().optional() }).transform((obj) => obj.input)
    });
  }
  /**
   * @deprecated Use .invoke() instead. Will be removed in 0.3.0.
   *
   * Calls the tool with the provided argument and callbacks. It handles
   * string inputs specifically.
   * @param arg The input argument for the tool, which can be a string, undefined, or an input of the tool's schema.
   * @param callbacks Optional callbacks for the tool.
   * @returns A Promise that resolves with a string.
   */
  // Match the base class signature including the generics and conditional return type
  call(arg, callbacks) {
    const structuredArg = typeof arg === "string" || arg == null ? { input: arg } : arg;
    return super.call(structuredArg, callbacks);
  }
};
var DynamicTool = class extends Tool {
  static lc_name() {
    return "DynamicTool";
  }
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "description", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "func", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.name = fields.name;
    this.description = fields.description;
    this.func = fields.func;
    this.returnDirect = fields.returnDirect ?? this.returnDirect;
  }
  /**
   * @deprecated Use .invoke() instead. Will be removed in 0.3.0.
   */
  async call(arg, configArg) {
    const config = parseCallbackConfigArg(configArg);
    if (config.runName === void 0) {
      config.runName = this.name;
    }
    return super.call(arg, config);
  }
  /** @ignore */
  async _call(input, runManager, parentConfig) {
    return this.func(input, runManager, parentConfig);
  }
};
var DynamicStructuredTool = class extends StructuredTool {
  static lc_name() {
    return "DynamicStructuredTool";
  }
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "description", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "func", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "schema", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.name = fields.name;
    this.description = fields.description;
    this.func = fields.func;
    this.returnDirect = fields.returnDirect ?? this.returnDirect;
    this.schema = fields.schema;
  }
  /**
   * @deprecated Use .invoke() instead. Will be removed in 0.3.0.
   */
  // Match the base class signature
  async call(arg, configArg, tags) {
    const config = parseCallbackConfigArg(configArg);
    if (config.runName === void 0) {
      config.runName = this.name;
    }
    return super.call(arg, config, tags);
  }
  _call(arg, runManager, parentConfig) {
    return this.func(arg, runManager, parentConfig);
  }
};
var BaseToolkit = class {
  getTools() {
    return this.tools;
  }
};
function tool(func, fields) {
  const isSimpleStringSchema = isSimpleStringZodSchema(fields.schema);
  const isStringJSONSchema = validatesOnlyStrings(fields.schema);
  if (!fields.schema || isSimpleStringSchema || isStringJSONSchema) {
    return new DynamicTool({
      ...fields,
      description: fields.description ?? fields.schema?.description ?? `${fields.name} tool`,
      func: async (input, runManager, config) => {
        return new Promise((resolve, reject) => {
          const childConfig = patchConfig(config, {
            callbacks: runManager?.getChild()
          });
          void AsyncLocalStorageProviderSingleton.runWithConfig(pickRunnableConfigKeys(childConfig), async () => {
            try {
              resolve(func(input, childConfig));
            } catch (e2) {
              reject(e2);
            }
          });
        });
      }
    });
  }
  const schema = fields.schema;
  const description = fields.description ?? fields.schema.description ?? `${fields.name} tool`;
  return new DynamicStructuredTool({
    ...fields,
    description,
    schema,
    func: async (input, runManager, config) => {
      return new Promise((resolve, reject) => {
        const childConfig = patchConfig(config, {
          callbacks: runManager?.getChild()
        });
        void AsyncLocalStorageProviderSingleton.runWithConfig(pickRunnableConfigKeys(childConfig), async () => {
          try {
            resolve(func(input, childConfig));
          } catch (e2) {
            reject(e2);
          }
        });
      });
    }
  });
}
function _formatToolOutput(params) {
  const { content, artifact, toolCallId } = params;
  if (toolCallId && !isDirectToolOutput(content)) {
    if (typeof content === "string" || Array.isArray(content) && content.every((item) => typeof item === "object")) {
      return new ToolMessage({
        content,
        artifact,
        tool_call_id: toolCallId,
        name: params.name
      });
    } else {
      return new ToolMessage({
        content: _stringify(content),
        artifact,
        tool_call_id: toolCallId,
        name: params.name
      });
    }
  } else {
    return content;
  }
}
function _stringify(content) {
  try {
    return JSON.stringify(content, null, 2) ?? "";
  } catch (_noOp) {
    return `${content}`;
  }
}

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/tracers/initialize.js
var initialize_exports = {};
__export(initialize_exports, {
  getTracingCallbackHandler: () => getTracingCallbackHandler,
  getTracingV2CallbackHandler: () => getTracingV2CallbackHandler
});
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/tracers/tracer_langchain_v1.js
var tracer_langchain_v1_exports = {};
__export(tracer_langchain_v1_exports, {
  LangChainTracerV1: () => LangChainTracerV1
});
init_esm();
var LangChainTracerV1 = class extends BaseTracer {
  constructor() {
    super();
    Object.defineProperty(this, "name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "langchain_tracer"
    });
    Object.defineProperty(this, "endpoint", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: getEnvironmentVariable("LANGCHAIN_ENDPOINT") || "http://localhost:1984"
    });
    Object.defineProperty(this, "headers", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {
        "Content-Type": "application/json"
      }
    });
    Object.defineProperty(this, "session", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    const apiKey = getEnvironmentVariable("LANGCHAIN_API_KEY");
    if (apiKey) {
      this.headers["x-api-key"] = apiKey;
    }
  }
  async newSession(sessionName) {
    const sessionCreate = {
      start_time: Date.now(),
      name: sessionName
    };
    const session = await this.persistSession(sessionCreate);
    this.session = session;
    return session;
  }
  async loadSession(sessionName) {
    const endpoint = `${this.endpoint}/sessions?name=${sessionName}`;
    return this._handleSessionResponse(endpoint);
  }
  async loadDefaultSession() {
    const endpoint = `${this.endpoint}/sessions?name=default`;
    return this._handleSessionResponse(endpoint);
  }
  async convertV2RunToRun(run) {
    const session = this.session ?? await this.loadDefaultSession();
    const serialized = run.serialized;
    let runResult;
    if (run.run_type === "llm") {
      const prompts = run.inputs.prompts ? run.inputs.prompts : run.inputs.messages.map((x2) => getBufferString(x2));
      const llmRun = {
        uuid: run.id,
        start_time: run.start_time,
        end_time: run.end_time,
        execution_order: run.execution_order,
        child_execution_order: run.child_execution_order,
        serialized,
        type: run.run_type,
        session_id: session.id,
        prompts,
        response: run.outputs
      };
      runResult = llmRun;
    } else if (run.run_type === "chain") {
      const child_runs = await Promise.all(run.child_runs.map((child_run) => this.convertV2RunToRun(child_run)));
      const chainRun = {
        uuid: run.id,
        start_time: run.start_time,
        end_time: run.end_time,
        execution_order: run.execution_order,
        child_execution_order: run.child_execution_order,
        serialized,
        type: run.run_type,
        session_id: session.id,
        inputs: run.inputs,
        outputs: run.outputs,
        child_llm_runs: child_runs.filter((child_run) => child_run.type === "llm"),
        child_chain_runs: child_runs.filter((child_run) => child_run.type === "chain"),
        child_tool_runs: child_runs.filter((child_run) => child_run.type === "tool")
      };
      runResult = chainRun;
    } else if (run.run_type === "tool") {
      const child_runs = await Promise.all(run.child_runs.map((child_run) => this.convertV2RunToRun(child_run)));
      const toolRun = {
        uuid: run.id,
        start_time: run.start_time,
        end_time: run.end_time,
        execution_order: run.execution_order,
        child_execution_order: run.child_execution_order,
        serialized,
        type: run.run_type,
        session_id: session.id,
        tool_input: run.inputs.input,
        output: run.outputs?.output,
        action: JSON.stringify(serialized),
        child_llm_runs: child_runs.filter((child_run) => child_run.type === "llm"),
        child_chain_runs: child_runs.filter((child_run) => child_run.type === "chain"),
        child_tool_runs: child_runs.filter((child_run) => child_run.type === "tool")
      };
      runResult = toolRun;
    } else {
      throw new Error(`Unknown run type: ${run.run_type}`);
    }
    return runResult;
  }
  async persistRun(run) {
    let endpoint;
    let v1Run;
    if (run.run_type !== void 0) {
      v1Run = await this.convertV2RunToRun(run);
    } else {
      v1Run = run;
    }
    if (v1Run.type === "llm") {
      endpoint = `${this.endpoint}/llm-runs`;
    } else if (v1Run.type === "chain") {
      endpoint = `${this.endpoint}/chain-runs`;
    } else {
      endpoint = `${this.endpoint}/tool-runs`;
    }
    const response = await fetch(endpoint, {
      method: "POST",
      headers: this.headers,
      body: JSON.stringify(v1Run)
    });
    if (!response.ok) {
      console.error(`Failed to persist run: ${response.status} ${response.statusText}`);
    }
  }
  async persistSession(sessionCreate) {
    const endpoint = `${this.endpoint}/sessions`;
    const response = await fetch(endpoint, {
      method: "POST",
      headers: this.headers,
      body: JSON.stringify(sessionCreate)
    });
    if (!response.ok) {
      console.error(`Failed to persist session: ${response.status} ${response.statusText}, using default session.`);
      return {
        id: 1,
        ...sessionCreate
      };
    }
    return {
      id: (await response.json()).id,
      ...sessionCreate
    };
  }
  async _handleSessionResponse(endpoint) {
    const response = await fetch(endpoint, {
      method: "GET",
      headers: this.headers
    });
    let tracerSession;
    if (!response.ok) {
      console.error(`Failed to load session: ${response.status} ${response.statusText}`);
      tracerSession = {
        id: 1,
        start_time: Date.now()
      };
      this.session = tracerSession;
      return tracerSession;
    }
    const resp = await response.json();
    if (resp.length === 0) {
      tracerSession = {
        id: 1,
        start_time: Date.now()
      };
      this.session = tracerSession;
      return tracerSession;
    }
    [tracerSession] = resp;
    this.session = tracerSession;
    return tracerSession;
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/tracers/initialize.js
async function getTracingCallbackHandler(session) {
  const tracer = new LangChainTracerV1();
  if (session) {
    await tracer.loadSession(session);
  } else {
    await tracer.loadDefaultSession();
  }
  return tracer;
}
async function getTracingV2CallbackHandler() {
  return new LangChainTracer();
}

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/tracers/run_collector.js
var run_collector_exports = {};
__export(run_collector_exports, {
  RunCollectorCallbackHandler: () => RunCollectorCallbackHandler
});
init_esm();
var RunCollectorCallbackHandler = class extends BaseTracer {
  /**
   * Creates a new instance of the RunCollectorCallbackHandler class.
   * @param exampleId The ID of the example.
   */
  constructor({ exampleId } = {}) {
    super({ _awaitHandler: true });
    Object.defineProperty(this, "name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "run_collector"
    });
    Object.defineProperty(this, "exampleId", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "tracedRuns", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.exampleId = exampleId;
    this.tracedRuns = [];
  }
  /**
   * Persists the given run object.
   * @param run The run object to persist.
   */
  async persistRun(run) {
    const run_ = { ...run };
    run_.reference_example_id = this.exampleId;
    this.tracedRuns.push(run_);
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/utils/chunk_array.js
var chunk_array_exports = {};
__export(chunk_array_exports, {
  chunkArray: () => chunkArray
});
init_esm();
var chunkArray = (arr2, chunkSize) => arr2.reduce((chunks, elem, index) => {
  const chunkIndex = Math.floor(index / chunkSize);
  const chunk = chunks[chunkIndex] || [];
  chunks[chunkIndex] = chunk.concat([elem]);
  return chunks;
}, []);

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/utils/function_calling.js
var function_calling_exports = {};
__export(function_calling_exports, {
  convertToOpenAIFunction: () => convertToOpenAIFunction,
  convertToOpenAITool: () => convertToOpenAITool,
  isLangChainTool: () => isLangChainTool,
  isRunnableToolLike: () => isRunnableToolLike,
  isStructuredTool: () => isStructuredTool,
  isStructuredToolParams: () => isStructuredToolParams
});
init_esm();
function convertToOpenAIFunction(tool2, fields) {
  const fieldsCopy = typeof fields === "number" ? void 0 : fields;
  return {
    name: tool2.name,
    description: tool2.description,
    parameters: toJsonSchema(tool2.schema),
    // Do not include the `strict` field if it is `undefined`.
    ...fieldsCopy?.strict !== void 0 ? { strict: fieldsCopy.strict } : {}
  };
}
function convertToOpenAITool(tool2, fields) {
  const fieldsCopy = typeof fields === "number" ? void 0 : fields;
  let toolDef;
  if (isLangChainTool(tool2)) {
    toolDef = {
      type: "function",
      function: convertToOpenAIFunction(tool2)
    };
  } else {
    toolDef = tool2;
  }
  if (fieldsCopy?.strict !== void 0) {
    toolDef.function.strict = fieldsCopy.strict;
  }
  return toolDef;
}

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/utils/math.js
var math_exports = {};
__export(math_exports, {
  cosineSimilarity: () => cosineSimilarity,
  euclideanDistance: () => euclideanDistance,
  innerProduct: () => innerProduct2,
  matrixFunc: () => matrixFunc,
  maximalMarginalRelevance: () => maximalMarginalRelevance,
  normalize: () => normalize
});
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/utils/ml-distance/similarities.js
init_esm();
function cosine(a, b2) {
  let p2 = 0;
  let p22 = 0;
  let q2 = 0;
  for (let i2 = 0; i2 < a.length; i2++) {
    p2 += a[i2] * b2[i2];
    p22 += a[i2] * a[i2];
    q2 += b2[i2] * b2[i2];
  }
  return p2 / (Math.sqrt(p22) * Math.sqrt(q2));
}

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/utils/ml-distance/distances.js
init_esm();
function innerProduct(a, b2) {
  let ans = 0;
  for (let i2 = 0; i2 < a.length; i2++) {
    ans += a[i2] * b2[i2];
  }
  return ans;
}

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/utils/ml-distance-euclidean/euclidean.js
init_esm();
function squaredEuclidean(p2, q) {
  let d2 = 0;
  for (let i2 = 0; i2 < p2.length; i2++) {
    d2 += (p2[i2] - q[i2]) * (p2[i2] - q[i2]);
  }
  return d2;
}
function euclidean(p2, q) {
  return Math.sqrt(squaredEuclidean(p2, q));
}

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/utils/math.js
function matrixFunc(X, Y, func) {
  if (X.length === 0 || X[0].length === 0 || Y.length === 0 || Y[0].length === 0) {
    return [[]];
  }
  if (X[0].length !== Y[0].length) {
    throw new Error(`Number of columns in X and Y must be the same. X has shape ${[
      X.length,
      X[0].length
    ]} and Y has shape ${[Y.length, Y[0].length]}.`);
  }
  return X.map((xVector) => Y.map((yVector) => func(xVector, yVector)).map((similarity) => Number.isNaN(similarity) ? 0 : similarity));
}
function normalize(M, similarity = false) {
  const max = matrixMaxVal(M);
  return M.map((row) => row.map((val) => similarity ? 1 - val / max : val / max));
}
function cosineSimilarity(X, Y) {
  return matrixFunc(X, Y, cosine);
}
function innerProduct2(X, Y) {
  return matrixFunc(X, Y, innerProduct);
}
function euclideanDistance(X, Y) {
  return matrixFunc(X, Y, euclidean);
}
function maximalMarginalRelevance(queryEmbedding, embeddingList, lambda = 0.5, k2 = 4) {
  if (Math.min(k2, embeddingList.length) <= 0) {
    return [];
  }
  const queryEmbeddingExpanded = Array.isArray(queryEmbedding[0]) ? queryEmbedding : [queryEmbedding];
  const similarityToQuery = cosineSimilarity(queryEmbeddingExpanded, embeddingList)[0];
  const mostSimilarEmbeddingIndex = argMax(similarityToQuery).maxIndex;
  const selectedEmbeddings = [embeddingList[mostSimilarEmbeddingIndex]];
  const selectedEmbeddingsIndexes = [mostSimilarEmbeddingIndex];
  while (selectedEmbeddingsIndexes.length < Math.min(k2, embeddingList.length)) {
    let bestScore = -Infinity;
    let bestIndex = -1;
    const similarityToSelected = cosineSimilarity(embeddingList, selectedEmbeddings);
    similarityToQuery.forEach((queryScore, queryScoreIndex) => {
      if (selectedEmbeddingsIndexes.includes(queryScoreIndex)) {
        return;
      }
      const maxSimilarityToSelected = Math.max(...similarityToSelected[queryScoreIndex]);
      const score = lambda * queryScore - (1 - lambda) * maxSimilarityToSelected;
      if (score > bestScore) {
        bestScore = score;
        bestIndex = queryScoreIndex;
      }
    });
    selectedEmbeddings.push(embeddingList[bestIndex]);
    selectedEmbeddingsIndexes.push(bestIndex);
  }
  return selectedEmbeddingsIndexes;
}
function argMax(array2) {
  if (array2.length === 0) {
    return {
      maxIndex: -1,
      maxValue: NaN
    };
  }
  let maxValue = array2[0];
  let maxIndex = 0;
  for (let i2 = 1; i2 < array2.length; i2 += 1) {
    if (array2[i2] > maxValue) {
      maxIndex = i2;
      maxValue = array2[i2];
    }
  }
  return { maxIndex, maxValue };
}
function matrixMaxVal(arrays) {
  return arrays.reduce((acc, array2) => Math.max(acc, argMax(array2).maxValue), 0);
}

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/utils/testing/index.js
var testing_exports = {};
__export(testing_exports, {
  FakeChatMessageHistory: () => FakeChatMessageHistory,
  FakeChatModel: () => FakeChatModel,
  FakeEmbeddings: () => FakeEmbeddings,
  FakeLLM: () => FakeLLM,
  FakeListChatMessageHistory: () => FakeListChatMessageHistory,
  FakeListChatModel: () => FakeListChatModel,
  FakeRetriever: () => FakeRetriever,
  FakeRunnable: () => FakeRunnable,
  FakeSplitIntoListParser: () => FakeSplitIntoListParser,
  FakeStreamingChatModel: () => FakeStreamingChatModel,
  FakeStreamingLLM: () => FakeStreamingLLM,
  FakeTool: () => FakeTool,
  FakeTracer: () => FakeTracer,
  FakeVectorStore: () => FakeVectorStore,
  SingleRunExtractor: () => SingleRunExtractor,
  SyntheticEmbeddings: () => SyntheticEmbeddings
});
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/vectorstores.js
var vectorstores_exports = {};
__export(vectorstores_exports, {
  SaveableVectorStore: () => SaveableVectorStore,
  VectorStore: () => VectorStore,
  VectorStoreRetriever: () => VectorStoreRetriever
});
init_esm();
var VectorStoreRetriever = class extends BaseRetriever {
  static lc_name() {
    return "VectorStoreRetriever";
  }
  get lc_namespace() {
    return ["langchain_core", "vectorstores"];
  }
  /**
   * Returns the type of vector store, as defined by the `vectorStore` instance.
   *
   * @returns {string} The vector store type.
   */
  _vectorstoreType() {
    return this.vectorStore._vectorstoreType();
  }
  /**
   * Initializes a new instance of `VectorStoreRetriever` with the specified configuration.
   *
   * This constructor configures the retriever to interact with a given `VectorStore`
   * and supports different retrieval strategies, including similarity search and maximal
   * marginal relevance (MMR) search. Various options allow customization of the number
   * of documents retrieved per query, filtering based on conditions, and fine-tuning
   * MMR-specific parameters.
   *
   * @param fields - Configuration options for setting up the retriever:
   *
   *   - `vectorStore` (required): The `VectorStore` instance implementing `VectorStoreInterface`
   *     that will be used to store and retrieve document embeddings. This is the core component
   *     of the retriever, enabling vector-based similarity and MMR searches.
   *
   *   - `k` (optional): Specifies the number of documents to retrieve per search query. If not
   *     provided, defaults to 4. This count determines the number of most relevant documents returned
   *     for each search operation, balancing performance with comprehensiveness.
   *
   *   - `searchType` (optional): Defines the search approach used by the retriever, allowing for
   *     flexibility between two methods:
   *       - `"similarity"` (default): A similarity-based search, retrieving documents with high vector
   *         similarity to the query. This type prioritizes relevance and is often used when diversity
   *         among results is less critical.
   *       - `"mmr"`: Maximal Marginal Relevance search, which combines relevance with diversity. MMR
   *         is useful for scenarios where varied content is essential, as it selects results that
   *         both match the query and introduce content diversity.
   *
   *   - `filter` (optional): A filter of type `FilterType`, defined by the vector store, that allows
   *     for refined and targeted search results. This filter applies specified conditions to limit
   *     which documents are eligible for retrieval, offering control over the scope of results.
   *
   *   - `searchKwargs` (optional, applicable only if `searchType` is `"mmr"`): Additional settings
   *     for configuring MMR-specific behavior. These parameters allow further tuning of the MMR
   *     search process:
   *       - `fetchK`: The initial number of documents fetched from the vector store before the MMR
   *         algorithm is applied. Fetching a larger set enables the algorithm to select a more
   *         diverse subset of documents.
   *       - `lambda`: A parameter controlling the relevance-diversity balance, where 0 emphasizes
   *         diversity and 1 prioritizes relevance. Intermediate values provide a blend of the two,
   *         allowing customization based on the importance of content variety relative to query relevance.
   */
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "vectorStore", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "k", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: 4
    });
    Object.defineProperty(this, "searchType", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "similarity"
    });
    Object.defineProperty(this, "searchKwargs", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "filter", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.vectorStore = fields.vectorStore;
    this.k = fields.k ?? this.k;
    this.searchType = fields.searchType ?? this.searchType;
    this.filter = fields.filter;
    if (fields.searchType === "mmr") {
      this.searchKwargs = fields.searchKwargs;
    }
  }
  /**
   * Retrieves relevant documents based on the specified query, using either
   * similarity or maximal marginal relevance (MMR) search.
   *
   * If `searchType` is set to `"mmr"`, performs an MMR search to balance
   * similarity and diversity among results. If `searchType` is `"similarity"`,
   * retrieves results purely based on similarity to the query.
   *
   * @param query - The query string used to find relevant documents.
   * @param runManager - Optional callback manager for tracking retrieval progress.
   * @returns A promise that resolves to an array of `DocumentInterface` instances
   *          representing the most relevant documents to the query.
   * @throws {Error} Throws an error if MMR search is requested but not supported
   *                 by the vector store.
   * @protected
   */
  async _getRelevantDocuments(query, runManager) {
    if (this.searchType === "mmr") {
      if (typeof this.vectorStore.maxMarginalRelevanceSearch !== "function") {
        throw new Error(`The vector store backing this retriever, ${this._vectorstoreType()} does not support max marginal relevance search.`);
      }
      return this.vectorStore.maxMarginalRelevanceSearch(query, {
        k: this.k,
        filter: this.filter,
        ...this.searchKwargs
      }, runManager?.getChild("vectorstore"));
    }
    return this.vectorStore.similaritySearch(query, this.k, this.filter, runManager?.getChild("vectorstore"));
  }
  /**
   * Adds an array of documents to the vector store, embedding them as part of
   * the storage process.
   *
   * This method delegates document embedding and storage to the `addDocuments`
   * method of the underlying vector store.
   *
   * @param documents - An array of documents to embed and add to the vector store.
   * @param options - Optional settings to customize document addition.
   * @returns A promise that resolves to an array of document IDs or `void`,
   *          depending on the vector store's implementation.
   */
  async addDocuments(documents, options) {
    return this.vectorStore.addDocuments(documents, options);
  }
};
var VectorStore = class extends Serializable {
  /**
   * Initializes a new vector store with embeddings and database configuration.
   *
   * @param embeddings - Instance of `EmbeddingsInterface` used to embed queries.
   * @param dbConfig - Configuration settings for the database or storage system.
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  constructor(embeddings, dbConfig) {
    super(dbConfig);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain", "vectorstores", this._vectorstoreType()]
    });
    Object.defineProperty(this, "embeddings", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.embeddings = embeddings;
  }
  /**
   * Deletes documents from the vector store based on the specified parameters.
   *
   * @param _params - Flexible key-value pairs defining conditions for document deletion.
   * @returns A promise that resolves once the deletion is complete.
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  async delete(_params) {
    throw new Error("Not implemented.");
  }
  /**
   * Searches for documents similar to a text query by embedding the query and
   * performing a similarity search on the resulting vector.
   *
   * @param query - Text query for finding similar documents.
   * @param k - Number of similar results to return. Defaults to 4.
   * @param filter - Optional filter based on `FilterType`.
   * @param _callbacks - Optional callbacks for monitoring search progress
   * @returns A promise resolving to an array of `DocumentInterface` instances representing similar documents.
   */
  async similaritySearch(query, k2 = 4, filter = void 0, _callbacks = void 0) {
    const results = await this.similaritySearchVectorWithScore(await this.embeddings.embedQuery(query), k2, filter);
    return results.map((result) => result[0]);
  }
  /**
   * Searches for documents similar to a text query by embedding the query,
   * and returns results with similarity scores.
   *
   * @param query - Text query for finding similar documents.
   * @param k - Number of similar results to return. Defaults to 4.
   * @param filter - Optional filter based on `FilterType`.
   * @param _callbacks - Optional callbacks for monitoring search progress
   * @returns A promise resolving to an array of tuples, each containing a
   *          document and its similarity score.
   */
  async similaritySearchWithScore(query, k2 = 4, filter = void 0, _callbacks = void 0) {
    return this.similaritySearchVectorWithScore(await this.embeddings.embedQuery(query), k2, filter);
  }
  /**
   * Creates a `VectorStore` instance from an array of text strings and optional
   * metadata, using the specified embeddings and database configuration.
   *
   * Subclasses must implement this method to define how text and metadata
   * are embedded and stored in the vector store. Throws an error if not overridden.
   *
   * @param _texts - Array of strings representing the text documents to be stored.
   * @param _metadatas - Metadata for the texts, either as an array (one for each text)
   *                     or a single object (applied to all texts).
   * @param _embeddings - Instance of `EmbeddingsInterface` to embed the texts.
   * @param _dbConfig - Database configuration settings.
   * @returns A promise that resolves to a new `VectorStore` instance.
   * @throws {Error} Throws an error if this method is not overridden by a subclass.
   */
  static fromTexts(_texts, _metadatas, _embeddings, _dbConfig) {
    throw new Error("the Langchain vectorstore implementation you are using forgot to override this, please report a bug");
  }
  /**
   * Creates a `VectorStore` instance from an array of documents, using the specified
   * embeddings and database configuration.
   *
   * Subclasses must implement this method to define how documents are embedded
   * and stored. Throws an error if not overridden.
   *
   * @param _docs - Array of `DocumentInterface` instances representing the documents to be stored.
   * @param _embeddings - Instance of `EmbeddingsInterface` to embed the documents.
   * @param _dbConfig - Database configuration settings.
   * @returns A promise that resolves to a new `VectorStore` instance.
   * @throws {Error} Throws an error if this method is not overridden by a subclass.
   */
  static fromDocuments(_docs, _embeddings, _dbConfig) {
    throw new Error("the Langchain vectorstore implementation you are using forgot to override this, please report a bug");
  }
  /**
   * Creates a `VectorStoreRetriever` instance with flexible configuration options.
   *
   * @param kOrFields
   *    - If a number is provided, it sets the `k` parameter (number of items to retrieve).
   *    - If an object is provided, it should contain various configuration options.
   * @param filter
   *    - Optional filter criteria to limit the items retrieved based on the specified filter type.
   * @param callbacks
   *    - Optional callbacks that may be triggered at specific stages of the retrieval process.
   * @param tags
   *    - Tags to categorize or label the `VectorStoreRetriever`. Defaults to an empty array if not provided.
   * @param metadata
   *    - Additional metadata as key-value pairs to add contextual information for the retrieval process.
   * @param verbose
   *    - If `true`, enables detailed logging for the retrieval process. Defaults to `false`.
   *
   * @returns
   *    - A configured `VectorStoreRetriever` instance based on the provided parameters.
   *
   * @example
   * Basic usage with a `k` value:
   * ```typescript
   * const retriever = myVectorStore.asRetriever(5);
   * ```
   *
   * Usage with a configuration object:
   * ```typescript
   * const retriever = myVectorStore.asRetriever({
   *   k: 10,
   *   filter: myFilter,
   *   tags: ['example', 'test'],
   *   verbose: true,
   *   searchType: 'mmr',
   *   searchKwargs: { alpha: 0.5 },
   * });
   * ```
   */
  asRetriever(kOrFields, filter, callbacks, tags, metadata, verbose) {
    if (typeof kOrFields === "number") {
      return new VectorStoreRetriever({
        vectorStore: this,
        k: kOrFields,
        filter,
        tags: [...tags ?? [], this._vectorstoreType()],
        metadata,
        verbose,
        callbacks
      });
    } else {
      const params = {
        vectorStore: this,
        k: kOrFields?.k,
        filter: kOrFields?.filter,
        tags: [...kOrFields?.tags ?? [], this._vectorstoreType()],
        metadata: kOrFields?.metadata,
        verbose: kOrFields?.verbose,
        callbacks: kOrFields?.callbacks,
        searchType: kOrFields?.searchType
      };
      if (kOrFields?.searchType === "mmr") {
        return new VectorStoreRetriever({
          ...params,
          searchKwargs: kOrFields.searchKwargs
        });
      }
      return new VectorStoreRetriever({ ...params });
    }
  }
};
var SaveableVectorStore = class extends VectorStore {
  /**
   * Loads a vector store instance from the specified directory, using the
   * provided embeddings to ensure compatibility.
   *
   * This static method reconstructs a `SaveableVectorStore` from previously
   * saved data. Implementations should interpret the saved data format to
   * recreate the vector store instance.
   *
   * @param _directory - The directory path from which the vector store
   * data will be loaded.
   * @param _embeddings - An instance of `EmbeddingsInterface` to align
   * the embeddings with the loaded vector data.
   * @returns A promise that resolves to a `SaveableVectorStore` instance
   * constructed from the saved data.
   */
  static load(_directory, _embeddings) {
    throw new Error("Not implemented");
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/utils/testing/index.js
var FakeSplitIntoListParser = class extends BaseOutputParser {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["tests", "fake"]
    });
  }
  getFormatInstructions() {
    return "";
  }
  async parse(text) {
    return text.split(",").map((value) => value.trim());
  }
};
var FakeRunnable = class extends Runnable {
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["tests", "fake"]
    });
    Object.defineProperty(this, "returnOptions", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.returnOptions = fields.returnOptions;
  }
  async invoke(input, options) {
    if (this.returnOptions) {
      return options ?? {};
    }
    return { input };
  }
};
var FakeLLM = class extends LLM {
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "response", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "thrownErrorString", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.response = fields.response;
    this.thrownErrorString = fields.thrownErrorString;
  }
  _llmType() {
    return "fake";
  }
  async _call(prompt, _options, runManager) {
    if (this.thrownErrorString) {
      throw new Error(this.thrownErrorString);
    }
    const response = this.response ?? prompt;
    await runManager?.handleLLMNewToken(response);
    return response;
  }
};
var FakeStreamingLLM = class extends LLM {
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "sleep", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: 50
    });
    Object.defineProperty(this, "responses", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "thrownErrorString", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.sleep = fields.sleep ?? this.sleep;
    this.responses = fields.responses;
    this.thrownErrorString = fields.thrownErrorString;
  }
  _llmType() {
    return "fake";
  }
  async _call(prompt) {
    if (this.thrownErrorString) {
      throw new Error(this.thrownErrorString);
    }
    const response = this.responses?.[0];
    this.responses = this.responses?.slice(1);
    return response ?? prompt;
  }
  async *_streamResponseChunks(input, _options, runManager) {
    if (this.thrownErrorString) {
      throw new Error(this.thrownErrorString);
    }
    const response = this.responses?.[0];
    this.responses = this.responses?.slice(1);
    for (const c2 of response ?? input) {
      await new Promise((resolve) => setTimeout(resolve, this.sleep));
      yield { text: c2, generationInfo: {} };
      await runManager?.handleLLMNewToken(c2);
    }
  }
};
var FakeChatModel = class extends BaseChatModel {
  _combineLLMOutput() {
    return [];
  }
  _llmType() {
    return "fake";
  }
  async _generate(messages, options, runManager) {
    if (options?.stop?.length) {
      return {
        generations: [
          {
            message: new AIMessage(options.stop[0]),
            text: options.stop[0]
          }
        ]
      };
    }
    const text = messages.map((m2) => {
      if (typeof m2.content === "string") {
        return m2.content;
      }
      return JSON.stringify(m2.content, null, 2);
    }).join("\n");
    await runManager?.handleLLMNewToken(text);
    return {
      generations: [
        {
          message: new AIMessage(text),
          text
        }
      ],
      llmOutput: {}
    };
  }
};
var FakeStreamingChatModel = class _FakeStreamingChatModel extends BaseChatModel {
  constructor({ sleep = 50, responses = [], chunks = [], toolStyle = "openai", thrownErrorString, ...rest }) {
    super(rest);
    Object.defineProperty(this, "sleep", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: 50
    });
    Object.defineProperty(this, "responses", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    Object.defineProperty(this, "chunks", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    Object.defineProperty(this, "toolStyle", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "openai"
    });
    Object.defineProperty(this, "thrownErrorString", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "tools", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    this.sleep = sleep;
    this.responses = responses;
    this.chunks = chunks;
    this.toolStyle = toolStyle;
    this.thrownErrorString = thrownErrorString;
  }
  _llmType() {
    return "fake";
  }
  bindTools(tools) {
    const merged = [...this.tools, ...tools];
    const toolDicts = merged.map((t2) => {
      switch (this.toolStyle) {
        case "openai":
          return {
            type: "function",
            function: {
              name: t2.name,
              description: t2.description,
              parameters: toJsonSchema(t2.schema)
            }
          };
        case "anthropic":
          return {
            name: t2.name,
            description: t2.description,
            input_schema: toJsonSchema(t2.schema)
          };
        case "bedrock":
          return {
            toolSpec: {
              name: t2.name,
              description: t2.description,
              inputSchema: toJsonSchema(t2.schema)
            }
          };
        case "google":
          return {
            name: t2.name,
            description: t2.description,
            parameters: toJsonSchema(t2.schema)
          };
        default:
          throw new Error(`Unsupported tool style: ${this.toolStyle}`);
      }
    });
    const wrapped = this.toolStyle === "google" ? [{ functionDeclarations: toolDicts }] : toolDicts;
    const next = new _FakeStreamingChatModel({
      sleep: this.sleep,
      responses: this.responses,
      chunks: this.chunks,
      toolStyle: this.toolStyle,
      thrownErrorString: this.thrownErrorString
    });
    next.tools = merged;
    return next.withConfig({ tools: wrapped });
  }
  async _generate(messages, _options, _runManager) {
    if (this.thrownErrorString) {
      throw new Error(this.thrownErrorString);
    }
    const content = this.responses?.[0]?.content ?? messages[0].content ?? "";
    const generation = {
      generations: [
        {
          text: "",
          message: new AIMessage({
            content,
            tool_calls: this.chunks?.[0]?.tool_calls
          })
        }
      ]
    };
    return generation;
  }
  async *_streamResponseChunks(_messages, _options, runManager) {
    if (this.thrownErrorString) {
      throw new Error(this.thrownErrorString);
    }
    if (this.chunks?.length) {
      for (const msgChunk of this.chunks) {
        const cg = new ChatGenerationChunk({
          message: new AIMessageChunk({
            content: msgChunk.content,
            tool_calls: msgChunk.tool_calls,
            additional_kwargs: msgChunk.additional_kwargs ?? {}
          }),
          text: msgChunk.content?.toString() ?? ""
        });
        yield cg;
        await runManager?.handleLLMNewToken(msgChunk.content, void 0, void 0, void 0, void 0, { chunk: cg });
      }
      return;
    }
    const fallback = this.responses?.[0] ?? new AIMessage(typeof _messages[0].content === "string" ? _messages[0].content : "");
    const text = typeof fallback.content === "string" ? fallback.content : "";
    for (const ch of text) {
      await new Promise((r2) => setTimeout(r2, this.sleep));
      const cg = new ChatGenerationChunk({
        message: new AIMessageChunk({ content: ch }),
        text: ch
      });
      yield cg;
      await runManager?.handleLLMNewToken(ch, void 0, void 0, void 0, void 0, { chunk: cg });
    }
  }
};
var FakeRetriever = class extends BaseRetriever {
  constructor(fields) {
    super();
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["test", "fake"]
    });
    Object.defineProperty(this, "output", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: [
        new Document({ pageContent: "foo" }),
        new Document({ pageContent: "bar" })
      ]
    });
    this.output = fields?.output ?? this.output;
  }
  async _getRelevantDocuments(_query) {
    return this.output;
  }
};
var FakeListChatModel = class extends BaseChatModel {
  static lc_name() {
    return "FakeListChatModel";
  }
  constructor(params) {
    super(params);
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "responses", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "i", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: 0
    });
    Object.defineProperty(this, "sleep", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "emitCustomEvent", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    const { responses, sleep, emitCustomEvent } = params;
    this.responses = responses;
    this.sleep = sleep;
    this.emitCustomEvent = emitCustomEvent ?? this.emitCustomEvent;
  }
  _combineLLMOutput() {
    return [];
  }
  _llmType() {
    return "fake-list";
  }
  async _generate(_messages, options, runManager) {
    await this._sleepIfRequested();
    if (options?.thrownErrorString) {
      throw new Error(options.thrownErrorString);
    }
    if (this.emitCustomEvent) {
      await runManager?.handleCustomEvent("some_test_event", {
        someval: true
      });
    }
    if (options?.stop?.length) {
      return {
        generations: [this._formatGeneration(options.stop[0])]
      };
    } else {
      const response = this._currentResponse();
      this._incrementResponse();
      return {
        generations: [this._formatGeneration(response)],
        llmOutput: {}
      };
    }
  }
  _formatGeneration(text) {
    return {
      message: new AIMessage(text),
      text
    };
  }
  async *_streamResponseChunks(_messages, options, runManager) {
    const response = this._currentResponse();
    this._incrementResponse();
    if (this.emitCustomEvent) {
      await runManager?.handleCustomEvent("some_test_event", {
        someval: true
      });
    }
    for await (const text of response) {
      await this._sleepIfRequested();
      if (options?.thrownErrorString) {
        throw new Error(options.thrownErrorString);
      }
      const chunk = this._createResponseChunk(text);
      yield chunk;
      void runManager?.handleLLMNewToken(text);
    }
  }
  async _sleepIfRequested() {
    if (this.sleep !== void 0) {
      await this._sleep();
    }
  }
  async _sleep() {
    return new Promise((resolve) => {
      setTimeout(() => resolve(), this.sleep);
    });
  }
  _createResponseChunk(text) {
    return new ChatGenerationChunk({
      message: new AIMessageChunk({ content: text }),
      text
    });
  }
  _currentResponse() {
    return this.responses[this.i];
  }
  _incrementResponse() {
    if (this.i < this.responses.length - 1) {
      this.i += 1;
    } else {
      this.i = 0;
    }
  }
  withStructuredOutput(_params, _config) {
    return RunnableLambda.from(async (input) => {
      const message = await this.invoke(input);
      if (message.tool_calls?.[0]?.args) {
        return message.tool_calls[0].args;
      }
      if (typeof message.content === "string") {
        return JSON.parse(message.content);
      }
      throw new Error("No structured output found");
    });
  }
};
var FakeChatMessageHistory = class extends BaseChatMessageHistory {
  constructor() {
    super();
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "message", "fake"]
    });
    Object.defineProperty(this, "messages", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
  }
  async getMessages() {
    return this.messages;
  }
  async addMessage(message) {
    this.messages.push(message);
  }
  async addUserMessage(message) {
    this.messages.push(new HumanMessage(message));
  }
  async addAIChatMessage(message) {
    this.messages.push(new AIMessage(message));
  }
  async clear() {
    this.messages = [];
  }
};
var FakeListChatMessageHistory = class extends BaseListChatMessageHistory {
  constructor() {
    super();
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "message", "fake"]
    });
    Object.defineProperty(this, "messages", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
  }
  async addMessage(message) {
    this.messages.push(message);
  }
  async getMessages() {
    return this.messages;
  }
};
var FakeTracer = class extends BaseTracer {
  constructor() {
    super();
    Object.defineProperty(this, "name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "fake_tracer"
    });
    Object.defineProperty(this, "runs", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
  }
  persistRun(run) {
    this.runs.push(run);
    return Promise.resolve();
  }
};
var FakeTool = class extends StructuredTool {
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "description", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "schema", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.name = fields.name;
    this.description = fields.description;
    this.schema = fields.schema;
  }
  async _call(arg, _runManager) {
    return JSON.stringify(arg);
  }
};
var FakeEmbeddings = class extends Embeddings {
  constructor(params) {
    super(params ?? {});
  }
  /**
   * Generates fixed embeddings for a list of documents.
   * @param documents List of documents to generate embeddings for.
   * @returns A promise that resolves with a list of fixed embeddings for each document.
   */
  embedDocuments(documents) {
    return Promise.resolve(documents.map(() => [0.1, 0.2, 0.3, 0.4]));
  }
  /**
   * Generates a fixed embedding for a query.
   * @param _ The query to generate an embedding for.
   * @returns A promise that resolves with a fixed embedding for the query.
   */
  embedQuery(_2) {
    return Promise.resolve([0.1, 0.2, 0.3, 0.4]);
  }
};
var SyntheticEmbeddings = class extends Embeddings {
  constructor(params) {
    super(params ?? {});
    Object.defineProperty(this, "vectorSize", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.vectorSize = params?.vectorSize ?? 4;
  }
  /**
   * Generates synthetic embeddings for a list of documents.
   * @param documents List of documents to generate embeddings for.
   * @returns A promise that resolves with a list of synthetic embeddings for each document.
   */
  async embedDocuments(documents) {
    return Promise.all(documents.map((doc) => this.embedQuery(doc)));
  }
  /**
   * Generates a synthetic embedding for a document. The document is
   * converted into chunks, a numerical value is calculated for each chunk,
   * and an array of these values is returned as the embedding.
   * @param document The document to generate an embedding for.
   * @returns A promise that resolves with a synthetic embedding for the document.
   */
  async embedQuery(document2) {
    let doc = document2;
    doc = doc.toLowerCase().replaceAll(/[^a-z ]/g, "");
    const padMod = doc.length % this.vectorSize;
    const padGapSize = padMod === 0 ? 0 : this.vectorSize - padMod;
    const padSize = doc.length + padGapSize;
    doc = doc.padEnd(padSize, " ");
    const chunkSize = doc.length / this.vectorSize;
    const docChunk = [];
    for (let co = 0; co < doc.length; co += chunkSize) {
      docChunk.push(doc.slice(co, co + chunkSize));
    }
    const ret = docChunk.map((s2) => {
      let sum = 0;
      for (let co = 0; co < s2.length; co += 1) {
        sum += s2 === " " ? 0 : s2.charCodeAt(co);
      }
      const ret2 = sum % 26 / 26;
      return ret2;
    });
    return ret;
  }
};
var SingleRunExtractor = class extends BaseTracer {
  constructor() {
    super();
    Object.defineProperty(this, "runPromiseResolver", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "runPromise", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "single_run_extractor"
    });
    this.runPromise = new Promise((extract) => {
      this.runPromiseResolver = extract;
    });
  }
  async persistRun(run) {
    this.runPromiseResolver(run);
  }
  async extract() {
    return this.runPromise;
  }
};
var FakeVectorStore = class _FakeVectorStore extends VectorStore {
  _vectorstoreType() {
    return "memory";
  }
  constructor(embeddings, { similarity, ...rest } = {}) {
    super(embeddings, rest);
    Object.defineProperty(this, "memoryVectors", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    Object.defineProperty(this, "similarity", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.similarity = similarity ?? cosine;
  }
  /**
   * Method to add documents to the memory vector store. It extracts the
   * text from each document, generates embeddings for them, and adds the
   * resulting vectors to the store.
   * @param documents Array of `Document` instances to be added to the store.
   * @returns Promise that resolves when all documents have been added.
   */
  async addDocuments(documents) {
    const texts = documents.map(({ pageContent }) => pageContent);
    return this.addVectors(await this.embeddings.embedDocuments(texts), documents);
  }
  /**
   * Method to add vectors to the memory vector store. It creates
   * `MemoryVector` instances for each vector and document pair and adds
   * them to the store.
   * @param vectors Array of vectors to be added to the store.
   * @param documents Array of `Document` instances corresponding to the vectors.
   * @returns Promise that resolves when all vectors have been added.
   */
  async addVectors(vectors, documents) {
    const memoryVectors = vectors.map((embedding, idx) => ({
      content: documents[idx].pageContent,
      embedding,
      metadata: documents[idx].metadata
    }));
    this.memoryVectors = this.memoryVectors.concat(memoryVectors);
  }
  /**
   * Method to perform a similarity search in the memory vector store. It
   * calculates the similarity between the query vector and each vector in
   * the store, sorts the results by similarity, and returns the top `k`
   * results along with their scores.
   * @param query Query vector to compare against the vectors in the store.
   * @param k Number of top results to return.
   * @param filter Optional filter function to apply to the vectors before performing the search.
   * @returns Promise that resolves with an array of tuples, each containing a `Document` and its similarity score.
   */
  async similaritySearchVectorWithScore(query, k2, filter) {
    const filterFunction = (memoryVector) => {
      if (!filter) {
        return true;
      }
      const doc = new Document({
        metadata: memoryVector.metadata,
        pageContent: memoryVector.content
      });
      return filter(doc);
    };
    const filteredMemoryVectors = this.memoryVectors.filter(filterFunction);
    const searches = filteredMemoryVectors.map((vector, index) => ({
      similarity: this.similarity(query, vector.embedding),
      index
    })).sort((a, b2) => a.similarity > b2.similarity ? -1 : 0).slice(0, k2);
    const result = searches.map((search) => [
      new Document({
        metadata: filteredMemoryVectors[search.index].metadata,
        pageContent: filteredMemoryVectors[search.index].content
      }),
      search.similarity
    ]);
    return result;
  }
  /**
   * Static method to create a `FakeVectorStore` instance from an array of
   * texts. It creates a `Document` for each text and metadata pair, and
   * adds them to the store.
   * @param texts Array of texts to be added to the store.
   * @param metadatas Array or single object of metadata corresponding to the texts.
   * @param embeddings `Embeddings` instance used to generate embeddings for the texts.
   * @param dbConfig Optional `FakeVectorStoreArgs` to configure the `FakeVectorStore` instance.
   * @returns Promise that resolves with a new `FakeVectorStore` instance.
   */
  static async fromTexts(texts, metadatas, embeddings, dbConfig) {
    const docs = [];
    for (let i2 = 0; i2 < texts.length; i2 += 1) {
      const metadata = Array.isArray(metadatas) ? metadatas[i2] : metadatas;
      const newDoc = new Document({
        pageContent: texts[i2],
        metadata
      });
      docs.push(newDoc);
    }
    return _FakeVectorStore.fromDocuments(docs, embeddings, dbConfig);
  }
  /**
   * Static method to create a `FakeVectorStore` instance from an array of
   * `Document` instances. It adds the documents to the store.
   * @param docs Array of `Document` instances to be added to the store.
   * @param embeddings `Embeddings` instance used to generate embeddings for the documents.
   * @param dbConfig Optional `FakeVectorStoreArgs` to configure the `FakeVectorStore` instance.
   * @returns Promise that resolves with a new `FakeVectorStore` instance.
   */
  static async fromDocuments(docs, embeddings, dbConfig) {
    const instance = new this(embeddings, dbConfig);
    await instance.addDocuments(docs);
    return instance;
  }
  /**
   * Static method to create a `FakeVectorStore` instance from an existing
   * index. It creates a new `FakeVectorStore` instance without adding any
   * documents or vectors.
   * @param embeddings `Embeddings` instance used to generate embeddings for the documents.
   * @param dbConfig Optional `FakeVectorStoreArgs` to configure the `FakeVectorStore` instance.
   * @returns Promise that resolves with a new `FakeVectorStore` instance.
   */
  static async fromExistingIndex(embeddings, dbConfig) {
    const instance = new this(embeddings, dbConfig);
    return instance;
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/utils/types/index.js
var types_exports = {};
__export(types_exports, {
  extendInteropZodObject: () => extendInteropZodObject,
  getInteropZodDefaultGetter: () => getInteropZodDefaultGetter,
  getInteropZodObjectShape: () => getInteropZodObjectShape,
  getSchemaDescription: () => getSchemaDescription,
  interopParse: () => interopParse,
  interopParseAsync: () => interopParseAsync,
  interopSafeParse: () => interopSafeParse,
  interopSafeParseAsync: () => interopSafeParseAsync,
  interopZodObjectPartial: () => interopZodObjectPartial,
  interopZodObjectPassthrough: () => interopZodObjectPassthrough,
  interopZodObjectStrict: () => interopZodObjectStrict,
  interopZodTransformInputSchema: () => interopZodTransformInputSchema,
  isInteropZodObject: () => isInteropZodObject,
  isInteropZodSchema: () => isInteropZodSchema,
  isShapelessZodSchema: () => isShapelessZodSchema,
  isSimpleStringZodSchema: () => isSimpleStringZodSchema,
  isZodArrayV4: () => isZodArrayV4,
  isZodObjectV3: () => isZodObjectV3,
  isZodObjectV4: () => isZodObjectV4,
  isZodSchema: () => isZodSchema,
  isZodSchemaV3: () => isZodSchemaV3,
  isZodSchemaV4: () => isZodSchemaV4
});
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/load/index.js
function combineAliasesAndInvert(constructor) {
  const aliases = {};
  for (let current = constructor; current && current.prototype; current = Object.getPrototypeOf(current)) {
    Object.assign(aliases, Reflect.get(current.prototype, "lc_aliases"));
  }
  return Object.entries(aliases).reduce((acc, [key, value]) => {
    acc[value] = key;
    return acc;
  }, {});
}
async function reviver(value) {
  const { optionalImportsMap = {}, optionalImportEntrypoints: optionalImportEntrypoints2 = [], importMap = {}, secretsMap = {}, path = ["$"] } = this;
  const pathStr = path.join(".");
  if (typeof value === "object" && value !== null && !Array.isArray(value) && "lc" in value && "type" in value && "id" in value && value.lc === 1 && value.type === "secret") {
    const serialized = value;
    const [key] = serialized.id;
    if (key in secretsMap) {
      return secretsMap[key];
    } else {
      const secretValueInEnv = getEnvironmentVariable(key);
      if (secretValueInEnv) {
        return secretValueInEnv;
      } else {
        throw new Error(`Missing key "${key}" for ${pathStr} in load(secretsMap={})`);
      }
    }
  } else if (typeof value === "object" && value !== null && !Array.isArray(value) && "lc" in value && "type" in value && "id" in value && value.lc === 1 && value.type === "not_implemented") {
    const serialized = value;
    const str = JSON.stringify(serialized);
    throw new Error(`Trying to load an object that doesn't implement serialization: ${pathStr} -> ${str}`);
  } else if (typeof value === "object" && value !== null && !Array.isArray(value) && "lc" in value && "type" in value && "id" in value && "kwargs" in value && value.lc === 1) {
    const serialized = value;
    const str = JSON.stringify(serialized);
    const [name, ...namespaceReverse] = serialized.id.slice().reverse();
    const namespace = namespaceReverse.reverse();
    const importMaps = { langchain_core: import_map_exports, langchain: importMap };
    let module = null;
    const optionalImportNamespaceAliases = [namespace.join("/")];
    if (namespace[0] === "langchain_community") {
      optionalImportNamespaceAliases.push(["langchain", ...namespace.slice(1)].join("/"));
    }
    const matchingNamespaceAlias = optionalImportNamespaceAliases.find((alias) => alias in optionalImportsMap);
    if (optionalImportEntrypoints.concat(optionalImportEntrypoints2).includes(namespace.join("/")) || matchingNamespaceAlias) {
      if (matchingNamespaceAlias !== void 0) {
        module = await optionalImportsMap[matchingNamespaceAlias];
      } else {
        throw new Error(`Missing key "${namespace.join("/")}" for ${pathStr} in load(optionalImportsMap={})`);
      }
    } else {
      let finalImportMap;
      if (namespace[0] === "langchain" || namespace[0] === "langchain_core") {
        finalImportMap = importMaps[namespace[0]];
        namespace.shift();
      } else {
        throw new Error(`Invalid namespace: ${pathStr} -> ${str}`);
      }
      if (namespace.length === 0) {
        throw new Error(`Invalid namespace: ${pathStr} -> ${str}`);
      }
      let importMapKey;
      do {
        importMapKey = namespace.join("__");
        if (importMapKey in finalImportMap) {
          break;
        } else {
          namespace.pop();
        }
      } while (namespace.length > 0);
      if (importMapKey in finalImportMap) {
        module = finalImportMap[importMapKey];
      }
    }
    if (typeof module !== "object" || module === null) {
      throw new Error(`Invalid namespace: ${pathStr} -> ${str}`);
    }
    const builder = (
      // look for a named export with the same name as the class
      module[name] ?? // look for an export with a lc_name property matching the class name
      // this is necessary for classes that are minified
      Object.values(module).find((v2) => typeof v2 === "function" && get_lc_unique_name(v2) === name)
    );
    if (typeof builder !== "function") {
      throw new Error(`Invalid identifer: ${pathStr} -> ${str}`);
    }
    const kwargs = await reviver.call({ ...this, path: [...path, "kwargs"] }, serialized.kwargs);
    if (serialized.type === "constructor") {
      const instance = new builder(mapKeys(kwargs, keyFromJson, combineAliasesAndInvert(builder)));
      Object.defineProperty(instance.constructor, "name", { value: name });
      return instance;
    } else {
      throw new Error(`Invalid type: ${pathStr} -> ${str}`);
    }
  } else if (typeof value === "object" && value !== null) {
    if (Array.isArray(value)) {
      return Promise.all(value.map((v2, i2) => reviver.call({ ...this, path: [...path, `${i2}`] }, v2)));
    } else {
      return Object.fromEntries(await Promise.all(Object.entries(value).map(async ([key, value2]) => [
        key,
        await reviver.call({ ...this, path: [...path, key] }, value2)
      ])));
    }
  }
  return value;
}
async function load(text, mappings) {
  const json = JSON.parse(text);
  return reviver.call({ ...mappings }, json);
}

// ../../../node_modules/.pnpm/@langchain+langgraph-checkpoint@0.0.18_@langchain+core@0.3.61_@opentelemetry+api@1.9.0__a6099cbbd47045e82bada733957b498f/node_modules/@langchain/langgraph-checkpoint/dist/serde/utils/fast-safe-stringify/index.js
init_esm();
var LIMIT_REPLACE_NODE = "[...]";
var CIRCULAR_REPLACE_NODE = "[Circular]";
var arr = [];
var replacerStack = [];
function defaultOptions() {
  return {
    depthLimit: Number.MAX_SAFE_INTEGER,
    edgesLimit: Number.MAX_SAFE_INTEGER
  };
}
function stringify(obj, replacer, spacer, options) {
  if (typeof options === "undefined") {
    options = defaultOptions();
  }
  decirc(obj, "", 0, [], void 0, 0, options);
  var res;
  try {
    if (replacerStack.length === 0) {
      res = JSON.stringify(obj, replacer, spacer);
    } else {
      res = JSON.stringify(obj, replaceGetterValues(replacer), spacer);
    }
  } catch (_2) {
    return JSON.stringify("[unable to serialize, circular reference is too complex to analyze]");
  } finally {
    while (arr.length !== 0) {
      var part = arr.pop();
      if (part.length === 4) {
        Object.defineProperty(part[0], part[1], part[3]);
      } else {
        part[0][part[1]] = part[2];
      }
    }
  }
  return res;
}
function setReplace(replace, val, k2, parent) {
  var propertyDescriptor = Object.getOwnPropertyDescriptor(parent, k2);
  if (propertyDescriptor.get !== void 0) {
    if (propertyDescriptor.configurable) {
      Object.defineProperty(parent, k2, { value: replace });
      arr.push([parent, k2, val, propertyDescriptor]);
    } else {
      replacerStack.push([val, k2, replace]);
    }
  } else {
    parent[k2] = replace;
    arr.push([parent, k2, val]);
  }
}
function decirc(val, k2, edgeIndex, stack, parent, depth, options) {
  depth += 1;
  var i2;
  if (typeof val === "object" && val !== null) {
    for (i2 = 0; i2 < stack.length; i2++) {
      if (stack[i2] === val) {
        setReplace(CIRCULAR_REPLACE_NODE, val, k2, parent);
        return;
      }
    }
    if (typeof options.depthLimit !== "undefined" && depth > options.depthLimit) {
      setReplace(LIMIT_REPLACE_NODE, val, k2, parent);
      return;
    }
    if (typeof options.edgesLimit !== "undefined" && edgeIndex + 1 > options.edgesLimit) {
      setReplace(LIMIT_REPLACE_NODE, val, k2, parent);
      return;
    }
    stack.push(val);
    if (Array.isArray(val)) {
      for (i2 = 0; i2 < val.length; i2++) {
        decirc(val[i2], i2, i2, stack, val, depth, options);
      }
    } else {
      var keys = Object.keys(val);
      for (i2 = 0; i2 < keys.length; i2++) {
        var key = keys[i2];
        decirc(val[key], key, i2, stack, val, depth, options);
      }
    }
    stack.pop();
  }
}
function replaceGetterValues(replacer) {
  replacer = typeof replacer !== "undefined" ? replacer : function(k2, v2) {
    return v2;
  };
  return function(key, val) {
    if (replacerStack.length > 0) {
      for (var i2 = 0; i2 < replacerStack.length; i2++) {
        var part = replacerStack[i2];
        if (part[1] === key && part[0] === val) {
          val = part[2];
          replacerStack.splice(i2, 1);
          break;
        }
      }
    }
    return replacer.call(this, key, val);
  };
}

// ../../../node_modules/.pnpm/@langchain+langgraph-checkpoint@0.0.18_@langchain+core@0.3.61_@opentelemetry+api@1.9.0__a6099cbbd47045e82bada733957b498f/node_modules/@langchain/langgraph-checkpoint/dist/serde/jsonplus.js
function isLangChainSerializedObject(value) {
  return value !== null && value.lc === 1 && value.type === "constructor" && Array.isArray(value.id);
}
async function _reviver(value) {
  if (value && typeof value === "object") {
    if (Array.isArray(value)) {
      const revivedArray = await Promise.all(value.map((item) => _reviver(item)));
      return revivedArray;
    } else {
      const revivedObj = {};
      for (const [k2, v2] of Object.entries(value)) {
        revivedObj[k2] = await _reviver(v2);
      }
      if (revivedObj.lc === 2 && revivedObj.type === "undefined") {
        return void 0;
      } else if (revivedObj.lc === 2 && revivedObj.type === "constructor" && Array.isArray(revivedObj.id)) {
        try {
          const constructorName = revivedObj.id[revivedObj.id.length - 1];
          let constructor;
          switch (constructorName) {
            case "Set":
              constructor = Set;
              break;
            case "Map":
              constructor = Map;
              break;
            case "RegExp":
              constructor = RegExp;
              break;
            case "Error":
              constructor = Error;
              break;
            default:
              return revivedObj;
          }
          if (revivedObj.method) {
            return constructor[revivedObj.method](...revivedObj.args || []);
          } else {
            return new constructor(...revivedObj.args || []);
          }
        } catch (error) {
          return revivedObj;
        }
      } else if (isLangChainSerializedObject(revivedObj)) {
        return load(JSON.stringify(revivedObj));
      }
      return revivedObj;
    }
  }
  return value;
}
function _encodeConstructorArgs(constructor, method, args, kwargs) {
  return {
    lc: 2,
    type: "constructor",
    id: [constructor.name],
    method: method ?? null,
    args: args ?? [],
    kwargs: kwargs ?? {}
  };
}
function _default(obj) {
  if (obj === void 0) {
    return {
      lc: 2,
      type: "undefined"
    };
  } else if (obj instanceof Set || obj instanceof Map) {
    return _encodeConstructorArgs(obj.constructor, void 0, [
      Array.from(obj)
    ]);
  } else if (obj instanceof RegExp) {
    return _encodeConstructorArgs(RegExp, void 0, [obj.source, obj.flags]);
  } else if (obj instanceof Error) {
    return _encodeConstructorArgs(obj.constructor, void 0, [obj.message]);
  } else if (obj?.lg_name === "Send") {
    return {
      node: obj.node,
      args: obj.args
    };
  } else {
    return obj;
  }
}
var JsonPlusSerializer = class {
  _dumps(obj) {
    const encoder = new TextEncoder();
    return encoder.encode(stringify(obj, (_2, value) => {
      return _default(value);
    }));
  }
  dumpsTyped(obj) {
    if (obj instanceof Uint8Array) {
      return ["bytes", obj];
    } else {
      return ["json", this._dumps(obj)];
    }
  }
  async _loads(data) {
    const parsed = JSON.parse(data);
    return _reviver(parsed);
  }
  async loadsTyped(type, data) {
    if (type === "bytes") {
      return typeof data === "string" ? new TextEncoder().encode(data) : data;
    } else if (type === "json") {
      return this._loads(typeof data === "string" ? data : new TextDecoder().decode(data));
    } else {
      throw new Error(`Unknown serialization type: ${type}`);
    }
  }
};

// ../../../node_modules/.pnpm/@langchain+langgraph-checkpoint@0.0.18_@langchain+core@0.3.61_@opentelemetry+api@1.9.0__a6099cbbd47045e82bada733957b498f/node_modules/@langchain/langgraph-checkpoint/dist/base.js
function deepCopy(obj) {
  if (typeof obj !== "object" || obj === null) {
    return obj;
  }
  const newObj = Array.isArray(obj) ? [] : {};
  for (const key in obj) {
    if (Object.prototype.hasOwnProperty.call(obj, key)) {
      newObj[key] = deepCopy(obj[key]);
    }
  }
  return newObj;
}
function emptyCheckpoint() {
  return {
    v: 1,
    id: uuid6(-2),
    ts: (/* @__PURE__ */ new Date()).toISOString(),
    channel_values: {},
    channel_versions: {},
    versions_seen: {},
    pending_sends: []
  };
}
function copyCheckpoint(checkpoint) {
  return {
    v: checkpoint.v,
    id: checkpoint.id,
    ts: checkpoint.ts,
    channel_values: { ...checkpoint.channel_values },
    channel_versions: { ...checkpoint.channel_versions },
    versions_seen: deepCopy(checkpoint.versions_seen),
    pending_sends: [...checkpoint.pending_sends]
  };
}
function compareChannelVersions(a, b2) {
  if (typeof a === "number" && typeof b2 === "number") {
    return Math.sign(a - b2);
  }
  return String(a).localeCompare(String(b2));
}
function maxChannelVersion(...versions) {
  return versions.reduce((max, version2, idx) => {
    if (idx === 0)
      return version2;
    return compareChannelVersions(max, version2) >= 0 ? max : version2;
  });
}
var WRITES_IDX_MAP = {
  [ERROR2]: -1,
  [SCHEDULED]: -2,
  [INTERRUPT]: -3,
  [RESUME]: -4
};

// ../../../node_modules/.pnpm/@langchain+langgraph-checkpoint@0.0.18_@langchain+core@0.3.61_@opentelemetry+api@1.9.0__a6099cbbd47045e82bada733957b498f/node_modules/@langchain/langgraph-checkpoint/dist/types.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph-checkpoint@0.0.18_@langchain+core@0.3.61_@opentelemetry+api@1.9.0__a6099cbbd47045e82bada733957b498f/node_modules/@langchain/langgraph-checkpoint/dist/serde/base.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph-checkpoint@0.0.18_@langchain+core@0.3.61_@opentelemetry+api@1.9.0__a6099cbbd47045e82bada733957b498f/node_modules/@langchain/langgraph-checkpoint/dist/store/index.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph-checkpoint@0.0.18_@langchain+core@0.3.61_@opentelemetry+api@1.9.0__a6099cbbd47045e82bada733957b498f/node_modules/@langchain/langgraph-checkpoint/dist/store/base.js
init_esm();
var InvalidNamespaceError = class extends Error {
  constructor(message) {
    super(message);
    this.name = "InvalidNamespaceError";
  }
};
function validateNamespace(namespace) {
  if (namespace.length === 0) {
    throw new InvalidNamespaceError("Namespace cannot be empty.");
  }
  for (const label of namespace) {
    if (typeof label !== "string") {
      throw new InvalidNamespaceError(`Invalid namespace label '${label}' found in ${namespace}. Namespace labels must be strings, but got ${typeof label}.`);
    }
    if (label.includes(".")) {
      throw new InvalidNamespaceError(`Invalid namespace label '${label}' found in ${namespace}. Namespace labels cannot contain periods ('.').`);
    }
    if (label === "") {
      throw new InvalidNamespaceError(`Namespace labels cannot be empty strings. Got ${label} in ${namespace}`);
    }
  }
  if (namespace[0] === "langgraph") {
    throw new InvalidNamespaceError(`Root label for namespace cannot be "langgraph". Got: ${namespace}`);
  }
}
var BaseStore2 = class {
  /**
   * Retrieve a single item by its namespace and key.
   *
   * @param namespace Hierarchical path for the item
   * @param key Unique identifier within the namespace
   * @returns Promise resolving to the item or null if not found
   */
  async get(namespace, key) {
    return (await this.batch([{ namespace, key }]))[0];
  }
  /**
   * Search for items within a namespace prefix.
   * Supports both metadata filtering and vector similarity search.
   *
   * @param namespacePrefix Hierarchical path prefix to search within
   * @param options Search options for filtering and pagination
   * @returns Promise resolving to list of matching items with relevance scores
   *
   * @example
   * // Search with filters
   * await store.search(["documents"], {
   *   filter: { type: "report", status: "active" },
   *   limit: 5,
   *   offset: 10
   * });
   *
   * // Vector similarity search
   * await store.search(["users", "content"], {
   *   query: "technical documentation about APIs",
   *   limit: 20
   * });
   */
  async search(namespacePrefix, options = {}) {
    const { filter, limit = 10, offset = 0, query } = options;
    return (await this.batch([
      {
        namespacePrefix,
        filter,
        limit,
        offset,
        query
      }
    ]))[0];
  }
  /**
   * Store or update an item.
   *
   * @param namespace Hierarchical path for the item
   * @param key Unique identifier within the namespace
   * @param value Object containing the item's data
   * @param index Optional indexing configuration
   *
   * @example
   * // Simple storage
   * await store.put(["docs"], "report", { title: "Annual Report" });
   *
   * // With specific field indexing
   * await store.put(
   *   ["docs"],
   *   "report",
   *   {
   *     title: "Q4 Report",
   *     chapters: [{ content: "..." }, { content: "..." }]
   *   },
   *   ["title", "chapters[*].content"]
   * );
   */
  async put(namespace, key, value, index) {
    validateNamespace(namespace);
    await this.batch([{ namespace, key, value, index }]);
  }
  /**
   * Delete an item from the store.
   *
   * @param namespace Hierarchical path for the item
   * @param key Unique identifier within the namespace
   */
  async delete(namespace, key) {
    await this.batch([{ namespace, key, value: null }]);
  }
  /**
   * List and filter namespaces in the store.
   * Used to explore data organization and navigate the namespace hierarchy.
   *
   * @param options Options for listing namespaces
   * @returns Promise resolving to list of namespace paths
   *
   * @example
   * // List all namespaces under "documents"
   * await store.listNamespaces({
   *   prefix: ["documents"],
   *   maxDepth: 2
   * });
   *
   * // List namespaces ending with "v1"
   * await store.listNamespaces({
   *   suffix: ["v1"],
   *   limit: 50
   * });
   */
  async listNamespaces(options = {}) {
    const { prefix, suffix, maxDepth, limit = 100, offset = 0 } = options;
    const matchConditions = [];
    if (prefix) {
      matchConditions.push({ matchType: "prefix", path: prefix });
    }
    if (suffix) {
      matchConditions.push({ matchType: "suffix", path: suffix });
    }
    return (await this.batch([
      {
        matchConditions: matchConditions.length ? matchConditions : void 0,
        maxDepth,
        limit,
        offset
      }
    ]))[0];
  }
  /**
   * Start the store. Override if initialization is needed.
   */
  start() {
  }
  /**
   * Stop the store. Override if cleanup is needed.
   */
  stop() {
  }
};

// ../../../node_modules/.pnpm/@langchain+langgraph-checkpoint@0.0.18_@langchain+core@0.3.61_@opentelemetry+api@1.9.0__a6099cbbd47045e82bada733957b498f/node_modules/@langchain/langgraph-checkpoint/dist/store/batch.js
init_esm();
var extractStore = (input) => {
  if ("lg_name" in input && input.lg_name === "AsyncBatchedStore") {
    return input.store;
  }
  return input;
};
var AsyncBatchedStore = class extends BaseStore2 {
  constructor(store6) {
    super();
    Object.defineProperty(this, "lg_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "AsyncBatchedStore"
    });
    Object.defineProperty(this, "store", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "queue", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: /* @__PURE__ */ new Map()
    });
    Object.defineProperty(this, "nextKey", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: 0
    });
    Object.defineProperty(this, "running", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    Object.defineProperty(this, "processingTask", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: null
    });
    this.store = extractStore(store6);
  }
  get isRunning() {
    return this.running;
  }
  /**
   * @ignore
   * Batch is not implemented here as we're only extending `BaseStore`
   * to allow it to be passed where `BaseStore` is expected, and implement
   * the convenience methods (get, search, put, delete).
   */
  async batch(_operations) {
    throw new Error("The `batch` method is not implemented on `AsyncBatchedStore`.\n Instead, it calls the `batch` method on the wrapped store.\n If you are seeing this error, something is wrong.");
  }
  async get(namespace, key) {
    return this.enqueueOperation({ namespace, key });
  }
  async search(namespacePrefix, options) {
    const { filter, limit = 10, offset = 0, query } = options || {};
    return this.enqueueOperation({
      namespacePrefix,
      filter,
      limit,
      offset,
      query
    });
  }
  async put(namespace, key, value) {
    return this.enqueueOperation({ namespace, key, value });
  }
  async delete(namespace, key) {
    return this.enqueueOperation({
      namespace,
      key,
      value: null
    });
  }
  start() {
    if (!this.running) {
      this.running = true;
      this.processingTask = this.processBatchQueue();
    }
  }
  async stop() {
    this.running = false;
    if (this.processingTask) {
      await this.processingTask;
    }
  }
  enqueueOperation(operation) {
    return new Promise((resolve, reject) => {
      const key = this.nextKey;
      this.nextKey += 1;
      this.queue.set(key, { operation, resolve, reject });
    });
  }
  async processBatchQueue() {
    while (this.running) {
      await new Promise((resolve) => {
        setTimeout(resolve, 0);
      });
      if (this.queue.size === 0)
        continue;
      const batch = new Map(this.queue);
      this.queue.clear();
      try {
        const operations = Array.from(batch.values()).map(({ operation }) => operation);
        const results = await this.store.batch(operations);
        batch.forEach(({ resolve }, key) => {
          const index = Array.from(batch.keys()).indexOf(key);
          resolve(results[index]);
        });
      } catch (e2) {
        batch.forEach(({ reject }) => {
          reject(e2);
        });
      }
    }
  }
  // AsyncBatchedStore is internal and gets passed as args into traced tasks
  // some BaseStores contain circular references so just serialize without it
  // as this causes warnings when tracing with LangSmith.
  toJSON() {
    return {
      queue: this.queue,
      nextKey: this.nextKey,
      running: this.running,
      store: "[LangGraphStore]"
    };
  }
};

// ../../../node_modules/.pnpm/@langchain+langgraph-checkpoint@0.0.18_@langchain+core@0.3.61_@opentelemetry+api@1.9.0__a6099cbbd47045e82bada733957b498f/node_modules/@langchain/langgraph-checkpoint/dist/store/memory.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph-checkpoint@0.0.18_@langchain+core@0.3.61_@opentelemetry+api@1.9.0__a6099cbbd47045e82bada733957b498f/node_modules/@langchain/langgraph-checkpoint/dist/store/utils.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph-checkpoint@0.0.18_@langchain+core@0.3.61_@opentelemetry+api@1.9.0__a6099cbbd47045e82bada733957b498f/node_modules/@langchain/langgraph-checkpoint/dist/cache/index.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph-checkpoint@0.0.18_@langchain+core@0.3.61_@opentelemetry+api@1.9.0__a6099cbbd47045e82bada733957b498f/node_modules/@langchain/langgraph-checkpoint/dist/cache/base.js
init_esm();
var BaseCache2 = class {
  /**
   * Initialize the cache with a serializer.
   *
   * @param serde - The serializer to use.
   */
  constructor(serde) {
    Object.defineProperty(this, "serde", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: new JsonPlusSerializer()
    });
    this.serde = serde || this.serde;
  }
};

// ../../../node_modules/.pnpm/@langchain+langgraph-checkpoint@0.0.18_@langchain+core@0.3.61_@opentelemetry+api@1.9.0__a6099cbbd47045e82bada733957b498f/node_modules/@langchain/langgraph-checkpoint/dist/cache/memory.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/channels/base.js
function isBaseChannel(obj) {
  return obj != null && obj.lg_is_channel === true;
}
var BaseChannel = class {
  constructor() {
    Object.defineProperty(this, "ValueType", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "UpdateType", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "lg_is_channel", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
  }
  /**
   * Mark the current value of the channel as consumed. By default, no-op.
   * A channel can use this method to modify its state, preventing the value
   * from being consumed again.
   *
   * Returns True if the channel was updated, False otherwise.
   */
  consume() {
    return false;
  }
  /**
   * Notify the channel that the Pregel run is finishing. By default, no-op.
   * A channel can use this method to modify its state, preventing finish.
   *
   * Returns True if the channel was updated, False otherwise.
   */
  finish() {
    return false;
  }
  /**
   * Return True if the channel is available (not empty), False otherwise.
   * Subclasses should override this method to provide a more efficient
   * implementation than calling get() and catching EmptyChannelError.
   */
  isAvailable() {
    try {
      this.get();
      return true;
    } catch (error) {
      if (error.name === EmptyChannelError.unminifiable_name) {
        return false;
      }
      throw error;
    }
  }
};
function emptyChannels(channels, checkpoint) {
  const filteredChannels = Object.fromEntries(Object.entries(channels).filter(([, value]) => isBaseChannel(value)));
  const newChannels = {};
  for (const k2 in filteredChannels) {
    if (Object.prototype.hasOwnProperty.call(filteredChannels, k2)) {
      const channelValue = checkpoint.channel_values[k2];
      newChannels[k2] = filteredChannels[k2].fromCheckpoint(channelValue);
    }
  }
  return newChannels;
}
function createCheckpoint(checkpoint, channels, step) {
  let values;
  if (channels === void 0) {
    values = checkpoint.channel_values;
  } else {
    values = {};
    for (const k2 of Object.keys(channels)) {
      try {
        values[k2] = channels[k2].checkpoint();
      } catch (error) {
        if (error.name === EmptyChannelError.unminifiable_name) {
        } else {
          throw error;
        }
      }
    }
  }
  return {
    v: 1,
    id: uuid6(step),
    ts: (/* @__PURE__ */ new Date()).toISOString(),
    channel_values: values,
    channel_versions: { ...checkpoint.channel_versions },
    versions_seen: deepCopy(checkpoint.versions_seen),
    pending_sends: checkpoint.pending_sends ?? []
  };
}

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/channels/binop.js
var BinaryOperatorAggregate = class _BinaryOperatorAggregate extends BaseChannel {
  constructor(operator, initialValueFactory) {
    super();
    Object.defineProperty(this, "lc_graph_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "BinaryOperatorAggregate"
    });
    Object.defineProperty(this, "value", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "operator", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "initialValueFactory", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.operator = operator;
    this.initialValueFactory = initialValueFactory;
    this.value = initialValueFactory?.();
  }
  fromCheckpoint(checkpoint) {
    const empty = new _BinaryOperatorAggregate(this.operator, this.initialValueFactory);
    if (typeof checkpoint !== "undefined") {
      empty.value = checkpoint;
    }
    return empty;
  }
  update(values) {
    let newValues = values;
    if (!newValues.length)
      return false;
    if (this.value === void 0) {
      [this.value] = newValues;
      newValues = newValues.slice(1);
    }
    for (const value of newValues) {
      if (this.value !== void 0) {
        this.value = this.operator(this.value, value);
      }
    }
    return true;
  }
  get() {
    if (this.value === void 0) {
      throw new EmptyChannelError();
    }
    return this.value;
  }
  checkpoint() {
    if (this.value === void 0) {
      throw new EmptyChannelError();
    }
    return this.value;
  }
  isAvailable() {
    return this.value !== void 0;
  }
};

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/channels/last_value.js
init_esm();
var LastValue = class _LastValue extends BaseChannel {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_graph_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "LastValue"
    });
    Object.defineProperty(this, "value", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
  }
  fromCheckpoint(checkpoint) {
    const empty = new _LastValue();
    if (typeof checkpoint !== "undefined") {
      empty.value = [checkpoint];
    }
    return empty;
  }
  update(values) {
    if (values.length === 0) {
      return false;
    }
    if (values.length !== 1) {
      throw new InvalidUpdateError("LastValue can only receive one value per step.", { lc_error_code: "INVALID_CONCURRENT_GRAPH_UPDATE" });
    }
    this.value = [values[values.length - 1]];
    return true;
  }
  get() {
    if (this.value.length === 0) {
      throw new EmptyChannelError();
    }
    return this.value[0];
  }
  checkpoint() {
    if (this.value.length === 0) {
      throw new EmptyChannelError();
    }
    return this.value[0];
  }
  isAvailable() {
    return this.value.length !== 0;
  }
};
var LastValueAfterFinish = class _LastValueAfterFinish extends BaseChannel {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_graph_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "LastValueAfterFinish"
    });
    Object.defineProperty(this, "value", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    Object.defineProperty(this, "finished", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
  }
  fromCheckpoint(checkpoint) {
    const empty = new _LastValueAfterFinish();
    if (typeof checkpoint !== "undefined") {
      const [value, finished] = checkpoint;
      empty.value = [value];
      empty.finished = finished;
    }
    return empty;
  }
  update(values) {
    if (values.length === 0) {
      return false;
    }
    this.finished = false;
    this.value = [values[values.length - 1]];
    return true;
  }
  get() {
    if (this.value.length === 0 || !this.finished) {
      throw new EmptyChannelError();
    }
    return this.value[0];
  }
  checkpoint() {
    if (this.value.length === 0)
      return void 0;
    return [this.value[0], this.finished];
  }
  consume() {
    if (this.finished) {
      this.finished = false;
      this.value = [];
      return true;
    }
    return false;
  }
  finish() {
    if (!this.finished && this.value.length > 0) {
      this.finished = true;
      return true;
    }
    return false;
  }
  isAvailable() {
    return this.value.length !== 0 && this.finished;
  }
};

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/managed/base.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/constants.js
init_esm();
var START = "__start__";
var END = "__end__";
var INPUT = "__input__";
var COPY = "__copy__";
var ERROR3 = "__error__";
var CACHE_NS_WRITES = "__pregel_ns_writes";
var CONFIG_KEY_SEND = "__pregel_send";
var CONFIG_KEY_CALL = "__pregel_call";
var CONFIG_KEY_READ = "__pregel_read";
var CONFIG_KEY_CHECKPOINTER = "__pregel_checkpointer";
var CONFIG_KEY_RESUMING = "__pregel_resuming";
var CONFIG_KEY_TASK_ID = "__pregel_task_id";
var CONFIG_KEY_STREAM = "__pregel_stream";
var CONFIG_KEY_RESUME_VALUE = "__pregel_resume_value";
var CONFIG_KEY_SCRATCHPAD = "__pregel_scratchpad";
var CONFIG_KEY_PREVIOUS_STATE = "__pregel_previous";
var CONFIG_KEY_CHECKPOINT_ID = "checkpoint_id";
var CONFIG_KEY_CHECKPOINT_NS = "checkpoint_ns";
var CONFIG_KEY_NODE_FINISHED = "__pregel_node_finished";
var CONFIG_KEY_CHECKPOINT_MAP = "checkpoint_map";
var CONFIG_KEY_ABORT_SIGNALS = "__pregel_abort_signals";
var INTERRUPT2 = "__interrupt__";
var RESUME2 = "__resume__";
var NO_WRITES = "__no_writes__";
var RETURN = "__return__";
var PREVIOUS = "__previous__";
var RUNTIME_PLACEHOLDER = "__pregel_runtime_placeholder__";
var TAG_HIDDEN = "langsmith:hidden";
var TAG_NOSTREAM = "langsmith:nostream";
var SELF = "__self__";
var TASKS2 = "__pregel_tasks";
var PUSH = "__pregel_push";
var PULL = "__pregel_pull";
var NULL_TASK_ID = "00000000-0000-0000-0000-000000000000";
var RESERVED = [
  TAG_HIDDEN,
  INPUT,
  INTERRUPT2,
  RESUME2,
  ERROR3,
  NO_WRITES,
  TASKS2,
  // reserved config.configurable keys
  CONFIG_KEY_SEND,
  CONFIG_KEY_READ,
  CONFIG_KEY_CHECKPOINTER,
  CONFIG_KEY_STREAM,
  CONFIG_KEY_RESUMING,
  CONFIG_KEY_TASK_ID,
  CONFIG_KEY_CALL,
  CONFIG_KEY_RESUME_VALUE,
  CONFIG_KEY_SCRATCHPAD,
  CONFIG_KEY_PREVIOUS_STATE,
  CONFIG_KEY_CHECKPOINT_MAP,
  CONFIG_KEY_CHECKPOINT_NS,
  CONFIG_KEY_CHECKPOINT_ID
];
var CHECKPOINT_NAMESPACE_SEPARATOR = "|";
var CHECKPOINT_NAMESPACE_END = ":";
function _isSendInterface(x2) {
  const operation = x2;
  return operation !== null && operation !== void 0 && typeof operation.node === "string" && operation.args !== void 0;
}
var Send = class {
  constructor(node, args) {
    Object.defineProperty(this, "lg_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "Send"
    });
    Object.defineProperty(this, "node", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "args", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.node = node;
    this.args = _deserializeCommandSendObjectGraph(args);
  }
  toJSON() {
    return { lg_name: this.lg_name, node: this.node, args: this.args };
  }
};
function _isSend(x2) {
  return x2 instanceof Send;
}
function isInterrupted(values) {
  if (!values || typeof values !== "object")
    return false;
  if (!(INTERRUPT2 in values))
    return false;
  return Array.isArray(values[INTERRUPT2]);
}
var Command = class {
  constructor(args) {
    Object.defineProperty(this, "lg_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "Command"
    });
    Object.defineProperty(this, "lc_direct_tool_output", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "graph", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "update", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "resume", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "goto", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    this.resume = args.resume;
    this.graph = args.graph;
    this.update = args.update;
    if (args.goto) {
      this.goto = Array.isArray(args.goto) ? _deserializeCommandSendObjectGraph(args.goto) : [_deserializeCommandSendObjectGraph(args.goto)];
    }
  }
  /**
   * Convert the update field to a list of {@link PendingWrite} tuples
   * @returns List of {@link PendingWrite} tuples of the form `[channelKey, value]`.
   * @internal
   */
  _updateAsTuples() {
    if (this.update && typeof this.update === "object" && !Array.isArray(this.update)) {
      return Object.entries(this.update);
    } else if (Array.isArray(this.update) && this.update.every((t2) => Array.isArray(t2) && t2.length === 2 && typeof t2[0] === "string")) {
      return this.update;
    } else {
      return [["__root__", this.update]];
    }
  }
  toJSON() {
    let serializedGoto;
    if (typeof this.goto === "string") {
      serializedGoto = this.goto;
    } else if (_isSend(this.goto)) {
      serializedGoto = this.goto.toJSON();
    } else {
      serializedGoto = this.goto?.map((innerGoto) => {
        if (typeof innerGoto === "string") {
          return innerGoto;
        } else {
          return innerGoto.toJSON();
        }
      });
    }
    return {
      lg_name: this.lg_name,
      update: this.update,
      resume: this.resume,
      goto: serializedGoto
    };
  }
};
Object.defineProperty(Command, "PARENT", {
  enumerable: true,
  configurable: true,
  writable: true,
  value: "__parent__"
});
function isCommand(x2) {
  if (typeof x2 !== "object") {
    return false;
  }
  if (x2 === null || x2 === void 0) {
    return false;
  }
  if ("lg_name" in x2 && x2.lg_name === "Command") {
    return true;
  }
  return false;
}
function _deserializeCommandSendObjectGraph(x2, seen = /* @__PURE__ */ new Map()) {
  if (x2 !== void 0 && x2 !== null && typeof x2 === "object") {
    if (seen.has(x2)) {
      return seen.get(x2);
    }
    let result;
    if (Array.isArray(x2)) {
      result = [];
      seen.set(x2, result);
      x2.forEach((item, index) => {
        result[index] = _deserializeCommandSendObjectGraph(item, seen);
      });
    } else if (isCommand(x2) && !(x2 instanceof Command)) {
      result = new Command(x2);
      seen.set(x2, result);
    } else if (_isSendInterface(x2) && !(x2 instanceof Send)) {
      result = new Send(x2.node, x2.args);
      seen.set(x2, result);
    } else if (isCommand(x2) || _isSend(x2)) {
      result = x2;
      seen.set(x2, result);
    } else if ("lc_serializable" in x2 && x2.lc_serializable) {
      result = x2;
      seen.set(x2, result);
    } else {
      result = {};
      seen.set(x2, result);
      for (const [key, value] of Object.entries(x2)) {
        result[key] = _deserializeCommandSendObjectGraph(value, seen);
      }
    }
    return result;
  }
  return x2;
}

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/managed/base.js
var ManagedValue = class {
  constructor(config, _params) {
    Object.defineProperty(this, "runtime", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    Object.defineProperty(this, "config", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "_promises", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    Object.defineProperty(this, "lg_is_managed_value", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    this.config = config;
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  static async initialize(_config, _args) {
    throw new Error("Not implemented");
  }
  async promises() {
    return Promise.all(this._promises);
  }
  addPromise(promise) {
    this._promises.push(promise);
  }
};
var ChannelKeyPlaceholder = "__channel_key_placeholder__";
var ManagedValueMapping = class extends Map {
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  constructor(entries) {
    super(entries ? Array.from(entries) : void 0);
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  replaceRuntimeValues(step, values) {
    if (this.size === 0 || !values) {
      return;
    }
    if (Array.from(this.values()).every((mv) => !mv.runtime)) {
      return;
    }
    if (typeof values === "object" && !Array.isArray(values)) {
      for (const [key, value] of Object.entries(values)) {
        for (const [chan, mv] of this.entries()) {
          if (mv.runtime && mv.call(step) === value) {
            values[key] = { [RUNTIME_PLACEHOLDER]: chan };
          }
        }
      }
    } else if (typeof values === "object" && "constructor" in values) {
      for (const key of Object.getOwnPropertyNames(Object.getPrototypeOf(values))) {
        try {
          const value = values[key];
          for (const [chan, mv] of this.entries()) {
            if (mv.runtime && mv.call(step) === value) {
              values[key] = { [RUNTIME_PLACEHOLDER]: chan };
            }
          }
        } catch (error) {
          if (error.name !== TypeError.name) {
            throw error;
          }
        }
      }
    }
  }
  replaceRuntimePlaceholders(step, values) {
    if (this.size === 0 || !values) {
      return;
    }
    if (Array.from(this.values()).every((mv) => !mv.runtime)) {
      return;
    }
    if (typeof values === "object" && !Array.isArray(values)) {
      for (const [key, value] of Object.entries(values)) {
        if (typeof value === "object" && value !== null && RUNTIME_PLACEHOLDER in value) {
          const placeholder = value[RUNTIME_PLACEHOLDER];
          if (typeof placeholder === "string") {
            values[key] = this.get(placeholder)?.call(step);
          }
        }
      }
    } else if (typeof values === "object" && "constructor" in values) {
      for (const key of Object.getOwnPropertyNames(Object.getPrototypeOf(values))) {
        try {
          const value = values[key];
          if (typeof value === "object" && value !== null && RUNTIME_PLACEHOLDER in value) {
            const managedValue = this.get(value[RUNTIME_PLACEHOLDER]);
            if (managedValue) {
              values[key] = managedValue.call(step);
            }
          }
        } catch (error) {
          if (error.name !== TypeError.name) {
            throw error;
          }
        }
      }
    }
  }
};
function isConfiguredManagedValue(value) {
  if (typeof value === "object" && value && "cls" in value && "params" in value) {
    return true;
  }
  return false;
}
var NoopManagedValue = class _NoopManagedValue extends ManagedValue {
  call() {
  }
  static async initialize(config, _args) {
    return Promise.resolve(new _NoopManagedValue(config));
  }
};

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/graph/annotation.js
var AnnotationRoot = class {
  constructor(s2) {
    Object.defineProperty(this, "lc_graph_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "AnnotationRoot"
    });
    Object.defineProperty(this, "spec", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.spec = s2;
  }
};
var Annotation = function(annotation) {
  if (isConfiguredManagedValue(annotation)) {
    return annotation;
  } else if (annotation) {
    return getChannel(annotation);
  } else {
    return new LastValue();
  }
};
Annotation.Root = (sd) => new AnnotationRoot(sd);
function getChannel(reducer) {
  if (typeof reducer === "object" && reducer && "reducer" in reducer && reducer.reducer) {
    return new BinaryOperatorAggregate(reducer.reducer, reducer.default);
  }
  if (typeof reducer === "object" && reducer && "value" in reducer && reducer.value) {
    return new BinaryOperatorAggregate(reducer.value, reducer.default);
  }
  return new LastValue();
}

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/graph/graph.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/runnables.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/runnables/graph.js
init_esm();

// ../../../node_modules/.pnpm/zod@3.24.4/node_modules/zod/lib/index.mjs
init_esm();
var util;
(function(util2) {
  util2.assertEqual = (val) => val;
  function assertIs(_arg) {
  }
  util2.assertIs = assertIs;
  function assertNever(_x) {
    throw new Error();
  }
  util2.assertNever = assertNever;
  util2.arrayToEnum = (items) => {
    const obj = {};
    for (const item of items) {
      obj[item] = item;
    }
    return obj;
  };
  util2.getValidEnumValues = (obj) => {
    const validKeys = util2.objectKeys(obj).filter((k2) => typeof obj[obj[k2]] !== "number");
    const filtered = {};
    for (const k2 of validKeys) {
      filtered[k2] = obj[k2];
    }
    return util2.objectValues(filtered);
  };
  util2.objectValues = (obj) => {
    return util2.objectKeys(obj).map(function(e2) {
      return obj[e2];
    });
  };
  util2.objectKeys = typeof Object.keys === "function" ? (obj) => Object.keys(obj) : (object2) => {
    const keys = [];
    for (const key in object2) {
      if (Object.prototype.hasOwnProperty.call(object2, key)) {
        keys.push(key);
      }
    }
    return keys;
  };
  util2.find = (arr2, checker) => {
    for (const item of arr2) {
      if (checker(item))
        return item;
    }
    return void 0;
  };
  util2.isInteger = typeof Number.isInteger === "function" ? (val) => Number.isInteger(val) : (val) => typeof val === "number" && isFinite(val) && Math.floor(val) === val;
  function joinValues(array2, separator = " | ") {
    return array2.map((val) => typeof val === "string" ? `'${val}'` : val).join(separator);
  }
  util2.joinValues = joinValues;
  util2.jsonStringifyReplacer = (_2, value) => {
    if (typeof value === "bigint") {
      return value.toString();
    }
    return value;
  };
})(util || (util = {}));
var objectUtil;
(function(objectUtil2) {
  objectUtil2.mergeShapes = (first, second) => {
    return {
      ...first,
      ...second
      // second overwrites first
    };
  };
})(objectUtil || (objectUtil = {}));
var ZodParsedType = util.arrayToEnum([
  "string",
  "nan",
  "number",
  "integer",
  "float",
  "boolean",
  "date",
  "bigint",
  "symbol",
  "function",
  "undefined",
  "null",
  "array",
  "object",
  "unknown",
  "promise",
  "void",
  "never",
  "map",
  "set"
]);
var getParsedType = (data) => {
  const t2 = typeof data;
  switch (t2) {
    case "undefined":
      return ZodParsedType.undefined;
    case "string":
      return ZodParsedType.string;
    case "number":
      return isNaN(data) ? ZodParsedType.nan : ZodParsedType.number;
    case "boolean":
      return ZodParsedType.boolean;
    case "function":
      return ZodParsedType.function;
    case "bigint":
      return ZodParsedType.bigint;
    case "symbol":
      return ZodParsedType.symbol;
    case "object":
      if (Array.isArray(data)) {
        return ZodParsedType.array;
      }
      if (data === null) {
        return ZodParsedType.null;
      }
      if (data.then && typeof data.then === "function" && data.catch && typeof data.catch === "function") {
        return ZodParsedType.promise;
      }
      if (typeof Map !== "undefined" && data instanceof Map) {
        return ZodParsedType.map;
      }
      if (typeof Set !== "undefined" && data instanceof Set) {
        return ZodParsedType.set;
      }
      if (typeof Date !== "undefined" && data instanceof Date) {
        return ZodParsedType.date;
      }
      return ZodParsedType.object;
    default:
      return ZodParsedType.unknown;
  }
};
var ZodIssueCode = util.arrayToEnum([
  "invalid_type",
  "invalid_literal",
  "custom",
  "invalid_union",
  "invalid_union_discriminator",
  "invalid_enum_value",
  "unrecognized_keys",
  "invalid_arguments",
  "invalid_return_type",
  "invalid_date",
  "invalid_string",
  "too_small",
  "too_big",
  "invalid_intersection_types",
  "not_multiple_of",
  "not_finite"
]);
var quotelessJson = (obj) => {
  const json = JSON.stringify(obj, null, 2);
  return json.replace(/"([^"]+)":/g, "$1:");
};
var ZodError = class _ZodError extends Error {
  get errors() {
    return this.issues;
  }
  constructor(issues) {
    super();
    this.issues = [];
    this.addIssue = (sub) => {
      this.issues = [...this.issues, sub];
    };
    this.addIssues = (subs = []) => {
      this.issues = [...this.issues, ...subs];
    };
    const actualProto = new.target.prototype;
    if (Object.setPrototypeOf) {
      Object.setPrototypeOf(this, actualProto);
    } else {
      this.__proto__ = actualProto;
    }
    this.name = "ZodError";
    this.issues = issues;
  }
  format(_mapper) {
    const mapper = _mapper || function(issue) {
      return issue.message;
    };
    const fieldErrors = { _errors: [] };
    const processError = (error) => {
      for (const issue of error.issues) {
        if (issue.code === "invalid_union") {
          issue.unionErrors.map(processError);
        } else if (issue.code === "invalid_return_type") {
          processError(issue.returnTypeError);
        } else if (issue.code === "invalid_arguments") {
          processError(issue.argumentsError);
        } else if (issue.path.length === 0) {
          fieldErrors._errors.push(mapper(issue));
        } else {
          let curr = fieldErrors;
          let i2 = 0;
          while (i2 < issue.path.length) {
            const el = issue.path[i2];
            const terminal = i2 === issue.path.length - 1;
            if (!terminal) {
              curr[el] = curr[el] || { _errors: [] };
            } else {
              curr[el] = curr[el] || { _errors: [] };
              curr[el]._errors.push(mapper(issue));
            }
            curr = curr[el];
            i2++;
          }
        }
      }
    };
    processError(this);
    return fieldErrors;
  }
  static assert(value) {
    if (!(value instanceof _ZodError)) {
      throw new Error(`Not a ZodError: ${value}`);
    }
  }
  toString() {
    return this.message;
  }
  get message() {
    return JSON.stringify(this.issues, util.jsonStringifyReplacer, 2);
  }
  get isEmpty() {
    return this.issues.length === 0;
  }
  flatten(mapper = (issue) => issue.message) {
    const fieldErrors = {};
    const formErrors = [];
    for (const sub of this.issues) {
      if (sub.path.length > 0) {
        fieldErrors[sub.path[0]] = fieldErrors[sub.path[0]] || [];
        fieldErrors[sub.path[0]].push(mapper(sub));
      } else {
        formErrors.push(mapper(sub));
      }
    }
    return { formErrors, fieldErrors };
  }
  get formErrors() {
    return this.flatten();
  }
};
ZodError.create = (issues) => {
  const error = new ZodError(issues);
  return error;
};
var errorMap = (issue, _ctx) => {
  let message;
  switch (issue.code) {
    case ZodIssueCode.invalid_type:
      if (issue.received === ZodParsedType.undefined) {
        message = "Required";
      } else {
        message = `Expected ${issue.expected}, received ${issue.received}`;
      }
      break;
    case ZodIssueCode.invalid_literal:
      message = `Invalid literal value, expected ${JSON.stringify(issue.expected, util.jsonStringifyReplacer)}`;
      break;
    case ZodIssueCode.unrecognized_keys:
      message = `Unrecognized key(s) in object: ${util.joinValues(issue.keys, ", ")}`;
      break;
    case ZodIssueCode.invalid_union:
      message = `Invalid input`;
      break;
    case ZodIssueCode.invalid_union_discriminator:
      message = `Invalid discriminator value. Expected ${util.joinValues(issue.options)}`;
      break;
    case ZodIssueCode.invalid_enum_value:
      message = `Invalid enum value. Expected ${util.joinValues(issue.options)}, received '${issue.received}'`;
      break;
    case ZodIssueCode.invalid_arguments:
      message = `Invalid function arguments`;
      break;
    case ZodIssueCode.invalid_return_type:
      message = `Invalid function return type`;
      break;
    case ZodIssueCode.invalid_date:
      message = `Invalid date`;
      break;
    case ZodIssueCode.invalid_string:
      if (typeof issue.validation === "object") {
        if ("includes" in issue.validation) {
          message = `Invalid input: must include "${issue.validation.includes}"`;
          if (typeof issue.validation.position === "number") {
            message = `${message} at one or more positions greater than or equal to ${issue.validation.position}`;
          }
        } else if ("startsWith" in issue.validation) {
          message = `Invalid input: must start with "${issue.validation.startsWith}"`;
        } else if ("endsWith" in issue.validation) {
          message = `Invalid input: must end with "${issue.validation.endsWith}"`;
        } else {
          util.assertNever(issue.validation);
        }
      } else if (issue.validation !== "regex") {
        message = `Invalid ${issue.validation}`;
      } else {
        message = "Invalid";
      }
      break;
    case ZodIssueCode.too_small:
      if (issue.type === "array")
        message = `Array must contain ${issue.exact ? "exactly" : issue.inclusive ? `at least` : `more than`} ${issue.minimum} element(s)`;
      else if (issue.type === "string")
        message = `String must contain ${issue.exact ? "exactly" : issue.inclusive ? `at least` : `over`} ${issue.minimum} character(s)`;
      else if (issue.type === "number")
        message = `Number must be ${issue.exact ? `exactly equal to ` : issue.inclusive ? `greater than or equal to ` : `greater than `}${issue.minimum}`;
      else if (issue.type === "date")
        message = `Date must be ${issue.exact ? `exactly equal to ` : issue.inclusive ? `greater than or equal to ` : `greater than `}${new Date(Number(issue.minimum))}`;
      else
        message = "Invalid input";
      break;
    case ZodIssueCode.too_big:
      if (issue.type === "array")
        message = `Array must contain ${issue.exact ? `exactly` : issue.inclusive ? `at most` : `less than`} ${issue.maximum} element(s)`;
      else if (issue.type === "string")
        message = `String must contain ${issue.exact ? `exactly` : issue.inclusive ? `at most` : `under`} ${issue.maximum} character(s)`;
      else if (issue.type === "number")
        message = `Number must be ${issue.exact ? `exactly` : issue.inclusive ? `less than or equal to` : `less than`} ${issue.maximum}`;
      else if (issue.type === "bigint")
        message = `BigInt must be ${issue.exact ? `exactly` : issue.inclusive ? `less than or equal to` : `less than`} ${issue.maximum}`;
      else if (issue.type === "date")
        message = `Date must be ${issue.exact ? `exactly` : issue.inclusive ? `smaller than or equal to` : `smaller than`} ${new Date(Number(issue.maximum))}`;
      else
        message = "Invalid input";
      break;
    case ZodIssueCode.custom:
      message = `Invalid input`;
      break;
    case ZodIssueCode.invalid_intersection_types:
      message = `Intersection results could not be merged`;
      break;
    case ZodIssueCode.not_multiple_of:
      message = `Number must be a multiple of ${issue.multipleOf}`;
      break;
    case ZodIssueCode.not_finite:
      message = "Number must be finite";
      break;
    default:
      message = _ctx.defaultError;
      util.assertNever(issue);
  }
  return { message };
};
var overrideErrorMap = errorMap;
function setErrorMap(map) {
  overrideErrorMap = map;
}
function getErrorMap() {
  return overrideErrorMap;
}
var makeIssue = (params) => {
  const { data, path, errorMaps, issueData } = params;
  const fullPath = [...path, ...issueData.path || []];
  const fullIssue = {
    ...issueData,
    path: fullPath
  };
  if (issueData.message !== void 0) {
    return {
      ...issueData,
      path: fullPath,
      message: issueData.message
    };
  }
  let errorMessage = "";
  const maps = errorMaps.filter((m2) => !!m2).slice().reverse();
  for (const map of maps) {
    errorMessage = map(fullIssue, { data, defaultError: errorMessage }).message;
  }
  return {
    ...issueData,
    path: fullPath,
    message: errorMessage
  };
};
var EMPTY_PATH = [];
function addIssueToContext(ctx, issueData) {
  const overrideMap = getErrorMap();
  const issue = makeIssue({
    issueData,
    data: ctx.data,
    path: ctx.path,
    errorMaps: [
      ctx.common.contextualErrorMap,
      // contextual error map is first priority
      ctx.schemaErrorMap,
      // then schema-bound map if available
      overrideMap,
      // then global override map
      overrideMap === errorMap ? void 0 : errorMap
      // then global default map
    ].filter((x2) => !!x2)
  });
  ctx.common.issues.push(issue);
}
var ParseStatus = class _ParseStatus {
  constructor() {
    this.value = "valid";
  }
  dirty() {
    if (this.value === "valid")
      this.value = "dirty";
  }
  abort() {
    if (this.value !== "aborted")
      this.value = "aborted";
  }
  static mergeArray(status, results) {
    const arrayValue = [];
    for (const s2 of results) {
      if (s2.status === "aborted")
        return INVALID;
      if (s2.status === "dirty")
        status.dirty();
      arrayValue.push(s2.value);
    }
    return { status: status.value, value: arrayValue };
  }
  static async mergeObjectAsync(status, pairs) {
    const syncPairs = [];
    for (const pair of pairs) {
      const key = await pair.key;
      const value = await pair.value;
      syncPairs.push({
        key,
        value
      });
    }
    return _ParseStatus.mergeObjectSync(status, syncPairs);
  }
  static mergeObjectSync(status, pairs) {
    const finalObject = {};
    for (const pair of pairs) {
      const { key, value } = pair;
      if (key.status === "aborted")
        return INVALID;
      if (value.status === "aborted")
        return INVALID;
      if (key.status === "dirty")
        status.dirty();
      if (value.status === "dirty")
        status.dirty();
      if (key.value !== "__proto__" && (typeof value.value !== "undefined" || pair.alwaysSet)) {
        finalObject[key.value] = value.value;
      }
    }
    return { status: status.value, value: finalObject };
  }
};
var INVALID = Object.freeze({
  status: "aborted"
});
var DIRTY = (value) => ({ status: "dirty", value });
var OK = (value) => ({ status: "valid", value });
var isAborted = (x2) => x2.status === "aborted";
var isDirty = (x2) => x2.status === "dirty";
var isValid = (x2) => x2.status === "valid";
var isAsync = (x2) => typeof Promise !== "undefined" && x2 instanceof Promise;
function __classPrivateFieldGet(receiver, state, kind, f) {
  if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a getter");
  if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot read private member from an object whose class did not declare it");
  return kind === "m" ? f : kind === "a" ? f.call(receiver) : f ? f.value : state.get(receiver);
}
function __classPrivateFieldSet(receiver, state, value, kind, f) {
  if (kind === "m") throw new TypeError("Private method is not writable");
  if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a setter");
  if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot write private member to an object whose class did not declare it");
  return kind === "a" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value), value;
}
var errorUtil;
(function(errorUtil2) {
  errorUtil2.errToObj = (message) => typeof message === "string" ? { message } : message || {};
  errorUtil2.toString = (message) => typeof message === "string" ? message : message === null || message === void 0 ? void 0 : message.message;
})(errorUtil || (errorUtil = {}));
var _ZodEnum_cache;
var _ZodNativeEnum_cache;
var ParseInputLazyPath = class {
  constructor(parent, value, path, key) {
    this._cachedPath = [];
    this.parent = parent;
    this.data = value;
    this._path = path;
    this._key = key;
  }
  get path() {
    if (!this._cachedPath.length) {
      if (this._key instanceof Array) {
        this._cachedPath.push(...this._path, ...this._key);
      } else {
        this._cachedPath.push(...this._path, this._key);
      }
    }
    return this._cachedPath;
  }
};
var handleResult = (ctx, result) => {
  if (isValid(result)) {
    return { success: true, data: result.value };
  } else {
    if (!ctx.common.issues.length) {
      throw new Error("Validation failed but no issues detected.");
    }
    return {
      success: false,
      get error() {
        if (this._error)
          return this._error;
        const error = new ZodError(ctx.common.issues);
        this._error = error;
        return this._error;
      }
    };
  }
};
function processCreateParams(params) {
  if (!params)
    return {};
  const { errorMap: errorMap2, invalid_type_error, required_error, description } = params;
  if (errorMap2 && (invalid_type_error || required_error)) {
    throw new Error(`Can't use "invalid_type_error" or "required_error" in conjunction with custom error map.`);
  }
  if (errorMap2)
    return { errorMap: errorMap2, description };
  const customMap = (iss, ctx) => {
    var _a, _b;
    const { message } = params;
    if (iss.code === "invalid_enum_value") {
      return { message: message !== null && message !== void 0 ? message : ctx.defaultError };
    }
    if (typeof ctx.data === "undefined") {
      return { message: (_a = message !== null && message !== void 0 ? message : required_error) !== null && _a !== void 0 ? _a : ctx.defaultError };
    }
    if (iss.code !== "invalid_type")
      return { message: ctx.defaultError };
    return { message: (_b = message !== null && message !== void 0 ? message : invalid_type_error) !== null && _b !== void 0 ? _b : ctx.defaultError };
  };
  return { errorMap: customMap, description };
}
var ZodType = class {
  get description() {
    return this._def.description;
  }
  _getType(input) {
    return getParsedType(input.data);
  }
  _getOrReturnCtx(input, ctx) {
    return ctx || {
      common: input.parent.common,
      data: input.data,
      parsedType: getParsedType(input.data),
      schemaErrorMap: this._def.errorMap,
      path: input.path,
      parent: input.parent
    };
  }
  _processInputParams(input) {
    return {
      status: new ParseStatus(),
      ctx: {
        common: input.parent.common,
        data: input.data,
        parsedType: getParsedType(input.data),
        schemaErrorMap: this._def.errorMap,
        path: input.path,
        parent: input.parent
      }
    };
  }
  _parseSync(input) {
    const result = this._parse(input);
    if (isAsync(result)) {
      throw new Error("Synchronous parse encountered promise.");
    }
    return result;
  }
  _parseAsync(input) {
    const result = this._parse(input);
    return Promise.resolve(result);
  }
  parse(data, params) {
    const result = this.safeParse(data, params);
    if (result.success)
      return result.data;
    throw result.error;
  }
  safeParse(data, params) {
    var _a;
    const ctx = {
      common: {
        issues: [],
        async: (_a = params === null || params === void 0 ? void 0 : params.async) !== null && _a !== void 0 ? _a : false,
        contextualErrorMap: params === null || params === void 0 ? void 0 : params.errorMap
      },
      path: (params === null || params === void 0 ? void 0 : params.path) || [],
      schemaErrorMap: this._def.errorMap,
      parent: null,
      data,
      parsedType: getParsedType(data)
    };
    const result = this._parseSync({ data, path: ctx.path, parent: ctx });
    return handleResult(ctx, result);
  }
  "~validate"(data) {
    var _a, _b;
    const ctx = {
      common: {
        issues: [],
        async: !!this["~standard"].async
      },
      path: [],
      schemaErrorMap: this._def.errorMap,
      parent: null,
      data,
      parsedType: getParsedType(data)
    };
    if (!this["~standard"].async) {
      try {
        const result = this._parseSync({ data, path: [], parent: ctx });
        return isValid(result) ? {
          value: result.value
        } : {
          issues: ctx.common.issues
        };
      } catch (err3) {
        if ((_b = (_a = err3 === null || err3 === void 0 ? void 0 : err3.message) === null || _a === void 0 ? void 0 : _a.toLowerCase()) === null || _b === void 0 ? void 0 : _b.includes("encountered")) {
          this["~standard"].async = true;
        }
        ctx.common = {
          issues: [],
          async: true
        };
      }
    }
    return this._parseAsync({ data, path: [], parent: ctx }).then((result) => isValid(result) ? {
      value: result.value
    } : {
      issues: ctx.common.issues
    });
  }
  async parseAsync(data, params) {
    const result = await this.safeParseAsync(data, params);
    if (result.success)
      return result.data;
    throw result.error;
  }
  async safeParseAsync(data, params) {
    const ctx = {
      common: {
        issues: [],
        contextualErrorMap: params === null || params === void 0 ? void 0 : params.errorMap,
        async: true
      },
      path: (params === null || params === void 0 ? void 0 : params.path) || [],
      schemaErrorMap: this._def.errorMap,
      parent: null,
      data,
      parsedType: getParsedType(data)
    };
    const maybeAsyncResult = this._parse({ data, path: ctx.path, parent: ctx });
    const result = await (isAsync(maybeAsyncResult) ? maybeAsyncResult : Promise.resolve(maybeAsyncResult));
    return handleResult(ctx, result);
  }
  refine(check, message) {
    const getIssueProperties = (val) => {
      if (typeof message === "string" || typeof message === "undefined") {
        return { message };
      } else if (typeof message === "function") {
        return message(val);
      } else {
        return message;
      }
    };
    return this._refinement((val, ctx) => {
      const result = check(val);
      const setError = () => ctx.addIssue({
        code: ZodIssueCode.custom,
        ...getIssueProperties(val)
      });
      if (typeof Promise !== "undefined" && result instanceof Promise) {
        return result.then((data) => {
          if (!data) {
            setError();
            return false;
          } else {
            return true;
          }
        });
      }
      if (!result) {
        setError();
        return false;
      } else {
        return true;
      }
    });
  }
  refinement(check, refinementData) {
    return this._refinement((val, ctx) => {
      if (!check(val)) {
        ctx.addIssue(typeof refinementData === "function" ? refinementData(val, ctx) : refinementData);
        return false;
      } else {
        return true;
      }
    });
  }
  _refinement(refinement) {
    return new ZodEffects({
      schema: this,
      typeName: ZodFirstPartyTypeKind.ZodEffects,
      effect: { type: "refinement", refinement }
    });
  }
  superRefine(refinement) {
    return this._refinement(refinement);
  }
  constructor(def) {
    this.spa = this.safeParseAsync;
    this._def = def;
    this.parse = this.parse.bind(this);
    this.safeParse = this.safeParse.bind(this);
    this.parseAsync = this.parseAsync.bind(this);
    this.safeParseAsync = this.safeParseAsync.bind(this);
    this.spa = this.spa.bind(this);
    this.refine = this.refine.bind(this);
    this.refinement = this.refinement.bind(this);
    this.superRefine = this.superRefine.bind(this);
    this.optional = this.optional.bind(this);
    this.nullable = this.nullable.bind(this);
    this.nullish = this.nullish.bind(this);
    this.array = this.array.bind(this);
    this.promise = this.promise.bind(this);
    this.or = this.or.bind(this);
    this.and = this.and.bind(this);
    this.transform = this.transform.bind(this);
    this.brand = this.brand.bind(this);
    this.default = this.default.bind(this);
    this.catch = this.catch.bind(this);
    this.describe = this.describe.bind(this);
    this.pipe = this.pipe.bind(this);
    this.readonly = this.readonly.bind(this);
    this.isNullable = this.isNullable.bind(this);
    this.isOptional = this.isOptional.bind(this);
    this["~standard"] = {
      version: 1,
      vendor: "zod",
      validate: (data) => this["~validate"](data)
    };
  }
  optional() {
    return ZodOptional.create(this, this._def);
  }
  nullable() {
    return ZodNullable.create(this, this._def);
  }
  nullish() {
    return this.nullable().optional();
  }
  array() {
    return ZodArray.create(this);
  }
  promise() {
    return ZodPromise.create(this, this._def);
  }
  or(option) {
    return ZodUnion.create([this, option], this._def);
  }
  and(incoming) {
    return ZodIntersection.create(this, incoming, this._def);
  }
  transform(transform) {
    return new ZodEffects({
      ...processCreateParams(this._def),
      schema: this,
      typeName: ZodFirstPartyTypeKind.ZodEffects,
      effect: { type: "transform", transform }
    });
  }
  default(def) {
    const defaultValueFunc = typeof def === "function" ? def : () => def;
    return new ZodDefault({
      ...processCreateParams(this._def),
      innerType: this,
      defaultValue: defaultValueFunc,
      typeName: ZodFirstPartyTypeKind.ZodDefault
    });
  }
  brand() {
    return new ZodBranded({
      typeName: ZodFirstPartyTypeKind.ZodBranded,
      type: this,
      ...processCreateParams(this._def)
    });
  }
  catch(def) {
    const catchValueFunc = typeof def === "function" ? def : () => def;
    return new ZodCatch({
      ...processCreateParams(this._def),
      innerType: this,
      catchValue: catchValueFunc,
      typeName: ZodFirstPartyTypeKind.ZodCatch
    });
  }
  describe(description) {
    const This = this.constructor;
    return new This({
      ...this._def,
      description
    });
  }
  pipe(target) {
    return ZodPipeline.create(this, target);
  }
  readonly() {
    return ZodReadonly.create(this);
  }
  isOptional() {
    return this.safeParse(void 0).success;
  }
  isNullable() {
    return this.safeParse(null).success;
  }
};
var cuidRegex = /^c[^\s-]{8,}$/i;
var cuid2Regex = /^[0-9a-z]+$/;
var ulidRegex = /^[0-9A-HJKMNP-TV-Z]{26}$/i;
var uuidRegex = /^[0-9a-fA-F]{8}\b-[0-9a-fA-F]{4}\b-[0-9a-fA-F]{4}\b-[0-9a-fA-F]{4}\b-[0-9a-fA-F]{12}$/i;
var nanoidRegex = /^[a-z0-9_-]{21}$/i;
var jwtRegex = /^[A-Za-z0-9-_]+\.[A-Za-z0-9-_]+\.[A-Za-z0-9-_]*$/;
var durationRegex = /^[-+]?P(?!$)(?:(?:[-+]?\d+Y)|(?:[-+]?\d+[.,]\d+Y$))?(?:(?:[-+]?\d+M)|(?:[-+]?\d+[.,]\d+M$))?(?:(?:[-+]?\d+W)|(?:[-+]?\d+[.,]\d+W$))?(?:(?:[-+]?\d+D)|(?:[-+]?\d+[.,]\d+D$))?(?:T(?=[\d+-])(?:(?:[-+]?\d+H)|(?:[-+]?\d+[.,]\d+H$))?(?:(?:[-+]?\d+M)|(?:[-+]?\d+[.,]\d+M$))?(?:[-+]?\d+(?:[.,]\d+)?S)?)??$/;
var emailRegex = /^(?!\.)(?!.*\.\.)([A-Z0-9_'+\-\.]*)[A-Z0-9_+-]@([A-Z0-9][A-Z0-9\-]*\.)+[A-Z]{2,}$/i;
var _emojiRegex = `^(\\p{Extended_Pictographic}|\\p{Emoji_Component})+$`;
var emojiRegex;
var ipv4Regex = /^(?:(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])\.){3}(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])$/;
var ipv4CidrRegex = /^(?:(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])\.){3}(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])\/(3[0-2]|[12]?[0-9])$/;
var ipv6Regex = /^(([0-9a-fA-F]{1,4}:){7,7}[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,7}:|([0-9a-fA-F]{1,4}:){1,6}:[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,5}(:[0-9a-fA-F]{1,4}){1,2}|([0-9a-fA-F]{1,4}:){1,4}(:[0-9a-fA-F]{1,4}){1,3}|([0-9a-fA-F]{1,4}:){1,3}(:[0-9a-fA-F]{1,4}){1,4}|([0-9a-fA-F]{1,4}:){1,2}(:[0-9a-fA-F]{1,4}){1,5}|[0-9a-fA-F]{1,4}:((:[0-9a-fA-F]{1,4}){1,6})|:((:[0-9a-fA-F]{1,4}){1,7}|:)|fe80:(:[0-9a-fA-F]{0,4}){0,4}%[0-9a-zA-Z]{1,}|::(ffff(:0{1,4}){0,1}:){0,1}((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])|([0-9a-fA-F]{1,4}:){1,4}:((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9]))$/;
var ipv6CidrRegex = /^(([0-9a-fA-F]{1,4}:){7,7}[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,7}:|([0-9a-fA-F]{1,4}:){1,6}:[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,5}(:[0-9a-fA-F]{1,4}){1,2}|([0-9a-fA-F]{1,4}:){1,4}(:[0-9a-fA-F]{1,4}){1,3}|([0-9a-fA-F]{1,4}:){1,3}(:[0-9a-fA-F]{1,4}){1,4}|([0-9a-fA-F]{1,4}:){1,2}(:[0-9a-fA-F]{1,4}){1,5}|[0-9a-fA-F]{1,4}:((:[0-9a-fA-F]{1,4}){1,6})|:((:[0-9a-fA-F]{1,4}){1,7}|:)|fe80:(:[0-9a-fA-F]{0,4}){0,4}%[0-9a-zA-Z]{1,}|::(ffff(:0{1,4}){0,1}:){0,1}((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])|([0-9a-fA-F]{1,4}:){1,4}:((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9]))\/(12[0-8]|1[01][0-9]|[1-9]?[0-9])$/;
var base64Regex = /^([0-9a-zA-Z+/]{4})*(([0-9a-zA-Z+/]{2}==)|([0-9a-zA-Z+/]{3}=))?$/;
var base64urlRegex = /^([0-9a-zA-Z-_]{4})*(([0-9a-zA-Z-_]{2}(==)?)|([0-9a-zA-Z-_]{3}(=)?))?$/;
var dateRegexSource = `((\\d\\d[2468][048]|\\d\\d[13579][26]|\\d\\d0[48]|[02468][048]00|[13579][26]00)-02-29|\\d{4}-((0[13578]|1[02])-(0[1-9]|[12]\\d|3[01])|(0[469]|11)-(0[1-9]|[12]\\d|30)|(02)-(0[1-9]|1\\d|2[0-8])))`;
var dateRegex = new RegExp(`^${dateRegexSource}$`);
function timeRegexSource(args) {
  let secondsRegexSource = `[0-5]\\d`;
  if (args.precision) {
    secondsRegexSource = `${secondsRegexSource}\\.\\d{${args.precision}}`;
  } else if (args.precision == null) {
    secondsRegexSource = `${secondsRegexSource}(\\.\\d+)?`;
  }
  const secondsQuantifier = args.precision ? "+" : "?";
  return `([01]\\d|2[0-3]):[0-5]\\d(:${secondsRegexSource})${secondsQuantifier}`;
}
function timeRegex(args) {
  return new RegExp(`^${timeRegexSource(args)}$`);
}
function datetimeRegex(args) {
  let regex2 = `${dateRegexSource}T${timeRegexSource(args)}`;
  const opts = [];
  opts.push(args.local ? `Z?` : `Z`);
  if (args.offset)
    opts.push(`([+-]\\d{2}:?\\d{2})`);
  regex2 = `${regex2}(${opts.join("|")})`;
  return new RegExp(`^${regex2}$`);
}
function isValidIP(ip, version2) {
  if ((version2 === "v4" || !version2) && ipv4Regex.test(ip)) {
    return true;
  }
  if ((version2 === "v6" || !version2) && ipv6Regex.test(ip)) {
    return true;
  }
  return false;
}
function isValidJWT(jwt, alg) {
  if (!jwtRegex.test(jwt))
    return false;
  try {
    const [header] = jwt.split(".");
    const base64 = header.replace(/-/g, "+").replace(/_/g, "/").padEnd(header.length + (4 - header.length % 4) % 4, "=");
    const decoded = JSON.parse(atob(base64));
    if (typeof decoded !== "object" || decoded === null)
      return false;
    if (!decoded.typ || !decoded.alg)
      return false;
    if (alg && decoded.alg !== alg)
      return false;
    return true;
  } catch (_a) {
    return false;
  }
}
function isValidCidr(ip, version2) {
  if ((version2 === "v4" || !version2) && ipv4CidrRegex.test(ip)) {
    return true;
  }
  if ((version2 === "v6" || !version2) && ipv6CidrRegex.test(ip)) {
    return true;
  }
  return false;
}
var ZodString = class _ZodString extends ZodType {
  _parse(input) {
    if (this._def.coerce) {
      input.data = String(input.data);
    }
    const parsedType = this._getType(input);
    if (parsedType !== ZodParsedType.string) {
      const ctx2 = this._getOrReturnCtx(input);
      addIssueToContext(ctx2, {
        code: ZodIssueCode.invalid_type,
        expected: ZodParsedType.string,
        received: ctx2.parsedType
      });
      return INVALID;
    }
    const status = new ParseStatus();
    let ctx = void 0;
    for (const check of this._def.checks) {
      if (check.kind === "min") {
        if (input.data.length < check.value) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            code: ZodIssueCode.too_small,
            minimum: check.value,
            type: "string",
            inclusive: true,
            exact: false,
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "max") {
        if (input.data.length > check.value) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            code: ZodIssueCode.too_big,
            maximum: check.value,
            type: "string",
            inclusive: true,
            exact: false,
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "length") {
        const tooBig = input.data.length > check.value;
        const tooSmall = input.data.length < check.value;
        if (tooBig || tooSmall) {
          ctx = this._getOrReturnCtx(input, ctx);
          if (tooBig) {
            addIssueToContext(ctx, {
              code: ZodIssueCode.too_big,
              maximum: check.value,
              type: "string",
              inclusive: true,
              exact: true,
              message: check.message
            });
          } else if (tooSmall) {
            addIssueToContext(ctx, {
              code: ZodIssueCode.too_small,
              minimum: check.value,
              type: "string",
              inclusive: true,
              exact: true,
              message: check.message
            });
          }
          status.dirty();
        }
      } else if (check.kind === "email") {
        if (!emailRegex.test(input.data)) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            validation: "email",
            code: ZodIssueCode.invalid_string,
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "emoji") {
        if (!emojiRegex) {
          emojiRegex = new RegExp(_emojiRegex, "u");
        }
        if (!emojiRegex.test(input.data)) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            validation: "emoji",
            code: ZodIssueCode.invalid_string,
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "uuid") {
        if (!uuidRegex.test(input.data)) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            validation: "uuid",
            code: ZodIssueCode.invalid_string,
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "nanoid") {
        if (!nanoidRegex.test(input.data)) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            validation: "nanoid",
            code: ZodIssueCode.invalid_string,
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "cuid") {
        if (!cuidRegex.test(input.data)) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            validation: "cuid",
            code: ZodIssueCode.invalid_string,
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "cuid2") {
        if (!cuid2Regex.test(input.data)) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            validation: "cuid2",
            code: ZodIssueCode.invalid_string,
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "ulid") {
        if (!ulidRegex.test(input.data)) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            validation: "ulid",
            code: ZodIssueCode.invalid_string,
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "url") {
        try {
          new URL(input.data);
        } catch (_a) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            validation: "url",
            code: ZodIssueCode.invalid_string,
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "regex") {
        check.regex.lastIndex = 0;
        const testResult = check.regex.test(input.data);
        if (!testResult) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            validation: "regex",
            code: ZodIssueCode.invalid_string,
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "trim") {
        input.data = input.data.trim();
      } else if (check.kind === "includes") {
        if (!input.data.includes(check.value, check.position)) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            code: ZodIssueCode.invalid_string,
            validation: { includes: check.value, position: check.position },
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "toLowerCase") {
        input.data = input.data.toLowerCase();
      } else if (check.kind === "toUpperCase") {
        input.data = input.data.toUpperCase();
      } else if (check.kind === "startsWith") {
        if (!input.data.startsWith(check.value)) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            code: ZodIssueCode.invalid_string,
            validation: { startsWith: check.value },
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "endsWith") {
        if (!input.data.endsWith(check.value)) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            code: ZodIssueCode.invalid_string,
            validation: { endsWith: check.value },
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "datetime") {
        const regex2 = datetimeRegex(check);
        if (!regex2.test(input.data)) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            code: ZodIssueCode.invalid_string,
            validation: "datetime",
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "date") {
        const regex2 = dateRegex;
        if (!regex2.test(input.data)) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            code: ZodIssueCode.invalid_string,
            validation: "date",
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "time") {
        const regex2 = timeRegex(check);
        if (!regex2.test(input.data)) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            code: ZodIssueCode.invalid_string,
            validation: "time",
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "duration") {
        if (!durationRegex.test(input.data)) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            validation: "duration",
            code: ZodIssueCode.invalid_string,
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "ip") {
        if (!isValidIP(input.data, check.version)) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            validation: "ip",
            code: ZodIssueCode.invalid_string,
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "jwt") {
        if (!isValidJWT(input.data, check.alg)) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            validation: "jwt",
            code: ZodIssueCode.invalid_string,
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "cidr") {
        if (!isValidCidr(input.data, check.version)) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            validation: "cidr",
            code: ZodIssueCode.invalid_string,
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "base64") {
        if (!base64Regex.test(input.data)) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            validation: "base64",
            code: ZodIssueCode.invalid_string,
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "base64url") {
        if (!base64urlRegex.test(input.data)) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            validation: "base64url",
            code: ZodIssueCode.invalid_string,
            message: check.message
          });
          status.dirty();
        }
      } else {
        util.assertNever(check);
      }
    }
    return { status: status.value, value: input.data };
  }
  _regex(regex2, validation, message) {
    return this.refinement((data) => regex2.test(data), {
      validation,
      code: ZodIssueCode.invalid_string,
      ...errorUtil.errToObj(message)
    });
  }
  _addCheck(check) {
    return new _ZodString({
      ...this._def,
      checks: [...this._def.checks, check]
    });
  }
  email(message) {
    return this._addCheck({ kind: "email", ...errorUtil.errToObj(message) });
  }
  url(message) {
    return this._addCheck({ kind: "url", ...errorUtil.errToObj(message) });
  }
  emoji(message) {
    return this._addCheck({ kind: "emoji", ...errorUtil.errToObj(message) });
  }
  uuid(message) {
    return this._addCheck({ kind: "uuid", ...errorUtil.errToObj(message) });
  }
  nanoid(message) {
    return this._addCheck({ kind: "nanoid", ...errorUtil.errToObj(message) });
  }
  cuid(message) {
    return this._addCheck({ kind: "cuid", ...errorUtil.errToObj(message) });
  }
  cuid2(message) {
    return this._addCheck({ kind: "cuid2", ...errorUtil.errToObj(message) });
  }
  ulid(message) {
    return this._addCheck({ kind: "ulid", ...errorUtil.errToObj(message) });
  }
  base64(message) {
    return this._addCheck({ kind: "base64", ...errorUtil.errToObj(message) });
  }
  base64url(message) {
    return this._addCheck({
      kind: "base64url",
      ...errorUtil.errToObj(message)
    });
  }
  jwt(options) {
    return this._addCheck({ kind: "jwt", ...errorUtil.errToObj(options) });
  }
  ip(options) {
    return this._addCheck({ kind: "ip", ...errorUtil.errToObj(options) });
  }
  cidr(options) {
    return this._addCheck({ kind: "cidr", ...errorUtil.errToObj(options) });
  }
  datetime(options) {
    var _a, _b;
    if (typeof options === "string") {
      return this._addCheck({
        kind: "datetime",
        precision: null,
        offset: false,
        local: false,
        message: options
      });
    }
    return this._addCheck({
      kind: "datetime",
      precision: typeof (options === null || options === void 0 ? void 0 : options.precision) === "undefined" ? null : options === null || options === void 0 ? void 0 : options.precision,
      offset: (_a = options === null || options === void 0 ? void 0 : options.offset) !== null && _a !== void 0 ? _a : false,
      local: (_b = options === null || options === void 0 ? void 0 : options.local) !== null && _b !== void 0 ? _b : false,
      ...errorUtil.errToObj(options === null || options === void 0 ? void 0 : options.message)
    });
  }
  date(message) {
    return this._addCheck({ kind: "date", message });
  }
  time(options) {
    if (typeof options === "string") {
      return this._addCheck({
        kind: "time",
        precision: null,
        message: options
      });
    }
    return this._addCheck({
      kind: "time",
      precision: typeof (options === null || options === void 0 ? void 0 : options.precision) === "undefined" ? null : options === null || options === void 0 ? void 0 : options.precision,
      ...errorUtil.errToObj(options === null || options === void 0 ? void 0 : options.message)
    });
  }
  duration(message) {
    return this._addCheck({ kind: "duration", ...errorUtil.errToObj(message) });
  }
  regex(regex2, message) {
    return this._addCheck({
      kind: "regex",
      regex: regex2,
      ...errorUtil.errToObj(message)
    });
  }
  includes(value, options) {
    return this._addCheck({
      kind: "includes",
      value,
      position: options === null || options === void 0 ? void 0 : options.position,
      ...errorUtil.errToObj(options === null || options === void 0 ? void 0 : options.message)
    });
  }
  startsWith(value, message) {
    return this._addCheck({
      kind: "startsWith",
      value,
      ...errorUtil.errToObj(message)
    });
  }
  endsWith(value, message) {
    return this._addCheck({
      kind: "endsWith",
      value,
      ...errorUtil.errToObj(message)
    });
  }
  min(minLength, message) {
    return this._addCheck({
      kind: "min",
      value: minLength,
      ...errorUtil.errToObj(message)
    });
  }
  max(maxLength, message) {
    return this._addCheck({
      kind: "max",
      value: maxLength,
      ...errorUtil.errToObj(message)
    });
  }
  length(len, message) {
    return this._addCheck({
      kind: "length",
      value: len,
      ...errorUtil.errToObj(message)
    });
  }
  /**
   * Equivalent to `.min(1)`
   */
  nonempty(message) {
    return this.min(1, errorUtil.errToObj(message));
  }
  trim() {
    return new _ZodString({
      ...this._def,
      checks: [...this._def.checks, { kind: "trim" }]
    });
  }
  toLowerCase() {
    return new _ZodString({
      ...this._def,
      checks: [...this._def.checks, { kind: "toLowerCase" }]
    });
  }
  toUpperCase() {
    return new _ZodString({
      ...this._def,
      checks: [...this._def.checks, { kind: "toUpperCase" }]
    });
  }
  get isDatetime() {
    return !!this._def.checks.find((ch) => ch.kind === "datetime");
  }
  get isDate() {
    return !!this._def.checks.find((ch) => ch.kind === "date");
  }
  get isTime() {
    return !!this._def.checks.find((ch) => ch.kind === "time");
  }
  get isDuration() {
    return !!this._def.checks.find((ch) => ch.kind === "duration");
  }
  get isEmail() {
    return !!this._def.checks.find((ch) => ch.kind === "email");
  }
  get isURL() {
    return !!this._def.checks.find((ch) => ch.kind === "url");
  }
  get isEmoji() {
    return !!this._def.checks.find((ch) => ch.kind === "emoji");
  }
  get isUUID() {
    return !!this._def.checks.find((ch) => ch.kind === "uuid");
  }
  get isNANOID() {
    return !!this._def.checks.find((ch) => ch.kind === "nanoid");
  }
  get isCUID() {
    return !!this._def.checks.find((ch) => ch.kind === "cuid");
  }
  get isCUID2() {
    return !!this._def.checks.find((ch) => ch.kind === "cuid2");
  }
  get isULID() {
    return !!this._def.checks.find((ch) => ch.kind === "ulid");
  }
  get isIP() {
    return !!this._def.checks.find((ch) => ch.kind === "ip");
  }
  get isCIDR() {
    return !!this._def.checks.find((ch) => ch.kind === "cidr");
  }
  get isBase64() {
    return !!this._def.checks.find((ch) => ch.kind === "base64");
  }
  get isBase64url() {
    return !!this._def.checks.find((ch) => ch.kind === "base64url");
  }
  get minLength() {
    let min = null;
    for (const ch of this._def.checks) {
      if (ch.kind === "min") {
        if (min === null || ch.value > min)
          min = ch.value;
      }
    }
    return min;
  }
  get maxLength() {
    let max = null;
    for (const ch of this._def.checks) {
      if (ch.kind === "max") {
        if (max === null || ch.value < max)
          max = ch.value;
      }
    }
    return max;
  }
};
ZodString.create = (params) => {
  var _a;
  return new ZodString({
    checks: [],
    typeName: ZodFirstPartyTypeKind.ZodString,
    coerce: (_a = params === null || params === void 0 ? void 0 : params.coerce) !== null && _a !== void 0 ? _a : false,
    ...processCreateParams(params)
  });
};
function floatSafeRemainder(val, step) {
  const valDecCount = (val.toString().split(".")[1] || "").length;
  const stepDecCount = (step.toString().split(".")[1] || "").length;
  const decCount = valDecCount > stepDecCount ? valDecCount : stepDecCount;
  const valInt = parseInt(val.toFixed(decCount).replace(".", ""));
  const stepInt = parseInt(step.toFixed(decCount).replace(".", ""));
  return valInt % stepInt / Math.pow(10, decCount);
}
var ZodNumber = class _ZodNumber extends ZodType {
  constructor() {
    super(...arguments);
    this.min = this.gte;
    this.max = this.lte;
    this.step = this.multipleOf;
  }
  _parse(input) {
    if (this._def.coerce) {
      input.data = Number(input.data);
    }
    const parsedType = this._getType(input);
    if (parsedType !== ZodParsedType.number) {
      const ctx2 = this._getOrReturnCtx(input);
      addIssueToContext(ctx2, {
        code: ZodIssueCode.invalid_type,
        expected: ZodParsedType.number,
        received: ctx2.parsedType
      });
      return INVALID;
    }
    let ctx = void 0;
    const status = new ParseStatus();
    for (const check of this._def.checks) {
      if (check.kind === "int") {
        if (!util.isInteger(input.data)) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            code: ZodIssueCode.invalid_type,
            expected: "integer",
            received: "float",
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "min") {
        const tooSmall = check.inclusive ? input.data < check.value : input.data <= check.value;
        if (tooSmall) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            code: ZodIssueCode.too_small,
            minimum: check.value,
            type: "number",
            inclusive: check.inclusive,
            exact: false,
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "max") {
        const tooBig = check.inclusive ? input.data > check.value : input.data >= check.value;
        if (tooBig) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            code: ZodIssueCode.too_big,
            maximum: check.value,
            type: "number",
            inclusive: check.inclusive,
            exact: false,
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "multipleOf") {
        if (floatSafeRemainder(input.data, check.value) !== 0) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            code: ZodIssueCode.not_multiple_of,
            multipleOf: check.value,
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "finite") {
        if (!Number.isFinite(input.data)) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            code: ZodIssueCode.not_finite,
            message: check.message
          });
          status.dirty();
        }
      } else {
        util.assertNever(check);
      }
    }
    return { status: status.value, value: input.data };
  }
  gte(value, message) {
    return this.setLimit("min", value, true, errorUtil.toString(message));
  }
  gt(value, message) {
    return this.setLimit("min", value, false, errorUtil.toString(message));
  }
  lte(value, message) {
    return this.setLimit("max", value, true, errorUtil.toString(message));
  }
  lt(value, message) {
    return this.setLimit("max", value, false, errorUtil.toString(message));
  }
  setLimit(kind, value, inclusive, message) {
    return new _ZodNumber({
      ...this._def,
      checks: [
        ...this._def.checks,
        {
          kind,
          value,
          inclusive,
          message: errorUtil.toString(message)
        }
      ]
    });
  }
  _addCheck(check) {
    return new _ZodNumber({
      ...this._def,
      checks: [...this._def.checks, check]
    });
  }
  int(message) {
    return this._addCheck({
      kind: "int",
      message: errorUtil.toString(message)
    });
  }
  positive(message) {
    return this._addCheck({
      kind: "min",
      value: 0,
      inclusive: false,
      message: errorUtil.toString(message)
    });
  }
  negative(message) {
    return this._addCheck({
      kind: "max",
      value: 0,
      inclusive: false,
      message: errorUtil.toString(message)
    });
  }
  nonpositive(message) {
    return this._addCheck({
      kind: "max",
      value: 0,
      inclusive: true,
      message: errorUtil.toString(message)
    });
  }
  nonnegative(message) {
    return this._addCheck({
      kind: "min",
      value: 0,
      inclusive: true,
      message: errorUtil.toString(message)
    });
  }
  multipleOf(value, message) {
    return this._addCheck({
      kind: "multipleOf",
      value,
      message: errorUtil.toString(message)
    });
  }
  finite(message) {
    return this._addCheck({
      kind: "finite",
      message: errorUtil.toString(message)
    });
  }
  safe(message) {
    return this._addCheck({
      kind: "min",
      inclusive: true,
      value: Number.MIN_SAFE_INTEGER,
      message: errorUtil.toString(message)
    })._addCheck({
      kind: "max",
      inclusive: true,
      value: Number.MAX_SAFE_INTEGER,
      message: errorUtil.toString(message)
    });
  }
  get minValue() {
    let min = null;
    for (const ch of this._def.checks) {
      if (ch.kind === "min") {
        if (min === null || ch.value > min)
          min = ch.value;
      }
    }
    return min;
  }
  get maxValue() {
    let max = null;
    for (const ch of this._def.checks) {
      if (ch.kind === "max") {
        if (max === null || ch.value < max)
          max = ch.value;
      }
    }
    return max;
  }
  get isInt() {
    return !!this._def.checks.find((ch) => ch.kind === "int" || ch.kind === "multipleOf" && util.isInteger(ch.value));
  }
  get isFinite() {
    let max = null, min = null;
    for (const ch of this._def.checks) {
      if (ch.kind === "finite" || ch.kind === "int" || ch.kind === "multipleOf") {
        return true;
      } else if (ch.kind === "min") {
        if (min === null || ch.value > min)
          min = ch.value;
      } else if (ch.kind === "max") {
        if (max === null || ch.value < max)
          max = ch.value;
      }
    }
    return Number.isFinite(min) && Number.isFinite(max);
  }
};
ZodNumber.create = (params) => {
  return new ZodNumber({
    checks: [],
    typeName: ZodFirstPartyTypeKind.ZodNumber,
    coerce: (params === null || params === void 0 ? void 0 : params.coerce) || false,
    ...processCreateParams(params)
  });
};
var ZodBigInt = class _ZodBigInt extends ZodType {
  constructor() {
    super(...arguments);
    this.min = this.gte;
    this.max = this.lte;
  }
  _parse(input) {
    if (this._def.coerce) {
      try {
        input.data = BigInt(input.data);
      } catch (_a) {
        return this._getInvalidInput(input);
      }
    }
    const parsedType = this._getType(input);
    if (parsedType !== ZodParsedType.bigint) {
      return this._getInvalidInput(input);
    }
    let ctx = void 0;
    const status = new ParseStatus();
    for (const check of this._def.checks) {
      if (check.kind === "min") {
        const tooSmall = check.inclusive ? input.data < check.value : input.data <= check.value;
        if (tooSmall) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            code: ZodIssueCode.too_small,
            type: "bigint",
            minimum: check.value,
            inclusive: check.inclusive,
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "max") {
        const tooBig = check.inclusive ? input.data > check.value : input.data >= check.value;
        if (tooBig) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            code: ZodIssueCode.too_big,
            type: "bigint",
            maximum: check.value,
            inclusive: check.inclusive,
            message: check.message
          });
          status.dirty();
        }
      } else if (check.kind === "multipleOf") {
        if (input.data % check.value !== BigInt(0)) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            code: ZodIssueCode.not_multiple_of,
            multipleOf: check.value,
            message: check.message
          });
          status.dirty();
        }
      } else {
        util.assertNever(check);
      }
    }
    return { status: status.value, value: input.data };
  }
  _getInvalidInput(input) {
    const ctx = this._getOrReturnCtx(input);
    addIssueToContext(ctx, {
      code: ZodIssueCode.invalid_type,
      expected: ZodParsedType.bigint,
      received: ctx.parsedType
    });
    return INVALID;
  }
  gte(value, message) {
    return this.setLimit("min", value, true, errorUtil.toString(message));
  }
  gt(value, message) {
    return this.setLimit("min", value, false, errorUtil.toString(message));
  }
  lte(value, message) {
    return this.setLimit("max", value, true, errorUtil.toString(message));
  }
  lt(value, message) {
    return this.setLimit("max", value, false, errorUtil.toString(message));
  }
  setLimit(kind, value, inclusive, message) {
    return new _ZodBigInt({
      ...this._def,
      checks: [
        ...this._def.checks,
        {
          kind,
          value,
          inclusive,
          message: errorUtil.toString(message)
        }
      ]
    });
  }
  _addCheck(check) {
    return new _ZodBigInt({
      ...this._def,
      checks: [...this._def.checks, check]
    });
  }
  positive(message) {
    return this._addCheck({
      kind: "min",
      value: BigInt(0),
      inclusive: false,
      message: errorUtil.toString(message)
    });
  }
  negative(message) {
    return this._addCheck({
      kind: "max",
      value: BigInt(0),
      inclusive: false,
      message: errorUtil.toString(message)
    });
  }
  nonpositive(message) {
    return this._addCheck({
      kind: "max",
      value: BigInt(0),
      inclusive: true,
      message: errorUtil.toString(message)
    });
  }
  nonnegative(message) {
    return this._addCheck({
      kind: "min",
      value: BigInt(0),
      inclusive: true,
      message: errorUtil.toString(message)
    });
  }
  multipleOf(value, message) {
    return this._addCheck({
      kind: "multipleOf",
      value,
      message: errorUtil.toString(message)
    });
  }
  get minValue() {
    let min = null;
    for (const ch of this._def.checks) {
      if (ch.kind === "min") {
        if (min === null || ch.value > min)
          min = ch.value;
      }
    }
    return min;
  }
  get maxValue() {
    let max = null;
    for (const ch of this._def.checks) {
      if (ch.kind === "max") {
        if (max === null || ch.value < max)
          max = ch.value;
      }
    }
    return max;
  }
};
ZodBigInt.create = (params) => {
  var _a;
  return new ZodBigInt({
    checks: [],
    typeName: ZodFirstPartyTypeKind.ZodBigInt,
    coerce: (_a = params === null || params === void 0 ? void 0 : params.coerce) !== null && _a !== void 0 ? _a : false,
    ...processCreateParams(params)
  });
};
var ZodBoolean = class extends ZodType {
  _parse(input) {
    if (this._def.coerce) {
      input.data = Boolean(input.data);
    }
    const parsedType = this._getType(input);
    if (parsedType !== ZodParsedType.boolean) {
      const ctx = this._getOrReturnCtx(input);
      addIssueToContext(ctx, {
        code: ZodIssueCode.invalid_type,
        expected: ZodParsedType.boolean,
        received: ctx.parsedType
      });
      return INVALID;
    }
    return OK(input.data);
  }
};
ZodBoolean.create = (params) => {
  return new ZodBoolean({
    typeName: ZodFirstPartyTypeKind.ZodBoolean,
    coerce: (params === null || params === void 0 ? void 0 : params.coerce) || false,
    ...processCreateParams(params)
  });
};
var ZodDate = class _ZodDate extends ZodType {
  _parse(input) {
    if (this._def.coerce) {
      input.data = new Date(input.data);
    }
    const parsedType = this._getType(input);
    if (parsedType !== ZodParsedType.date) {
      const ctx2 = this._getOrReturnCtx(input);
      addIssueToContext(ctx2, {
        code: ZodIssueCode.invalid_type,
        expected: ZodParsedType.date,
        received: ctx2.parsedType
      });
      return INVALID;
    }
    if (isNaN(input.data.getTime())) {
      const ctx2 = this._getOrReturnCtx(input);
      addIssueToContext(ctx2, {
        code: ZodIssueCode.invalid_date
      });
      return INVALID;
    }
    const status = new ParseStatus();
    let ctx = void 0;
    for (const check of this._def.checks) {
      if (check.kind === "min") {
        if (input.data.getTime() < check.value) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            code: ZodIssueCode.too_small,
            message: check.message,
            inclusive: true,
            exact: false,
            minimum: check.value,
            type: "date"
          });
          status.dirty();
        }
      } else if (check.kind === "max") {
        if (input.data.getTime() > check.value) {
          ctx = this._getOrReturnCtx(input, ctx);
          addIssueToContext(ctx, {
            code: ZodIssueCode.too_big,
            message: check.message,
            inclusive: true,
            exact: false,
            maximum: check.value,
            type: "date"
          });
          status.dirty();
        }
      } else {
        util.assertNever(check);
      }
    }
    return {
      status: status.value,
      value: new Date(input.data.getTime())
    };
  }
  _addCheck(check) {
    return new _ZodDate({
      ...this._def,
      checks: [...this._def.checks, check]
    });
  }
  min(minDate, message) {
    return this._addCheck({
      kind: "min",
      value: minDate.getTime(),
      message: errorUtil.toString(message)
    });
  }
  max(maxDate, message) {
    return this._addCheck({
      kind: "max",
      value: maxDate.getTime(),
      message: errorUtil.toString(message)
    });
  }
  get minDate() {
    let min = null;
    for (const ch of this._def.checks) {
      if (ch.kind === "min") {
        if (min === null || ch.value > min)
          min = ch.value;
      }
    }
    return min != null ? new Date(min) : null;
  }
  get maxDate() {
    let max = null;
    for (const ch of this._def.checks) {
      if (ch.kind === "max") {
        if (max === null || ch.value < max)
          max = ch.value;
      }
    }
    return max != null ? new Date(max) : null;
  }
};
ZodDate.create = (params) => {
  return new ZodDate({
    checks: [],
    coerce: (params === null || params === void 0 ? void 0 : params.coerce) || false,
    typeName: ZodFirstPartyTypeKind.ZodDate,
    ...processCreateParams(params)
  });
};
var ZodSymbol = class extends ZodType {
  _parse(input) {
    const parsedType = this._getType(input);
    if (parsedType !== ZodParsedType.symbol) {
      const ctx = this._getOrReturnCtx(input);
      addIssueToContext(ctx, {
        code: ZodIssueCode.invalid_type,
        expected: ZodParsedType.symbol,
        received: ctx.parsedType
      });
      return INVALID;
    }
    return OK(input.data);
  }
};
ZodSymbol.create = (params) => {
  return new ZodSymbol({
    typeName: ZodFirstPartyTypeKind.ZodSymbol,
    ...processCreateParams(params)
  });
};
var ZodUndefined = class extends ZodType {
  _parse(input) {
    const parsedType = this._getType(input);
    if (parsedType !== ZodParsedType.undefined) {
      const ctx = this._getOrReturnCtx(input);
      addIssueToContext(ctx, {
        code: ZodIssueCode.invalid_type,
        expected: ZodParsedType.undefined,
        received: ctx.parsedType
      });
      return INVALID;
    }
    return OK(input.data);
  }
};
ZodUndefined.create = (params) => {
  return new ZodUndefined({
    typeName: ZodFirstPartyTypeKind.ZodUndefined,
    ...processCreateParams(params)
  });
};
var ZodNull = class extends ZodType {
  _parse(input) {
    const parsedType = this._getType(input);
    if (parsedType !== ZodParsedType.null) {
      const ctx = this._getOrReturnCtx(input);
      addIssueToContext(ctx, {
        code: ZodIssueCode.invalid_type,
        expected: ZodParsedType.null,
        received: ctx.parsedType
      });
      return INVALID;
    }
    return OK(input.data);
  }
};
ZodNull.create = (params) => {
  return new ZodNull({
    typeName: ZodFirstPartyTypeKind.ZodNull,
    ...processCreateParams(params)
  });
};
var ZodAny = class extends ZodType {
  constructor() {
    super(...arguments);
    this._any = true;
  }
  _parse(input) {
    return OK(input.data);
  }
};
ZodAny.create = (params) => {
  return new ZodAny({
    typeName: ZodFirstPartyTypeKind.ZodAny,
    ...processCreateParams(params)
  });
};
var ZodUnknown = class extends ZodType {
  constructor() {
    super(...arguments);
    this._unknown = true;
  }
  _parse(input) {
    return OK(input.data);
  }
};
ZodUnknown.create = (params) => {
  return new ZodUnknown({
    typeName: ZodFirstPartyTypeKind.ZodUnknown,
    ...processCreateParams(params)
  });
};
var ZodNever = class extends ZodType {
  _parse(input) {
    const ctx = this._getOrReturnCtx(input);
    addIssueToContext(ctx, {
      code: ZodIssueCode.invalid_type,
      expected: ZodParsedType.never,
      received: ctx.parsedType
    });
    return INVALID;
  }
};
ZodNever.create = (params) => {
  return new ZodNever({
    typeName: ZodFirstPartyTypeKind.ZodNever,
    ...processCreateParams(params)
  });
};
var ZodVoid = class extends ZodType {
  _parse(input) {
    const parsedType = this._getType(input);
    if (parsedType !== ZodParsedType.undefined) {
      const ctx = this._getOrReturnCtx(input);
      addIssueToContext(ctx, {
        code: ZodIssueCode.invalid_type,
        expected: ZodParsedType.void,
        received: ctx.parsedType
      });
      return INVALID;
    }
    return OK(input.data);
  }
};
ZodVoid.create = (params) => {
  return new ZodVoid({
    typeName: ZodFirstPartyTypeKind.ZodVoid,
    ...processCreateParams(params)
  });
};
var ZodArray = class _ZodArray extends ZodType {
  _parse(input) {
    const { ctx, status } = this._processInputParams(input);
    const def = this._def;
    if (ctx.parsedType !== ZodParsedType.array) {
      addIssueToContext(ctx, {
        code: ZodIssueCode.invalid_type,
        expected: ZodParsedType.array,
        received: ctx.parsedType
      });
      return INVALID;
    }
    if (def.exactLength !== null) {
      const tooBig = ctx.data.length > def.exactLength.value;
      const tooSmall = ctx.data.length < def.exactLength.value;
      if (tooBig || tooSmall) {
        addIssueToContext(ctx, {
          code: tooBig ? ZodIssueCode.too_big : ZodIssueCode.too_small,
          minimum: tooSmall ? def.exactLength.value : void 0,
          maximum: tooBig ? def.exactLength.value : void 0,
          type: "array",
          inclusive: true,
          exact: true,
          message: def.exactLength.message
        });
        status.dirty();
      }
    }
    if (def.minLength !== null) {
      if (ctx.data.length < def.minLength.value) {
        addIssueToContext(ctx, {
          code: ZodIssueCode.too_small,
          minimum: def.minLength.value,
          type: "array",
          inclusive: true,
          exact: false,
          message: def.minLength.message
        });
        status.dirty();
      }
    }
    if (def.maxLength !== null) {
      if (ctx.data.length > def.maxLength.value) {
        addIssueToContext(ctx, {
          code: ZodIssueCode.too_big,
          maximum: def.maxLength.value,
          type: "array",
          inclusive: true,
          exact: false,
          message: def.maxLength.message
        });
        status.dirty();
      }
    }
    if (ctx.common.async) {
      return Promise.all([...ctx.data].map((item, i2) => {
        return def.type._parseAsync(new ParseInputLazyPath(ctx, item, ctx.path, i2));
      })).then((result2) => {
        return ParseStatus.mergeArray(status, result2);
      });
    }
    const result = [...ctx.data].map((item, i2) => {
      return def.type._parseSync(new ParseInputLazyPath(ctx, item, ctx.path, i2));
    });
    return ParseStatus.mergeArray(status, result);
  }
  get element() {
    return this._def.type;
  }
  min(minLength, message) {
    return new _ZodArray({
      ...this._def,
      minLength: { value: minLength, message: errorUtil.toString(message) }
    });
  }
  max(maxLength, message) {
    return new _ZodArray({
      ...this._def,
      maxLength: { value: maxLength, message: errorUtil.toString(message) }
    });
  }
  length(len, message) {
    return new _ZodArray({
      ...this._def,
      exactLength: { value: len, message: errorUtil.toString(message) }
    });
  }
  nonempty(message) {
    return this.min(1, message);
  }
};
ZodArray.create = (schema, params) => {
  return new ZodArray({
    type: schema,
    minLength: null,
    maxLength: null,
    exactLength: null,
    typeName: ZodFirstPartyTypeKind.ZodArray,
    ...processCreateParams(params)
  });
};
function deepPartialify(schema) {
  if (schema instanceof ZodObject) {
    const newShape = {};
    for (const key in schema.shape) {
      const fieldSchema = schema.shape[key];
      newShape[key] = ZodOptional.create(deepPartialify(fieldSchema));
    }
    return new ZodObject({
      ...schema._def,
      shape: () => newShape
    });
  } else if (schema instanceof ZodArray) {
    return new ZodArray({
      ...schema._def,
      type: deepPartialify(schema.element)
    });
  } else if (schema instanceof ZodOptional) {
    return ZodOptional.create(deepPartialify(schema.unwrap()));
  } else if (schema instanceof ZodNullable) {
    return ZodNullable.create(deepPartialify(schema.unwrap()));
  } else if (schema instanceof ZodTuple) {
    return ZodTuple.create(schema.items.map((item) => deepPartialify(item)));
  } else {
    return schema;
  }
}
var ZodObject = class _ZodObject extends ZodType {
  constructor() {
    super(...arguments);
    this._cached = null;
    this.nonstrict = this.passthrough;
    this.augment = this.extend;
  }
  _getCached() {
    if (this._cached !== null)
      return this._cached;
    const shape = this._def.shape();
    const keys = util.objectKeys(shape);
    return this._cached = { shape, keys };
  }
  _parse(input) {
    const parsedType = this._getType(input);
    if (parsedType !== ZodParsedType.object) {
      const ctx2 = this._getOrReturnCtx(input);
      addIssueToContext(ctx2, {
        code: ZodIssueCode.invalid_type,
        expected: ZodParsedType.object,
        received: ctx2.parsedType
      });
      return INVALID;
    }
    const { status, ctx } = this._processInputParams(input);
    const { shape, keys: shapeKeys } = this._getCached();
    const extraKeys = [];
    if (!(this._def.catchall instanceof ZodNever && this._def.unknownKeys === "strip")) {
      for (const key in ctx.data) {
        if (!shapeKeys.includes(key)) {
          extraKeys.push(key);
        }
      }
    }
    const pairs = [];
    for (const key of shapeKeys) {
      const keyValidator = shape[key];
      const value = ctx.data[key];
      pairs.push({
        key: { status: "valid", value: key },
        value: keyValidator._parse(new ParseInputLazyPath(ctx, value, ctx.path, key)),
        alwaysSet: key in ctx.data
      });
    }
    if (this._def.catchall instanceof ZodNever) {
      const unknownKeys = this._def.unknownKeys;
      if (unknownKeys === "passthrough") {
        for (const key of extraKeys) {
          pairs.push({
            key: { status: "valid", value: key },
            value: { status: "valid", value: ctx.data[key] }
          });
        }
      } else if (unknownKeys === "strict") {
        if (extraKeys.length > 0) {
          addIssueToContext(ctx, {
            code: ZodIssueCode.unrecognized_keys,
            keys: extraKeys
          });
          status.dirty();
        }
      } else if (unknownKeys === "strip") ;
      else {
        throw new Error(`Internal ZodObject error: invalid unknownKeys value.`);
      }
    } else {
      const catchall = this._def.catchall;
      for (const key of extraKeys) {
        const value = ctx.data[key];
        pairs.push({
          key: { status: "valid", value: key },
          value: catchall._parse(
            new ParseInputLazyPath(ctx, value, ctx.path, key)
            //, ctx.child(key), value, getParsedType(value)
          ),
          alwaysSet: key in ctx.data
        });
      }
    }
    if (ctx.common.async) {
      return Promise.resolve().then(async () => {
        const syncPairs = [];
        for (const pair of pairs) {
          const key = await pair.key;
          const value = await pair.value;
          syncPairs.push({
            key,
            value,
            alwaysSet: pair.alwaysSet
          });
        }
        return syncPairs;
      }).then((syncPairs) => {
        return ParseStatus.mergeObjectSync(status, syncPairs);
      });
    } else {
      return ParseStatus.mergeObjectSync(status, pairs);
    }
  }
  get shape() {
    return this._def.shape();
  }
  strict(message) {
    errorUtil.errToObj;
    return new _ZodObject({
      ...this._def,
      unknownKeys: "strict",
      ...message !== void 0 ? {
        errorMap: (issue, ctx) => {
          var _a, _b, _c, _d;
          const defaultError = (_c = (_b = (_a = this._def).errorMap) === null || _b === void 0 ? void 0 : _b.call(_a, issue, ctx).message) !== null && _c !== void 0 ? _c : ctx.defaultError;
          if (issue.code === "unrecognized_keys")
            return {
              message: (_d = errorUtil.errToObj(message).message) !== null && _d !== void 0 ? _d : defaultError
            };
          return {
            message: defaultError
          };
        }
      } : {}
    });
  }
  strip() {
    return new _ZodObject({
      ...this._def,
      unknownKeys: "strip"
    });
  }
  passthrough() {
    return new _ZodObject({
      ...this._def,
      unknownKeys: "passthrough"
    });
  }
  // const AugmentFactory =
  //   <Def extends ZodObjectDef>(def: Def) =>
  //   <Augmentation extends ZodRawShape>(
  //     augmentation: Augmentation
  //   ): ZodObject<
  //     extendShape<ReturnType<Def["shape"]>, Augmentation>,
  //     Def["unknownKeys"],
  //     Def["catchall"]
  //   > => {
  //     return new ZodObject({
  //       ...def,
  //       shape: () => ({
  //         ...def.shape(),
  //         ...augmentation,
  //       }),
  //     }) as any;
  //   };
  extend(augmentation) {
    return new _ZodObject({
      ...this._def,
      shape: () => ({
        ...this._def.shape(),
        ...augmentation
      })
    });
  }
  /**
   * Prior to zod@1.0.12 there was a bug in the
   * inferred type of merged objects. Please
   * upgrade if you are experiencing issues.
   */
  merge(merging) {
    const merged = new _ZodObject({
      unknownKeys: merging._def.unknownKeys,
      catchall: merging._def.catchall,
      shape: () => ({
        ...this._def.shape(),
        ...merging._def.shape()
      }),
      typeName: ZodFirstPartyTypeKind.ZodObject
    });
    return merged;
  }
  // merge<
  //   Incoming extends AnyZodObject,
  //   Augmentation extends Incoming["shape"],
  //   NewOutput extends {
  //     [k in keyof Augmentation | keyof Output]: k extends keyof Augmentation
  //       ? Augmentation[k]["_output"]
  //       : k extends keyof Output
  //       ? Output[k]
  //       : never;
  //   },
  //   NewInput extends {
  //     [k in keyof Augmentation | keyof Input]: k extends keyof Augmentation
  //       ? Augmentation[k]["_input"]
  //       : k extends keyof Input
  //       ? Input[k]
  //       : never;
  //   }
  // >(
  //   merging: Incoming
  // ): ZodObject<
  //   extendShape<T, ReturnType<Incoming["_def"]["shape"]>>,
  //   Incoming["_def"]["unknownKeys"],
  //   Incoming["_def"]["catchall"],
  //   NewOutput,
  //   NewInput
  // > {
  //   const merged: any = new ZodObject({
  //     unknownKeys: merging._def.unknownKeys,
  //     catchall: merging._def.catchall,
  //     shape: () =>
  //       objectUtil.mergeShapes(this._def.shape(), merging._def.shape()),
  //     typeName: ZodFirstPartyTypeKind.ZodObject,
  //   }) as any;
  //   return merged;
  // }
  setKey(key, schema) {
    return this.augment({ [key]: schema });
  }
  // merge<Incoming extends AnyZodObject>(
  //   merging: Incoming
  // ): //ZodObject<T & Incoming["_shape"], UnknownKeys, Catchall> = (merging) => {
  // ZodObject<
  //   extendShape<T, ReturnType<Incoming["_def"]["shape"]>>,
  //   Incoming["_def"]["unknownKeys"],
  //   Incoming["_def"]["catchall"]
  // > {
  //   // const mergedShape = objectUtil.mergeShapes(
  //   //   this._def.shape(),
  //   //   merging._def.shape()
  //   // );
  //   const merged: any = new ZodObject({
  //     unknownKeys: merging._def.unknownKeys,
  //     catchall: merging._def.catchall,
  //     shape: () =>
  //       objectUtil.mergeShapes(this._def.shape(), merging._def.shape()),
  //     typeName: ZodFirstPartyTypeKind.ZodObject,
  //   }) as any;
  //   return merged;
  // }
  catchall(index) {
    return new _ZodObject({
      ...this._def,
      catchall: index
    });
  }
  pick(mask) {
    const shape = {};
    util.objectKeys(mask).forEach((key) => {
      if (mask[key] && this.shape[key]) {
        shape[key] = this.shape[key];
      }
    });
    return new _ZodObject({
      ...this._def,
      shape: () => shape
    });
  }
  omit(mask) {
    const shape = {};
    util.objectKeys(this.shape).forEach((key) => {
      if (!mask[key]) {
        shape[key] = this.shape[key];
      }
    });
    return new _ZodObject({
      ...this._def,
      shape: () => shape
    });
  }
  /**
   * @deprecated
   */
  deepPartial() {
    return deepPartialify(this);
  }
  partial(mask) {
    const newShape = {};
    util.objectKeys(this.shape).forEach((key) => {
      const fieldSchema = this.shape[key];
      if (mask && !mask[key]) {
        newShape[key] = fieldSchema;
      } else {
        newShape[key] = fieldSchema.optional();
      }
    });
    return new _ZodObject({
      ...this._def,
      shape: () => newShape
    });
  }
  required(mask) {
    const newShape = {};
    util.objectKeys(this.shape).forEach((key) => {
      if (mask && !mask[key]) {
        newShape[key] = this.shape[key];
      } else {
        const fieldSchema = this.shape[key];
        let newField = fieldSchema;
        while (newField instanceof ZodOptional) {
          newField = newField._def.innerType;
        }
        newShape[key] = newField;
      }
    });
    return new _ZodObject({
      ...this._def,
      shape: () => newShape
    });
  }
  keyof() {
    return createZodEnum(util.objectKeys(this.shape));
  }
};
ZodObject.create = (shape, params) => {
  return new ZodObject({
    shape: () => shape,
    unknownKeys: "strip",
    catchall: ZodNever.create(),
    typeName: ZodFirstPartyTypeKind.ZodObject,
    ...processCreateParams(params)
  });
};
ZodObject.strictCreate = (shape, params) => {
  return new ZodObject({
    shape: () => shape,
    unknownKeys: "strict",
    catchall: ZodNever.create(),
    typeName: ZodFirstPartyTypeKind.ZodObject,
    ...processCreateParams(params)
  });
};
ZodObject.lazycreate = (shape, params) => {
  return new ZodObject({
    shape,
    unknownKeys: "strip",
    catchall: ZodNever.create(),
    typeName: ZodFirstPartyTypeKind.ZodObject,
    ...processCreateParams(params)
  });
};
var ZodUnion = class extends ZodType {
  _parse(input) {
    const { ctx } = this._processInputParams(input);
    const options = this._def.options;
    function handleResults(results) {
      for (const result of results) {
        if (result.result.status === "valid") {
          return result.result;
        }
      }
      for (const result of results) {
        if (result.result.status === "dirty") {
          ctx.common.issues.push(...result.ctx.common.issues);
          return result.result;
        }
      }
      const unionErrors = results.map((result) => new ZodError(result.ctx.common.issues));
      addIssueToContext(ctx, {
        code: ZodIssueCode.invalid_union,
        unionErrors
      });
      return INVALID;
    }
    if (ctx.common.async) {
      return Promise.all(options.map(async (option) => {
        const childCtx = {
          ...ctx,
          common: {
            ...ctx.common,
            issues: []
          },
          parent: null
        };
        return {
          result: await option._parseAsync({
            data: ctx.data,
            path: ctx.path,
            parent: childCtx
          }),
          ctx: childCtx
        };
      })).then(handleResults);
    } else {
      let dirty = void 0;
      const issues = [];
      for (const option of options) {
        const childCtx = {
          ...ctx,
          common: {
            ...ctx.common,
            issues: []
          },
          parent: null
        };
        const result = option._parseSync({
          data: ctx.data,
          path: ctx.path,
          parent: childCtx
        });
        if (result.status === "valid") {
          return result;
        } else if (result.status === "dirty" && !dirty) {
          dirty = { result, ctx: childCtx };
        }
        if (childCtx.common.issues.length) {
          issues.push(childCtx.common.issues);
        }
      }
      if (dirty) {
        ctx.common.issues.push(...dirty.ctx.common.issues);
        return dirty.result;
      }
      const unionErrors = issues.map((issues2) => new ZodError(issues2));
      addIssueToContext(ctx, {
        code: ZodIssueCode.invalid_union,
        unionErrors
      });
      return INVALID;
    }
  }
  get options() {
    return this._def.options;
  }
};
ZodUnion.create = (types, params) => {
  return new ZodUnion({
    options: types,
    typeName: ZodFirstPartyTypeKind.ZodUnion,
    ...processCreateParams(params)
  });
};
var getDiscriminator = (type) => {
  if (type instanceof ZodLazy) {
    return getDiscriminator(type.schema);
  } else if (type instanceof ZodEffects) {
    return getDiscriminator(type.innerType());
  } else if (type instanceof ZodLiteral) {
    return [type.value];
  } else if (type instanceof ZodEnum) {
    return type.options;
  } else if (type instanceof ZodNativeEnum) {
    return util.objectValues(type.enum);
  } else if (type instanceof ZodDefault) {
    return getDiscriminator(type._def.innerType);
  } else if (type instanceof ZodUndefined) {
    return [void 0];
  } else if (type instanceof ZodNull) {
    return [null];
  } else if (type instanceof ZodOptional) {
    return [void 0, ...getDiscriminator(type.unwrap())];
  } else if (type instanceof ZodNullable) {
    return [null, ...getDiscriminator(type.unwrap())];
  } else if (type instanceof ZodBranded) {
    return getDiscriminator(type.unwrap());
  } else if (type instanceof ZodReadonly) {
    return getDiscriminator(type.unwrap());
  } else if (type instanceof ZodCatch) {
    return getDiscriminator(type._def.innerType);
  } else {
    return [];
  }
};
var ZodDiscriminatedUnion = class _ZodDiscriminatedUnion extends ZodType {
  _parse(input) {
    const { ctx } = this._processInputParams(input);
    if (ctx.parsedType !== ZodParsedType.object) {
      addIssueToContext(ctx, {
        code: ZodIssueCode.invalid_type,
        expected: ZodParsedType.object,
        received: ctx.parsedType
      });
      return INVALID;
    }
    const discriminator = this.discriminator;
    const discriminatorValue = ctx.data[discriminator];
    const option = this.optionsMap.get(discriminatorValue);
    if (!option) {
      addIssueToContext(ctx, {
        code: ZodIssueCode.invalid_union_discriminator,
        options: Array.from(this.optionsMap.keys()),
        path: [discriminator]
      });
      return INVALID;
    }
    if (ctx.common.async) {
      return option._parseAsync({
        data: ctx.data,
        path: ctx.path,
        parent: ctx
      });
    } else {
      return option._parseSync({
        data: ctx.data,
        path: ctx.path,
        parent: ctx
      });
    }
  }
  get discriminator() {
    return this._def.discriminator;
  }
  get options() {
    return this._def.options;
  }
  get optionsMap() {
    return this._def.optionsMap;
  }
  /**
   * The constructor of the discriminated union schema. Its behaviour is very similar to that of the normal z.union() constructor.
   * However, it only allows a union of objects, all of which need to share a discriminator property. This property must
   * have a different value for each object in the union.
   * @param discriminator the name of the discriminator property
   * @param types an array of object schemas
   * @param params
   */
  static create(discriminator, options, params) {
    const optionsMap = /* @__PURE__ */ new Map();
    for (const type of options) {
      const discriminatorValues = getDiscriminator(type.shape[discriminator]);
      if (!discriminatorValues.length) {
        throw new Error(`A discriminator value for key \`${discriminator}\` could not be extracted from all schema options`);
      }
      for (const value of discriminatorValues) {
        if (optionsMap.has(value)) {
          throw new Error(`Discriminator property ${String(discriminator)} has duplicate value ${String(value)}`);
        }
        optionsMap.set(value, type);
      }
    }
    return new _ZodDiscriminatedUnion({
      typeName: ZodFirstPartyTypeKind.ZodDiscriminatedUnion,
      discriminator,
      options,
      optionsMap,
      ...processCreateParams(params)
    });
  }
};
function mergeValues(a, b2) {
  const aType = getParsedType(a);
  const bType = getParsedType(b2);
  if (a === b2) {
    return { valid: true, data: a };
  } else if (aType === ZodParsedType.object && bType === ZodParsedType.object) {
    const bKeys = util.objectKeys(b2);
    const sharedKeys = util.objectKeys(a).filter((key) => bKeys.indexOf(key) !== -1);
    const newObj = { ...a, ...b2 };
    for (const key of sharedKeys) {
      const sharedValue = mergeValues(a[key], b2[key]);
      if (!sharedValue.valid) {
        return { valid: false };
      }
      newObj[key] = sharedValue.data;
    }
    return { valid: true, data: newObj };
  } else if (aType === ZodParsedType.array && bType === ZodParsedType.array) {
    if (a.length !== b2.length) {
      return { valid: false };
    }
    const newArray = [];
    for (let index = 0; index < a.length; index++) {
      const itemA = a[index];
      const itemB = b2[index];
      const sharedValue = mergeValues(itemA, itemB);
      if (!sharedValue.valid) {
        return { valid: false };
      }
      newArray.push(sharedValue.data);
    }
    return { valid: true, data: newArray };
  } else if (aType === ZodParsedType.date && bType === ZodParsedType.date && +a === +b2) {
    return { valid: true, data: a };
  } else {
    return { valid: false };
  }
}
var ZodIntersection = class extends ZodType {
  _parse(input) {
    const { status, ctx } = this._processInputParams(input);
    const handleParsed = (parsedLeft, parsedRight) => {
      if (isAborted(parsedLeft) || isAborted(parsedRight)) {
        return INVALID;
      }
      const merged = mergeValues(parsedLeft.value, parsedRight.value);
      if (!merged.valid) {
        addIssueToContext(ctx, {
          code: ZodIssueCode.invalid_intersection_types
        });
        return INVALID;
      }
      if (isDirty(parsedLeft) || isDirty(parsedRight)) {
        status.dirty();
      }
      return { status: status.value, value: merged.data };
    };
    if (ctx.common.async) {
      return Promise.all([
        this._def.left._parseAsync({
          data: ctx.data,
          path: ctx.path,
          parent: ctx
        }),
        this._def.right._parseAsync({
          data: ctx.data,
          path: ctx.path,
          parent: ctx
        })
      ]).then(([left, right]) => handleParsed(left, right));
    } else {
      return handleParsed(this._def.left._parseSync({
        data: ctx.data,
        path: ctx.path,
        parent: ctx
      }), this._def.right._parseSync({
        data: ctx.data,
        path: ctx.path,
        parent: ctx
      }));
    }
  }
};
ZodIntersection.create = (left, right, params) => {
  return new ZodIntersection({
    left,
    right,
    typeName: ZodFirstPartyTypeKind.ZodIntersection,
    ...processCreateParams(params)
  });
};
var ZodTuple = class _ZodTuple extends ZodType {
  _parse(input) {
    const { status, ctx } = this._processInputParams(input);
    if (ctx.parsedType !== ZodParsedType.array) {
      addIssueToContext(ctx, {
        code: ZodIssueCode.invalid_type,
        expected: ZodParsedType.array,
        received: ctx.parsedType
      });
      return INVALID;
    }
    if (ctx.data.length < this._def.items.length) {
      addIssueToContext(ctx, {
        code: ZodIssueCode.too_small,
        minimum: this._def.items.length,
        inclusive: true,
        exact: false,
        type: "array"
      });
      return INVALID;
    }
    const rest = this._def.rest;
    if (!rest && ctx.data.length > this._def.items.length) {
      addIssueToContext(ctx, {
        code: ZodIssueCode.too_big,
        maximum: this._def.items.length,
        inclusive: true,
        exact: false,
        type: "array"
      });
      status.dirty();
    }
    const items = [...ctx.data].map((item, itemIndex) => {
      const schema = this._def.items[itemIndex] || this._def.rest;
      if (!schema)
        return null;
      return schema._parse(new ParseInputLazyPath(ctx, item, ctx.path, itemIndex));
    }).filter((x2) => !!x2);
    if (ctx.common.async) {
      return Promise.all(items).then((results) => {
        return ParseStatus.mergeArray(status, results);
      });
    } else {
      return ParseStatus.mergeArray(status, items);
    }
  }
  get items() {
    return this._def.items;
  }
  rest(rest) {
    return new _ZodTuple({
      ...this._def,
      rest
    });
  }
};
ZodTuple.create = (schemas, params) => {
  if (!Array.isArray(schemas)) {
    throw new Error("You must pass an array of schemas to z.tuple([ ... ])");
  }
  return new ZodTuple({
    items: schemas,
    typeName: ZodFirstPartyTypeKind.ZodTuple,
    rest: null,
    ...processCreateParams(params)
  });
};
var ZodRecord = class _ZodRecord extends ZodType {
  get keySchema() {
    return this._def.keyType;
  }
  get valueSchema() {
    return this._def.valueType;
  }
  _parse(input) {
    const { status, ctx } = this._processInputParams(input);
    if (ctx.parsedType !== ZodParsedType.object) {
      addIssueToContext(ctx, {
        code: ZodIssueCode.invalid_type,
        expected: ZodParsedType.object,
        received: ctx.parsedType
      });
      return INVALID;
    }
    const pairs = [];
    const keyType = this._def.keyType;
    const valueType = this._def.valueType;
    for (const key in ctx.data) {
      pairs.push({
        key: keyType._parse(new ParseInputLazyPath(ctx, key, ctx.path, key)),
        value: valueType._parse(new ParseInputLazyPath(ctx, ctx.data[key], ctx.path, key)),
        alwaysSet: key in ctx.data
      });
    }
    if (ctx.common.async) {
      return ParseStatus.mergeObjectAsync(status, pairs);
    } else {
      return ParseStatus.mergeObjectSync(status, pairs);
    }
  }
  get element() {
    return this._def.valueType;
  }
  static create(first, second, third) {
    if (second instanceof ZodType) {
      return new _ZodRecord({
        keyType: first,
        valueType: second,
        typeName: ZodFirstPartyTypeKind.ZodRecord,
        ...processCreateParams(third)
      });
    }
    return new _ZodRecord({
      keyType: ZodString.create(),
      valueType: first,
      typeName: ZodFirstPartyTypeKind.ZodRecord,
      ...processCreateParams(second)
    });
  }
};
var ZodMap = class extends ZodType {
  get keySchema() {
    return this._def.keyType;
  }
  get valueSchema() {
    return this._def.valueType;
  }
  _parse(input) {
    const { status, ctx } = this._processInputParams(input);
    if (ctx.parsedType !== ZodParsedType.map) {
      addIssueToContext(ctx, {
        code: ZodIssueCode.invalid_type,
        expected: ZodParsedType.map,
        received: ctx.parsedType
      });
      return INVALID;
    }
    const keyType = this._def.keyType;
    const valueType = this._def.valueType;
    const pairs = [...ctx.data.entries()].map(([key, value], index) => {
      return {
        key: keyType._parse(new ParseInputLazyPath(ctx, key, ctx.path, [index, "key"])),
        value: valueType._parse(new ParseInputLazyPath(ctx, value, ctx.path, [index, "value"]))
      };
    });
    if (ctx.common.async) {
      const finalMap = /* @__PURE__ */ new Map();
      return Promise.resolve().then(async () => {
        for (const pair of pairs) {
          const key = await pair.key;
          const value = await pair.value;
          if (key.status === "aborted" || value.status === "aborted") {
            return INVALID;
          }
          if (key.status === "dirty" || value.status === "dirty") {
            status.dirty();
          }
          finalMap.set(key.value, value.value);
        }
        return { status: status.value, value: finalMap };
      });
    } else {
      const finalMap = /* @__PURE__ */ new Map();
      for (const pair of pairs) {
        const key = pair.key;
        const value = pair.value;
        if (key.status === "aborted" || value.status === "aborted") {
          return INVALID;
        }
        if (key.status === "dirty" || value.status === "dirty") {
          status.dirty();
        }
        finalMap.set(key.value, value.value);
      }
      return { status: status.value, value: finalMap };
    }
  }
};
ZodMap.create = (keyType, valueType, params) => {
  return new ZodMap({
    valueType,
    keyType,
    typeName: ZodFirstPartyTypeKind.ZodMap,
    ...processCreateParams(params)
  });
};
var ZodSet = class _ZodSet extends ZodType {
  _parse(input) {
    const { status, ctx } = this._processInputParams(input);
    if (ctx.parsedType !== ZodParsedType.set) {
      addIssueToContext(ctx, {
        code: ZodIssueCode.invalid_type,
        expected: ZodParsedType.set,
        received: ctx.parsedType
      });
      return INVALID;
    }
    const def = this._def;
    if (def.minSize !== null) {
      if (ctx.data.size < def.minSize.value) {
        addIssueToContext(ctx, {
          code: ZodIssueCode.too_small,
          minimum: def.minSize.value,
          type: "set",
          inclusive: true,
          exact: false,
          message: def.minSize.message
        });
        status.dirty();
      }
    }
    if (def.maxSize !== null) {
      if (ctx.data.size > def.maxSize.value) {
        addIssueToContext(ctx, {
          code: ZodIssueCode.too_big,
          maximum: def.maxSize.value,
          type: "set",
          inclusive: true,
          exact: false,
          message: def.maxSize.message
        });
        status.dirty();
      }
    }
    const valueType = this._def.valueType;
    function finalizeSet(elements2) {
      const parsedSet = /* @__PURE__ */ new Set();
      for (const element of elements2) {
        if (element.status === "aborted")
          return INVALID;
        if (element.status === "dirty")
          status.dirty();
        parsedSet.add(element.value);
      }
      return { status: status.value, value: parsedSet };
    }
    const elements = [...ctx.data.values()].map((item, i2) => valueType._parse(new ParseInputLazyPath(ctx, item, ctx.path, i2)));
    if (ctx.common.async) {
      return Promise.all(elements).then((elements2) => finalizeSet(elements2));
    } else {
      return finalizeSet(elements);
    }
  }
  min(minSize, message) {
    return new _ZodSet({
      ...this._def,
      minSize: { value: minSize, message: errorUtil.toString(message) }
    });
  }
  max(maxSize, message) {
    return new _ZodSet({
      ...this._def,
      maxSize: { value: maxSize, message: errorUtil.toString(message) }
    });
  }
  size(size, message) {
    return this.min(size, message).max(size, message);
  }
  nonempty(message) {
    return this.min(1, message);
  }
};
ZodSet.create = (valueType, params) => {
  return new ZodSet({
    valueType,
    minSize: null,
    maxSize: null,
    typeName: ZodFirstPartyTypeKind.ZodSet,
    ...processCreateParams(params)
  });
};
var ZodFunction = class _ZodFunction extends ZodType {
  constructor() {
    super(...arguments);
    this.validate = this.implement;
  }
  _parse(input) {
    const { ctx } = this._processInputParams(input);
    if (ctx.parsedType !== ZodParsedType.function) {
      addIssueToContext(ctx, {
        code: ZodIssueCode.invalid_type,
        expected: ZodParsedType.function,
        received: ctx.parsedType
      });
      return INVALID;
    }
    function makeArgsIssue(args, error) {
      return makeIssue({
        data: args,
        path: ctx.path,
        errorMaps: [
          ctx.common.contextualErrorMap,
          ctx.schemaErrorMap,
          getErrorMap(),
          errorMap
        ].filter((x2) => !!x2),
        issueData: {
          code: ZodIssueCode.invalid_arguments,
          argumentsError: error
        }
      });
    }
    function makeReturnsIssue(returns, error) {
      return makeIssue({
        data: returns,
        path: ctx.path,
        errorMaps: [
          ctx.common.contextualErrorMap,
          ctx.schemaErrorMap,
          getErrorMap(),
          errorMap
        ].filter((x2) => !!x2),
        issueData: {
          code: ZodIssueCode.invalid_return_type,
          returnTypeError: error
        }
      });
    }
    const params = { errorMap: ctx.common.contextualErrorMap };
    const fn = ctx.data;
    if (this._def.returns instanceof ZodPromise) {
      const me = this;
      return OK(async function(...args) {
        const error = new ZodError([]);
        const parsedArgs = await me._def.args.parseAsync(args, params).catch((e2) => {
          error.addIssue(makeArgsIssue(args, e2));
          throw error;
        });
        const result = await Reflect.apply(fn, this, parsedArgs);
        const parsedReturns = await me._def.returns._def.type.parseAsync(result, params).catch((e2) => {
          error.addIssue(makeReturnsIssue(result, e2));
          throw error;
        });
        return parsedReturns;
      });
    } else {
      const me = this;
      return OK(function(...args) {
        const parsedArgs = me._def.args.safeParse(args, params);
        if (!parsedArgs.success) {
          throw new ZodError([makeArgsIssue(args, parsedArgs.error)]);
        }
        const result = Reflect.apply(fn, this, parsedArgs.data);
        const parsedReturns = me._def.returns.safeParse(result, params);
        if (!parsedReturns.success) {
          throw new ZodError([makeReturnsIssue(result, parsedReturns.error)]);
        }
        return parsedReturns.data;
      });
    }
  }
  parameters() {
    return this._def.args;
  }
  returnType() {
    return this._def.returns;
  }
  args(...items) {
    return new _ZodFunction({
      ...this._def,
      args: ZodTuple.create(items).rest(ZodUnknown.create())
    });
  }
  returns(returnType) {
    return new _ZodFunction({
      ...this._def,
      returns: returnType
    });
  }
  implement(func) {
    const validatedFunc = this.parse(func);
    return validatedFunc;
  }
  strictImplement(func) {
    const validatedFunc = this.parse(func);
    return validatedFunc;
  }
  static create(args, returns, params) {
    return new _ZodFunction({
      args: args ? args : ZodTuple.create([]).rest(ZodUnknown.create()),
      returns: returns || ZodUnknown.create(),
      typeName: ZodFirstPartyTypeKind.ZodFunction,
      ...processCreateParams(params)
    });
  }
};
var ZodLazy = class extends ZodType {
  get schema() {
    return this._def.getter();
  }
  _parse(input) {
    const { ctx } = this._processInputParams(input);
    const lazySchema = this._def.getter();
    return lazySchema._parse({ data: ctx.data, path: ctx.path, parent: ctx });
  }
};
ZodLazy.create = (getter, params) => {
  return new ZodLazy({
    getter,
    typeName: ZodFirstPartyTypeKind.ZodLazy,
    ...processCreateParams(params)
  });
};
var ZodLiteral = class extends ZodType {
  _parse(input) {
    if (input.data !== this._def.value) {
      const ctx = this._getOrReturnCtx(input);
      addIssueToContext(ctx, {
        received: ctx.data,
        code: ZodIssueCode.invalid_literal,
        expected: this._def.value
      });
      return INVALID;
    }
    return { status: "valid", value: input.data };
  }
  get value() {
    return this._def.value;
  }
};
ZodLiteral.create = (value, params) => {
  return new ZodLiteral({
    value,
    typeName: ZodFirstPartyTypeKind.ZodLiteral,
    ...processCreateParams(params)
  });
};
function createZodEnum(values, params) {
  return new ZodEnum({
    values,
    typeName: ZodFirstPartyTypeKind.ZodEnum,
    ...processCreateParams(params)
  });
}
var ZodEnum = class _ZodEnum extends ZodType {
  constructor() {
    super(...arguments);
    _ZodEnum_cache.set(this, void 0);
  }
  _parse(input) {
    if (typeof input.data !== "string") {
      const ctx = this._getOrReturnCtx(input);
      const expectedValues = this._def.values;
      addIssueToContext(ctx, {
        expected: util.joinValues(expectedValues),
        received: ctx.parsedType,
        code: ZodIssueCode.invalid_type
      });
      return INVALID;
    }
    if (!__classPrivateFieldGet(this, _ZodEnum_cache, "f")) {
      __classPrivateFieldSet(this, _ZodEnum_cache, new Set(this._def.values), "f");
    }
    if (!__classPrivateFieldGet(this, _ZodEnum_cache, "f").has(input.data)) {
      const ctx = this._getOrReturnCtx(input);
      const expectedValues = this._def.values;
      addIssueToContext(ctx, {
        received: ctx.data,
        code: ZodIssueCode.invalid_enum_value,
        options: expectedValues
      });
      return INVALID;
    }
    return OK(input.data);
  }
  get options() {
    return this._def.values;
  }
  get enum() {
    const enumValues = {};
    for (const val of this._def.values) {
      enumValues[val] = val;
    }
    return enumValues;
  }
  get Values() {
    const enumValues = {};
    for (const val of this._def.values) {
      enumValues[val] = val;
    }
    return enumValues;
  }
  get Enum() {
    const enumValues = {};
    for (const val of this._def.values) {
      enumValues[val] = val;
    }
    return enumValues;
  }
  extract(values, newDef = this._def) {
    return _ZodEnum.create(values, {
      ...this._def,
      ...newDef
    });
  }
  exclude(values, newDef = this._def) {
    return _ZodEnum.create(this.options.filter((opt) => !values.includes(opt)), {
      ...this._def,
      ...newDef
    });
  }
};
_ZodEnum_cache = /* @__PURE__ */ new WeakMap();
ZodEnum.create = createZodEnum;
var ZodNativeEnum = class extends ZodType {
  constructor() {
    super(...arguments);
    _ZodNativeEnum_cache.set(this, void 0);
  }
  _parse(input) {
    const nativeEnumValues = util.getValidEnumValues(this._def.values);
    const ctx = this._getOrReturnCtx(input);
    if (ctx.parsedType !== ZodParsedType.string && ctx.parsedType !== ZodParsedType.number) {
      const expectedValues = util.objectValues(nativeEnumValues);
      addIssueToContext(ctx, {
        expected: util.joinValues(expectedValues),
        received: ctx.parsedType,
        code: ZodIssueCode.invalid_type
      });
      return INVALID;
    }
    if (!__classPrivateFieldGet(this, _ZodNativeEnum_cache, "f")) {
      __classPrivateFieldSet(this, _ZodNativeEnum_cache, new Set(util.getValidEnumValues(this._def.values)), "f");
    }
    if (!__classPrivateFieldGet(this, _ZodNativeEnum_cache, "f").has(input.data)) {
      const expectedValues = util.objectValues(nativeEnumValues);
      addIssueToContext(ctx, {
        received: ctx.data,
        code: ZodIssueCode.invalid_enum_value,
        options: expectedValues
      });
      return INVALID;
    }
    return OK(input.data);
  }
  get enum() {
    return this._def.values;
  }
};
_ZodNativeEnum_cache = /* @__PURE__ */ new WeakMap();
ZodNativeEnum.create = (values, params) => {
  return new ZodNativeEnum({
    values,
    typeName: ZodFirstPartyTypeKind.ZodNativeEnum,
    ...processCreateParams(params)
  });
};
var ZodPromise = class extends ZodType {
  unwrap() {
    return this._def.type;
  }
  _parse(input) {
    const { ctx } = this._processInputParams(input);
    if (ctx.parsedType !== ZodParsedType.promise && ctx.common.async === false) {
      addIssueToContext(ctx, {
        code: ZodIssueCode.invalid_type,
        expected: ZodParsedType.promise,
        received: ctx.parsedType
      });
      return INVALID;
    }
    const promisified = ctx.parsedType === ZodParsedType.promise ? ctx.data : Promise.resolve(ctx.data);
    return OK(promisified.then((data) => {
      return this._def.type.parseAsync(data, {
        path: ctx.path,
        errorMap: ctx.common.contextualErrorMap
      });
    }));
  }
};
ZodPromise.create = (schema, params) => {
  return new ZodPromise({
    type: schema,
    typeName: ZodFirstPartyTypeKind.ZodPromise,
    ...processCreateParams(params)
  });
};
var ZodEffects = class extends ZodType {
  innerType() {
    return this._def.schema;
  }
  sourceType() {
    return this._def.schema._def.typeName === ZodFirstPartyTypeKind.ZodEffects ? this._def.schema.sourceType() : this._def.schema;
  }
  _parse(input) {
    const { status, ctx } = this._processInputParams(input);
    const effect = this._def.effect || null;
    const checkCtx = {
      addIssue: (arg) => {
        addIssueToContext(ctx, arg);
        if (arg.fatal) {
          status.abort();
        } else {
          status.dirty();
        }
      },
      get path() {
        return ctx.path;
      }
    };
    checkCtx.addIssue = checkCtx.addIssue.bind(checkCtx);
    if (effect.type === "preprocess") {
      const processed = effect.transform(ctx.data, checkCtx);
      if (ctx.common.async) {
        return Promise.resolve(processed).then(async (processed2) => {
          if (status.value === "aborted")
            return INVALID;
          const result = await this._def.schema._parseAsync({
            data: processed2,
            path: ctx.path,
            parent: ctx
          });
          if (result.status === "aborted")
            return INVALID;
          if (result.status === "dirty")
            return DIRTY(result.value);
          if (status.value === "dirty")
            return DIRTY(result.value);
          return result;
        });
      } else {
        if (status.value === "aborted")
          return INVALID;
        const result = this._def.schema._parseSync({
          data: processed,
          path: ctx.path,
          parent: ctx
        });
        if (result.status === "aborted")
          return INVALID;
        if (result.status === "dirty")
          return DIRTY(result.value);
        if (status.value === "dirty")
          return DIRTY(result.value);
        return result;
      }
    }
    if (effect.type === "refinement") {
      const executeRefinement = (acc) => {
        const result = effect.refinement(acc, checkCtx);
        if (ctx.common.async) {
          return Promise.resolve(result);
        }
        if (result instanceof Promise) {
          throw new Error("Async refinement encountered during synchronous parse operation. Use .parseAsync instead.");
        }
        return acc;
      };
      if (ctx.common.async === false) {
        const inner = this._def.schema._parseSync({
          data: ctx.data,
          path: ctx.path,
          parent: ctx
        });
        if (inner.status === "aborted")
          return INVALID;
        if (inner.status === "dirty")
          status.dirty();
        executeRefinement(inner.value);
        return { status: status.value, value: inner.value };
      } else {
        return this._def.schema._parseAsync({ data: ctx.data, path: ctx.path, parent: ctx }).then((inner) => {
          if (inner.status === "aborted")
            return INVALID;
          if (inner.status === "dirty")
            status.dirty();
          return executeRefinement(inner.value).then(() => {
            return { status: status.value, value: inner.value };
          });
        });
      }
    }
    if (effect.type === "transform") {
      if (ctx.common.async === false) {
        const base = this._def.schema._parseSync({
          data: ctx.data,
          path: ctx.path,
          parent: ctx
        });
        if (!isValid(base))
          return base;
        const result = effect.transform(base.value, checkCtx);
        if (result instanceof Promise) {
          throw new Error(`Asynchronous transform encountered during synchronous parse operation. Use .parseAsync instead.`);
        }
        return { status: status.value, value: result };
      } else {
        return this._def.schema._parseAsync({ data: ctx.data, path: ctx.path, parent: ctx }).then((base) => {
          if (!isValid(base))
            return base;
          return Promise.resolve(effect.transform(base.value, checkCtx)).then((result) => ({ status: status.value, value: result }));
        });
      }
    }
    util.assertNever(effect);
  }
};
ZodEffects.create = (schema, effect, params) => {
  return new ZodEffects({
    schema,
    typeName: ZodFirstPartyTypeKind.ZodEffects,
    effect,
    ...processCreateParams(params)
  });
};
ZodEffects.createWithPreprocess = (preprocess, schema, params) => {
  return new ZodEffects({
    schema,
    effect: { type: "preprocess", transform: preprocess },
    typeName: ZodFirstPartyTypeKind.ZodEffects,
    ...processCreateParams(params)
  });
};
var ZodOptional = class extends ZodType {
  _parse(input) {
    const parsedType = this._getType(input);
    if (parsedType === ZodParsedType.undefined) {
      return OK(void 0);
    }
    return this._def.innerType._parse(input);
  }
  unwrap() {
    return this._def.innerType;
  }
};
ZodOptional.create = (type, params) => {
  return new ZodOptional({
    innerType: type,
    typeName: ZodFirstPartyTypeKind.ZodOptional,
    ...processCreateParams(params)
  });
};
var ZodNullable = class extends ZodType {
  _parse(input) {
    const parsedType = this._getType(input);
    if (parsedType === ZodParsedType.null) {
      return OK(null);
    }
    return this._def.innerType._parse(input);
  }
  unwrap() {
    return this._def.innerType;
  }
};
ZodNullable.create = (type, params) => {
  return new ZodNullable({
    innerType: type,
    typeName: ZodFirstPartyTypeKind.ZodNullable,
    ...processCreateParams(params)
  });
};
var ZodDefault = class extends ZodType {
  _parse(input) {
    const { ctx } = this._processInputParams(input);
    let data = ctx.data;
    if (ctx.parsedType === ZodParsedType.undefined) {
      data = this._def.defaultValue();
    }
    return this._def.innerType._parse({
      data,
      path: ctx.path,
      parent: ctx
    });
  }
  removeDefault() {
    return this._def.innerType;
  }
};
ZodDefault.create = (type, params) => {
  return new ZodDefault({
    innerType: type,
    typeName: ZodFirstPartyTypeKind.ZodDefault,
    defaultValue: typeof params.default === "function" ? params.default : () => params.default,
    ...processCreateParams(params)
  });
};
var ZodCatch = class extends ZodType {
  _parse(input) {
    const { ctx } = this._processInputParams(input);
    const newCtx = {
      ...ctx,
      common: {
        ...ctx.common,
        issues: []
      }
    };
    const result = this._def.innerType._parse({
      data: newCtx.data,
      path: newCtx.path,
      parent: {
        ...newCtx
      }
    });
    if (isAsync(result)) {
      return result.then((result2) => {
        return {
          status: "valid",
          value: result2.status === "valid" ? result2.value : this._def.catchValue({
            get error() {
              return new ZodError(newCtx.common.issues);
            },
            input: newCtx.data
          })
        };
      });
    } else {
      return {
        status: "valid",
        value: result.status === "valid" ? result.value : this._def.catchValue({
          get error() {
            return new ZodError(newCtx.common.issues);
          },
          input: newCtx.data
        })
      };
    }
  }
  removeCatch() {
    return this._def.innerType;
  }
};
ZodCatch.create = (type, params) => {
  return new ZodCatch({
    innerType: type,
    typeName: ZodFirstPartyTypeKind.ZodCatch,
    catchValue: typeof params.catch === "function" ? params.catch : () => params.catch,
    ...processCreateParams(params)
  });
};
var ZodNaN = class extends ZodType {
  _parse(input) {
    const parsedType = this._getType(input);
    if (parsedType !== ZodParsedType.nan) {
      const ctx = this._getOrReturnCtx(input);
      addIssueToContext(ctx, {
        code: ZodIssueCode.invalid_type,
        expected: ZodParsedType.nan,
        received: ctx.parsedType
      });
      return INVALID;
    }
    return { status: "valid", value: input.data };
  }
};
ZodNaN.create = (params) => {
  return new ZodNaN({
    typeName: ZodFirstPartyTypeKind.ZodNaN,
    ...processCreateParams(params)
  });
};
var BRAND = Symbol("zod_brand");
var ZodBranded = class extends ZodType {
  _parse(input) {
    const { ctx } = this._processInputParams(input);
    const data = ctx.data;
    return this._def.type._parse({
      data,
      path: ctx.path,
      parent: ctx
    });
  }
  unwrap() {
    return this._def.type;
  }
};
var ZodPipeline = class _ZodPipeline extends ZodType {
  _parse(input) {
    const { status, ctx } = this._processInputParams(input);
    if (ctx.common.async) {
      const handleAsync = async () => {
        const inResult = await this._def.in._parseAsync({
          data: ctx.data,
          path: ctx.path,
          parent: ctx
        });
        if (inResult.status === "aborted")
          return INVALID;
        if (inResult.status === "dirty") {
          status.dirty();
          return DIRTY(inResult.value);
        } else {
          return this._def.out._parseAsync({
            data: inResult.value,
            path: ctx.path,
            parent: ctx
          });
        }
      };
      return handleAsync();
    } else {
      const inResult = this._def.in._parseSync({
        data: ctx.data,
        path: ctx.path,
        parent: ctx
      });
      if (inResult.status === "aborted")
        return INVALID;
      if (inResult.status === "dirty") {
        status.dirty();
        return {
          status: "dirty",
          value: inResult.value
        };
      } else {
        return this._def.out._parseSync({
          data: inResult.value,
          path: ctx.path,
          parent: ctx
        });
      }
    }
  }
  static create(a, b2) {
    return new _ZodPipeline({
      in: a,
      out: b2,
      typeName: ZodFirstPartyTypeKind.ZodPipeline
    });
  }
};
var ZodReadonly = class extends ZodType {
  _parse(input) {
    const result = this._def.innerType._parse(input);
    const freeze = (data) => {
      if (isValid(data)) {
        data.value = Object.freeze(data.value);
      }
      return data;
    };
    return isAsync(result) ? result.then((data) => freeze(data)) : freeze(result);
  }
  unwrap() {
    return this._def.innerType;
  }
};
ZodReadonly.create = (type, params) => {
  return new ZodReadonly({
    innerType: type,
    typeName: ZodFirstPartyTypeKind.ZodReadonly,
    ...processCreateParams(params)
  });
};
function cleanParams(params, data) {
  const p2 = typeof params === "function" ? params(data) : typeof params === "string" ? { message: params } : params;
  const p22 = typeof p2 === "string" ? { message: p2 } : p2;
  return p22;
}
function custom(check, _params = {}, fatal) {
  if (check)
    return ZodAny.create().superRefine((data, ctx) => {
      var _a, _b;
      const r2 = check(data);
      if (r2 instanceof Promise) {
        return r2.then((r3) => {
          var _a2, _b2;
          if (!r3) {
            const params = cleanParams(_params, data);
            const _fatal = (_b2 = (_a2 = params.fatal) !== null && _a2 !== void 0 ? _a2 : fatal) !== null && _b2 !== void 0 ? _b2 : true;
            ctx.addIssue({ code: "custom", ...params, fatal: _fatal });
          }
        });
      }
      if (!r2) {
        const params = cleanParams(_params, data);
        const _fatal = (_b = (_a = params.fatal) !== null && _a !== void 0 ? _a : fatal) !== null && _b !== void 0 ? _b : true;
        ctx.addIssue({ code: "custom", ...params, fatal: _fatal });
      }
      return;
    });
  return ZodAny.create();
}
var late = {
  object: ZodObject.lazycreate
};
var ZodFirstPartyTypeKind;
(function(ZodFirstPartyTypeKind2) {
  ZodFirstPartyTypeKind2["ZodString"] = "ZodString";
  ZodFirstPartyTypeKind2["ZodNumber"] = "ZodNumber";
  ZodFirstPartyTypeKind2["ZodNaN"] = "ZodNaN";
  ZodFirstPartyTypeKind2["ZodBigInt"] = "ZodBigInt";
  ZodFirstPartyTypeKind2["ZodBoolean"] = "ZodBoolean";
  ZodFirstPartyTypeKind2["ZodDate"] = "ZodDate";
  ZodFirstPartyTypeKind2["ZodSymbol"] = "ZodSymbol";
  ZodFirstPartyTypeKind2["ZodUndefined"] = "ZodUndefined";
  ZodFirstPartyTypeKind2["ZodNull"] = "ZodNull";
  ZodFirstPartyTypeKind2["ZodAny"] = "ZodAny";
  ZodFirstPartyTypeKind2["ZodUnknown"] = "ZodUnknown";
  ZodFirstPartyTypeKind2["ZodNever"] = "ZodNever";
  ZodFirstPartyTypeKind2["ZodVoid"] = "ZodVoid";
  ZodFirstPartyTypeKind2["ZodArray"] = "ZodArray";
  ZodFirstPartyTypeKind2["ZodObject"] = "ZodObject";
  ZodFirstPartyTypeKind2["ZodUnion"] = "ZodUnion";
  ZodFirstPartyTypeKind2["ZodDiscriminatedUnion"] = "ZodDiscriminatedUnion";
  ZodFirstPartyTypeKind2["ZodIntersection"] = "ZodIntersection";
  ZodFirstPartyTypeKind2["ZodTuple"] = "ZodTuple";
  ZodFirstPartyTypeKind2["ZodRecord"] = "ZodRecord";
  ZodFirstPartyTypeKind2["ZodMap"] = "ZodMap";
  ZodFirstPartyTypeKind2["ZodSet"] = "ZodSet";
  ZodFirstPartyTypeKind2["ZodFunction"] = "ZodFunction";
  ZodFirstPartyTypeKind2["ZodLazy"] = "ZodLazy";
  ZodFirstPartyTypeKind2["ZodLiteral"] = "ZodLiteral";
  ZodFirstPartyTypeKind2["ZodEnum"] = "ZodEnum";
  ZodFirstPartyTypeKind2["ZodEffects"] = "ZodEffects";
  ZodFirstPartyTypeKind2["ZodNativeEnum"] = "ZodNativeEnum";
  ZodFirstPartyTypeKind2["ZodOptional"] = "ZodOptional";
  ZodFirstPartyTypeKind2["ZodNullable"] = "ZodNullable";
  ZodFirstPartyTypeKind2["ZodDefault"] = "ZodDefault";
  ZodFirstPartyTypeKind2["ZodCatch"] = "ZodCatch";
  ZodFirstPartyTypeKind2["ZodPromise"] = "ZodPromise";
  ZodFirstPartyTypeKind2["ZodBranded"] = "ZodBranded";
  ZodFirstPartyTypeKind2["ZodPipeline"] = "ZodPipeline";
  ZodFirstPartyTypeKind2["ZodReadonly"] = "ZodReadonly";
})(ZodFirstPartyTypeKind || (ZodFirstPartyTypeKind = {}));
var instanceOfType = (cls, params = {
  message: `Input not instance of ${cls.name}`
}) => custom((data) => data instanceof cls, params);
var stringType = ZodString.create;
var numberType = ZodNumber.create;
var nanType = ZodNaN.create;
var bigIntType = ZodBigInt.create;
var booleanType = ZodBoolean.create;
var dateType = ZodDate.create;
var symbolType = ZodSymbol.create;
var undefinedType = ZodUndefined.create;
var nullType = ZodNull.create;
var anyType = ZodAny.create;
var unknownType = ZodUnknown.create;
var neverType = ZodNever.create;
var voidType = ZodVoid.create;
var arrayType = ZodArray.create;
var objectType = ZodObject.create;
var strictObjectType = ZodObject.strictCreate;
var unionType = ZodUnion.create;
var discriminatedUnionType = ZodDiscriminatedUnion.create;
var intersectionType = ZodIntersection.create;
var tupleType = ZodTuple.create;
var recordType = ZodRecord.create;
var mapType = ZodMap.create;
var setType = ZodSet.create;
var functionType = ZodFunction.create;
var lazyType = ZodLazy.create;
var literalType = ZodLiteral.create;
var enumType = ZodEnum.create;
var nativeEnumType = ZodNativeEnum.create;
var promiseType = ZodPromise.create;
var effectsType = ZodEffects.create;
var optionalType = ZodOptional.create;
var nullableType = ZodNullable.create;
var preprocessType = ZodEffects.createWithPreprocess;
var pipelineType = ZodPipeline.create;
var ostring = () => stringType().optional();
var onumber = () => numberType().optional();
var oboolean = () => booleanType().optional();
var coerce = {
  string: (arg) => ZodString.create({ ...arg, coerce: true }),
  number: (arg) => ZodNumber.create({ ...arg, coerce: true }),
  boolean: (arg) => ZodBoolean.create({
    ...arg,
    coerce: true
  }),
  bigint: (arg) => ZodBigInt.create({ ...arg, coerce: true }),
  date: (arg) => ZodDate.create({ ...arg, coerce: true })
};
var NEVER = INVALID;
var z = /* @__PURE__ */ Object.freeze({
  __proto__: null,
  defaultErrorMap: errorMap,
  setErrorMap,
  getErrorMap,
  makeIssue,
  EMPTY_PATH,
  addIssueToContext,
  ParseStatus,
  INVALID,
  DIRTY,
  OK,
  isAborted,
  isDirty,
  isValid,
  isAsync,
  get util() {
    return util;
  },
  get objectUtil() {
    return objectUtil;
  },
  ZodParsedType,
  getParsedType,
  ZodType,
  datetimeRegex,
  ZodString,
  ZodNumber,
  ZodBigInt,
  ZodBoolean,
  ZodDate,
  ZodSymbol,
  ZodUndefined,
  ZodNull,
  ZodAny,
  ZodUnknown,
  ZodNever,
  ZodVoid,
  ZodArray,
  ZodObject,
  ZodUnion,
  ZodDiscriminatedUnion,
  ZodIntersection,
  ZodTuple,
  ZodRecord,
  ZodMap,
  ZodSet,
  ZodFunction,
  ZodLazy,
  ZodLiteral,
  ZodEnum,
  ZodNativeEnum,
  ZodPromise,
  ZodEffects,
  ZodTransformer: ZodEffects,
  ZodOptional,
  ZodNullable,
  ZodDefault,
  ZodCatch,
  ZodNaN,
  BRAND,
  ZodBranded,
  ZodPipeline,
  ZodReadonly,
  custom,
  Schema: ZodType,
  ZodSchema: ZodType,
  late,
  get ZodFirstPartyTypeKind() {
    return ZodFirstPartyTypeKind;
  },
  coerce,
  any: anyType,
  array: arrayType,
  bigint: bigIntType,
  boolean: booleanType,
  date: dateType,
  discriminatedUnion: discriminatedUnionType,
  effect: effectsType,
  "enum": enumType,
  "function": functionType,
  "instanceof": instanceOfType,
  intersection: intersectionType,
  lazy: lazyType,
  literal: literalType,
  map: mapType,
  nan: nanType,
  nativeEnum: nativeEnumType,
  never: neverType,
  "null": nullType,
  nullable: nullableType,
  number: numberType,
  object: objectType,
  oboolean,
  onumber,
  optional: optionalType,
  ostring,
  pipeline: pipelineType,
  preprocess: preprocessType,
  promise: promiseType,
  record: recordType,
  set: setType,
  strictObject: strictObjectType,
  string: stringType,
  symbol: symbolType,
  transformer: effectsType,
  tuple: tupleType,
  "undefined": undefinedType,
  union: unionType,
  unknown: unknownType,
  "void": voidType,
  NEVER,
  ZodIssueCode,
  quotelessJson,
  ZodError
});

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/graph/graph.js
import { validate as isUuid } from "uuid";

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/read.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/write.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/utils.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/utils/config.js
init_esm();
var COPIABLE_KEYS = ["tags", "metadata", "callbacks", "configurable"];
var CONFIG_KEYS = [
  "tags",
  "metadata",
  "callbacks",
  "runName",
  "maxConcurrency",
  "recursionLimit",
  "configurable",
  "runId",
  "outputKeys",
  "streamMode",
  "store",
  "writer",
  "interruptBefore",
  "interruptAfter",
  "signal"
];
var DEFAULT_RECURSION_LIMIT = 25;
function ensureLangGraphConfig(...configs) {
  const empty = {
    tags: [],
    metadata: {},
    callbacks: void 0,
    recursionLimit: DEFAULT_RECURSION_LIMIT,
    configurable: {}
  };
  const implicitConfig = AsyncLocalStorageProviderSingleton.getRunnableConfig();
  if (implicitConfig !== void 0) {
    for (const [k2, v2] of Object.entries(implicitConfig)) {
      if (v2 !== void 0) {
        if (COPIABLE_KEYS.includes(k2)) {
          let copiedValue;
          if (Array.isArray(v2)) {
            copiedValue = [...v2];
          } else if (typeof v2 === "object") {
            if (k2 === "callbacks" && "copy" in v2 && typeof v2.copy === "function") {
              copiedValue = v2.copy();
            } else {
              copiedValue = { ...v2 };
            }
          } else {
            copiedValue = v2;
          }
          empty[k2] = copiedValue;
        } else {
          empty[k2] = v2;
        }
      }
    }
  }
  for (const config of configs) {
    if (config === void 0) {
      continue;
    }
    for (const [k2, v2] of Object.entries(config)) {
      if (v2 !== void 0 && CONFIG_KEYS.includes(k2)) {
        empty[k2] = v2;
      }
    }
  }
  for (const [key, value] of Object.entries(empty.configurable)) {
    empty.metadata = empty.metadata ?? {};
    if (!key.startsWith("__") && (typeof value === "string" || typeof value === "number" || typeof value === "boolean") && !(key in empty.metadata)) {
      empty.metadata[key] = value;
    }
  }
  return empty;
}
function recastCheckpointNamespace(namespace) {
  return namespace.split(CHECKPOINT_NAMESPACE_SEPARATOR).filter((part) => !part.match(/^\d+$/)).map((part) => part.split(CHECKPOINT_NAMESPACE_END)[0]).join(CHECKPOINT_NAMESPACE_SEPARATOR);
}
function getParentCheckpointNamespace(namespace) {
  const parts = namespace.split(CHECKPOINT_NAMESPACE_SEPARATOR);
  while (parts.length > 1 && parts[parts.length - 1].match(/^\d+$/)) {
    parts.pop();
  }
  return parts.slice(0, -1).join(CHECKPOINT_NAMESPACE_SEPARATOR);
}

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/utils.js
var RunnableCallable = class extends Runnable {
  constructor(fields) {
    super();
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langgraph"]
    });
    Object.defineProperty(this, "func", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "tags", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "config", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "trace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "recurse", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    this.name = fields.name ?? fields.func.name;
    this.func = fields.func;
    this.config = fields.tags ? { tags: fields.tags } : void 0;
    this.trace = fields.trace ?? this.trace;
    this.recurse = fields.recurse ?? this.recurse;
  }
  async _tracedInvoke(input, config, runManager) {
    return new Promise((resolve, reject) => {
      const childConfig = patchConfig(config, {
        callbacks: runManager?.getChild()
      });
      void AsyncLocalStorageProviderSingleton.runWithConfig(childConfig, async () => {
        try {
          const output = await this.func(input, childConfig);
          resolve(output);
        } catch (e2) {
          reject(e2);
        }
      });
    });
  }
  async invoke(input, options) {
    let returnValue;
    const config = ensureLangGraphConfig(options);
    const mergedConfig = mergeConfigs(this.config, config);
    if (this.trace) {
      returnValue = await this._callWithConfig(this._tracedInvoke, input, mergedConfig);
    } else {
      returnValue = await AsyncLocalStorageProviderSingleton.runWithConfig(mergedConfig, async () => this.func(input, mergedConfig));
    }
    if (Runnable.isRunnable(returnValue) && this.recurse) {
      return await AsyncLocalStorageProviderSingleton.runWithConfig(mergedConfig, async () => returnValue.invoke(input, mergedConfig));
    }
    return returnValue;
  }
};
function* prefixGenerator(generator, prefix) {
  if (prefix === void 0) {
    yield* generator;
  } else {
    for (const value of generator) {
      yield [prefix, value];
    }
  }
}
async function gatherIterator(i2) {
  const out = [];
  for await (const item of await i2) {
    out.push(item);
  }
  return out;
}
function gatherIteratorSync(i2) {
  const out = [];
  for (const item of i2) {
    out.push(item);
  }
  return out;
}
function patchConfigurable(config, patch) {
  if (!config) {
    return {
      configurable: patch
    };
  } else if (!("configurable" in config)) {
    return {
      ...config,
      configurable: patch
    };
  } else {
    return {
      ...config,
      configurable: {
        ...config.configurable,
        ...patch
      }
    };
  }
}
function isAsyncGeneratorFunction(val) {
  return val != null && typeof val === "function" && // eslint-disable-next-line no-instanceof/no-instanceof
  val instanceof Object.getPrototypeOf(async function* () {
  }).constructor;
}
function isGeneratorFunction(val) {
  return val != null && typeof val === "function" && // eslint-disable-next-line no-instanceof/no-instanceof
  val instanceof Object.getPrototypeOf(function* () {
  }).constructor;
}

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/write.js
var SKIP_WRITE = {
  [Symbol.for("LG_SKIP_WRITE")]: true
};
function _isSkipWrite(x2) {
  return typeof x2 === "object" && // eslint-disable-next-line @typescript-eslint/no-explicit-any
  x2?.[Symbol.for("LG_SKIP_WRITE")] !== void 0;
}
var PASSTHROUGH = {
  [Symbol.for("LG_PASSTHROUGH")]: true
};
function _isPassthrough(x2) {
  return typeof x2 === "object" && // eslint-disable-next-line @typescript-eslint/no-explicit-any
  x2?.[Symbol.for("LG_PASSTHROUGH")] !== void 0;
}
var IS_WRITER = Symbol("IS_WRITER");
var ChannelWrite = class _ChannelWrite extends RunnableCallable {
  constructor(writes, tags) {
    const name = `ChannelWrite<${writes.map((packet) => {
      if (_isSend(packet)) {
        return packet.node;
      } else if ("channel" in packet) {
        return packet.channel;
      }
      return "...";
    }).join(",")}>`;
    super({
      ...{ writes, name, tags },
      func: async (input, config) => {
        return this._write(input, config ?? {});
      }
    });
    Object.defineProperty(this, "writes", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.writes = writes;
  }
  async _write(input, config) {
    const writes = this.writes.map((write) => {
      if (_isChannelWriteTupleEntry(write) && _isPassthrough(write.value)) {
        return {
          mapper: write.mapper,
          value: input
        };
      } else if (_isChannelWriteEntry(write) && _isPassthrough(write.value)) {
        return {
          channel: write.channel,
          value: input,
          skipNone: write.skipNone,
          mapper: write.mapper
        };
      } else {
        return write;
      }
    });
    await _ChannelWrite.doWrite(config, writes);
    return input;
  }
  // TODO: Support requireAtLeastOneOf
  static async doWrite(config, writes) {
    for (const w2 of writes) {
      if (_isChannelWriteEntry(w2)) {
        if (w2.channel === TASKS2) {
          throw new InvalidUpdateError("Cannot write to the reserved channel TASKS");
        }
        if (_isPassthrough(w2.value)) {
          throw new InvalidUpdateError("PASSTHROUGH value must be replaced");
        }
      }
      if (_isChannelWriteTupleEntry(w2)) {
        if (_isPassthrough(w2.value)) {
          throw new InvalidUpdateError("PASSTHROUGH value must be replaced");
        }
      }
    }
    const writeEntries = [];
    for (const w2 of writes) {
      if (_isSend(w2)) {
        writeEntries.push([TASKS2, w2]);
      } else if (_isChannelWriteTupleEntry(w2)) {
        const mappedResult = await w2.mapper.invoke(w2.value, config);
        if (mappedResult != null && mappedResult.length > 0) {
          writeEntries.push(...mappedResult);
        }
      } else if (_isChannelWriteEntry(w2)) {
        const mappedValue = w2.mapper !== void 0 ? await w2.mapper.invoke(w2.value, config) : w2.value;
        if (_isSkipWrite(mappedValue)) {
          continue;
        }
        if (w2.skipNone && mappedValue === void 0) {
          continue;
        }
        writeEntries.push([w2.channel, mappedValue]);
      } else {
        throw new Error(`Invalid write entry: ${JSON.stringify(w2)}`);
      }
    }
    const write = config.configurable?.[CONFIG_KEY_SEND];
    write(writeEntries);
  }
  static isWriter(runnable) {
    return (
      // eslint-disable-next-line no-instanceof/no-instanceof
      runnable instanceof _ChannelWrite || IS_WRITER in runnable && !!runnable[IS_WRITER]
    );
  }
  static registerWriter(runnable) {
    return Object.defineProperty(runnable, IS_WRITER, { value: true });
  }
};
function _isChannelWriteEntry(x2) {
  return x2 !== void 0 && typeof x2.channel === "string";
}
function _isChannelWriteTupleEntry(x2) {
  return x2 !== void 0 && !_isChannelWriteEntry(x2) && Runnable.isRunnable(x2.mapper);
}

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/read.js
var ChannelRead = class _ChannelRead extends RunnableCallable {
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  constructor(channel, mapper, fresh = false) {
    super({
      func: (_2, config) => _ChannelRead.doRead(config, this.channel, this.fresh, this.mapper)
    });
    Object.defineProperty(this, "lc_graph_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "ChannelRead"
    });
    Object.defineProperty(this, "channel", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "fresh", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    Object.defineProperty(this, "mapper", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.fresh = fresh;
    this.mapper = mapper;
    this.channel = channel;
    this.name = Array.isArray(channel) ? `ChannelRead<${channel.join(",")}>` : `ChannelRead<${channel}>`;
  }
  static doRead(config, channel, fresh, mapper) {
    const read = config.configurable?.[CONFIG_KEY_READ];
    if (!read) {
      throw new Error("Runnable is not configured with a read function. Make sure to call in the context of a Pregel process");
    }
    if (mapper) {
      return mapper(read(channel, fresh));
    } else {
      return read(channel, fresh);
    }
  }
};
var defaultRunnableBound = /* @__PURE__ */ new RunnablePassthrough();
var PregelNode = class _PregelNode extends RunnableBinding {
  constructor(fields) {
    const { channels, triggers, mapper, writers, bound, kwargs, metadata, retryPolicy, cachePolicy, tags, subgraphs, ends } = fields;
    const mergedTags = [
      ...fields.config?.tags ? fields.config.tags : [],
      ...tags ?? []
    ];
    super({
      ...fields,
      bound: fields.bound ?? defaultRunnableBound,
      config: {
        ...fields.config ? fields.config : {},
        tags: mergedTags
      }
    });
    Object.defineProperty(this, "lc_graph_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "PregelNode"
    });
    Object.defineProperty(this, "channels", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "triggers", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    Object.defineProperty(this, "mapper", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "writers", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    Object.defineProperty(this, "bound", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: defaultRunnableBound
    });
    Object.defineProperty(this, "kwargs", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {}
    });
    Object.defineProperty(this, "metadata", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {}
    });
    Object.defineProperty(this, "tags", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    Object.defineProperty(this, "retryPolicy", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "cachePolicy", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "subgraphs", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "ends", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.channels = channels;
    this.triggers = triggers;
    this.mapper = mapper;
    this.writers = writers ?? this.writers;
    this.bound = bound ?? this.bound;
    this.kwargs = kwargs ?? this.kwargs;
    this.metadata = metadata ?? this.metadata;
    this.tags = mergedTags;
    this.retryPolicy = retryPolicy;
    this.cachePolicy = cachePolicy;
    this.subgraphs = subgraphs;
    this.ends = ends;
  }
  getWriters() {
    const newWriters = [...this.writers];
    while (newWriters.length > 1 && // eslint-disable-next-line no-instanceof/no-instanceof
    newWriters[newWriters.length - 1] instanceof ChannelWrite && // eslint-disable-next-line no-instanceof/no-instanceof
    newWriters[newWriters.length - 2] instanceof ChannelWrite) {
      const endWriters = newWriters.slice(-2);
      const combinedWrites = endWriters[0].writes.concat(endWriters[1].writes);
      newWriters[newWriters.length - 2] = new ChannelWrite(combinedWrites, endWriters[0].config?.tags);
      newWriters.pop();
    }
    return newWriters;
  }
  getNode() {
    const writers = this.getWriters();
    if (this.bound === defaultRunnableBound && writers.length === 0) {
      return void 0;
    } else if (this.bound === defaultRunnableBound && writers.length === 1) {
      return writers[0];
    } else if (this.bound === defaultRunnableBound) {
      return new RunnableSequence({
        first: writers[0],
        middle: writers.slice(1, writers.length - 1),
        last: writers[writers.length - 1],
        omitSequenceTags: true
      });
    } else if (writers.length > 0) {
      return new RunnableSequence({
        first: this.bound,
        middle: writers.slice(0, writers.length - 1),
        last: writers[writers.length - 1],
        omitSequenceTags: true
      });
    } else {
      return this.bound;
    }
  }
  join(channels) {
    if (!Array.isArray(channels)) {
      throw new Error("channels must be a list");
    }
    if (typeof this.channels !== "object") {
      throw new Error("all channels must be named when using .join()");
    }
    return new _PregelNode({
      channels: {
        ...this.channels,
        ...Object.fromEntries(channels.map((chan) => [chan, chan]))
      },
      triggers: this.triggers,
      mapper: this.mapper,
      writers: this.writers,
      bound: this.bound,
      kwargs: this.kwargs,
      config: this.config,
      retryPolicy: this.retryPolicy,
      cachePolicy: this.cachePolicy
    });
  }
  pipe(coerceable) {
    if (ChannelWrite.isWriter(coerceable)) {
      return new _PregelNode({
        channels: this.channels,
        triggers: this.triggers,
        mapper: this.mapper,
        writers: [...this.writers, coerceable],
        bound: this.bound,
        config: this.config,
        kwargs: this.kwargs,
        retryPolicy: this.retryPolicy,
        cachePolicy: this.cachePolicy
      });
    } else if (this.bound === defaultRunnableBound) {
      return new _PregelNode({
        channels: this.channels,
        triggers: this.triggers,
        mapper: this.mapper,
        writers: this.writers,
        bound: _coerceToRunnable(coerceable),
        config: this.config,
        kwargs: this.kwargs,
        retryPolicy: this.retryPolicy,
        cachePolicy: this.cachePolicy
      });
    } else {
      return new _PregelNode({
        channels: this.channels,
        triggers: this.triggers,
        mapper: this.mapper,
        writers: this.writers,
        bound: this.bound.pipe(coerceable),
        config: this.config,
        kwargs: this.kwargs,
        retryPolicy: this.retryPolicy,
        cachePolicy: this.cachePolicy
      });
    }
  }
};

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/index.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/validate.js
init_esm();
var GraphValidationError = class extends Error {
  constructor(message) {
    super(message);
    this.name = "GraphValidationError";
  }
};
function validateGraph({ nodes, channels, inputChannels, outputChannels, streamChannels, interruptAfterNodes, interruptBeforeNodes }) {
  if (!channels) {
    throw new GraphValidationError("Channels not provided");
  }
  const subscribedChannels = /* @__PURE__ */ new Set();
  const allOutputChannels = /* @__PURE__ */ new Set();
  for (const [name, node] of Object.entries(nodes)) {
    if (name === INTERRUPT2) {
      throw new GraphValidationError(`"Node name ${INTERRUPT2} is reserved"`);
    }
    if (node.constructor === PregelNode) {
      node.triggers.forEach((trigger) => subscribedChannels.add(trigger));
    } else {
      throw new GraphValidationError(`Invalid node type ${typeof node}, expected PregelNode`);
    }
  }
  for (const chan of subscribedChannels) {
    if (!(chan in channels)) {
      throw new GraphValidationError(`Subcribed channel '${String(chan)}' not in channels`);
    }
  }
  if (!Array.isArray(inputChannels)) {
    if (!subscribedChannels.has(inputChannels)) {
      throw new GraphValidationError(`Input channel ${String(inputChannels)} is not subscribed to by any node`);
    }
  } else {
    if (inputChannels.every((channel) => !subscribedChannels.has(channel))) {
      throw new GraphValidationError(`None of the input channels ${inputChannels} are subscribed to by any node`);
    }
  }
  if (!Array.isArray(outputChannels)) {
    allOutputChannels.add(outputChannels);
  } else {
    outputChannels.forEach((chan) => allOutputChannels.add(chan));
  }
  if (streamChannels && !Array.isArray(streamChannels)) {
    allOutputChannels.add(streamChannels);
  } else if (Array.isArray(streamChannels)) {
    streamChannels.forEach((chan) => allOutputChannels.add(chan));
  }
  for (const chan of allOutputChannels) {
    if (!(chan in channels)) {
      throw new GraphValidationError(`Output channel '${String(chan)}' not in channels`);
    }
  }
  if (interruptAfterNodes && interruptAfterNodes !== "*") {
    for (const node of interruptAfterNodes) {
      if (!(node in nodes)) {
        throw new GraphValidationError(`Node ${String(node)} not in nodes`);
      }
    }
  }
  if (interruptBeforeNodes && interruptBeforeNodes !== "*") {
    for (const node of interruptBeforeNodes) {
      if (!(node in nodes)) {
        throw new GraphValidationError(`Node ${String(node)} not in nodes`);
      }
    }
  }
}
function validateKeys(keys, channels) {
  if (Array.isArray(keys)) {
    for (const key of keys) {
      if (!(key in channels)) {
        throw new Error(`Key ${String(key)} not found in channels`);
      }
    }
  } else {
    if (!(keys in channels)) {
      throw new Error(`Key ${String(keys)} not found in channels`);
    }
  }
}

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/io.js
init_esm();
import { validate as validate2 } from "uuid";
function readChannel(channels, chan, catchErrors = true, returnException = false) {
  try {
    return channels[chan].get();
  } catch (e2) {
    if (e2.name === EmptyChannelError.unminifiable_name) {
      if (returnException) {
        return e2;
      } else if (catchErrors) {
        return null;
      }
    }
    throw e2;
  }
}
function readChannels(channels, select, skipEmpty = true) {
  if (Array.isArray(select)) {
    const values = {};
    for (const k2 of select) {
      try {
        values[k2] = readChannel(channels, k2, !skipEmpty);
      } catch (e2) {
        if (e2.name === EmptyChannelError.unminifiable_name) {
          continue;
        }
      }
    }
    return values;
  } else {
    return readChannel(channels, select);
  }
}
function* mapCommand(cmd, pendingWrites) {
  if (cmd.graph === Command.PARENT) {
    throw new InvalidUpdateError("There is no parent graph.");
  }
  if (cmd.goto) {
    let sends;
    if (Array.isArray(cmd.goto)) {
      sends = cmd.goto;
    } else {
      sends = [cmd.goto];
    }
    for (const send of sends) {
      if (_isSend(send)) {
        yield [NULL_TASK_ID, TASKS2, send];
      } else if (typeof send === "string") {
        yield [NULL_TASK_ID, `branch:to:${send}`, "__start__"];
      } else {
        throw new Error(`In Command.send, expected Send or string, got ${typeof send}`);
      }
    }
  }
  if (cmd.resume) {
    if (typeof cmd.resume === "object" && Object.keys(cmd.resume).length && Object.keys(cmd.resume).every(validate2)) {
      for (const [tid, resume] of Object.entries(cmd.resume)) {
        const existing = pendingWrites.filter((w2) => w2[0] === tid && w2[1] === RESUME2).map((w2) => w2[2]).slice(0, 1) ?? [];
        existing.push(resume);
        yield [tid, RESUME2, existing];
      }
    } else {
      yield [NULL_TASK_ID, RESUME2, cmd.resume];
    }
  }
  if (cmd.update) {
    if (typeof cmd.update !== "object" || !cmd.update) {
      throw new Error("Expected cmd.update to be a dict mapping channel names to update values");
    }
    if (Array.isArray(cmd.update)) {
      for (const [k2, v2] of cmd.update) {
        yield [NULL_TASK_ID, k2, v2];
      }
    } else {
      for (const [k2, v2] of Object.entries(cmd.update)) {
        yield [NULL_TASK_ID, k2, v2];
      }
    }
  }
}
function* mapInput(inputChannels, chunk) {
  if (chunk !== void 0 && chunk !== null) {
    if (Array.isArray(inputChannels) && typeof chunk === "object" && !Array.isArray(chunk)) {
      for (const k2 in chunk) {
        if (inputChannels.includes(k2)) {
          yield [k2, chunk[k2]];
        }
      }
    } else if (Array.isArray(inputChannels)) {
      throw new Error(`Input chunk must be an object when "inputChannels" is an array`);
    } else {
      yield [inputChannels, chunk];
    }
  }
}
function* mapOutputValues(outputChannels, pendingWrites, channels) {
  if (Array.isArray(outputChannels)) {
    if (pendingWrites === true || pendingWrites.find(([chan, _2]) => outputChannels.includes(chan))) {
      yield readChannels(channels, outputChannels);
    }
  } else {
    if (pendingWrites === true || pendingWrites.some(([chan, _2]) => chan === outputChannels)) {
      yield readChannel(channels, outputChannels);
    }
  }
}
function* mapOutputUpdates(outputChannels, tasks, cached) {
  const outputTasks = tasks.filter(([task3, ww]) => {
    return (task3.config === void 0 || !task3.config.tags?.includes(TAG_HIDDEN)) && ww[0][0] !== ERROR3 && ww[0][0] !== INTERRUPT2;
  });
  if (!outputTasks.length) {
    return;
  }
  let updated;
  if (outputTasks.some(([task3]) => task3.writes.some(([chan, _2]) => chan === RETURN))) {
    updated = outputTasks.flatMap(([task3]) => task3.writes.filter(([chan, _2]) => chan === RETURN).map(([_2, value]) => [task3.name, value]));
  } else if (!Array.isArray(outputChannels)) {
    updated = outputTasks.flatMap(([task3]) => task3.writes.filter(([chan, _2]) => chan === outputChannels).map(([_2, value]) => [task3.name, value]));
  } else {
    updated = outputTasks.flatMap(([task3]) => {
      const { writes } = task3;
      const counts = {};
      for (const [chan] of writes) {
        if (outputChannels.includes(chan)) {
          counts[chan] = (counts[chan] || 0) + 1;
        }
      }
      if (Object.values(counts).some((count) => count > 1)) {
        return writes.filter(([chan]) => outputChannels.includes(chan)).map(([chan, value]) => [task3.name, { [chan]: value }]);
      } else {
        return [
          [
            task3.name,
            Object.fromEntries(writes.filter(([chan]) => outputChannels.includes(chan)))
          ]
        ];
      }
    });
  }
  const grouped = {};
  for (const [node, value] of updated) {
    if (!(node in grouped)) {
      grouped[node] = [];
    }
    grouped[node].push(value);
  }
  const flattened = {};
  for (const node in grouped) {
    if (grouped[node].length === 1) {
      const [write] = grouped[node];
      flattened[node] = write;
    } else {
      flattened[node] = grouped[node];
    }
  }
  if (cached) {
    flattened["__metadata__"] = { cached };
  }
  yield flattened;
}

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/debug.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/utils/subgraph.js
init_esm();
function isRunnableSequence(x2) {
  return "steps" in x2 && Array.isArray(x2.steps);
}
function isPregelLike(x2) {
  return "lg_is_pregel" in x2 && x2.lg_is_pregel === true;
}
function findSubgraphPregel(candidate) {
  const candidates = [candidate];
  for (const candidate2 of candidates) {
    if (isPregelLike(candidate2)) {
      return candidate2;
    } else if (isRunnableSequence(candidate2)) {
      candidates.push(...candidate2.steps);
    }
  }
  return void 0;
}

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/debug.js
var COLORS_MAP = {
  blue: {
    start: "\x1B[34m",
    end: "\x1B[0m"
  },
  green: {
    start: "\x1B[32m",
    end: "\x1B[0m"
  },
  yellow: {
    start: "\x1B[33;1m",
    end: "\x1B[0m"
  }
};
var wrap = (color, text) => `${color.start}${text}${color.end}`;
function* mapDebugTasks(step, tasks) {
  const ts = (/* @__PURE__ */ new Date()).toISOString();
  for (const { id, name, input, config, triggers, writes } of tasks) {
    if (config?.tags?.includes(TAG_HIDDEN))
      continue;
    const interrupts = writes.filter(([writeId, n2]) => {
      return writeId === id && n2 === INTERRUPT2;
    }).map(([, v2]) => {
      return v2;
    });
    yield {
      type: "task",
      timestamp: ts,
      step,
      payload: {
        id,
        name,
        input,
        triggers,
        interrupts
      }
    };
  }
}
function* mapDebugTaskResults(step, tasks, streamChannels) {
  const ts = (/* @__PURE__ */ new Date()).toISOString();
  for (const [{ id, name, config }, writes] of tasks) {
    if (config?.tags?.includes(TAG_HIDDEN))
      continue;
    yield {
      type: "task_result",
      timestamp: ts,
      step,
      payload: {
        id,
        name,
        result: writes.filter(([channel]) => {
          return Array.isArray(streamChannels) ? streamChannels.includes(channel) : channel === streamChannels;
        }),
        interrupts: writes.filter((w2) => w2[0] === INTERRUPT2).map((w2) => w2[1])
      }
    };
  }
}
function* mapDebugCheckpoint(step, config, channels, streamChannels, metadata, tasks, pendingWrites, parentConfig) {
  function formatConfig(config2) {
    const pyConfig = {};
    if (config2.callbacks != null)
      pyConfig.callbacks = config2.callbacks;
    if (config2.configurable != null)
      pyConfig.configurable = config2.configurable;
    if (config2.maxConcurrency != null)
      pyConfig.max_concurrency = config2.maxConcurrency;
    if (config2.metadata != null)
      pyConfig.metadata = config2.metadata;
    if (config2.recursionLimit != null)
      pyConfig.recursion_limit = config2.recursionLimit;
    if (config2.runId != null)
      pyConfig.run_id = config2.runId;
    if (config2.runName != null)
      pyConfig.run_name = config2.runName;
    if (config2.tags != null)
      pyConfig.tags = config2.tags;
    return pyConfig;
  }
  const parentNs = config.configurable?.checkpoint_ns;
  const taskStates = {};
  for (const task3 of tasks) {
    const candidates = task3.subgraphs?.length ? task3.subgraphs : [task3.proc];
    if (!candidates.find(findSubgraphPregel))
      continue;
    let taskNs = `${task3.name}:${task3.id}`;
    if (parentNs)
      taskNs = `${parentNs}|${taskNs}`;
    taskStates[task3.id] = {
      configurable: {
        thread_id: config.configurable?.thread_id,
        checkpoint_ns: taskNs
      }
    };
  }
  const ts = (/* @__PURE__ */ new Date()).toISOString();
  yield {
    type: "checkpoint",
    timestamp: ts,
    step,
    payload: {
      config: formatConfig(config),
      values: readChannels(channels, streamChannels),
      metadata,
      next: tasks.map((task3) => task3.name),
      tasks: tasksWithWrites(tasks, pendingWrites, taskStates),
      parentConfig: parentConfig ? formatConfig(parentConfig) : void 0
    }
  };
}
function tasksWithWrites(tasks, pendingWrites, states) {
  return tasks.map((task3) => {
    const error = pendingWrites.find(([id, n2]) => id === task3.id && n2 === ERROR3)?.[2];
    const interrupts = pendingWrites.filter(([id, n2]) => {
      return id === task3.id && n2 === INTERRUPT2;
    }).map(([, , v2]) => {
      return v2;
    });
    if (error) {
      return {
        id: task3.id,
        name: task3.name,
        path: task3.path,
        error,
        interrupts
      };
    }
    const taskState = states?.[task3.id];
    return {
      id: task3.id,
      name: task3.name,
      path: task3.path,
      interrupts,
      ...taskState !== void 0 ? { state: taskState } : {}
    };
  });
}
function printStepCheckpoint(step, channels, whitelist) {
  console.log([
    `${wrap(COLORS_MAP.blue, `[${step}:checkpoint]`)}`,
    `\x1B[1m State at the end of step ${step}:\x1B[0m
`,
    JSON.stringify(readChannels(channels, whitelist), null, 2)
  ].join(""));
}
function printStepTasks(step, nextTasks) {
  const nTasks = nextTasks.length;
  console.log([
    `${wrap(COLORS_MAP.blue, `[${step}:tasks]`)}`,
    `\x1B[1m Starting step ${step} with ${nTasks} task${nTasks === 1 ? "" : "s"}:\x1B[0m
`,
    nextTasks.map((task3) => `- ${wrap(COLORS_MAP.green, String(task3.name))} -> ${JSON.stringify(task3.input, null, 2)}`).join("\n")
  ].join(""));
}
function printStepWrites(step, writes, whitelist) {
  const byChannel = {};
  for (const [channel, value] of writes) {
    if (whitelist.includes(channel)) {
      if (!byChannel[channel]) {
        byChannel[channel] = [];
      }
      byChannel[channel].push(value);
    }
  }
  console.log([
    `${wrap(COLORS_MAP.blue, `[${step}:writes]`)}`,
    `\x1B[1m Finished step ${step} with writes to ${Object.keys(byChannel).length} channel${Object.keys(byChannel).length !== 1 ? "s" : ""}:\x1B[0m
`,
    Object.entries(byChannel).map(([name, vals]) => `- ${wrap(COLORS_MAP.yellow, name)} -> ${vals.map((v2) => JSON.stringify(v2)).join(", ")}`).join("\n")
  ].join(""));
}

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/algo.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/types.js
init_esm();
var Call = class {
  constructor({ func, name, input, retry, cache: cache2, callbacks }) {
    Object.defineProperty(this, "func", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "input", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "retry", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "cache", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "callbacks", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "__lg_type", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "call"
    });
    this.func = func;
    this.name = name;
    this.input = input;
    this.retry = retry;
    this.cache = cache2;
    this.callbacks = callbacks;
  }
};
function isCall(value) {
  return typeof value === "object" && value !== null && "__lg_type" in value && value.__lg_type === "call";
}

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/utils/index.js
init_esm();
function getNullChannelVersion(currentVersions) {
  const versionValues = Object.values(currentVersions);
  const versionType = versionValues.length > 0 ? typeof versionValues[0] : void 0;
  let nullVersion;
  if (versionType === "number") {
    nullVersion = 0;
  } else if (versionType === "string") {
    nullVersion = "";
  }
  return nullVersion;
}
function getNewChannelVersions(previousVersions, currentVersions) {
  if (Object.keys(previousVersions).length > 0) {
    const nullVersion = getNullChannelVersion(currentVersions);
    return Object.fromEntries(Object.entries(currentVersions).filter(([k2, v2]) => v2 > (previousVersions[k2] ?? nullVersion)));
  } else {
    return currentVersions;
  }
}
function _coerceToDict2(value, defaultKey) {
  return value && !Array.isArray(value) && // eslint-disable-next-line no-instanceof/no-instanceof
  !(value instanceof Date) && typeof value === "object" ? value : { [defaultKey]: value };
}
function patchConfigurable2(config, patch) {
  if (config === null) {
    return { configurable: patch };
  } else if (config?.configurable === void 0) {
    return { ...config, configurable: patch };
  } else {
    return {
      ...config,
      configurable: { ...config.configurable, ...patch }
    };
  }
}
function patchCheckpointMap(config, metadata) {
  const parents = metadata?.parents ?? {};
  if (Object.keys(parents).length > 0) {
    return patchConfigurable2(config, {
      [CONFIG_KEY_CHECKPOINT_MAP]: {
        ...parents,
        [config.configurable?.checkpoint_ns ?? ""]: config.configurable?.checkpoint_id
      }
    });
  } else {
    return config;
  }
}
function combineAbortSignals(...signals) {
  if (signals.length === 1) {
    return signals[0];
  }
  const combinedController = new AbortController();
  const listener = () => {
    combinedController.abort();
    signals.forEach((s2) => s2.removeEventListener("abort", listener));
  };
  signals.forEach((s2) => s2.addEventListener("abort", listener));
  if (signals.some((s2) => s2.aborted)) {
    combinedController.abort();
  }
  return combinedController.signal;
}

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/call.js
init_esm();
function getRunnableForFunc(name, func) {
  const run = new RunnableCallable({
    func: (input) => func(...input),
    name,
    trace: false,
    recurse: false
  });
  return new RunnableSequence({
    name,
    first: run,
    last: new ChannelWrite([{ channel: RETURN, value: PASSTHROUGH }], [TAG_HIDDEN])
  });
}
function getRunnableForEntrypoint(name, func) {
  const run = new RunnableCallable({
    func: (input, config) => {
      return func(input, config);
    },
    name,
    trace: false,
    recurse: false
  });
  return run;
}

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/algo.js
var increment = (current) => {
  return current !== void 0 ? current + 1 : 1;
};
function shouldInterrupt(checkpoint, interruptNodes, tasks) {
  const versionValues = Object.values(checkpoint.channel_versions);
  const versionType = versionValues.length > 0 ? typeof versionValues[0] : void 0;
  let nullVersion;
  if (versionType === "number") {
    nullVersion = 0;
  } else if (versionType === "string") {
    nullVersion = "";
  }
  const seen = checkpoint.versions_seen[INTERRUPT2] ?? {};
  const anyChannelUpdated = Object.entries(checkpoint.channel_versions).some(([chan, version2]) => {
    return version2 > (seen[chan] ?? nullVersion);
  });
  const anyTriggeredNodeInInterruptNodes = tasks.some((task3) => interruptNodes === "*" ? !task3.config?.tags?.includes(TAG_HIDDEN) : interruptNodes.includes(task3.name));
  return anyChannelUpdated && anyTriggeredNodeInInterruptNodes;
}
function _localRead(step, checkpoint, channels, managed, task3, select, fresh = false) {
  let managedKeys = [];
  let updated = /* @__PURE__ */ new Set();
  if (!Array.isArray(select)) {
    for (const [c2] of task3.writes) {
      if (c2 === select) {
        updated = /* @__PURE__ */ new Set([c2]);
        break;
      }
    }
    updated = updated || /* @__PURE__ */ new Set();
  } else {
    managedKeys = select.filter((k2) => managed.get(k2));
    select = select.filter((k2) => !managed.get(k2));
    updated = new Set(select.filter((c2) => task3.writes.some(([key, _2]) => key === c2)));
  }
  let values;
  if (fresh && updated.size > 0) {
    const localChannels = Object.fromEntries(Object.entries(channels).filter(([k2, _2]) => updated.has(k2)));
    const newCheckpoint = createCheckpoint(checkpoint, localChannels, -1);
    const newChannels = emptyChannels(localChannels, newCheckpoint);
    _applyWrites(copyCheckpoint(newCheckpoint), newChannels, [task3], void 0, void 0);
    values = readChannels({ ...channels, ...newChannels }, select);
  } else {
    values = readChannels(channels, select);
  }
  if (managedKeys.length > 0) {
    for (const k2 of managedKeys) {
      const managedValue = managed.get(k2);
      if (managedValue) {
        const resultOfManagedCall = managedValue.call(step);
        values[k2] = resultOfManagedCall;
      }
    }
  }
  return values;
}
function _localWrite(step, commit, processes, managed, writes) {
  for (const [chan, value] of writes) {
    if ([PUSH, TASKS2].includes(chan) && value != null) {
      if (!_isSend(value)) {
        throw new InvalidUpdateError(`Invalid packet type, expected SendProtocol, got ${JSON.stringify(value)}`);
      }
      if (!(value.node in processes)) {
        throw new InvalidUpdateError(`Invalid node name "${value.node}" in Send packet`);
      }
      managed.replaceRuntimeValues(step, value.args);
    }
  }
  commit(writes);
}
var IGNORE = /* @__PURE__ */ new Set([
  NO_WRITES,
  PUSH,
  RESUME2,
  INTERRUPT2,
  RETURN,
  ERROR3
]);
function _applyWrites(checkpoint, channels, tasks, getNextVersion, triggerToNodes) {
  tasks.sort((a, b2) => {
    const aPath = a.path?.slice(0, 3) || [];
    const bPath = b2.path?.slice(0, 3) || [];
    for (let i2 = 0; i2 < Math.min(aPath.length, bPath.length); i2 += 1) {
      if (aPath[i2] < bPath[i2])
        return -1;
      if (aPath[i2] > bPath[i2])
        return 1;
    }
    return aPath.length - bPath.length;
  });
  const bumpStep = tasks.some((task3) => task3.triggers.length > 0);
  const onlyChannels = Object.fromEntries(Object.entries(channels).filter(([_2, value]) => isBaseChannel(value)));
  for (const task3 of tasks) {
    checkpoint.versions_seen[task3.name] ??= {};
    for (const chan of task3.triggers) {
      if (chan in checkpoint.channel_versions) {
        checkpoint.versions_seen[task3.name][chan] = checkpoint.channel_versions[chan];
      }
    }
  }
  let maxVersion;
  if (Object.keys(checkpoint.channel_versions).length > 0) {
    maxVersion = maxChannelVersion(...Object.values(checkpoint.channel_versions));
  }
  const channelsToConsume = new Set(tasks.flatMap((task3) => task3.triggers).filter((chan) => !RESERVED.includes(chan)));
  for (const chan of channelsToConsume) {
    if (chan in onlyChannels && onlyChannels[chan].consume()) {
      if (getNextVersion !== void 0) {
        checkpoint.channel_versions[chan] = getNextVersion(maxVersion, onlyChannels[chan]);
      }
    }
  }
  if (checkpoint.pending_sends?.length && bumpStep) {
    checkpoint.pending_sends = [];
  }
  const pendingWriteValuesByChannel = {};
  const pendingWritesByManaged = {};
  for (const task3 of tasks) {
    for (const [chan, val] of task3.writes) {
      if (IGNORE.has(chan)) {
      } else if (chan === TASKS2) {
        checkpoint.pending_sends.push({
          node: val.node,
          args: val.args
        });
      } else if (chan in onlyChannels) {
        pendingWriteValuesByChannel[chan] ??= [];
        pendingWriteValuesByChannel[chan].push(val);
      } else {
        pendingWritesByManaged[chan] ??= [];
        pendingWritesByManaged[chan].push(val);
      }
    }
  }
  maxVersion = void 0;
  if (Object.keys(checkpoint.channel_versions).length > 0) {
    maxVersion = maxChannelVersion(...Object.values(checkpoint.channel_versions));
  }
  const updatedChannels = /* @__PURE__ */ new Set();
  for (const [chan, vals] of Object.entries(pendingWriteValuesByChannel)) {
    if (chan in onlyChannels) {
      let updated;
      try {
        updated = onlyChannels[chan].update(vals);
      } catch (e2) {
        if (e2.name === InvalidUpdateError.unminifiable_name) {
          const wrappedError = new InvalidUpdateError(`Invalid update for channel "${chan}" with values ${JSON.stringify(vals)}: ${e2.message}`);
          wrappedError.lc_error_code = e2.lc_error_code;
          throw wrappedError;
        } else {
          throw e2;
        }
      }
      if (updated && getNextVersion !== void 0) {
        checkpoint.channel_versions[chan] = getNextVersion(maxVersion, onlyChannels[chan]);
        if (onlyChannels[chan].isAvailable()) {
          updatedChannels.add(chan);
        }
      }
    }
  }
  if (bumpStep) {
    for (const chan of Object.keys(onlyChannels)) {
      if (onlyChannels[chan].isAvailable() && !updatedChannels.has(chan)) {
        const updated = onlyChannels[chan].update([]);
        if (updated && getNextVersion !== void 0) {
          checkpoint.channel_versions[chan] = getNextVersion(maxVersion, onlyChannels[chan]);
          if (onlyChannels[chan].isAvailable()) {
            updatedChannels.add(chan);
          }
        }
      }
    }
  }
  if (bumpStep && checkpoint.pending_sends.length === 0 && !Object.keys(triggerToNodes ?? {}).some((channel) => updatedChannels.has(channel))) {
    for (const chan of Object.keys(onlyChannels)) {
      if (onlyChannels[chan].finish() && getNextVersion !== void 0) {
        checkpoint.channel_versions[chan] = getNextVersion(maxVersion, onlyChannels[chan]);
        if (onlyChannels[chan].isAvailable()) {
          updatedChannels.add(chan);
        }
      }
    }
  }
  return pendingWritesByManaged;
}
function _prepareNextTasks(checkpoint, pendingWrites, processes, channels, managed, config, forExecution, extra) {
  const tasks = {};
  for (let i2 = 0; i2 < checkpoint.pending_sends.length; i2 += 1) {
    const task3 = _prepareSingleTask([PUSH, i2], checkpoint, pendingWrites, processes, channels, managed, config, forExecution, extra);
    if (task3 !== void 0) {
      tasks[task3.id] = task3;
    }
  }
  for (const name of Object.keys(processes)) {
    const task3 = _prepareSingleTask([PULL, name], checkpoint, pendingWrites, processes, channels, managed, config, forExecution, extra);
    if (task3 !== void 0) {
      tasks[task3.id] = task3;
    }
  }
  return tasks;
}
function _prepareSingleTask(taskPath, checkpoint, pendingWrites, processes, channels, managed, config, forExecution, extra) {
  const { step, checkpointer, manager: manager2 } = extra;
  const configurable = config.configurable ?? {};
  const parentNamespace = configurable.checkpoint_ns ?? "";
  if (taskPath[0] === PUSH && isCall(taskPath[taskPath.length - 1])) {
    const call3 = taskPath[taskPath.length - 1];
    const proc = getRunnableForFunc(call3.name, call3.func);
    const triggers = [PUSH];
    const checkpointNamespace = parentNamespace === "" ? call3.name : `${parentNamespace}${CHECKPOINT_NAMESPACE_SEPARATOR}${call3.name}`;
    const id = uuid5(JSON.stringify([
      checkpointNamespace,
      step.toString(),
      call3.name,
      PUSH,
      taskPath[1],
      taskPath[2]
    ]), checkpoint.id);
    const taskCheckpointNamespace = `${checkpointNamespace}${CHECKPOINT_NAMESPACE_END}${id}`;
    const metadata = {
      langgraph_step: step,
      langgraph_node: call3.name,
      langgraph_triggers: triggers,
      langgraph_path: taskPath.slice(0, 3),
      langgraph_checkpoint_ns: taskCheckpointNamespace
    };
    if (forExecution) {
      const writes = [];
      const task3 = {
        name: call3.name,
        input: call3.input,
        proc,
        writes,
        config: patchConfig(mergeConfigs(config, {
          metadata,
          store: extra.store ?? config.store
        }), {
          runName: call3.name,
          callbacks: manager2?.getChild(`graph:step:${step}`),
          configurable: {
            [CONFIG_KEY_TASK_ID]: id,
            // eslint-disable-next-line @typescript-eslint/no-explicit-any
            [CONFIG_KEY_SEND]: (writes_) => _localWrite(step, (items) => writes.push(...items), processes, managed, writes_),
            [CONFIG_KEY_READ]: (select_, fresh_ = false) => _localRead(step, checkpoint, channels, managed, {
              name: call3.name,
              writes,
              triggers,
              path: taskPath.slice(0, 3)
            }, select_, fresh_),
            [CONFIG_KEY_CHECKPOINTER]: checkpointer ?? configurable[CONFIG_KEY_CHECKPOINTER],
            [CONFIG_KEY_CHECKPOINT_MAP]: {
              ...configurable[CONFIG_KEY_CHECKPOINT_MAP],
              [parentNamespace]: checkpoint.id
            },
            [CONFIG_KEY_SCRATCHPAD]: _scratchpad({
              pendingWrites: pendingWrites ?? [],
              taskId: id,
              currentTaskInput: call3.input
            }),
            [CONFIG_KEY_PREVIOUS_STATE]: checkpoint.channel_values[PREVIOUS],
            checkpoint_id: void 0,
            checkpoint_ns: taskCheckpointNamespace
          }
        }),
        triggers,
        retry_policy: call3.retry,
        cache_key: call3.cache ? {
          // TODO: add xxh3_128 hex digest
          key: (call3.cache.keyFunc ?? JSON.stringify)([call3.input]),
          ns: [CACHE_NS_WRITES, call3.name ?? "__dynamic__"],
          ttl: call3.cache.ttl
        } : void 0,
        id,
        path: taskPath.slice(0, 3),
        writers: []
      };
      return task3;
    } else {
      return {
        id,
        name: call3.name,
        interrupts: [],
        path: taskPath.slice(0, 3)
      };
    }
  } else if (taskPath[0] === PUSH) {
    const index = typeof taskPath[1] === "number" ? taskPath[1] : parseInt(taskPath[1], 10);
    if (index >= checkpoint.pending_sends.length) {
      return void 0;
    }
    const packet = _isSendInterface(checkpoint.pending_sends[index]) && !_isSend(checkpoint.pending_sends[index]) ? new Send(checkpoint.pending_sends[index].node, checkpoint.pending_sends[index].args) : checkpoint.pending_sends[index];
    if (!_isSendInterface(packet)) {
      console.warn(`Ignoring invalid packet ${JSON.stringify(packet)} in pending sends.`);
      return void 0;
    }
    if (!(packet.node in processes)) {
      console.warn(`Ignoring unknown node name ${packet.node} in pending sends.`);
      return void 0;
    }
    const triggers = [PUSH];
    const checkpointNamespace = parentNamespace === "" ? packet.node : `${parentNamespace}${CHECKPOINT_NAMESPACE_SEPARATOR}${packet.node}`;
    const taskId = uuid5(JSON.stringify([
      checkpointNamespace,
      step.toString(),
      packet.node,
      PUSH,
      index.toString()
    ]), checkpoint.id);
    const taskCheckpointNamespace = `${checkpointNamespace}${CHECKPOINT_NAMESPACE_END}${taskId}`;
    let metadata = {
      langgraph_step: step,
      langgraph_node: packet.node,
      langgraph_triggers: triggers,
      langgraph_path: taskPath.slice(0, 3),
      langgraph_checkpoint_ns: taskCheckpointNamespace
    };
    if (forExecution) {
      const proc = processes[packet.node];
      const node = proc.getNode();
      if (node !== void 0) {
        managed.replaceRuntimePlaceholders(step, packet.args);
        if (proc.metadata !== void 0) {
          metadata = { ...metadata, ...proc.metadata };
        }
        const writes = [];
        return {
          name: packet.node,
          input: packet.args,
          proc: node,
          subgraphs: proc.subgraphs,
          writes,
          config: patchConfig(mergeConfigs(config, {
            metadata,
            tags: proc.tags,
            store: extra.store ?? config.store
          }), {
            runName: packet.node,
            callbacks: manager2?.getChild(`graph:step:${step}`),
            configurable: {
              [CONFIG_KEY_TASK_ID]: taskId,
              // eslint-disable-next-line @typescript-eslint/no-explicit-any
              [CONFIG_KEY_SEND]: (writes_) => _localWrite(step, (items) => writes.push(...items), processes, managed, writes_),
              [CONFIG_KEY_READ]: (select_, fresh_ = false) => _localRead(step, checkpoint, channels, managed, {
                name: packet.node,
                writes,
                triggers,
                path: taskPath
              }, select_, fresh_),
              [CONFIG_KEY_CHECKPOINTER]: checkpointer ?? configurable[CONFIG_KEY_CHECKPOINTER],
              [CONFIG_KEY_CHECKPOINT_MAP]: {
                ...configurable[CONFIG_KEY_CHECKPOINT_MAP],
                [parentNamespace]: checkpoint.id
              },
              [CONFIG_KEY_SCRATCHPAD]: _scratchpad({
                pendingWrites: pendingWrites ?? [],
                taskId,
                currentTaskInput: packet.args
              }),
              [CONFIG_KEY_PREVIOUS_STATE]: checkpoint.channel_values[PREVIOUS],
              checkpoint_id: void 0,
              checkpoint_ns: taskCheckpointNamespace
            }
          }),
          triggers,
          retry_policy: proc.retryPolicy,
          cache_key: proc.cachePolicy ? {
            key: (proc.cachePolicy.keyFunc ?? JSON.stringify)([
              packet.args
            ]),
            ns: [CACHE_NS_WRITES, proc.name ?? "__dynamic__", packet.node],
            ttl: proc.cachePolicy.ttl
          } : void 0,
          id: taskId,
          path: taskPath,
          writers: proc.getWriters()
        };
      }
    } else {
      return {
        id: taskId,
        name: packet.node,
        interrupts: [],
        path: taskPath
      };
    }
  } else if (taskPath[0] === PULL) {
    const name = taskPath[1].toString();
    const proc = processes[name];
    if (proc === void 0) {
      return void 0;
    }
    if (pendingWrites?.length) {
      const checkpointNamespace = parentNamespace === "" ? name : `${parentNamespace}${CHECKPOINT_NAMESPACE_SEPARATOR}${name}`;
      const taskId = uuid5(JSON.stringify([
        checkpointNamespace,
        step.toString(),
        name,
        PULL,
        name
      ]), checkpoint.id);
      const hasSuccessfulWrites = pendingWrites.some((w2) => w2[0] === taskId && w2[1] !== ERROR3);
      if (hasSuccessfulWrites) {
        return void 0;
      }
    }
    const nullVersion = getNullChannelVersion(checkpoint.channel_versions);
    if (nullVersion === void 0) {
      return void 0;
    }
    const seen = checkpoint.versions_seen[name] ?? {};
    const triggers = proc.triggers.filter((chan) => {
      const result = readChannel(channels, chan, false, true);
      const isEmptyChannelError = (
        // eslint-disable-next-line no-instanceof/no-instanceof
        result instanceof Error && result.name === EmptyChannelError.unminifiable_name
      );
      return !isEmptyChannelError && (checkpoint.channel_versions[chan] ?? nullVersion) > (seen[chan] ?? nullVersion);
    }).sort();
    if (triggers.length > 0) {
      const val = _procInput(step, proc, managed, channels, forExecution);
      if (val === void 0) {
        return void 0;
      }
      const checkpointNamespace = parentNamespace === "" ? name : `${parentNamespace}${CHECKPOINT_NAMESPACE_SEPARATOR}${name}`;
      const taskId = uuid5(JSON.stringify([
        checkpointNamespace,
        step.toString(),
        name,
        PULL,
        triggers
      ]), checkpoint.id);
      const taskCheckpointNamespace = `${checkpointNamespace}${CHECKPOINT_NAMESPACE_END}${taskId}`;
      let metadata = {
        langgraph_step: step,
        langgraph_node: name,
        langgraph_triggers: triggers,
        langgraph_path: taskPath,
        langgraph_checkpoint_ns: taskCheckpointNamespace
      };
      if (forExecution) {
        const node = proc.getNode();
        if (node !== void 0) {
          if (proc.metadata !== void 0) {
            metadata = { ...metadata, ...proc.metadata };
          }
          const writes = [];
          return {
            name,
            input: val,
            proc: node,
            subgraphs: proc.subgraphs,
            writes,
            config: patchConfig(mergeConfigs(config, {
              metadata,
              tags: proc.tags,
              store: extra.store ?? config.store
            }), {
              runName: name,
              callbacks: manager2?.getChild(`graph:step:${step}`),
              configurable: {
                [CONFIG_KEY_TASK_ID]: taskId,
                // eslint-disable-next-line @typescript-eslint/no-explicit-any
                [CONFIG_KEY_SEND]: (writes_) => _localWrite(step, (items) => {
                  writes.push(...items);
                }, processes, managed, writes_),
                [CONFIG_KEY_READ]: (select_, fresh_ = false) => _localRead(step, checkpoint, channels, managed, {
                  name,
                  writes,
                  triggers,
                  path: taskPath
                }, select_, fresh_),
                [CONFIG_KEY_CHECKPOINTER]: checkpointer ?? configurable[CONFIG_KEY_CHECKPOINTER],
                [CONFIG_KEY_CHECKPOINT_MAP]: {
                  ...configurable[CONFIG_KEY_CHECKPOINT_MAP],
                  [parentNamespace]: checkpoint.id
                },
                [CONFIG_KEY_SCRATCHPAD]: _scratchpad({
                  pendingWrites: pendingWrites ?? [],
                  taskId,
                  currentTaskInput: val
                }),
                [CONFIG_KEY_PREVIOUS_STATE]: checkpoint.channel_values[PREVIOUS],
                checkpoint_id: void 0,
                checkpoint_ns: taskCheckpointNamespace
              }
            }),
            triggers,
            retry_policy: proc.retryPolicy,
            cache_key: proc.cachePolicy ? {
              key: (proc.cachePolicy.keyFunc ?? JSON.stringify)([val]),
              ns: [CACHE_NS_WRITES, proc.name ?? "__dynamic__", name],
              ttl: proc.cachePolicy.ttl
            } : void 0,
            id: taskId,
            path: taskPath,
            writers: proc.getWriters()
          };
        }
      } else {
        return {
          id: taskId,
          name,
          interrupts: [],
          path: taskPath
        };
      }
    }
  }
  return void 0;
}
function _procInput(step, proc, managed, channels, forExecution) {
  let val;
  if (typeof proc.channels === "object" && !Array.isArray(proc.channels)) {
    val = {};
    for (const [k2, chan] of Object.entries(proc.channels)) {
      if (proc.triggers.includes(chan)) {
        try {
          val[k2] = readChannel(channels, chan, false);
        } catch (e2) {
          if (e2.name === EmptyChannelError.unminifiable_name) {
            return void 0;
          } else {
            throw e2;
          }
        }
      } else if (chan in channels) {
        try {
          val[k2] = readChannel(channels, chan, false);
        } catch (e2) {
          if (e2.name === EmptyChannelError.unminifiable_name) {
            continue;
          } else {
            throw e2;
          }
        }
      } else {
        val[k2] = managed.get(k2)?.call(step);
      }
    }
  } else if (Array.isArray(proc.channels)) {
    let successfulRead = false;
    for (const chan of proc.channels) {
      try {
        val = readChannel(channels, chan, false);
        successfulRead = true;
        break;
      } catch (e2) {
        if (e2.name === EmptyChannelError.unminifiable_name) {
          continue;
        } else {
          throw e2;
        }
      }
    }
    if (!successfulRead) {
      return void 0;
    }
  } else {
    throw new Error(`Invalid channels type, expected list or dict, got ${proc.channels}`);
  }
  if (forExecution && proc.mapper !== void 0) {
    val = proc.mapper(val);
  }
  return val;
}
function _scratchpad({ pendingWrites, taskId, currentTaskInput }) {
  const nullResume = pendingWrites.find(([writeTaskId, chan]) => writeTaskId === NULL_TASK_ID && chan === RESUME2)?.[2];
  const scratchpad = {
    callCounter: 0,
    interruptCounter: -1,
    resume: pendingWrites.filter(([writeTaskId, chan]) => writeTaskId === taskId && chan === RESUME2).flatMap(([_writeTaskId, _chan, resume]) => resume),
    nullResume,
    subgraphCounter: 0,
    currentTaskInput,
    consumeNullResume: () => {
      if (scratchpad.nullResume) {
        delete scratchpad.nullResume;
        pendingWrites.splice(pendingWrites.findIndex(([writeTaskId, chan]) => writeTaskId === NULL_TASK_ID && chan === RESUME2), 1);
        return nullResume;
      }
      return void 0;
    }
  };
  return scratchpad;
}

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/loop.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/stream.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/utils/stream.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/stream.js
var IterableReadableStreamWithAbortSignal = class extends IterableReadableStream {
  /**
   * @param readableStream - The stream to wrap.
   * @param abortController - The abort controller to use. Optional. One will be created if not provided.
   */
  constructor(readableStream, abortController) {
    const reader = readableStream.getReader();
    const ac = abortController ?? new AbortController();
    super({
      start(controller) {
        return pump();
        function pump() {
          return reader.read().then(({ done, value }) => {
            if (done) {
              controller.close();
              return;
            }
            controller.enqueue(value);
            return pump();
          });
        }
      }
    });
    Object.defineProperty(this, "_abortController", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "_reader", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this._abortController = ac;
    this._reader = reader;
  }
  /**
   * Aborts the stream, abandoning any pending operations in progress. Calling this triggers an
   * {@link AbortSignal} that is propagated to the tasks that are producing the data for this stream.
   * @param reason - The reason for aborting the stream. Optional.
   */
  async cancel(reason) {
    this._abortController.abort(reason);
    this._reader.releaseLock();
  }
  /**
   * The {@link AbortSignal} for the stream. Aborted when {@link cancel} is called.
   */
  get signal() {
    return this._abortController.signal;
  }
};
var IterableReadableWritableStream = class extends IterableReadableStream {
  get closed() {
    return this._closed;
  }
  constructor(params) {
    let streamControllerPromiseResolver;
    const streamControllerPromise = new Promise((resolve) => {
      streamControllerPromiseResolver = resolve;
    });
    super({
      start: (controller) => {
        streamControllerPromiseResolver(controller);
      }
    });
    Object.defineProperty(this, "modes", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "controller", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "passthroughFn", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "_closed", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    void streamControllerPromise.then((controller) => {
      this.controller = controller;
    });
    this.passthroughFn = params.passthroughFn;
    this.modes = params.modes;
  }
  push(chunk) {
    this.passthroughFn?.(chunk);
    this.controller.enqueue(chunk);
  }
  close() {
    try {
      this.controller.close();
    } catch (e2) {
    } finally {
      this._closed = true;
    }
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  error(e2) {
    this.controller.error(e2);
  }
};

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/loop.js
var INPUT_DONE = Symbol.for("INPUT_DONE");
var INPUT_RESUMING = Symbol.for("INPUT_RESUMING");
var DEFAULT_LOOP_LIMIT = 25;
function createDuplexStream(...streams) {
  return new IterableReadableWritableStream({
    passthroughFn: (value) => {
      for (const stream of streams) {
        if (stream.modes.has(value[1])) {
          stream.push(value);
        }
      }
    },
    modes: new Set(streams.flatMap((s2) => Array.from(s2.modes)))
  });
}
var AsyncBatchedCache = class extends BaseCache2 {
  constructor(cache2) {
    super();
    Object.defineProperty(this, "cache", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "queue", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: Promise.resolve()
    });
    this.cache = cache2;
  }
  async get(keys) {
    return this.enqueueOperation("get", keys);
  }
  async set(pairs) {
    return this.enqueueOperation("set", pairs);
  }
  async clear(namespaces) {
    return this.enqueueOperation("clear", namespaces);
  }
  async stop() {
    await this.queue;
  }
  enqueueOperation(type, ...args) {
    const newPromise = this.queue.then(() => {
      return this.cache[type](...args);
    });
    this.queue = newPromise.then(() => void 0, () => void 0);
    return newPromise;
  }
};
var PregelLoop = class _PregelLoop {
  get isResuming() {
    const hasChannelVersions = Object.keys(this.checkpoint.channel_versions).length !== 0;
    const configHasResumingFlag = this.config.configurable?.[CONFIG_KEY_RESUMING] !== void 0;
    const configIsResuming = configHasResumingFlag && this.config.configurable?.[CONFIG_KEY_RESUMING];
    const inputIsNullOrUndefined = this.input === null || this.input === void 0;
    const inputIsCommandResuming = isCommand(this.input) && this.input.resume != null;
    const inputIsResuming = this.input === INPUT_RESUMING;
    return hasChannelVersions && (configIsResuming || inputIsNullOrUndefined || inputIsCommandResuming || inputIsResuming);
  }
  constructor(params) {
    Object.defineProperty(this, "input", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "output", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "config", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "checkpointer", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "checkpointerGetNextVersion", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "channels", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "managed", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "checkpoint", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "checkpointConfig", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "checkpointMetadata", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "checkpointNamespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "checkpointPendingWrites", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    Object.defineProperty(this, "checkpointPreviousVersions", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "step", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "stop", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "outputKeys", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "streamKeys", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "nodes", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "skipDoneTasks", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "prevCheckpointConfig", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "status", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "pending"
    });
    Object.defineProperty(this, "tasks", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {}
    });
    Object.defineProperty(this, "stream", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "checkpointerPromises", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    Object.defineProperty(this, "isNested", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "_checkpointerChainedPromise", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: Promise.resolve()
    });
    Object.defineProperty(this, "store", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "cache", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "manager", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "interruptAfter", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "interruptBefore", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "toInterrupt", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    Object.defineProperty(this, "debug", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    Object.defineProperty(this, "triggerToNodes", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.input = params.input;
    this.checkpointer = params.checkpointer;
    if (this.checkpointer !== void 0) {
      this.checkpointerGetNextVersion = this.checkpointer.getNextVersion.bind(this.checkpointer);
    } else {
      this.checkpointerGetNextVersion = increment;
    }
    this.checkpoint = params.checkpoint;
    this.checkpointMetadata = params.checkpointMetadata;
    this.checkpointPreviousVersions = params.checkpointPreviousVersions;
    this.channels = params.channels;
    this.managed = params.managed;
    this.checkpointPendingWrites = params.checkpointPendingWrites;
    this.step = params.step;
    this.stop = params.stop;
    this.config = params.config;
    this.checkpointConfig = params.checkpointConfig;
    this.isNested = params.isNested;
    this.manager = params.manager;
    this.outputKeys = params.outputKeys;
    this.streamKeys = params.streamKeys;
    this.nodes = params.nodes;
    this.skipDoneTasks = params.skipDoneTasks;
    this.store = params.store;
    this.cache = params.cache ? new AsyncBatchedCache(params.cache) : void 0;
    this.stream = params.stream;
    this.checkpointNamespace = params.checkpointNamespace;
    this.prevCheckpointConfig = params.prevCheckpointConfig;
    this.interruptAfter = params.interruptAfter;
    this.interruptBefore = params.interruptBefore;
    this.debug = params.debug;
    this.triggerToNodes = params.triggerToNodes;
  }
  static async initialize(params) {
    let { config, stream } = params;
    if (stream !== void 0 && config.configurable?.[CONFIG_KEY_STREAM] !== void 0) {
      stream = createDuplexStream(stream, config.configurable[CONFIG_KEY_STREAM]);
    }
    const skipDoneTasks = config.configurable ? !("checkpoint_id" in config.configurable) : true;
    const scratchpad = config.configurable?.[CONFIG_KEY_SCRATCHPAD];
    if (config.configurable && scratchpad) {
      if (scratchpad.subgraphCounter > 0) {
        config = patchConfigurable2(config, {
          [CONFIG_KEY_CHECKPOINT_NS]: [
            config.configurable[CONFIG_KEY_CHECKPOINT_NS],
            scratchpad.subgraphCounter.toString()
          ].join(CHECKPOINT_NAMESPACE_SEPARATOR)
        });
      }
      scratchpad.subgraphCounter += 1;
    }
    const isNested = CONFIG_KEY_READ in (config.configurable ?? {});
    if (!isNested && config.configurable?.checkpoint_ns !== void 0 && config.configurable?.checkpoint_ns !== "") {
      config = patchConfigurable2(config, {
        checkpoint_ns: "",
        checkpoint_id: void 0
      });
    }
    let checkpointConfig = config;
    if (config.configurable?.[CONFIG_KEY_CHECKPOINT_MAP] !== void 0 && config.configurable?.[CONFIG_KEY_CHECKPOINT_MAP]?.[config.configurable?.checkpoint_ns]) {
      checkpointConfig = patchConfigurable2(config, {
        checkpoint_id: config.configurable[CONFIG_KEY_CHECKPOINT_MAP][config.configurable?.checkpoint_ns]
      });
    }
    const checkpointNamespace = config.configurable?.checkpoint_ns?.split(CHECKPOINT_NAMESPACE_SEPARATOR) ?? [];
    const saved = await params.checkpointer?.getTuple(checkpointConfig) ?? {
      config,
      checkpoint: emptyCheckpoint(),
      metadata: {
        source: "input",
        step: -2,
        writes: null,
        parents: {}
      },
      pendingWrites: []
    };
    checkpointConfig = {
      ...config,
      ...saved.config,
      configurable: {
        checkpoint_ns: "",
        ...config.configurable,
        ...saved.config.configurable
      }
    };
    const prevCheckpointConfig = saved.parentConfig;
    const checkpoint = copyCheckpoint(saved.checkpoint);
    const checkpointMetadata = { ...saved.metadata };
    const checkpointPendingWrites = saved.pendingWrites ?? [];
    const channels = emptyChannels(params.channelSpecs, checkpoint);
    const step = (checkpointMetadata.step ?? 0) + 1;
    const stop = step + (config.recursionLimit ?? DEFAULT_LOOP_LIMIT) + 1;
    const checkpointPreviousVersions = { ...checkpoint.channel_versions };
    const store6 = params.store ? new AsyncBatchedStore(params.store) : void 0;
    if (store6) {
      store6.start();
    }
    return new _PregelLoop({
      input: params.input,
      config,
      checkpointer: params.checkpointer,
      checkpoint,
      checkpointMetadata,
      checkpointConfig,
      prevCheckpointConfig,
      checkpointNamespace,
      channels,
      managed: params.managed,
      isNested,
      manager: params.manager,
      skipDoneTasks,
      step,
      stop,
      checkpointPreviousVersions,
      checkpointPendingWrites,
      outputKeys: params.outputKeys ?? [],
      streamKeys: params.streamKeys ?? [],
      nodes: params.nodes,
      stream,
      store: store6,
      cache: params.cache,
      interruptAfter: params.interruptAfter,
      interruptBefore: params.interruptBefore,
      debug: params.debug,
      triggerToNodes: params.triggerToNodes
    });
  }
  _checkpointerPutAfterPrevious(input) {
    this._checkpointerChainedPromise = this._checkpointerChainedPromise.then(() => {
      return this.checkpointer?.put(input.config, input.checkpoint, input.metadata, input.newVersions);
    });
    this.checkpointerPromises.push(this._checkpointerChainedPromise);
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  async updateManagedValues(key, values) {
    const mv = this.managed.get(key);
    if (mv && "update" in mv && typeof mv.update === "function") {
      await mv.update(values);
    }
  }
  /**
   * Put writes for a task, to be read by the next tick.
   * @param taskId
   * @param writes
   */
  putWrites(taskId, writes) {
    let writesCopy = writes;
    if (writesCopy.length === 0) {
      return;
    }
    if (writesCopy.every(([key]) => key in WRITES_IDX_MAP)) {
      writesCopy = Array.from(new Map(writesCopy.map((w2) => [w2[0], w2])).values());
    }
    for (const [c2, v2] of writesCopy) {
      const idx = this.checkpointPendingWrites.findIndex((w2) => w2[0] === taskId && w2[1] === c2);
      if (c2 in WRITES_IDX_MAP && idx !== -1) {
        this.checkpointPendingWrites[idx] = [taskId, c2, v2];
      } else {
        this.checkpointPendingWrites.push([taskId, c2, v2]);
      }
    }
    const putWritePromise = this.checkpointer?.putWrites({
      ...this.checkpointConfig,
      configurable: {
        ...this.checkpointConfig.configurable,
        checkpoint_ns: this.config.configurable?.checkpoint_ns ?? "",
        checkpoint_id: this.checkpoint.id
      }
    }, writesCopy, taskId);
    if (putWritePromise !== void 0) {
      this.checkpointerPromises.push(putWritePromise);
    }
    if (this.tasks) {
      this._outputWrites(taskId, writesCopy);
    }
    if (!writes.length || !this.cache || !this.tasks) {
      return;
    }
    const task3 = this.tasks[taskId];
    if (task3 == null || task3.cache_key == null) {
      return;
    }
    if (writes[0][0] === ERROR3 || writes[0][0] === INTERRUPT2) {
      return;
    }
    void this.cache.set([
      {
        key: [task3.cache_key.ns, task3.cache_key.key],
        value: task3.writes,
        ttl: task3.cache_key.ttl
      }
    ]);
  }
  _outputWrites(taskId, writes, cached = false) {
    const task3 = this.tasks[taskId];
    if (task3 !== void 0) {
      if (task3.config !== void 0 && (task3.config.tags ?? []).includes(TAG_HIDDEN)) {
        return;
      }
      if (writes.length > 0 && writes[0][0] !== ERROR3 && writes[0][0] !== INTERRUPT2) {
        this._emit(gatherIteratorSync(prefixGenerator(mapOutputUpdates(this.outputKeys, [[task3, writes]], cached), "updates")));
      }
      if (!cached) {
        this._emit(gatherIteratorSync(prefixGenerator(mapDebugTaskResults(this.step, [[task3, writes]], this.streamKeys), "debug")));
      }
    }
  }
  async _matchCachedWrites() {
    if (!this.cache)
      return [];
    const matched = [];
    const serializeKey = ([ns, key]) => {
      return `ns:${ns.join(",")}|key:${key}`;
    };
    const keys = [];
    const keyMap = {};
    for (const task3 of Object.values(this.tasks)) {
      if (task3.cache_key != null && !task3.writes.length) {
        keys.push([task3.cache_key.ns, task3.cache_key.key]);
        keyMap[serializeKey([task3.cache_key.ns, task3.cache_key.key])] = task3;
      }
    }
    if (keys.length === 0)
      return [];
    const cache2 = await this.cache.get(keys);
    for (const { key, value } of cache2) {
      const task3 = keyMap[serializeKey(key)];
      if (task3 != null) {
        task3.writes.push(...value);
        matched.push({ task: task3, result: value });
      }
    }
    return matched;
  }
  /**
   * Execute a single iteration of the Pregel loop.
   * Returns true if more iterations are needed.
   * @param params
   */
  async tick(params) {
    if (this.store && !this.store.isRunning) {
      this.store?.start();
    }
    const { inputKeys = [] } = params;
    if (this.status !== "pending") {
      throw new Error(`Cannot tick when status is no longer "pending". Current status: "${this.status}"`);
    }
    if (![INPUT_DONE, INPUT_RESUMING].includes(this.input)) {
      await this._first(inputKeys);
    } else if (this.toInterrupt.length > 0) {
      this.status = "interrupt_before";
      throw new GraphInterrupt();
    } else if (Object.values(this.tasks).every((task3) => task3.writes.length > 0)) {
      const writes = Object.values(this.tasks).flatMap((t2) => t2.writes);
      const managedValueWrites = _applyWrites(this.checkpoint, this.channels, Object.values(this.tasks), this.checkpointerGetNextVersion, this.triggerToNodes);
      for (const [key, values] of Object.entries(managedValueWrites)) {
        await this.updateManagedValues(key, values);
      }
      const valuesOutput = await gatherIterator(prefixGenerator(mapOutputValues(this.outputKeys, writes, this.channels), "values"));
      this._emit(valuesOutput);
      this.checkpointPendingWrites = [];
      await this._putCheckpoint({
        source: "loop",
        writes: mapOutputUpdates(this.outputKeys, Object.values(this.tasks).map((task3) => [task3, task3.writes])).next().value ?? null
      });
      if (shouldInterrupt(this.checkpoint, this.interruptAfter, Object.values(this.tasks))) {
        this.status = "interrupt_after";
        throw new GraphInterrupt();
      }
      if (this.config.configurable?.[CONFIG_KEY_RESUMING] !== void 0) {
        delete this.config.configurable?.[CONFIG_KEY_RESUMING];
      }
    } else {
      return false;
    }
    if (this.step > this.stop) {
      this.status = "out_of_steps";
      return false;
    }
    const nextTasks = _prepareNextTasks(this.checkpoint, this.checkpointPendingWrites, this.nodes, this.channels, this.managed, this.config, true, {
      step: this.step,
      checkpointer: this.checkpointer,
      isResuming: this.isResuming,
      manager: this.manager,
      store: this.store,
      stream: this.stream
    });
    this.tasks = nextTasks;
    if (this.checkpointer) {
      this._emit(await gatherIterator(prefixGenerator(mapDebugCheckpoint(
        this.step - 1,
        // printing checkpoint for previous step
        this.checkpointConfig,
        this.channels,
        this.streamKeys,
        this.checkpointMetadata,
        Object.values(this.tasks),
        this.checkpointPendingWrites,
        this.prevCheckpointConfig
      ), "debug")));
    }
    if (Object.values(this.tasks).length === 0) {
      this.status = "done";
      return false;
    }
    if (this.skipDoneTasks && this.checkpointPendingWrites.length > 0) {
      for (const [tid, k2, v2] of this.checkpointPendingWrites) {
        if (k2 === ERROR3 || k2 === INTERRUPT2 || k2 === RESUME2) {
          continue;
        }
        const task3 = Object.values(this.tasks).find((t2) => t2.id === tid);
        if (task3) {
          task3.writes.push([k2, v2]);
        }
      }
      for (const task3 of Object.values(this.tasks)) {
        if (task3.writes.length > 0) {
          this._outputWrites(task3.id, task3.writes, true);
        }
      }
    }
    if (Object.values(this.tasks).every((task3) => task3.writes.length > 0)) {
      return this.tick({ inputKeys });
    }
    if (shouldInterrupt(this.checkpoint, this.interruptBefore, Object.values(this.tasks))) {
      this.status = "interrupt_before";
      throw new GraphInterrupt();
    }
    const debugOutput = await gatherIterator(prefixGenerator(mapDebugTasks(this.step, Object.values(this.tasks)), "debug"));
    this._emit(debugOutput);
    return true;
  }
  async finishAndHandleError(error) {
    const suppress = this._suppressInterrupt(error);
    if (suppress || error === void 0) {
      this.output = readChannels(this.channels, this.outputKeys);
    }
    if (suppress) {
      if (this.tasks !== void 0 && this.checkpointPendingWrites.length > 0 && Object.values(this.tasks).some((task3) => task3.writes.length > 0)) {
        const managedValueWrites = _applyWrites(this.checkpoint, this.channels, Object.values(this.tasks), this.checkpointerGetNextVersion, this.triggerToNodes);
        for (const [key, values] of Object.entries(managedValueWrites)) {
          await this.updateManagedValues(key, values);
        }
        this._emit(gatherIteratorSync(prefixGenerator(mapOutputValues(this.outputKeys, Object.values(this.tasks).flatMap((t2) => t2.writes), this.channels), "values")));
      }
      const interrupts = { [INTERRUPT2]: error.interrupts };
      this._emit([
        ["updates", interrupts],
        ["values", interrupts]
      ]);
    }
    return suppress;
  }
  async acceptPush(task3, writeIdx, call3) {
    if (this.interruptAfter?.length > 0 && shouldInterrupt(this.checkpoint, this.interruptAfter, [task3])) {
      this.toInterrupt.push(task3);
      return;
    }
    const pushed = _prepareSingleTask([PUSH, task3.path ?? [], writeIdx, task3.id, call3], this.checkpoint, this.checkpointPendingWrites, this.nodes, this.channels, this.managed, task3.config ?? {}, true, {
      step: this.step,
      checkpointer: this.checkpointer,
      manager: this.manager,
      store: this.store,
      stream: this.stream
    });
    if (!pushed)
      return;
    if (this.interruptBefore?.length > 0 && shouldInterrupt(this.checkpoint, this.interruptBefore, [pushed])) {
      this.toInterrupt.push(pushed);
      return;
    }
    this._emit(gatherIteratorSync(prefixGenerator(mapDebugTasks(this.step, [pushed]), "debug")));
    if (this.debug)
      printStepTasks(this.step, [pushed]);
    this.tasks[pushed.id] = pushed;
    if (this.skipDoneTasks)
      this._matchWrites({ [pushed.id]: pushed });
    const tasks = await this._matchCachedWrites();
    for (const { task: task4 } of tasks) {
      this._outputWrites(task4.id, task4.writes, true);
    }
    return pushed;
  }
  _suppressInterrupt(e2) {
    return isGraphInterrupt(e2) && !this.isNested;
  }
  async _first(inputKeys) {
    const { configurable } = this.config;
    const scratchpad = configurable?.[CONFIG_KEY_SCRATCHPAD];
    if (scratchpad && scratchpad.nullResume !== void 0) {
      this.putWrites(NULL_TASK_ID, [[RESUME2, scratchpad.nullResume]]);
    }
    if (isCommand(this.input)) {
      const hasResume = this.input.resume != null;
      if (hasResume && this.checkpointer == null) {
        throw new Error("Cannot use Command(resume=...) without checkpointer");
      }
      const writes = {};
      for (const [tid, key, value] of mapCommand(this.input, this.checkpointPendingWrites)) {
        if (writes[tid] === void 0) {
          writes[tid] = [];
        }
        writes[tid].push([key, value]);
      }
      if (Object.keys(writes).length === 0) {
        throw new EmptyInputError("Received empty Command input");
      }
      for (const [tid, ws] of Object.entries(writes)) {
        this.putWrites(tid, ws);
      }
    }
    const nullWrites = (this.checkpointPendingWrites ?? []).filter((w2) => w2[0] === NULL_TASK_ID).map((w2) => w2.slice(1));
    if (nullWrites.length > 0) {
      _applyWrites(this.checkpoint, this.channels, [
        {
          name: INPUT,
          writes: nullWrites,
          triggers: []
        }
      ], this.checkpointerGetNextVersion, this.triggerToNodes);
    }
    const isCommandUpdateOrGoto = isCommand(this.input) && nullWrites.length > 0;
    if (this.isResuming || isCommandUpdateOrGoto) {
      for (const channelName of Object.keys(this.channels)) {
        if (this.checkpoint.channel_versions[channelName] !== void 0) {
          const version2 = this.checkpoint.channel_versions[channelName];
          this.checkpoint.versions_seen[INTERRUPT2] = {
            ...this.checkpoint.versions_seen[INTERRUPT2],
            [channelName]: version2
          };
        }
      }
      const valuesOutput = await gatherIterator(prefixGenerator(mapOutputValues(this.outputKeys, true, this.channels), "values"));
      this._emit(valuesOutput);
    }
    if (this.isResuming) {
      this.input = INPUT_RESUMING;
    } else if (isCommandUpdateOrGoto) {
      await this._putCheckpoint({ source: "input", writes: {} });
      this.input = INPUT_DONE;
    } else {
      const inputWrites = await gatherIterator(mapInput(inputKeys, this.input));
      if (inputWrites.length > 0) {
        const discardTasks = _prepareNextTasks(this.checkpoint, this.checkpointPendingWrites, this.nodes, this.channels, this.managed, this.config, true, { step: this.step });
        _applyWrites(this.checkpoint, this.channels, Object.values(discardTasks).concat([
          {
            name: INPUT,
            writes: inputWrites,
            triggers: []
          }
        ]), this.checkpointerGetNextVersion, this.triggerToNodes);
        await this._putCheckpoint({
          source: "input",
          writes: Object.fromEntries(inputWrites)
        });
        this.input = INPUT_DONE;
      } else if (!(CONFIG_KEY_RESUMING in (this.config.configurable ?? {}))) {
        throw new EmptyInputError(`Received no input writes for ${JSON.stringify(inputKeys, null, 2)}`);
      } else {
        this.input = INPUT_DONE;
      }
    }
    if (!this.isNested) {
      this.config = patchConfigurable2(this.config, {
        [CONFIG_KEY_RESUMING]: this.isResuming
      });
    }
  }
  _emit(values) {
    for (const chunk of values) {
      if (this.stream.modes.has(chunk[0])) {
        this.stream.push([this.checkpointNamespace, ...chunk]);
      }
    }
  }
  async _putCheckpoint(inputMetadata) {
    const metadata = {
      ...inputMetadata,
      step: this.step,
      parents: this.config.configurable?.[CONFIG_KEY_CHECKPOINT_MAP] ?? {}
    };
    if (this.checkpointer !== void 0) {
      this.prevCheckpointConfig = this.checkpointConfig?.configurable?.checkpoint_id ? this.checkpointConfig : void 0;
      this.checkpointMetadata = metadata;
      this.checkpoint = createCheckpoint(this.checkpoint, this.channels, this.step);
      this.checkpointConfig = {
        ...this.checkpointConfig,
        configurable: {
          ...this.checkpointConfig.configurable,
          checkpoint_ns: this.config.configurable?.checkpoint_ns ?? ""
        }
      };
      const channelVersions = { ...this.checkpoint.channel_versions };
      const newVersions = getNewChannelVersions(this.checkpointPreviousVersions, channelVersions);
      this.checkpointPreviousVersions = channelVersions;
      void this._checkpointerPutAfterPrevious({
        config: { ...this.checkpointConfig },
        checkpoint: copyCheckpoint(this.checkpoint),
        metadata: { ...this.checkpointMetadata },
        newVersions
      });
      this.checkpointConfig = {
        ...this.checkpointConfig,
        configurable: {
          ...this.checkpointConfig.configurable,
          checkpoint_id: this.checkpoint.id
        }
      };
    }
    this.step += 1;
  }
  _matchWrites(tasks) {
    for (const [tid, k2, v2] of this.checkpointPendingWrites) {
      if (k2 === ERROR3 || k2 === INTERRUPT2 || k2 === RESUME2) {
        continue;
      }
      const task3 = Object.values(tasks).find((t2) => t2.id === tid);
      if (task3) {
        task3.writes.push([k2, v2]);
      }
    }
    for (const task3 of Object.values(tasks)) {
      if (task3.writes.length > 0) {
        this._outputWrites(task3.id, task3.writes, true);
      }
    }
  }
};

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/messages.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/callbacks/base.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/messages.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/messages.js
function isChatGenerationChunk(x2) {
  return isBaseMessage(x2?.message);
}
var StreamMessagesHandler = class extends BaseCallbackHandler {
  constructor(streamFn) {
    super();
    Object.defineProperty(this, "name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "StreamMessagesHandler"
    });
    Object.defineProperty(this, "streamFn", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "metadatas", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {}
    });
    Object.defineProperty(this, "seen", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {}
    });
    Object.defineProperty(this, "emittedChatModelRunIds", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {}
    });
    Object.defineProperty(this, "stableMessageIdMap", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {}
    });
    Object.defineProperty(this, "lc_prefer_streaming", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    this.streamFn = streamFn;
  }
  _emit(meta, message, runId, dedupe = false) {
    if (dedupe && message.id !== void 0 && this.seen[message.id] !== void 0) {
      return;
    }
    let messageId = message.id;
    if (runId != null) {
      if (isToolMessage(message)) {
        messageId ??= `run-${runId}-tool-${message.tool_call_id}`;
      } else {
        if (messageId == null || messageId === `run-${runId}`) {
          messageId = this.stableMessageIdMap[runId] ?? messageId ?? `run-${runId}`;
        }
        this.stableMessageIdMap[runId] ??= messageId;
      }
    }
    if (messageId !== message.id) {
      message.id = messageId;
      message.lc_kwargs.id = messageId;
    }
    if (message.id != null)
      this.seen[message.id] = message;
    this.streamFn([meta[0], "messages", [message, meta[1]]]);
  }
  handleChatModelStart(_llm, _messages, runId, _parentRunId, _extraParams, tags, metadata, name) {
    if (metadata && // Include legacy LangGraph SDK tag
    (!tags || !tags.includes(TAG_NOSTREAM) && !tags.includes("nostream"))) {
      this.metadatas[runId] = [
        metadata.langgraph_checkpoint_ns.split("|"),
        { tags, name, ...metadata }
      ];
    }
  }
  handleLLMNewToken(token, _idx, runId, _parentRunId, _tags, fields) {
    const chunk = fields?.chunk;
    this.emittedChatModelRunIds[runId] = true;
    if (this.metadatas[runId] !== void 0) {
      if (isChatGenerationChunk(chunk)) {
        this._emit(this.metadatas[runId], chunk.message, runId);
      } else {
        this._emit(this.metadatas[runId], new AIMessageChunk({ content: token }), runId);
      }
    }
  }
  handleLLMEnd(output, runId) {
    if (!this.emittedChatModelRunIds[runId]) {
      const chatGeneration = output.generations?.[0]?.[0];
      if (isBaseMessage(chatGeneration?.message)) {
        this._emit(this.metadatas[runId], chatGeneration?.message, runId, true);
      }
      delete this.emittedChatModelRunIds[runId];
    }
    delete this.metadatas[runId];
    delete this.stableMessageIdMap[runId];
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  handleLLMError(_err, runId) {
    delete this.metadatas[runId];
  }
  handleChainStart(_chain, inputs, runId, _parentRunId, tags, metadata, _runType, name) {
    if (metadata !== void 0 && name === metadata.langgraph_node && (tags === void 0 || !tags.includes(TAG_HIDDEN))) {
      this.metadatas[runId] = [
        metadata.langgraph_checkpoint_ns.split("|"),
        { tags, name, ...metadata }
      ];
      if (typeof inputs === "object") {
        for (const value of Object.values(inputs)) {
          if ((isBaseMessage(value) || isBaseMessageChunk(value)) && value.id !== void 0) {
            this.seen[value.id] = value;
          } else if (Array.isArray(value)) {
            for (const item of value) {
              if ((isBaseMessage(item) || isBaseMessageChunk(item)) && item.id !== void 0) {
                this.seen[item.id] = item;
              }
            }
          }
        }
      }
    }
  }
  handleChainEnd(outputs, runId) {
    const metadata = this.metadatas[runId];
    delete this.metadatas[runId];
    if (metadata !== void 0) {
      if (isBaseMessage(outputs)) {
        this._emit(metadata, outputs, runId, true);
      } else if (Array.isArray(outputs)) {
        for (const value of outputs) {
          if (isBaseMessage(value)) {
            this._emit(metadata, value, runId, true);
          }
        }
      } else if (outputs != null && typeof outputs === "object") {
        for (const value of Object.values(outputs)) {
          if (isBaseMessage(value)) {
            this._emit(metadata, value, runId, true);
          } else if (Array.isArray(value)) {
            for (const item of value) {
              if (isBaseMessage(item)) {
                this._emit(metadata, item, runId, true);
              }
            }
          }
        }
      }
    }
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  handleChainError(_err, runId) {
    delete this.metadatas[runId];
  }
};

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/runner.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/retry.js
init_esm();
var DEFAULT_INITIAL_INTERVAL = 500;
var DEFAULT_BACKOFF_FACTOR = 2;
var DEFAULT_MAX_INTERVAL = 128e3;
var DEFAULT_MAX_RETRIES = 3;
var DEFAULT_STATUS_NO_RETRY = [
  400,
  // Bad Request
  401,
  // Unauthorized
  402,
  // Payment Required
  403,
  // Forbidden
  404,
  // Not Found
  405,
  // Method Not Allowed
  406,
  // Not Acceptable
  407,
  // Proxy Authentication Required
  409
  // Conflict
];
var DEFAULT_RETRY_ON_HANDLER = (error) => {
  if (error.message.startsWith("Cancel") || error.message.startsWith("AbortError") || error.name === "AbortError") {
    return false;
  }
  if (error?.code === "ECONNABORTED") {
    return false;
  }
  const status = (
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    error?.response?.status ?? error?.status
  );
  if (status && DEFAULT_STATUS_NO_RETRY.includes(+status)) {
    return false;
  }
  if (error?.error?.code === "insufficient_quota") {
    return false;
  }
  return true;
};
async function _runWithRetry(pregelTask, retryPolicy, configurable, signal) {
  const resolvedRetryPolicy = pregelTask.retry_policy ?? retryPolicy;
  let interval = resolvedRetryPolicy !== void 0 ? resolvedRetryPolicy.initialInterval ?? DEFAULT_INITIAL_INTERVAL : 0;
  let attempts = 0;
  let error;
  let result;
  let { config } = pregelTask;
  if (configurable)
    config = patchConfigurable2(config, configurable);
  config = { ...config, signal };
  while (true) {
    if (signal?.aborted) {
      break;
    }
    pregelTask.writes.splice(0, pregelTask.writes.length);
    error = void 0;
    try {
      result = await pregelTask.proc.invoke(pregelTask.input, config);
      break;
    } catch (e2) {
      error = e2;
      error.pregelTaskId = pregelTask.id;
      if (isParentCommand(error)) {
        const ns = config?.configurable?.checkpoint_ns;
        const cmd = error.command;
        if (cmd.graph === ns) {
          for (const writer of pregelTask.writers) {
            await writer.invoke(cmd, config);
          }
          error = void 0;
          break;
        } else if (cmd.graph === Command.PARENT) {
          const parentNs = getParentCheckpointNamespace(ns);
          error.command = new Command({
            ...error.command,
            graph: parentNs
          });
        }
      }
      if (isGraphBubbleUp(error)) {
        break;
      }
      if (resolvedRetryPolicy === void 0) {
        break;
      }
      attempts += 1;
      if (attempts >= (resolvedRetryPolicy.maxAttempts ?? DEFAULT_MAX_RETRIES)) {
        break;
      }
      const retryOn = resolvedRetryPolicy.retryOn ?? DEFAULT_RETRY_ON_HANDLER;
      if (!retryOn(error)) {
        break;
      }
      interval = Math.min(resolvedRetryPolicy.maxInterval ?? DEFAULT_MAX_INTERVAL, interval * (resolvedRetryPolicy.backoffFactor ?? DEFAULT_BACKOFF_FACTOR));
      const intervalWithJitter = resolvedRetryPolicy.jitter ? Math.floor(interval + Math.random() * 1e3) : interval;
      await new Promise((resolve) => setTimeout(resolve, intervalWithJitter));
      const errorName = error.name ?? // eslint-disable-next-line @typescript-eslint/no-explicit-any
      error.constructor.unminifiable_name ?? error.constructor.name;
      if (resolvedRetryPolicy?.logWarning ?? true) {
        console.log(`Retrying task "${String(pregelTask.name)}" after ${interval.toFixed(2)}ms (attempt ${attempts}) after ${errorName}: ${error}`);
      }
      config = patchConfigurable2(config, { [CONFIG_KEY_RESUMING]: true });
    }
  }
  return {
    task: pregelTask,
    result,
    error,
    signalAborted: signal?.aborted
  };
}

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/runner.js
var PROMISE_ADDED_SYMBOL = Symbol.for("promiseAdded");
function createPromiseBarrier() {
  const barrier = {
    next: () => void 0,
    wait: Promise.resolve(PROMISE_ADDED_SYMBOL)
  };
  function waitHandler(resolve) {
    barrier.next = () => {
      barrier.wait = new Promise(waitHandler);
      resolve(PROMISE_ADDED_SYMBOL);
    };
  }
  barrier.wait = new Promise(waitHandler);
  return barrier;
}
var PregelRunner = class {
  /**
   * Construct a new PregelRunner, which executes tasks from the provided PregelLoop.
   * @param loop - The PregelLoop that produces tasks for this runner to execute.
   */
  constructor({ loop, nodeFinished }) {
    Object.defineProperty(this, "nodeFinished", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "loop", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.loop = loop;
    this.nodeFinished = nodeFinished;
  }
  /**
   * Execute tasks from the current step of the PregelLoop.
   *
   * Note: this method does NOT call {@link PregelLoop}#tick. That must be handled externally.
   * @param options - Options for the execution.
   */
  async tick(options = {}) {
    const { timeout, retryPolicy, onStepWrite, maxConcurrency } = options;
    const nodeErrors = /* @__PURE__ */ new Set();
    let graphBubbleUp;
    const exceptionSignalController = new AbortController();
    const pendingTasks = Object.values(this.loop.tasks).filter((t2) => t2.writes.length === 0);
    const currentSignals = this._initializeAbortSignals({
      exceptionSignalController,
      timeout,
      signal: options.signal
    });
    const taskStream = this._executeTasksWithRetry(pendingTasks, {
      signals: currentSignals,
      retryPolicy,
      maxConcurrency
    });
    for await (const { task: task3, error, signalAborted } of taskStream) {
      this._commit(task3, error);
      if (isGraphInterrupt(error)) {
        graphBubbleUp = error;
      } else if (isGraphBubbleUp(error) && !isGraphInterrupt(graphBubbleUp)) {
        graphBubbleUp = error;
      } else if (error && (nodeErrors.size === 0 || !signalAborted)) {
        exceptionSignalController.abort();
        nodeErrors.add(error);
      }
    }
    onStepWrite?.(this.loop.step, Object.values(this.loop.tasks).map((task3) => task3.writes).flat());
    if (nodeErrors.size === 1) {
      throw Array.from(nodeErrors)[0];
    } else if (nodeErrors.size > 1) {
      throw new AggregateError(Array.from(nodeErrors), `Multiple errors occurred during superstep ${this.loop.step}. See the "errors" field of this exception for more details.`);
    }
    if (isGraphInterrupt(graphBubbleUp)) {
      throw graphBubbleUp;
    }
    if (isGraphBubbleUp(graphBubbleUp) && this.loop.isNested) {
      throw graphBubbleUp;
    }
  }
  /**
   * Initializes the current AbortSignals for the PregelRunner, handling the various ways that
   * AbortSignals must be chained together so that the PregelLoop can be interrupted if necessary
   * while still allowing nodes to gracefully exit.
   *
   * This method must only be called once per PregelRunner#tick. It has the side effect of updating
   * the PregelLoop#config with the new AbortSignals so they may be propagated correctly to future
   * ticks and subgraph calls.
   *
   * @param options - Options for the initialization.
   * @returns The current abort signals.
   * @internal
   */
  _initializeAbortSignals({ exceptionSignalController, timeout, signal }) {
    const previousSignals = this.loop.config.configurable?.[CONFIG_KEY_ABORT_SIGNALS] ?? {};
    const subgraphCalledWithSignalCreatedByNode = signal && previousSignals.composedAbortSignal && signal !== previousSignals.composedAbortSignal;
    const externalAbortSignal = subgraphCalledWithSignalCreatedByNode ? (
      // Chain the signals here to make sure that the subgraph receives the external abort signal in
      // addition to the signal created by the node.
      combineAbortSignals(previousSignals.externalAbortSignal, signal)
    ) : (
      // Otherwise, just keep using the external abort signal, or initialize it if it hasn't been
      // assigned yet
      previousSignals.externalAbortSignal ?? signal
    );
    const errorAbortSignal = previousSignals.errorAbortSignal ? (
      // Chaining here rather than always using a fresh one handles the case where a subgraph is
      // called in a parallel branch to some other node in the parent graph.
      combineAbortSignals(previousSignals.errorAbortSignal, exceptionSignalController.signal)
    ) : exceptionSignalController.signal;
    const timeoutAbortSignal = timeout ? AbortSignal.timeout(timeout) : void 0;
    const composedAbortSignal = combineAbortSignals(...externalAbortSignal ? [externalAbortSignal] : [], ...timeoutAbortSignal ? [timeoutAbortSignal] : [], errorAbortSignal);
    const currentSignals = {
      externalAbortSignal,
      errorAbortSignal,
      timeoutAbortSignal,
      composedAbortSignal
    };
    this.loop.config = patchConfigurable2(this.loop.config, {
      [CONFIG_KEY_ABORT_SIGNALS]: currentSignals
    });
    return currentSignals;
  }
  /**
   * Concurrently executes tasks with the requested retry policy, yielding a {@link SettledPregelTask} for each task as it completes.
   * @param tasks - The tasks to execute.
   * @param options - Options for the execution.
   */
  async *_executeTasksWithRetry(tasks, options) {
    const { retryPolicy, maxConcurrency, signals } = options ?? {};
    const barrier = createPromiseBarrier();
    const executingTasksMap = {};
    const thisCall = {
      executingTasksMap,
      barrier,
      retryPolicy,
      scheduleTask: async (task3, writeIdx, call3) => this.loop.acceptPush(task3, writeIdx, call3)
    };
    if (signals?.composedAbortSignal?.aborted) {
      throw new Error("Abort");
    }
    let startedTasksCount = 0;
    let listener;
    const timeoutOrCancelSignal = signals?.externalAbortSignal || signals?.timeoutAbortSignal ? combineAbortSignals(...signals.externalAbortSignal ? [signals.externalAbortSignal] : [], ...signals.timeoutAbortSignal ? [signals.timeoutAbortSignal] : []) : void 0;
    const abortPromise = timeoutOrCancelSignal ? new Promise((_resolve, reject) => {
      listener = () => reject(new Error("Abort"));
      timeoutOrCancelSignal.addEventListener("abort", listener, {
        once: true
      });
    }) : void 0;
    while ((startedTasksCount === 0 || Object.keys(executingTasksMap).length > 0) && tasks.length) {
      for (; Object.values(executingTasksMap).length < (maxConcurrency ?? tasks.length) && startedTasksCount < tasks.length; startedTasksCount += 1) {
        const task3 = tasks[startedTasksCount];
        executingTasksMap[task3.id] = _runWithRetry(task3, retryPolicy, { [CONFIG_KEY_CALL]: call?.bind(thisCall, this, task3) }, signals?.composedAbortSignal).catch((error) => {
          return {
            task: task3,
            error,
            signalAborted: signals?.composedAbortSignal?.aborted
          };
        });
      }
      const settledTask = await Promise.race([
        ...Object.values(executingTasksMap),
        ...abortPromise ? [abortPromise] : [],
        barrier.wait
      ]);
      if (settledTask === PROMISE_ADDED_SYMBOL) {
        continue;
      }
      yield settledTask;
      delete executingTasksMap[settledTask.task.id];
    }
  }
  /**
   * Determines what writes to apply based on whether the task completed successfully, and what type of error occurred.
   *
   * Throws an error if the error is a {@link GraphBubbleUp} error and {@link PregelLoop}#isNested is true.
   *
   * @param task - The task to commit.
   * @param error - The error that occurred, if any.
   */
  _commit(task3, error) {
    if (error !== void 0) {
      if (isGraphInterrupt(error)) {
        if (error.interrupts.length) {
          const interrupts = error.interrupts.map((interrupt2) => [INTERRUPT2, interrupt2]);
          const resumes = task3.writes.filter((w2) => w2[0] === RESUME2);
          if (resumes.length) {
            interrupts.push(...resumes);
          }
          this.loop.putWrites(task3.id, interrupts);
        }
      } else if (isGraphBubbleUp(error) && task3.writes.length) {
        this.loop.putWrites(task3.id, task3.writes);
      } else {
        this.loop.putWrites(task3.id, [
          [ERROR3, { message: error.message, name: error.name }]
        ]);
      }
    } else {
      if (this.nodeFinished && (task3.config?.tags == null || !task3.config.tags.includes(TAG_HIDDEN))) {
        this.nodeFinished(String(task3.name));
      }
      if (task3.writes.length === 0) {
        task3.writes.push([NO_WRITES, null]);
      }
      this.loop.putWrites(task3.id, task3.writes);
    }
  }
};
async function call(runner, task3, func, name, input, options = {}) {
  const scratchpad = task3.config?.configurable?.[CONFIG_KEY_SCRATCHPAD];
  if (!scratchpad) {
    throw new Error(`BUG: No scratchpad found on task ${task3.name}__${task3.id}`);
  }
  const cnt = scratchpad.callCounter;
  scratchpad.callCounter += 1;
  const wcall = new Call({
    func,
    name,
    input,
    cache: options.cache,
    retry: options.retry,
    callbacks: options.callbacks
  });
  const nextTask = await this.scheduleTask(task3, cnt, wcall);
  if (!nextTask)
    return void 0;
  const existingPromise = this.executingTasksMap[nextTask.id];
  if (existingPromise !== void 0) {
    return existingPromise;
  }
  if (nextTask.writes.length > 0) {
    const returns = nextTask.writes.filter(([c2]) => c2 === RETURN);
    const errors = nextTask.writes.filter(([c2]) => c2 === ERROR3);
    if (returns.length > 0) {
      if (returns.length === 1)
        return Promise.resolve(returns[0][1]);
      throw new Error(`BUG: multiple returns found for task ${nextTask.name}__${nextTask.id}`);
    }
    if (errors.length > 0) {
      if (errors.length === 1) {
        const errorValue = errors[0][1];
        const error = (
          // eslint-disable-next-line no-instanceof/no-instanceof
          errorValue instanceof Error ? errorValue : new Error(String(errorValue))
        );
        return Promise.reject(error);
      }
      throw new Error(`BUG: multiple errors found for task ${nextTask.name}__${nextTask.id}`);
    }
    return void 0;
  } else {
    const prom = _runWithRetry(nextTask, options.retry, {
      [CONFIG_KEY_CALL]: call.bind(this, runner, nextTask)
    });
    this.executingTasksMap[nextTask.id] = prom;
    this.barrier.next();
    return prom.then(({ result, error }) => {
      if (error)
        return Promise.reject(error);
      return result;
    });
  }
}

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/pregel/index.js
var Channel = class {
  static subscribeTo(channels, options) {
    const { key, tags } = {
      key: void 0,
      tags: void 0,
      ...options ?? {}
    };
    if (Array.isArray(channels) && key !== void 0) {
      throw new Error("Can't specify a key when subscribing to multiple channels");
    }
    let channelMappingOrArray;
    if (typeof channels === "string") {
      if (key) {
        channelMappingOrArray = { [key]: channels };
      } else {
        channelMappingOrArray = [channels];
      }
    } else {
      channelMappingOrArray = Object.fromEntries(channels.map((chan) => [chan, chan]));
    }
    const triggers = Array.isArray(channels) ? channels : [channels];
    return new PregelNode({
      channels: channelMappingOrArray,
      triggers,
      tags
    });
  }
  /**
   * Creates a ChannelWrite that specifies how to write values to channels.
   * This is used to define how nodes send output to channels.
   *
   * @example
   * ```typescript
   * // Write to multiple channels
   * const write = Channel.writeTo(["output", "state"]);
   *
   * // Write with specific values
   * const write = Channel.writeTo(["output"], {
   *   state: "completed",
   *   result: calculateResult()
   * });
   *
   * // Write with a transformation function
   * const write = Channel.writeTo(["output"], {
   *   result: (x) => processResult(x)
   * });
   * ```
   *
   * @param channels - Array of channel names to write to
   * @param writes - Optional map of channel names to values or transformations
   * @returns A ChannelWrite object that can be used to write to the specified channels
   */
  static writeTo(channels, writes) {
    const channelWriteEntries = [];
    for (const channel of channels) {
      channelWriteEntries.push({
        channel,
        value: PASSTHROUGH,
        skipNone: false
      });
    }
    for (const [key, value] of Object.entries(writes ?? {})) {
      if (Runnable.isRunnable(value) || typeof value === "function") {
        channelWriteEntries.push({
          channel: key,
          value: PASSTHROUGH,
          skipNone: true,
          mapper: _coerceToRunnable(value)
        });
      } else {
        channelWriteEntries.push({
          channel: key,
          value,
          skipNone: false
        });
      }
    }
    return new ChannelWrite(channelWriteEntries);
  }
};
var PartialRunnable = class extends Runnable {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langgraph", "pregel"]
    });
  }
  invoke(_input, _options) {
    throw new Error("Not implemented");
  }
  // Overriden by `Pregel`
  withConfig(_config) {
    return super.withConfig(_config);
  }
  // Overriden by `Pregel`
  stream(input, options) {
    return super.stream(input, options);
  }
};
var Pregel = class extends PartialRunnable {
  /**
   * Name of the class when serialized
   * @internal
   */
  static lc_name() {
    return "LangGraph";
  }
  /**
   * Constructor for Pregel - meant for internal use only.
   *
   * @internal
   */
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langgraph", "pregel"]
    });
    Object.defineProperty(this, "lg_is_pregel", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "nodes", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "channels", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "inputChannels", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "outputChannels", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "autoValidate", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "streamMode", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["values"]
    });
    Object.defineProperty(this, "streamChannels", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "interruptAfter", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "interruptBefore", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "stepTimeout", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "debug", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    Object.defineProperty(this, "checkpointer", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "retryPolicy", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "config", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "store", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "triggerToNodes", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {}
    });
    Object.defineProperty(this, "cache", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    let { streamMode } = fields;
    if (streamMode != null && !Array.isArray(streamMode)) {
      streamMode = [streamMode];
    }
    this.nodes = fields.nodes;
    this.channels = fields.channels;
    this.autoValidate = fields.autoValidate ?? this.autoValidate;
    this.streamMode = streamMode ?? this.streamMode;
    this.inputChannels = fields.inputChannels;
    this.outputChannels = fields.outputChannels;
    this.streamChannels = fields.streamChannels ?? this.streamChannels;
    this.interruptAfter = fields.interruptAfter;
    this.interruptBefore = fields.interruptBefore;
    this.stepTimeout = fields.stepTimeout ?? this.stepTimeout;
    this.debug = fields.debug ?? this.debug;
    this.checkpointer = fields.checkpointer;
    this.retryPolicy = fields.retryPolicy;
    this.config = fields.config;
    this.store = fields.store;
    this.cache = fields.cache;
    this.name = fields.name;
    if (this.autoValidate) {
      this.validate();
    }
  }
  /**
   * Creates a new instance of the Pregel graph with updated configuration.
   * This method follows the immutable pattern - instead of modifying the current instance,
   * it returns a new instance with the merged configuration.
   *
   * @example
   * ```typescript
   * // Create a new instance with debug enabled
   * const debugGraph = graph.withConfig({ debug: true });
   *
   * // Create a new instance with a specific thread ID
   * const threadGraph = graph.withConfig({
   *   configurable: { thread_id: "123" }
   * });
   * ```
   *
   * @param config - The configuration to merge with the current configuration
   * @returns A new Pregel instance with the merged configuration
   */
  withConfig(config) {
    const mergedConfig = mergeConfigs(this.config, config);
    return new this.constructor({ ...this, config: mergedConfig });
  }
  /**
   * Validates the graph structure to ensure it is well-formed.
   * Checks for:
   * - No orphaned nodes
   * - Valid input/output channel configurations
   * - Valid interrupt configurations
   *
   * @returns this - The Pregel instance for method chaining
   * @throws {GraphValidationError} If the graph structure is invalid
   */
  validate() {
    validateGraph({
      nodes: this.nodes,
      channels: this.channels,
      outputChannels: this.outputChannels,
      inputChannels: this.inputChannels,
      streamChannels: this.streamChannels,
      interruptAfterNodes: this.interruptAfter,
      interruptBeforeNodes: this.interruptBefore
    });
    for (const [name, node] of Object.entries(this.nodes)) {
      for (const trigger of node.triggers) {
        this.triggerToNodes[trigger] ??= [];
        this.triggerToNodes[trigger].push(name);
      }
    }
    return this;
  }
  /**
   * Gets a list of all channels that should be streamed.
   * If streamChannels is specified, returns those channels.
   * Otherwise, returns all channels in the graph.
   *
   * @returns Array of channel keys to stream
   */
  get streamChannelsList() {
    if (Array.isArray(this.streamChannels)) {
      return this.streamChannels;
    } else if (this.streamChannels) {
      return [this.streamChannels];
    } else {
      return Object.keys(this.channels);
    }
  }
  /**
   * Gets the channels to stream in their original format.
   * If streamChannels is specified, returns it as-is (either single key or array).
   * Otherwise, returns all channels in the graph as an array.
   *
   * @returns Channel keys to stream, either as a single key or array
   */
  get streamChannelsAsIs() {
    if (this.streamChannels) {
      return this.streamChannels;
    } else {
      return Object.keys(this.channels);
    }
  }
  /**
   * Gets a drawable representation of the graph structure.
   * This is an async version of getGraph() and is the preferred method to use.
   *
   * @param config - Configuration for generating the graph visualization
   * @returns A representation of the graph that can be visualized
   */
  async getGraphAsync(config) {
    return this.getGraph(config);
  }
  /**
   * Gets all subgraphs within this graph.
   * A subgraph is a Pregel instance that is nested within a node of this graph.
   *
   * @deprecated Use getSubgraphsAsync instead. The async method will become the default in the next minor release.
   * @param namespace - Optional namespace to filter subgraphs
   * @param recurse - Whether to recursively get subgraphs of subgraphs
   * @returns Generator yielding tuples of [name, subgraph]
   */
  *getSubgraphs(namespace, recurse) {
    for (const [name, node] of Object.entries(this.nodes)) {
      if (namespace !== void 0) {
        if (!namespace.startsWith(name)) {
          continue;
        }
      }
      const candidates = node.subgraphs?.length ? node.subgraphs : [node.bound];
      for (const candidate of candidates) {
        const graph = findSubgraphPregel(candidate);
        if (graph !== void 0) {
          if (name === namespace) {
            yield [name, graph];
            return;
          }
          if (namespace === void 0) {
            yield [name, graph];
          }
          if (recurse) {
            let newNamespace = namespace;
            if (namespace !== void 0) {
              newNamespace = namespace.slice(name.length + 1);
            }
            for (const [subgraphName, subgraph] of graph.getSubgraphs(newNamespace, recurse)) {
              yield [
                `${name}${CHECKPOINT_NAMESPACE_SEPARATOR}${subgraphName}`,
                subgraph
              ];
            }
          }
        }
      }
    }
  }
  /**
   * Gets all subgraphs within this graph asynchronously.
   * A subgraph is a Pregel instance that is nested within a node of this graph.
   *
   * @param namespace - Optional namespace to filter subgraphs
   * @param recurse - Whether to recursively get subgraphs of subgraphs
   * @returns AsyncGenerator yielding tuples of [name, subgraph]
   */
  async *getSubgraphsAsync(namespace, recurse) {
    yield* this.getSubgraphs(namespace, recurse);
  }
  /**
   * Prepares a state snapshot from saved checkpoint data.
   * This is an internal method used by getState and getStateHistory.
   *
   * @param config - Configuration for preparing the snapshot
   * @param saved - Optional saved checkpoint data
   * @param subgraphCheckpointer - Optional checkpointer for subgraphs
   * @param applyPendingWrites - Whether to apply pending writes to tasks and then to channels
   * @returns A snapshot of the graph state
   * @internal
   */
  async _prepareStateSnapshot({ config, saved, subgraphCheckpointer, applyPendingWrites = false }) {
    if (saved === void 0) {
      return {
        values: {},
        next: [],
        config,
        tasks: []
      };
    }
    const { managed } = await this.prepareSpecs(config, {
      skipManaged: true
    });
    const channels = emptyChannels(this.channels, saved.checkpoint);
    if (saved.pendingWrites?.length) {
      const nullWrites = saved.pendingWrites.filter(([taskId, _2]) => taskId === NULL_TASK_ID).map(([_2, channel, value]) => [String(channel), value]);
      if (nullWrites.length > 0) {
        _applyWrites(saved.checkpoint, channels, [
          {
            name: INPUT,
            writes: nullWrites,
            triggers: []
          }
        ], void 0, this.triggerToNodes);
      }
    }
    const nextTasks = Object.values(_prepareNextTasks(saved.checkpoint, saved.pendingWrites, this.nodes, channels, managed, saved.config, true, { step: (saved.metadata?.step ?? -1) + 1, store: this.store }));
    const subgraphs = await gatherIterator(this.getSubgraphsAsync());
    const parentNamespace = saved.config.configurable?.checkpoint_ns ?? "";
    const taskStates = {};
    for (const task3 of nextTasks) {
      const matchingSubgraph = subgraphs.find(([name]) => name === task3.name);
      if (!matchingSubgraph) {
        continue;
      }
      let taskNs = `${String(task3.name)}${CHECKPOINT_NAMESPACE_END}${task3.id}`;
      if (parentNamespace) {
        taskNs = `${parentNamespace}${CHECKPOINT_NAMESPACE_SEPARATOR}${taskNs}`;
      }
      if (subgraphCheckpointer === void 0) {
        const config2 = {
          configurable: {
            thread_id: saved.config.configurable?.thread_id,
            checkpoint_ns: taskNs
          }
        };
        taskStates[task3.id] = config2;
      } else {
        const subgraphConfig = {
          configurable: {
            [CONFIG_KEY_CHECKPOINTER]: subgraphCheckpointer,
            thread_id: saved.config.configurable?.thread_id,
            checkpoint_ns: taskNs
          }
        };
        const pregel = matchingSubgraph[1];
        taskStates[task3.id] = await pregel.getState(subgraphConfig, {
          subgraphs: true
        });
      }
    }
    if (applyPendingWrites && saved.pendingWrites?.length) {
      const nextTaskById = Object.fromEntries(nextTasks.map((task3) => [task3.id, task3]));
      for (const [taskId, channel, value] of saved.pendingWrites) {
        if ([ERROR3, INTERRUPT2, SCHEDULED].includes(channel)) {
          continue;
        }
        if (!(taskId in nextTaskById)) {
          continue;
        }
        nextTaskById[taskId].writes.push([String(channel), value]);
      }
      const tasksWithWrites2 = nextTasks.filter((task3) => task3.writes.length > 0);
      if (tasksWithWrites2.length > 0) {
        _applyWrites(saved.checkpoint, channels, tasksWithWrites2, void 0, this.triggerToNodes);
      }
    }
    let metadata = saved?.metadata;
    if (metadata && saved?.config?.configurable?.thread_id) {
      metadata = {
        ...metadata,
        thread_id: saved.config.configurable.thread_id
      };
    }
    const nextList = nextTasks.filter((task3) => task3.writes.length === 0).map((task3) => task3.name);
    return {
      values: readChannels(channels, this.streamChannelsAsIs),
      next: nextList,
      tasks: tasksWithWrites(nextTasks, saved?.pendingWrites ?? [], taskStates),
      metadata,
      config: patchCheckpointMap(saved.config, saved.metadata),
      createdAt: saved.checkpoint.ts,
      parentConfig: saved.parentConfig
    };
  }
  /**
   * Gets the current state of the graph.
   * Requires a checkpointer to be configured.
   *
   * @param config - Configuration for retrieving the state
   * @param options - Additional options
   * @returns A snapshot of the current graph state
   * @throws {GraphValueError} If no checkpointer is configured
   */
  async getState(config, options) {
    const checkpointer = config.configurable?.[CONFIG_KEY_CHECKPOINTER] ?? this.checkpointer;
    if (!checkpointer) {
      throw new GraphValueError("No checkpointer set");
    }
    const checkpointNamespace = config.configurable?.checkpoint_ns ?? "";
    if (checkpointNamespace !== "" && config.configurable?.[CONFIG_KEY_CHECKPOINTER] === void 0) {
      const recastNamespace = recastCheckpointNamespace(checkpointNamespace);
      for await (const [name, subgraph] of this.getSubgraphsAsync(recastNamespace, true)) {
        if (name === recastNamespace) {
          return await subgraph.getState(patchConfigurable(config, {
            [CONFIG_KEY_CHECKPOINTER]: checkpointer
          }), { subgraphs: options?.subgraphs });
        }
      }
      throw new Error(`Subgraph with namespace "${recastNamespace}" not found.`);
    }
    const mergedConfig = mergeConfigs(this.config, config);
    const saved = await checkpointer.getTuple(config);
    const snapshot = await this._prepareStateSnapshot({
      config: mergedConfig,
      saved,
      subgraphCheckpointer: options?.subgraphs ? checkpointer : void 0,
      applyPendingWrites: !config.configurable?.checkpoint_id
    });
    return snapshot;
  }
  /**
   * Gets the history of graph states.
   * Requires a checkpointer to be configured.
   * Useful for:
   * - Debugging execution history
   * - Implementing time travel
   * - Analyzing graph behavior
   *
   * @param config - Configuration for retrieving the history
   * @param options - Options for filtering the history
   * @returns An async iterator of state snapshots
   * @throws {Error} If no checkpointer is configured
   */
  async *getStateHistory(config, options) {
    const checkpointer = config.configurable?.[CONFIG_KEY_CHECKPOINTER] ?? this.checkpointer;
    if (!checkpointer) {
      throw new Error("No checkpointer set");
    }
    const checkpointNamespace = config.configurable?.checkpoint_ns ?? "";
    if (checkpointNamespace !== "" && config.configurable?.[CONFIG_KEY_CHECKPOINTER] === void 0) {
      const recastNamespace = recastCheckpointNamespace(checkpointNamespace);
      for await (const [name, pregel] of this.getSubgraphsAsync(recastNamespace, true)) {
        if (name === recastNamespace) {
          yield* pregel.getStateHistory(patchConfigurable(config, {
            [CONFIG_KEY_CHECKPOINTER]: checkpointer
          }), options);
          return;
        }
      }
      throw new Error(`Subgraph with namespace "${recastNamespace}" not found.`);
    }
    const mergedConfig = mergeConfigs(this.config, config, {
      configurable: { checkpoint_ns: checkpointNamespace }
    });
    for await (const checkpointTuple of checkpointer.list(mergedConfig, options)) {
      yield this._prepareStateSnapshot({
        config: checkpointTuple.config,
        saved: checkpointTuple
      });
    }
  }
  /**
   * Apply updates to the graph state in bulk.
   * Requires a checkpointer to be configured.
   *
   * This method is useful for recreating a thread
   * from a list of updates, especially if a checkpoint
   * is created as a result of multiple tasks.
   *
   * @internal The API might change in the future.
   *
   * @param startConfig - Configuration for the update
   * @param updates - The list of updates to apply to graph state
   * @returns Updated configuration
   * @throws {GraphValueError} If no checkpointer is configured
   * @throws {InvalidUpdateError} If the update cannot be attributed to a node or an update can be only applied in sequence.
   */
  async bulkUpdateState(startConfig, supersteps) {
    const checkpointer = startConfig.configurable?.[CONFIG_KEY_CHECKPOINTER] ?? this.checkpointer;
    if (!checkpointer) {
      throw new GraphValueError("No checkpointer set");
    }
    if (supersteps.length === 0) {
      throw new Error("No supersteps provided");
    }
    if (supersteps.some((s2) => s2.updates.length === 0)) {
      throw new Error("No updates provided");
    }
    const checkpointNamespace = startConfig.configurable?.checkpoint_ns ?? "";
    if (checkpointNamespace !== "" && startConfig.configurable?.[CONFIG_KEY_CHECKPOINTER] === void 0) {
      const recastNamespace = recastCheckpointNamespace(checkpointNamespace);
      for await (const [, pregel] of this.getSubgraphsAsync(recastNamespace, true)) {
        return await pregel.bulkUpdateState(patchConfigurable(startConfig, {
          [CONFIG_KEY_CHECKPOINTER]: checkpointer
        }), supersteps);
      }
      throw new Error(`Subgraph "${recastNamespace}" not found`);
    }
    const updateSuperStep = async (inputConfig, updates) => {
      const config = this.config ? mergeConfigs(this.config, inputConfig) : inputConfig;
      const saved = await checkpointer.getTuple(config);
      const checkpoint = saved !== void 0 ? copyCheckpoint(saved.checkpoint) : emptyCheckpoint();
      const checkpointPreviousVersions = {
        ...saved?.checkpoint.channel_versions
      };
      const step = saved?.metadata?.step ?? -1;
      let checkpointConfig = patchConfigurable(config, {
        checkpoint_ns: config.configurable?.checkpoint_ns ?? ""
      });
      let checkpointMetadata = config.metadata ?? {};
      if (saved?.config.configurable) {
        checkpointConfig = patchConfigurable(config, saved.config.configurable);
        checkpointMetadata = {
          ...saved.metadata,
          ...checkpointMetadata
        };
      }
      const { values, asNode } = updates[0];
      if (values == null && asNode === void 0) {
        if (updates.length > 1) {
          throw new InvalidUpdateError(`Cannot create empty checkpoint with multiple updates`);
        }
        const nextConfig2 = await checkpointer.put(checkpointConfig, createCheckpoint(checkpoint, void 0, step), {
          source: "update",
          step: step + 1,
          writes: {},
          parents: saved?.metadata?.parents ?? {}
        }, {});
        return patchCheckpointMap(nextConfig2, saved ? saved.metadata : void 0);
      }
      const channels = emptyChannels(this.channels, checkpoint);
      const { managed } = await this.prepareSpecs(config, {
        skipManaged: true
      });
      if (values === null && asNode === END) {
        if (updates.length > 1) {
          throw new InvalidUpdateError(`Cannot apply multiple updates when clearing state`);
        }
        if (saved) {
          const nextTasks = _prepareNextTasks(checkpoint, saved.pendingWrites || [], this.nodes, channels, managed, saved.config, true, {
            step: (saved.metadata?.step ?? -1) + 1,
            checkpointer: this.checkpointer || void 0,
            store: this.store
          });
          const nullWrites = (saved.pendingWrites || []).filter((w2) => w2[0] === NULL_TASK_ID).map((w2) => w2.slice(1));
          if (nullWrites.length > 0) {
            _applyWrites(saved.checkpoint, channels, [
              {
                name: INPUT,
                writes: nullWrites,
                triggers: []
              }
            ], void 0, this.triggerToNodes);
          }
          for (const [taskId, k2, v2] of saved.pendingWrites || []) {
            if ([ERROR3, INTERRUPT2, SCHEDULED].includes(k2)) {
              continue;
            }
            if (!(taskId in nextTasks)) {
              continue;
            }
            nextTasks[taskId].writes.push([k2, v2]);
          }
          _applyWrites(checkpoint, channels, Object.values(nextTasks), void 0, this.triggerToNodes);
        }
        const nextConfig2 = await checkpointer.put(checkpointConfig, createCheckpoint(checkpoint, void 0, step), {
          ...checkpointMetadata,
          source: "update",
          step: step + 1,
          writes: {},
          parents: saved?.metadata?.parents ?? {}
        }, {});
        return patchCheckpointMap(nextConfig2, saved ? saved.metadata : void 0);
      }
      if (values == null && asNode === COPY) {
        if (updates.length > 1) {
          throw new InvalidUpdateError(`Cannot copy checkpoint with multiple updates`);
        }
        const nextConfig2 = await checkpointer.put(saved?.parentConfig ?? checkpointConfig, createCheckpoint(checkpoint, void 0, step), {
          source: "fork",
          step: step + 1,
          writes: {},
          parents: saved?.metadata?.parents ?? {}
        }, {});
        return patchCheckpointMap(nextConfig2, saved ? saved.metadata : void 0);
      }
      if (asNode === INPUT) {
        if (updates.length > 1) {
          throw new InvalidUpdateError(`Cannot apply multiple updates when updating as input`);
        }
        const inputWrites = await gatherIterator(mapInput(this.inputChannels, values));
        if (inputWrites.length === 0) {
          throw new InvalidUpdateError(`Received no input writes for ${JSON.stringify(this.inputChannels, null, 2)}`);
        }
        _applyWrites(checkpoint, channels, [
          {
            name: INPUT,
            writes: inputWrites,
            triggers: []
          }
        ], checkpointer.getNextVersion.bind(this.checkpointer), this.triggerToNodes);
        const nextStep = saved?.metadata?.step != null ? saved.metadata.step + 1 : -1;
        const nextConfig2 = await checkpointer.put(checkpointConfig, createCheckpoint(checkpoint, channels, nextStep), {
          source: "input",
          step: nextStep,
          writes: Object.fromEntries(inputWrites),
          parents: saved?.metadata?.parents ?? {}
        }, getNewChannelVersions(checkpointPreviousVersions, checkpoint.channel_versions));
        await checkpointer.putWrites(nextConfig2, inputWrites, uuid5(INPUT, checkpoint.id));
        return patchCheckpointMap(nextConfig2, saved ? saved.metadata : void 0);
      }
      if (config.configurable?.checkpoint_id === void 0 && saved?.pendingWrites !== void 0 && saved.pendingWrites.length > 0) {
        const nextTasks = _prepareNextTasks(checkpoint, saved.pendingWrites, this.nodes, channels, managed, saved.config, true, {
          store: this.store,
          // eslint-disable-next-line @typescript-eslint/no-explicit-any
          checkpointer: this.checkpointer,
          step: (saved.metadata?.step ?? -1) + 1
        });
        const nullWrites = (saved.pendingWrites ?? []).filter((w2) => w2[0] === NULL_TASK_ID).map((w2) => w2.slice(1));
        if (nullWrites.length > 0) {
          _applyWrites(saved.checkpoint, channels, [{ name: INPUT, writes: nullWrites, triggers: [] }], void 0, this.triggerToNodes);
        }
        for (const [tid, k2, v2] of saved.pendingWrites) {
          if ([ERROR3, INTERRUPT2, SCHEDULED].includes(k2) || nextTasks[tid] === void 0) {
            continue;
          }
          nextTasks[tid].writes.push([k2, v2]);
        }
        const tasks2 = Object.values(nextTasks).filter((task3) => {
          return task3.writes.length > 0;
        });
        if (tasks2.length > 0) {
          _applyWrites(checkpoint, channels, tasks2, void 0, this.triggerToNodes);
        }
      }
      const nonNullVersion = Object.values(checkpoint.versions_seen).map((seenVersions) => {
        return Object.values(seenVersions);
      }).flat().find((v2) => !!v2);
      const validUpdates = [];
      if (updates.length === 1) {
        let { values: values2, asNode: asNode2 } = updates[0];
        if (asNode2 === void 0 && Object.keys(this.nodes).length === 1) {
          [asNode2] = Object.keys(this.nodes);
        } else if (asNode2 === void 0 && nonNullVersion === void 0) {
          if (typeof this.inputChannels === "string" && this.nodes[this.inputChannels] !== void 0) {
            asNode2 = this.inputChannels;
          }
        } else if (asNode2 === void 0) {
          const lastSeenByNode = Object.entries(checkpoint.versions_seen).map(([n2, seen]) => {
            return Object.values(seen).map((v2) => {
              return [v2, n2];
            });
          }).flat().sort(([aNumber], [bNumber]) => compareChannelVersions(aNumber, bNumber));
          if (lastSeenByNode) {
            if (lastSeenByNode.length === 1) {
              asNode2 = lastSeenByNode[0][1];
            } else if (lastSeenByNode[lastSeenByNode.length - 1][0] !== lastSeenByNode[lastSeenByNode.length - 2][0]) {
              asNode2 = lastSeenByNode[lastSeenByNode.length - 1][1];
            }
          }
        }
        if (asNode2 === void 0) {
          throw new InvalidUpdateError(`Ambiguous update, specify "asNode"`);
        }
        validUpdates.push({ values: values2, asNode: asNode2 });
      } else {
        for (const { asNode: asNode2, values: values2 } of updates) {
          if (asNode2 == null) {
            throw new InvalidUpdateError(`"asNode" is required when applying multiple updates`);
          }
          validUpdates.push({ values: values2, asNode: asNode2 });
        }
      }
      const tasks = [];
      for (const { asNode: asNode2, values: values2 } of validUpdates) {
        if (this.nodes[asNode2] === void 0) {
          throw new InvalidUpdateError(`Node "${asNode2.toString()}" does not exist`);
        }
        const writers = this.nodes[asNode2].getWriters();
        if (!writers.length) {
          throw new InvalidUpdateError(`No writers found for node "${asNode2.toString()}"`);
        }
        tasks.push({
          name: asNode2,
          input: values2,
          proc: writers.length > 1 ? (
            // eslint-disable-next-line @typescript-eslint/no-explicit-any
            RunnableSequence.from(writers, {
              omitSequenceTags: true
            })
          ) : writers[0],
          writes: [],
          triggers: [INTERRUPT2],
          id: uuid5(INTERRUPT2, checkpoint.id),
          writers: []
        });
      }
      for (const task3 of tasks) {
        await task3.proc.invoke(task3.input, patchConfig({
          ...config,
          store: config?.store ?? this.store
        }, {
          runName: config.runName ?? `${this.getName()}UpdateState`,
          configurable: {
            [CONFIG_KEY_SEND]: (items) => task3.writes.push(...items),
            [CONFIG_KEY_READ]: (select_, fresh_ = false) => _localRead(
              step,
              checkpoint,
              channels,
              managed,
              // TODO: Why does keyof StrRecord allow number and symbol?
              task3,
              select_,
              fresh_
            )
          }
        }));
      }
      for (const task3 of tasks) {
        const channelWrites = task3.writes.filter((w2) => w2[0] !== PUSH);
        if (saved !== void 0 && channelWrites.length > 0) {
          await checkpointer.putWrites(checkpointConfig, channelWrites, task3.id);
        }
      }
      _applyWrites(checkpoint, channels, tasks, checkpointer.getNextVersion.bind(this.checkpointer), this.triggerToNodes);
      const newVersions = getNewChannelVersions(checkpointPreviousVersions, checkpoint.channel_versions);
      const nextConfig = await checkpointer.put(checkpointConfig, createCheckpoint(checkpoint, channels, step + 1), {
        source: "update",
        step: step + 1,
        writes: Object.fromEntries(validUpdates.map((update) => [update.asNode, update.values])),
        parents: saved?.metadata?.parents ?? {}
      }, newVersions);
      for (const task3 of tasks) {
        const pushWrites = task3.writes.filter((w2) => w2[0] === PUSH);
        if (pushWrites.length > 0) {
          await checkpointer.putWrites(nextConfig, pushWrites, task3.id);
        }
      }
      return patchCheckpointMap(nextConfig, saved ? saved.metadata : void 0);
    };
    let currentConfig = startConfig;
    for (const { updates } of supersteps) {
      currentConfig = await updateSuperStep(currentConfig, updates);
    }
    return currentConfig;
  }
  /**
   * Updates the state of the graph with new values.
   * Requires a checkpointer to be configured.
   *
   * This method can be used for:
   * - Implementing human-in-the-loop workflows
   * - Modifying graph state during breakpoints
   * - Integrating external inputs into the graph
   *
   * @param inputConfig - Configuration for the update
   * @param values - The values to update the state with
   * @param asNode - Optional node name to attribute the update to
   * @returns Updated configuration
   * @throws {GraphValueError} If no checkpointer is configured
   * @throws {InvalidUpdateError} If the update cannot be attributed to a node
   */
  async updateState(inputConfig, values, asNode) {
    return this.bulkUpdateState(inputConfig, [
      { updates: [{ values, asNode }] }
    ]);
  }
  /**
   * Gets the default values for various graph configuration options.
   * This is an internal method used to process and normalize configuration options.
   *
   * @param config - The input configuration options
   * @returns A tuple containing normalized values for:
   * - debug mode
   * - stream modes
   * - input keys
   * - output keys
   * - remaining config
   * - interrupt before nodes
   * - interrupt after nodes
   * - checkpointer
   * - store
   * - whether stream mode is single
   * @internal
   */
  _defaults(config) {
    const { debug, streamMode, inputKeys, outputKeys, interruptAfter, interruptBefore, ...rest } = config;
    let streamModeSingle = true;
    const defaultDebug = debug !== void 0 ? debug : this.debug;
    let defaultOutputKeys = outputKeys;
    if (defaultOutputKeys === void 0) {
      defaultOutputKeys = this.streamChannelsAsIs;
    } else {
      validateKeys(defaultOutputKeys, this.channels);
    }
    let defaultInputKeys = inputKeys;
    if (defaultInputKeys === void 0) {
      defaultInputKeys = this.inputChannels;
    } else {
      validateKeys(defaultInputKeys, this.channels);
    }
    const defaultInterruptBefore = interruptBefore ?? this.interruptBefore ?? [];
    const defaultInterruptAfter = interruptAfter ?? this.interruptAfter ?? [];
    let defaultStreamMode;
    if (streamMode !== void 0) {
      defaultStreamMode = Array.isArray(streamMode) ? streamMode : [streamMode];
      streamModeSingle = typeof streamMode === "string";
    } else {
      defaultStreamMode = this.streamMode;
      streamModeSingle = true;
    }
    if (config.configurable?.[CONFIG_KEY_TASK_ID] !== void 0) {
      defaultStreamMode = ["values"];
    }
    let defaultCheckpointer;
    if (this.checkpointer === false) {
      defaultCheckpointer = void 0;
    } else if (config !== void 0 && config.configurable?.[CONFIG_KEY_CHECKPOINTER] !== void 0) {
      defaultCheckpointer = config.configurable[CONFIG_KEY_CHECKPOINTER];
    } else {
      defaultCheckpointer = this.checkpointer;
    }
    const defaultStore = config.store ?? this.store;
    const defaultCache = config.cache ?? this.cache;
    return [
      defaultDebug,
      defaultStreamMode,
      defaultInputKeys,
      defaultOutputKeys,
      rest,
      defaultInterruptBefore,
      defaultInterruptAfter,
      defaultCheckpointer,
      defaultStore,
      streamModeSingle,
      defaultCache
    ];
  }
  /**
   * Streams the execution of the graph, emitting state updates as they occur.
   * This is the primary method for observing graph execution in real-time.
   *
   * Stream modes:
   * - "values": Emits complete state after each step
   * - "updates": Emits only state changes after each step
   * - "debug": Emits detailed debug information
   * - "messages": Emits messages from within nodes
   *
   * For more details, see the [Streaming how-to guides](../../how-tos/#streaming_1).
   *
   * @param input - The input to start graph execution with
   * @param options - Configuration options for streaming
   * @returns An async iterable stream of graph state updates
   */
  async stream(input, options) {
    const abortController = new AbortController();
    const config = {
      recursionLimit: this.config?.recursionLimit,
      ...options,
      signal: options?.signal ? combineAbortSignals(options.signal, abortController.signal) : abortController.signal
    };
    return new IterableReadableStreamWithAbortSignal(await super.stream(input, config), abortController);
  }
  streamEvents(input, options, streamOptions) {
    const abortController = new AbortController();
    const config = {
      recursionLimit: this.config?.recursionLimit,
      // Similar to `stream`, we need to pass the `config.callbacks` here,
      // otherwise the user-provided callback will get lost in `ensureLangGraphConfig`.
      callbacks: this.config?.callbacks,
      ...options,
      signal: options?.signal ? combineAbortSignals(options.signal, abortController.signal) : abortController.signal
    };
    return new IterableReadableStreamWithAbortSignal(super.streamEvents(input, config, streamOptions), abortController);
  }
  /**
   * Prepares channel specifications and managed values for graph execution.
   * This is an internal method used to set up the graph's communication channels
   * and managed state before execution.
   *
   * @param config - Configuration for preparing specs
   * @param options - Additional options
   * @param options.skipManaged - Whether to skip initialization of managed values
   * @returns Object containing channel specs and managed value mapping
   * @internal
   */
  async prepareSpecs(config, options) {
    const configForManaged = {
      ...config,
      store: this.store
    };
    const channelSpecs = {};
    const managedSpecs = {};
    for (const [name, spec] of Object.entries(this.channels)) {
      if (isBaseChannel(spec)) {
        channelSpecs[name] = spec;
      } else if (options?.skipManaged) {
        managedSpecs[name] = {
          cls: NoopManagedValue,
          params: { config: {} }
        };
      } else {
        managedSpecs[name] = spec;
      }
    }
    const managed = new ManagedValueMapping(await Object.entries(managedSpecs).reduce(async (accPromise, [key, value]) => {
      const acc = await accPromise;
      let initializedValue;
      if (isConfiguredManagedValue(value)) {
        if ("key" in value.params && value.params.key === ChannelKeyPlaceholder) {
          value.params.key = key;
        }
        initializedValue = await value.cls.initialize(configForManaged, value.params);
      } else {
        initializedValue = await value.initialize(configForManaged);
      }
      if (initializedValue !== void 0) {
        acc.push([key, initializedValue]);
      }
      return acc;
    }, Promise.resolve([])));
    return {
      channelSpecs,
      managed
    };
  }
  /**
   * Validates the input for the graph.
   * @param input - The input to validate
   * @returns The validated input
   * @internal
   */
  async _validateInput(input) {
    return input;
  }
  /**
   * Validates the configurable options for the graph.
   * @param config - The configurable options to validate
   * @returns The validated configurable options
   * @internal
   */
  async _validateConfigurable(config) {
    return config;
  }
  /**
   * Internal iterator used by stream() to generate state updates.
   * This method handles the core logic of graph execution and streaming.
   *
   * @param input - The input to start graph execution with
   * @param options - Configuration options for streaming
   * @returns AsyncGenerator yielding state updates
   * @internal
   */
  async *_streamIterator(input, options) {
    const streamSubgraphs = options?.subgraphs;
    const inputConfig = ensureLangGraphConfig(this.config, options);
    if (inputConfig.recursionLimit === void 0 || inputConfig.recursionLimit < 1) {
      throw new Error(`Passed "recursionLimit" must be at least 1.`);
    }
    if (this.checkpointer !== void 0 && this.checkpointer !== false && inputConfig.configurable === void 0) {
      throw new Error(`Checkpointer requires one or more of the following "configurable" keys: "thread_id", "checkpoint_ns", "checkpoint_id"`);
    }
    const validInput = await this._validateInput(input);
    const { runId, ...restConfig } = inputConfig;
    const [debug, streamMode, , outputKeys, config, interruptBefore, interruptAfter, checkpointer, store6, streamModeSingle, cache2] = this._defaults(restConfig);
    config.configurable = await this._validateConfigurable(config.configurable);
    const stream = new IterableReadableWritableStream({
      modes: new Set(streamMode)
    });
    if (streamMode.includes("messages")) {
      const messageStreamer = new StreamMessagesHandler((chunk) => stream.push(chunk));
      const { callbacks } = config;
      if (callbacks === void 0) {
        config.callbacks = [messageStreamer];
      } else if (Array.isArray(callbacks)) {
        config.callbacks = callbacks.concat(messageStreamer);
      } else {
        const copiedCallbacks = callbacks.copy();
        copiedCallbacks.addHandler(messageStreamer, true);
        config.callbacks = copiedCallbacks;
      }
    }
    if (streamMode.includes("custom")) {
      config.writer = (chunk) => stream.push([[], "custom", chunk]);
    }
    const callbackManager = await getCallbackManagerForConfig(config);
    const runManager = await callbackManager?.handleChainStart(
      this.toJSON(),
      // chain
      _coerceToDict2(input, "input"),
      // inputs
      runId,
      // run_id
      void 0,
      // run_type
      void 0,
      // tags
      void 0,
      // metadata
      config?.runName ?? this.getName()
      // run_name
    );
    const { channelSpecs, managed } = await this.prepareSpecs(config);
    let loop;
    let loopError;
    const createAndRunLoop = async () => {
      try {
        loop = await PregelLoop.initialize({
          input: validInput,
          config,
          checkpointer,
          nodes: this.nodes,
          channelSpecs,
          managed,
          outputKeys,
          streamKeys: this.streamChannelsAsIs,
          store: store6,
          cache: cache2,
          stream,
          interruptAfter,
          interruptBefore,
          manager: runManager,
          debug: this.debug,
          triggerToNodes: this.triggerToNodes
        });
        const runner = new PregelRunner({
          loop,
          nodeFinished: config.configurable?.[CONFIG_KEY_NODE_FINISHED]
        });
        if (options?.subgraphs) {
          loop.config.configurable = {
            ...loop.config.configurable,
            [CONFIG_KEY_STREAM]: loop.stream
          };
        }
        await this._runLoop({ loop, runner, debug, config });
      } catch (e2) {
        loopError = e2;
      } finally {
        try {
          if (loop) {
            await loop.store?.stop();
            await loop.cache?.stop();
          }
          await Promise.all([
            ...loop?.checkpointerPromises ?? [],
            ...Array.from(managed.values()).map((mv) => mv.promises())
          ]);
        } catch (e2) {
          loopError = loopError ?? e2;
        }
        if (loopError) {
          stream.error(loopError);
        } else {
          stream.close();
        }
      }
    };
    const runLoopPromise = createAndRunLoop();
    try {
      for await (const chunk of stream) {
        if (chunk === void 0) {
          throw new Error("Data structure error.");
        }
        const [namespace, mode, payload] = chunk;
        if (streamMode.includes(mode)) {
          if (streamSubgraphs && !streamModeSingle) {
            yield [namespace, mode, payload];
          } else if (!streamModeSingle) {
            yield [mode, payload];
          } else if (streamSubgraphs) {
            yield [namespace, payload];
          } else {
            yield payload;
          }
        }
      }
    } catch (e2) {
      await runManager?.handleChainError(loopError);
      throw e2;
    } finally {
      await runLoopPromise;
    }
    await runManager?.handleChainEnd(
      loop?.output ?? {},
      runId,
      // run_id
      void 0,
      // run_type
      void 0,
      // tags
      void 0
      // metadata
    );
  }
  /**
   * Run the graph with a single input and config.
   * @param input The input to the graph.
   * @param options The configuration to use for the run.
   */
  async invoke(input, options) {
    const streamMode = options?.streamMode ?? "values";
    const config = {
      ...options,
      outputKeys: options?.outputKeys ?? this.outputChannels,
      streamMode
    };
    const chunks = [];
    const stream = await this.stream(input, config);
    const interruptChunks = [];
    let latest;
    for await (const chunk of stream) {
      if (streamMode === "values") {
        if (isInterrupted(chunk)) {
          interruptChunks.push(chunk[INTERRUPT2]);
        } else {
          latest = chunk;
        }
      } else {
        chunks.push(chunk);
      }
    }
    if (streamMode === "values") {
      if (interruptChunks.length > 0) {
        const interrupts = interruptChunks.flat(1);
        if (latest == null)
          return { [INTERRUPT2]: interrupts };
        if (typeof latest === "object") {
          return { ...latest, [INTERRUPT2]: interrupts };
        }
      }
      return latest;
    }
    return chunks;
  }
  async _runLoop(params) {
    const { loop, runner, debug, config } = params;
    let tickError;
    try {
      while (await loop.tick({ inputKeys: this.inputChannels })) {
        for (const { task: task3 } of await loop._matchCachedWrites()) {
          loop._outputWrites(task3.id, task3.writes, true);
        }
        if (debug) {
          printStepCheckpoint(loop.checkpointMetadata.step, loop.channels, this.streamChannelsList);
        }
        if (debug) {
          printStepTasks(loop.step, Object.values(loop.tasks));
        }
        await runner.tick({
          timeout: this.stepTimeout,
          retryPolicy: this.retryPolicy,
          onStepWrite: (step, writes) => {
            if (debug) {
              printStepWrites(step, writes, this.streamChannelsList);
            }
          },
          maxConcurrency: config.maxConcurrency,
          signal: config.signal
        });
      }
      if (loop.status === "out_of_steps") {
        throw new GraphRecursionError([
          `Recursion limit of ${config.recursionLimit} reached`,
          "without hitting a stop condition. You can increase the",
          `limit by setting the "recursionLimit" config key.`
        ].join(" "), {
          lc_error_code: "GRAPH_RECURSION_LIMIT"
        });
      }
    } catch (e2) {
      tickError = e2;
      const suppress = await loop.finishAndHandleError(tickError);
      if (!suppress) {
        throw e2;
      }
    } finally {
      if (tickError === void 0) {
        await loop.finishAndHandleError();
      }
    }
  }
  async clearCache() {
    await this.cache?.clear([]);
  }
};

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/channels/ephemeral_value.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/channels/index.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/channels/ephemeral_value.js
var EphemeralValue = class _EphemeralValue extends BaseChannel {
  constructor(guard = true) {
    super();
    Object.defineProperty(this, "lc_graph_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "EphemeralValue"
    });
    Object.defineProperty(this, "guard", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "value", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    this.guard = guard;
  }
  fromCheckpoint(checkpoint) {
    const empty = new _EphemeralValue(this.guard);
    if (typeof checkpoint !== "undefined") {
      empty.value = [checkpoint];
    }
    return empty;
  }
  update(values) {
    if (values.length === 0) {
      const updated = this.value.length > 0;
      this.value = [];
      return updated;
    }
    if (values.length !== 1 && this.guard) {
      throw new InvalidUpdateError("EphemeralValue can only receive one value per step.");
    }
    this.value = [values[values.length - 1]];
    return true;
  }
  get() {
    if (this.value.length === 0) {
      throw new EmptyChannelError();
    }
    return this.value[0];
  }
  checkpoint() {
    if (this.value.length === 0) {
      throw new EmptyChannelError();
    }
    return this.value[0];
  }
  isAvailable() {
    return this.value.length !== 0;
  }
};

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/graph/graph.js
var Branch = class {
  constructor(options) {
    Object.defineProperty(this, "path", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "ends", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    if (Runnable.isRunnable(options.path)) {
      this.path = options.path;
    } else {
      this.path = _coerceToRunnable(options.path).withConfig({
        runName: `Branch`
      });
    }
    this.ends = Array.isArray(options.pathMap) ? options.pathMap.reduce((acc, n2) => {
      acc[n2] = n2;
      return acc;
    }, {}) : options.pathMap;
  }
  run(writer, reader) {
    return ChannelWrite.registerWriter(new RunnableCallable({
      name: "<branch_run>",
      trace: false,
      func: async (input, config) => {
        try {
          return await this._route(input, config, writer, reader);
        } catch (e2) {
          if (e2.name === NodeInterrupt.unminifiable_name) {
            console.warn("[WARN]: 'NodeInterrupt' thrown in conditional edge. This is likely a bug in your graph implementation.\nNodeInterrupt should only be thrown inside a node, not in edge conditions.");
          }
          throw e2;
        }
      }
    }));
  }
  async _route(input, config, writer, reader) {
    let result = await this.path.invoke(reader ? reader(config) : input, config);
    if (!Array.isArray(result)) {
      result = [result];
    }
    let destinations;
    if (this.ends) {
      destinations = result.map((r2) => _isSend(r2) ? r2 : this.ends[r2]);
    } else {
      destinations = result;
    }
    if (destinations.some((dest) => !dest)) {
      throw new Error("Branch condition returned unknown or null destination");
    }
    if (destinations.filter(_isSend).some((packet) => packet.node === END)) {
      throw new InvalidUpdateError("Cannot send a packet to the END node");
    }
    const writeResult = await writer(destinations, config);
    return writeResult ?? input;
  }
};
var Graph2 = class {
  constructor() {
    Object.defineProperty(this, "nodes", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "edges", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "branches", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "entryPoint", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "compiled", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    this.nodes = {};
    this.edges = /* @__PURE__ */ new Set();
    this.branches = {};
  }
  warnIfCompiled(message) {
    if (this.compiled) {
      console.warn(message);
    }
  }
  get allEdges() {
    return this.edges;
  }
  addNode(...args) {
    function isMutlipleNodes(args2) {
      return args2.length >= 1 && typeof args2[0] !== "string";
    }
    const nodes = isMutlipleNodes(args) ? Array.isArray(args[0]) ? args[0] : Object.entries(args[0]) : [[args[0], args[1], args[2]]];
    if (nodes.length === 0) {
      throw new Error("No nodes provided in `addNode`");
    }
    for (const [key, action, options] of nodes) {
      for (const reservedChar of [
        CHECKPOINT_NAMESPACE_SEPARATOR,
        CHECKPOINT_NAMESPACE_END
      ]) {
        if (key.includes(reservedChar)) {
          throw new Error(`"${reservedChar}" is a reserved character and is not allowed in node names.`);
        }
      }
      this.warnIfCompiled(`Adding a node to a graph that has already been compiled. This will not be reflected in the compiled graph.`);
      if (key in this.nodes) {
        throw new Error(`Node \`${key}\` already present.`);
      }
      if (key === END) {
        throw new Error(`Node \`${key}\` is reserved.`);
      }
      const runnable = _coerceToRunnable(
        // Account for arbitrary state due to Send API
        action
      );
      this.nodes[key] = {
        runnable,
        metadata: options?.metadata,
        subgraphs: isPregelLike(runnable) ? [runnable] : options?.subgraphs,
        ends: options?.ends
      };
    }
    return this;
  }
  addEdge(startKey, endKey) {
    this.warnIfCompiled(`Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.`);
    if (startKey === END) {
      throw new Error("END cannot be a start node");
    }
    if (endKey === START) {
      throw new Error("START cannot be an end node");
    }
    if (Array.from(this.edges).some(([start]) => start === startKey) && !("channels" in this)) {
      throw new Error(`Already found path for ${startKey}. For multiple edges, use StateGraph.`);
    }
    this.edges.add([startKey, endKey]);
    return this;
  }
  addConditionalEdges(source, path, pathMap) {
    const options = typeof source === "object" ? source : { source, path, pathMap };
    this.warnIfCompiled("Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.");
    if (!Runnable.isRunnable(options.path)) {
      const pathDisplayValues = Array.isArray(options.pathMap) ? options.pathMap.join(",") : Object.keys(options.pathMap ?? {}).join(",");
      options.path = _coerceToRunnable(options.path).withConfig({
        runName: `Branch<${options.source}${pathDisplayValues !== "" ? `,${pathDisplayValues}` : ""}>`.slice(0, 63)
      });
    }
    const name = options.path.getName() === "RunnableLambda" ? "condition" : options.path.getName();
    if (this.branches[options.source] && this.branches[options.source][name]) {
      throw new Error(`Condition \`${name}\` already present for node \`${source}\``);
    }
    this.branches[options.source] ??= {};
    this.branches[options.source][name] = new Branch(options);
    return this;
  }
  /**
   * @deprecated use `addEdge(START, key)` instead
   */
  setEntryPoint(key) {
    this.warnIfCompiled("Setting the entry point of a graph that has already been compiled. This will not be reflected in the compiled graph.");
    return this.addEdge(START, key);
  }
  /**
   * @deprecated use `addEdge(key, END)` instead
   */
  setFinishPoint(key) {
    this.warnIfCompiled("Setting a finish point of a graph that has already been compiled. This will not be reflected in the compiled graph.");
    return this.addEdge(key, END);
  }
  compile({ checkpointer, interruptBefore, interruptAfter, name } = {}) {
    this.validate([
      ...Array.isArray(interruptBefore) ? interruptBefore : [],
      ...Array.isArray(interruptAfter) ? interruptAfter : []
    ]);
    const compiled = new CompiledGraph({
      builder: this,
      checkpointer,
      interruptAfter,
      interruptBefore,
      autoValidate: false,
      nodes: {},
      channels: {
        [START]: new EphemeralValue(),
        [END]: new EphemeralValue()
      },
      inputChannels: START,
      outputChannels: END,
      streamChannels: [],
      streamMode: "values",
      name
    });
    for (const [key, node] of Object.entries(this.nodes)) {
      compiled.attachNode(key, node);
    }
    for (const [start, end] of this.edges) {
      compiled.attachEdge(start, end);
    }
    for (const [start, branches] of Object.entries(this.branches)) {
      for (const [name2, branch] of Object.entries(branches)) {
        compiled.attachBranch(start, name2, branch);
      }
    }
    return compiled.validate();
  }
  validate(interrupt2) {
    const allSources = new Set([...this.allEdges].map(([src, _2]) => src));
    for (const [start] of Object.entries(this.branches)) {
      allSources.add(start);
    }
    for (const source of allSources) {
      if (source !== START && !(source in this.nodes)) {
        throw new Error(`Found edge starting at unknown node \`${source}\``);
      }
    }
    const allTargets = new Set([...this.allEdges].map(([_2, target]) => target));
    for (const [start, branches] of Object.entries(this.branches)) {
      for (const branch of Object.values(branches)) {
        if (branch.ends != null) {
          for (const end of Object.values(branch.ends)) {
            allTargets.add(end);
          }
        } else {
          allTargets.add(END);
          for (const node of Object.keys(this.nodes)) {
            if (node !== start) {
              allTargets.add(node);
            }
          }
        }
      }
    }
    for (const node of Object.values(this.nodes)) {
      for (const target of node.ends ?? []) {
        allTargets.add(target);
      }
    }
    for (const node of Object.keys(this.nodes)) {
      if (!allTargets.has(node)) {
        throw new UnreachableNodeError([
          `Node \`${node}\` is not reachable.`,
          "",
          "If you are returning Command objects from your node,",
          'make sure you are passing names of potential destination nodes as an "ends" array',
          'into ".addNode(..., { ends: ["node1", "node2"] })".'
        ].join("\n"), {
          lc_error_code: "UNREACHABLE_NODE"
        });
      }
    }
    for (const target of allTargets) {
      if (target !== END && !(target in this.nodes)) {
        throw new Error(`Found edge ending at unknown node \`${target}\``);
      }
    }
    if (interrupt2) {
      for (const node of interrupt2) {
        if (!(node in this.nodes)) {
          throw new Error(`Interrupt node \`${node}\` is not present`);
        }
      }
    }
    this.compiled = true;
  }
};
var CompiledGraph = class extends Pregel {
  constructor({ builder, ...rest }) {
    super(rest);
    Object.defineProperty(this, "builder", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.builder = builder;
  }
  attachNode(key, node) {
    this.channels[key] = new EphemeralValue();
    this.nodes[key] = new PregelNode({
      channels: [],
      triggers: [],
      metadata: node.metadata,
      subgraphs: node.subgraphs,
      ends: node.ends
    }).pipe(node.runnable).pipe(new ChannelWrite([{ channel: key, value: PASSTHROUGH }], [TAG_HIDDEN]));
    this.streamChannels.push(key);
  }
  attachEdge(start, end) {
    if (end === END) {
      if (start === START) {
        throw new Error("Cannot have an edge from START to END");
      }
      this.nodes[start].writers.push(new ChannelWrite([{ channel: END, value: PASSTHROUGH }], [TAG_HIDDEN]));
    } else {
      this.nodes[end].triggers.push(start);
      this.nodes[end].channels.push(start);
    }
  }
  attachBranch(start, name, branch) {
    if (start === START && !this.nodes[START]) {
      this.nodes[START] = Channel.subscribeTo(START, { tags: [TAG_HIDDEN] });
    }
    this.nodes[start].pipe(branch.run((dests) => {
      const writes = dests.map((dest) => {
        if (_isSend(dest)) {
          return dest;
        }
        return {
          channel: dest === END ? END : `branch:${start}:${name}:${dest}`,
          value: PASSTHROUGH
        };
      });
      return new ChannelWrite(writes, [TAG_HIDDEN]);
    }));
    const ends = branch.ends ? Object.values(branch.ends) : Object.keys(this.nodes);
    for (const end of ends) {
      if (end !== END) {
        const channelName = `branch:${start}:${name}:${end}`;
        this.channels[channelName] = new EphemeralValue();
        this.nodes[end].triggers.push(channelName);
        this.nodes[end].channels.push(channelName);
      }
    }
  }
  /**
   * Returns a drawable representation of the computation graph.
   */
  async getGraphAsync(config) {
    const xray = config?.xray;
    const graph = new Graph();
    const startNodes = {
      [START]: graph.addNode({
        schema: z.any()
      }, START)
    };
    const endNodes = {};
    let subgraphs = {};
    if (xray) {
      subgraphs = Object.fromEntries((await gatherIterator(this.getSubgraphsAsync())).filter(
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        (x2) => isCompiledGraph(x2[1])
      ));
    }
    function addEdge(start, end, label, conditional = false) {
      if (end === END && endNodes[END] === void 0) {
        endNodes[END] = graph.addNode({ schema: z.any() }, END);
      }
      if (startNodes[start] === void 0) {
        return;
      }
      if (endNodes[end] === void 0) {
        throw new Error(`End node ${end} not found!`);
      }
      return graph.addEdge(startNodes[start], endNodes[end], label !== end ? label : void 0, conditional);
    }
    for (const [key, nodeSpec] of Object.entries(this.builder.nodes)) {
      const displayKey = _escapeMermaidKeywords(key);
      const node = nodeSpec.runnable;
      const metadata = nodeSpec.metadata ?? {};
      if (this.interruptBefore?.includes(key) && this.interruptAfter?.includes(key)) {
        metadata.__interrupt = "before,after";
      } else if (this.interruptBefore?.includes(key)) {
        metadata.__interrupt = "before";
      } else if (this.interruptAfter?.includes(key)) {
        metadata.__interrupt = "after";
      }
      if (xray) {
        const newXrayValue = typeof xray === "number" ? xray - 1 : xray;
        const drawableSubgraph = subgraphs[key] !== void 0 ? await subgraphs[key].getGraphAsync({
          ...config,
          xray: newXrayValue
        }) : node.getGraph(config);
        drawableSubgraph.trimFirstNode();
        drawableSubgraph.trimLastNode();
        if (Object.keys(drawableSubgraph.nodes).length > 1) {
          let _isRunnableInterface = function(thing) {
            return thing ? thing.lc_runnable : false;
          }, _nodeDataStr = function(id, data) {
            if (id !== void 0 && !isUuid(id)) {
              return id;
            } else if (_isRunnableInterface(data)) {
              try {
                let dataStr = data.getName();
                dataStr = dataStr.startsWith("Runnable") ? dataStr.slice("Runnable".length) : dataStr;
                return dataStr;
              } catch (error) {
                return data.getName();
              }
            } else {
              return data.name ?? "UnknownSchema";
            }
          };
          const [e2, s2] = graph.extend(drawableSubgraph, displayKey);
          if (e2 === void 0) {
            throw new Error(`Could not extend subgraph "${key}" due to missing entrypoint.`);
          }
          if (s2 !== void 0) {
            startNodes[displayKey] = {
              name: _nodeDataStr(s2.id, s2.data),
              ...s2
            };
          }
          endNodes[displayKey] = {
            name: _nodeDataStr(e2.id, e2.data),
            ...e2
          };
        } else {
          const newNode = graph.addNode(node, displayKey, metadata);
          startNodes[displayKey] = newNode;
          endNodes[displayKey] = newNode;
        }
      } else {
        const newNode = graph.addNode(node, displayKey, metadata);
        startNodes[displayKey] = newNode;
        endNodes[displayKey] = newNode;
      }
    }
    const sortedEdges = [...this.builder.allEdges].sort(([a], [b2]) => {
      if (a < b2) {
        return -1;
      } else if (b2 > a) {
        return 1;
      } else {
        return 0;
      }
    });
    for (const [start, end] of sortedEdges) {
      addEdge(_escapeMermaidKeywords(start), _escapeMermaidKeywords(end));
    }
    for (const [start, branches] of Object.entries(this.builder.branches)) {
      const defaultEnds = {
        ...Object.fromEntries(Object.keys(this.builder.nodes).filter((k2) => k2 !== start).map((k2) => [_escapeMermaidKeywords(k2), _escapeMermaidKeywords(k2)])),
        [END]: END
      };
      for (const branch of Object.values(branches)) {
        let ends;
        if (branch.ends !== void 0) {
          ends = branch.ends;
        } else {
          ends = defaultEnds;
        }
        for (const [label, end] of Object.entries(ends)) {
          addEdge(_escapeMermaidKeywords(start), _escapeMermaidKeywords(end), label, true);
        }
      }
    }
    for (const [key, node] of Object.entries(this.builder.nodes)) {
      if (node.ends !== void 0) {
        for (const end of node.ends) {
          addEdge(_escapeMermaidKeywords(key), _escapeMermaidKeywords(end), void 0, true);
        }
      }
    }
    return graph;
  }
  /**
   * Returns a drawable representation of the computation graph.
   *
   * @deprecated Use getGraphAsync instead. The async method will be the default in the next minor core release.
   */
  getGraph(config) {
    const xray = config?.xray;
    const graph = new Graph();
    const startNodes = {
      [START]: graph.addNode({
        schema: z.any()
      }, START)
    };
    const endNodes = {};
    let subgraphs = {};
    if (xray) {
      subgraphs = Object.fromEntries(gatherIteratorSync(this.getSubgraphs()).filter(
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        (x2) => isCompiledGraph(x2[1])
      ));
    }
    function addEdge(start, end, label, conditional = false) {
      if (end === END && endNodes[END] === void 0) {
        endNodes[END] = graph.addNode({ schema: z.any() }, END);
      }
      return graph.addEdge(startNodes[start], endNodes[end], label !== end ? label : void 0, conditional);
    }
    for (const [key, nodeSpec] of Object.entries(this.builder.nodes)) {
      const displayKey = _escapeMermaidKeywords(key);
      const node = nodeSpec.runnable;
      const metadata = nodeSpec.metadata ?? {};
      if (this.interruptBefore?.includes(key) && this.interruptAfter?.includes(key)) {
        metadata.__interrupt = "before,after";
      } else if (this.interruptBefore?.includes(key)) {
        metadata.__interrupt = "before";
      } else if (this.interruptAfter?.includes(key)) {
        metadata.__interrupt = "after";
      }
      if (xray) {
        const newXrayValue = typeof xray === "number" ? xray - 1 : xray;
        const drawableSubgraph = subgraphs[key] !== void 0 ? subgraphs[key].getGraph({
          ...config,
          xray: newXrayValue
        }) : node.getGraph(config);
        drawableSubgraph.trimFirstNode();
        drawableSubgraph.trimLastNode();
        if (Object.keys(drawableSubgraph.nodes).length > 1) {
          let _isRunnableInterface = function(thing) {
            return thing ? thing.lc_runnable : false;
          }, _nodeDataStr = function(id, data) {
            if (id !== void 0 && !isUuid(id)) {
              return id;
            } else if (_isRunnableInterface(data)) {
              try {
                let dataStr = data.getName();
                dataStr = dataStr.startsWith("Runnable") ? dataStr.slice("Runnable".length) : dataStr;
                return dataStr;
              } catch (error) {
                return data.getName();
              }
            } else {
              return data.name ?? "UnknownSchema";
            }
          };
          const [e2, s2] = graph.extend(drawableSubgraph, displayKey);
          if (e2 === void 0) {
            throw new Error(`Could not extend subgraph "${key}" due to missing entrypoint.`);
          }
          if (s2 !== void 0) {
            startNodes[displayKey] = {
              name: _nodeDataStr(s2.id, s2.data),
              ...s2
            };
          }
          endNodes[displayKey] = {
            name: _nodeDataStr(e2.id, e2.data),
            ...e2
          };
        } else {
          const newNode = graph.addNode(node, displayKey, metadata);
          startNodes[displayKey] = newNode;
          endNodes[displayKey] = newNode;
        }
      } else {
        const newNode = graph.addNode(node, displayKey, metadata);
        startNodes[displayKey] = newNode;
        endNodes[displayKey] = newNode;
      }
    }
    const sortedEdges = [...this.builder.allEdges].sort(([a], [b2]) => {
      if (a < b2) {
        return -1;
      } else if (b2 > a) {
        return 1;
      } else {
        return 0;
      }
    });
    for (const [start, end] of sortedEdges) {
      addEdge(_escapeMermaidKeywords(start), _escapeMermaidKeywords(end));
    }
    for (const [start, branches] of Object.entries(this.builder.branches)) {
      const defaultEnds = {
        ...Object.fromEntries(Object.keys(this.builder.nodes).filter((k2) => k2 !== start).map((k2) => [_escapeMermaidKeywords(k2), _escapeMermaidKeywords(k2)])),
        [END]: END
      };
      for (const branch of Object.values(branches)) {
        let ends;
        if (branch.ends !== void 0) {
          ends = branch.ends;
        } else {
          ends = defaultEnds;
        }
        for (const [label, end] of Object.entries(ends)) {
          addEdge(_escapeMermaidKeywords(start), _escapeMermaidKeywords(end), label, true);
        }
      }
    }
    return graph;
  }
};
function isCompiledGraph(x2) {
  return (
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    typeof x2.attachNode === "function" && // eslint-disable-next-line @typescript-eslint/no-explicit-any
    typeof x2.attachEdge === "function"
  );
}
function _escapeMermaidKeywords(key) {
  if (key === "subgraph") {
    return `"${key}"`;
  }
  return key;
}

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/graph/state.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/channels/named_barrier_value.js
init_esm();
var areSetsEqual = (a, b2) => a.size === b2.size && [...a].every((value) => b2.has(value));
var NamedBarrierValue = class _NamedBarrierValue extends BaseChannel {
  constructor(names) {
    super();
    Object.defineProperty(this, "lc_graph_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "NamedBarrierValue"
    });
    Object.defineProperty(this, "names", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "seen", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.names = names;
    this.seen = /* @__PURE__ */ new Set();
  }
  fromCheckpoint(checkpoint) {
    const empty = new _NamedBarrierValue(this.names);
    if (typeof checkpoint !== "undefined") {
      empty.seen = new Set(checkpoint);
    }
    return empty;
  }
  update(values) {
    let updated = false;
    for (const nodeName of values) {
      if (this.names.has(nodeName)) {
        if (!this.seen.has(nodeName)) {
          this.seen.add(nodeName);
          updated = true;
        }
      } else {
        throw new InvalidUpdateError(`Value ${JSON.stringify(nodeName)} not in names ${JSON.stringify(this.names)}`);
      }
    }
    return updated;
  }
  // If we have not yet seen all the node names we want to wait for,
  // throw an error to prevent continuing.
  get() {
    if (!areSetsEqual(this.names, this.seen)) {
      throw new EmptyChannelError();
    }
    return void 0;
  }
  checkpoint() {
    return [...this.seen];
  }
  consume() {
    if (this.seen && this.names && areSetsEqual(this.seen, this.names)) {
      this.seen = /* @__PURE__ */ new Set();
      return true;
    }
    return false;
  }
  isAvailable() {
    return !!this.names && areSetsEqual(this.names, this.seen);
  }
};
var NamedBarrierValueAfterFinish = class _NamedBarrierValueAfterFinish extends BaseChannel {
  constructor(names) {
    super();
    Object.defineProperty(this, "lc_graph_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "NamedBarrierValueAfterFinish"
    });
    Object.defineProperty(this, "names", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "seen", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "finished", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.names = names;
    this.seen = /* @__PURE__ */ new Set();
    this.finished = false;
  }
  fromCheckpoint(checkpoint) {
    const empty = new _NamedBarrierValueAfterFinish(this.names);
    if (typeof checkpoint !== "undefined") {
      const [seen, finished] = checkpoint;
      empty.seen = new Set(seen);
      empty.finished = finished;
    }
    return empty;
  }
  update(values) {
    let updated = false;
    for (const nodeName of values) {
      if (this.names.has(nodeName) && !this.seen.has(nodeName)) {
        this.seen.add(nodeName);
        updated = true;
      } else if (!this.names.has(nodeName)) {
        throw new InvalidUpdateError(`Value ${JSON.stringify(nodeName)} not in names ${JSON.stringify(this.names)}`);
      }
    }
    return updated;
  }
  get() {
    if (!this.finished || !areSetsEqual(this.names, this.seen)) {
      throw new EmptyChannelError();
    }
    return void 0;
  }
  checkpoint() {
    return [[...this.seen], this.finished];
  }
  consume() {
    if (this.finished && this.seen && this.names && areSetsEqual(this.seen, this.names)) {
      this.seen = /* @__PURE__ */ new Set();
      this.finished = false;
      return true;
    }
    return false;
  }
  finish() {
    if (!this.finished && !!this.names && areSetsEqual(this.names, this.seen)) {
      this.finished = true;
      return true;
    }
    return false;
  }
  isAvailable() {
    return this.finished && !!this.names && areSetsEqual(this.names, this.seen);
  }
};

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/graph/zod/state.js
init_esm();
var META_MAP = /* @__PURE__ */ new WeakMap();
function isZodType(value) {
  return typeof value === "object" && value != null && "_parse" in value && typeof value._parse === "function";
}
function isZodDefault(value) {
  return isZodType(value) && "removeDefault" in value && typeof value.removeDefault === "function";
}
function isAnyZodObject(value) {
  return isZodType(value) && "partial" in value && typeof value.partial === "function";
}
function withLangGraph(schema, meta) {
  if (meta.reducer && !meta.default) {
    const defaultValue = isZodDefault(schema) ? schema._def.defaultValue : void 0;
    if (defaultValue != null) {
      meta.default = defaultValue;
    }
  }
  META_MAP.set(schema, meta);
  return schema;
}
function getMeta(schema) {
  return META_MAP.get(schema);
}
function getChannelsFromZod(schema) {
  const channels = {};
  for (const key in schema.shape) {
    if (Object.prototype.hasOwnProperty.call(schema.shape, key)) {
      const keySchema = schema.shape[key];
      const meta = getMeta(keySchema);
      if (meta?.reducer) {
        channels[key] = new BinaryOperatorAggregate(meta.reducer.fn, meta.default);
      } else {
        channels[key] = new LastValue();
      }
    }
  }
  return channels;
}
var ZOD_TYPE_CACHE = {};
var ZOD_DESCRIPTION_PREFIX = "lg:";
function applyZodPlugin(schema, actions) {
  const cacheKey = [
    `reducer:${actions.reducer ?? false}`,
    `jsonSchemaExtra:${actions.jsonSchemaExtra ?? false}`,
    `partial:${actions.partial ?? false}`
  ].join("|");
  ZOD_TYPE_CACHE[cacheKey] ??= /* @__PURE__ */ new WeakMap();
  const cache2 = ZOD_TYPE_CACHE[cacheKey];
  if (cache2.has(schema))
    return cache2.get(schema);
  let shape = schema.extend({
    ...Object.fromEntries(Object.entries(schema.shape).map(([key, input]) => {
      const meta = getMeta(input);
      let output = actions.reducer ? meta?.reducer?.schema ?? input : input;
      if (actions.jsonSchemaExtra) {
        const strMeta = JSON.stringify({
          ...meta?.jsonSchemaExtra,
          description: output.description ?? input.description
        });
        if (strMeta !== "{}") {
          output = output.describe(`${ZOD_DESCRIPTION_PREFIX}${strMeta}`);
        }
      }
      return [key, output];
    }))
  });
  if ("_def" in shape && shape._def != null && typeof shape._def === "object" && "unknownKeys" in shape._def) {
    shape._def.unknownKeys = "strip";
  }
  if (actions.partial)
    shape = shape.partial();
  cache2.set(schema, shape);
  return shape;
}

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/graph/state.js
var ROOT = "__root__";
var PartialStateSchema = Symbol.for("langgraph.state.partial");
var StateGraph = class extends Graph2 {
  constructor(fields, configSchema) {
    super();
    Object.defineProperty(this, "channels", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {}
    });
    Object.defineProperty(this, "waitingEdges", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: /* @__PURE__ */ new Set()
    });
    Object.defineProperty(this, "_schemaDefinition", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "_schemaRuntimeDefinition", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "_inputDefinition", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "_inputRuntimeDefinition", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "_outputDefinition", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "_outputRuntimeDefinition", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "_schemaDefinitions", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: /* @__PURE__ */ new Map()
    });
    Object.defineProperty(this, "_configSchema", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "_configRuntimeSchema", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    if (isZodStateGraphArgsWithStateSchema(fields)) {
      const stateDef = getChannelsFromZod(fields.state);
      const inputDef = fields.input != null ? getChannelsFromZod(fields.input) : stateDef;
      const outputDef = fields.output != null ? getChannelsFromZod(fields.output) : stateDef;
      this._schemaDefinition = stateDef;
      this._schemaRuntimeDefinition = fields.state;
      this._inputDefinition = inputDef;
      this._inputRuntimeDefinition = fields.input ?? PartialStateSchema;
      this._outputDefinition = outputDef;
      this._outputRuntimeDefinition = fields.output ?? fields.state;
    } else if (isAnyZodObject(fields)) {
      const stateDef = getChannelsFromZod(fields);
      this._schemaDefinition = stateDef;
      this._schemaRuntimeDefinition = fields;
      this._inputDefinition = stateDef;
      this._inputRuntimeDefinition = PartialStateSchema;
      this._outputDefinition = stateDef;
      this._outputRuntimeDefinition = fields;
    } else if (isStateGraphArgsWithInputOutputSchemas(fields)) {
      this._schemaDefinition = fields.input.spec;
      this._inputDefinition = fields.input.spec;
      this._outputDefinition = fields.output.spec;
    } else if (isStateGraphArgsWithStateSchema(fields)) {
      this._schemaDefinition = fields.stateSchema.spec;
      this._inputDefinition = fields.input?.spec ?? this._schemaDefinition;
      this._outputDefinition = fields.output?.spec ?? this._schemaDefinition;
    } else if (isStateDefinition(fields) || isAnnotationRoot(fields)) {
      const spec = isAnnotationRoot(fields) ? fields.spec : fields;
      this._schemaDefinition = spec;
    } else if (isStateGraphArgs(fields)) {
      const spec = _getChannels(fields.channels);
      this._schemaDefinition = spec;
    } else {
      throw new Error("Invalid StateGraph input. Make sure to pass a valid Annotation.Root or Zod schema.");
    }
    this._inputDefinition ??= this._schemaDefinition;
    this._outputDefinition ??= this._schemaDefinition;
    this._addSchema(this._schemaDefinition);
    this._addSchema(this._inputDefinition);
    this._addSchema(this._outputDefinition);
    if (isAnyZodObject(configSchema)) {
      this._configRuntimeSchema = configSchema.passthrough();
    }
  }
  get allEdges() {
    return /* @__PURE__ */ new Set([
      ...this.edges,
      ...Array.from(this.waitingEdges).flatMap(([starts, end]) => starts.map((start) => [start, end]))
    ]);
  }
  _addSchema(stateDefinition) {
    if (this._schemaDefinitions.has(stateDefinition)) {
      return;
    }
    this._schemaDefinitions.set(stateDefinition, stateDefinition);
    for (const [key, val] of Object.entries(stateDefinition)) {
      let channel;
      if (typeof val === "function") {
        channel = val();
      } else {
        channel = val;
      }
      if (this.channels[key] !== void 0) {
        if (this.channels[key] !== channel) {
          if (!isConfiguredManagedValue(channel) && channel.lc_graph_name !== "LastValue") {
            throw new Error(`Channel "${key}" already exists with a different type.`);
          }
        }
      } else {
        this.channels[key] = channel;
      }
    }
  }
  addNode(...args) {
    function isMultipleNodes(args2) {
      return args2.length >= 1 && typeof args2[0] !== "string";
    }
    const nodes = isMultipleNodes(args) ? Array.isArray(args[0]) ? args[0] : Object.entries(args[0]).map(([key, action]) => [
      key,
      action,
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      action[Symbol.for("langgraph.state.node")] ?? void 0
    ]) : [[args[0], args[1], args[2]]];
    if (nodes.length === 0) {
      throw new Error("No nodes provided in `addNode`");
    }
    for (const [key, action, options] of nodes) {
      if (key in this.channels) {
        throw new Error(`${key} is already being used as a state attribute (a.k.a. a channel), cannot also be used as a node name.`);
      }
      for (const reservedChar of [
        CHECKPOINT_NAMESPACE_SEPARATOR,
        CHECKPOINT_NAMESPACE_END
      ]) {
        if (key.includes(reservedChar)) {
          throw new Error(`"${reservedChar}" is a reserved character and is not allowed in node names.`);
        }
      }
      this.warnIfCompiled(`Adding a node to a graph that has already been compiled. This will not be reflected in the compiled graph.`);
      if (key in this.nodes) {
        throw new Error(`Node \`${key}\` already present.`);
      }
      if (key === END || key === START) {
        throw new Error(`Node \`${key}\` is reserved.`);
      }
      let inputSpec = this._schemaDefinition;
      if (options?.input !== void 0) {
        if (isAnyZodObject(options.input)) {
          inputSpec = getChannelsFromZod(options.input);
        } else if (options.input.spec !== void 0) {
          inputSpec = options.input.spec;
        }
      }
      if (inputSpec !== void 0) {
        this._addSchema(inputSpec);
      }
      let runnable;
      if (Runnable.isRunnable(action)) {
        runnable = action;
      } else if (typeof action === "function") {
        runnable = new RunnableCallable({
          func: action,
          name: key,
          trace: false
        });
      } else {
        runnable = _coerceToRunnable(action);
      }
      let cachePolicy = options?.cachePolicy;
      if (typeof cachePolicy === "boolean") {
        cachePolicy = cachePolicy ? {} : void 0;
      }
      const nodeSpec = {
        runnable,
        retryPolicy: options?.retryPolicy,
        cachePolicy,
        metadata: options?.metadata,
        input: inputSpec ?? this._schemaDefinition,
        subgraphs: isPregelLike(runnable) ? (
          // eslint-disable-next-line @typescript-eslint/no-explicit-any
          [runnable]
        ) : options?.subgraphs,
        ends: options?.ends,
        defer: options?.defer
      };
      this.nodes[key] = nodeSpec;
    }
    return this;
  }
  addEdge(startKey, endKey) {
    if (typeof startKey === "string") {
      return super.addEdge(startKey, endKey);
    }
    if (this.compiled) {
      console.warn("Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.");
    }
    for (const start of startKey) {
      if (start === END) {
        throw new Error("END cannot be a start node");
      }
      if (!Object.keys(this.nodes).some((node) => node === start)) {
        throw new Error(`Need to add a node named "${start}" first`);
      }
    }
    if (endKey === END) {
      throw new Error("END cannot be an end node");
    }
    if (!Object.keys(this.nodes).some((node) => node === endKey)) {
      throw new Error(`Need to add a node named "${endKey}" first`);
    }
    this.waitingEdges.add([startKey, endKey]);
    return this;
  }
  addSequence(nodes) {
    const parsedNodes = Array.isArray(nodes) ? nodes : Object.entries(nodes).map(([key, action]) => [
      key,
      action,
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      action[Symbol.for("langgraph.state.node")] ?? void 0
    ]);
    if (parsedNodes.length === 0) {
      throw new Error("Sequence requires at least one node.");
    }
    let previousNode;
    for (const [key, action, options] of parsedNodes) {
      if (key in this.nodes) {
        throw new Error(`Node names must be unique: node with the name "${key}" already exists.`);
      }
      const validKey = key;
      this.addNode(validKey, action, options);
      if (previousNode != null) {
        this.addEdge(previousNode, validKey);
      }
      previousNode = validKey;
    }
    return this;
  }
  compile({ checkpointer, store: store6, cache: cache2, interruptBefore, interruptAfter, name } = {}) {
    this.validate([
      ...Array.isArray(interruptBefore) ? interruptBefore : [],
      ...Array.isArray(interruptAfter) ? interruptAfter : []
    ]);
    const outputKeys = Object.keys(this._schemaDefinitions.get(this._outputDefinition));
    const outputChannels = outputKeys.length === 1 && outputKeys[0] === ROOT ? ROOT : outputKeys;
    const streamKeys = Object.keys(this.channels);
    const streamChannels = streamKeys.length === 1 && streamKeys[0] === ROOT ? ROOT : streamKeys;
    const compiled = new CompiledStateGraph({
      builder: this,
      checkpointer,
      interruptAfter,
      interruptBefore,
      autoValidate: false,
      nodes: {},
      channels: {
        ...this.channels,
        [START]: new EphemeralValue()
      },
      inputChannels: START,
      outputChannels,
      streamChannels,
      streamMode: "updates",
      store: store6,
      cache: cache2,
      name
    });
    compiled.attachNode(START);
    for (const [key, node] of Object.entries(this.nodes)) {
      compiled.attachNode(key, node);
    }
    compiled.attachBranch(START, SELF, _getControlBranch(), {
      withReader: false
    });
    for (const [key] of Object.entries(this.nodes)) {
      compiled.attachBranch(key, SELF, _getControlBranch(), {
        withReader: false
      });
    }
    for (const [start, end] of this.edges) {
      compiled.attachEdge(start, end);
    }
    for (const [starts, end] of this.waitingEdges) {
      compiled.attachEdge(starts, end);
    }
    for (const [start, branches] of Object.entries(this.branches)) {
      for (const [name2, branch] of Object.entries(branches)) {
        compiled.attachBranch(start, name2, branch);
      }
    }
    return compiled.validate();
  }
};
function _getChannels(schema) {
  const channels = {};
  for (const [name, val] of Object.entries(schema)) {
    if (name === ROOT) {
      channels[name] = getChannel(val);
    } else {
      const key = name;
      channels[name] = getChannel(val);
    }
  }
  return channels;
}
var CompiledStateGraph = class extends CompiledGraph {
  attachNode(key, node) {
    let outputKeys;
    if (key === START) {
      outputKeys = Object.entries(this.builder._schemaDefinitions.get(this.builder._inputDefinition)).filter(([_2, v2]) => !isConfiguredManagedValue(v2)).map(([k2]) => k2);
    } else {
      outputKeys = Object.keys(this.builder.channels);
    }
    function _getRoot(input) {
      if (isCommand(input)) {
        if (input.graph === Command.PARENT) {
          return null;
        }
        return input._updateAsTuples();
      } else if (Array.isArray(input) && input.length > 0 && input.some((i2) => isCommand(i2))) {
        const updates = [];
        for (const i2 of input) {
          if (isCommand(i2)) {
            if (i2.graph === Command.PARENT) {
              continue;
            }
            updates.push(...i2._updateAsTuples());
          } else {
            updates.push([ROOT, i2]);
          }
        }
        return updates;
      } else if (input != null) {
        return [[ROOT, input]];
      }
      return null;
    }
    const nodeKey = key;
    function _getUpdates(input) {
      if (!input) {
        return null;
      } else if (isCommand(input)) {
        if (input.graph === Command.PARENT) {
          return null;
        }
        return input._updateAsTuples().filter(([k2]) => outputKeys.includes(k2));
      } else if (Array.isArray(input) && input.length > 0 && input.some(isCommand)) {
        const updates = [];
        for (const item of input) {
          if (isCommand(item)) {
            if (item.graph === Command.PARENT) {
              continue;
            }
            updates.push(...item._updateAsTuples().filter(([k2]) => outputKeys.includes(k2)));
          } else {
            const itemUpdates = _getUpdates(item);
            if (itemUpdates) {
              updates.push(...itemUpdates ?? []);
            }
          }
        }
        return updates;
      } else if (typeof input === "object" && !Array.isArray(input)) {
        return Object.entries(input).filter(([k2]) => outputKeys.includes(k2));
      } else {
        const typeofInput = Array.isArray(input) ? "array" : typeof input;
        throw new InvalidUpdateError(`Expected node "${nodeKey.toString()}" to return an object or an array containing at least one Command object, received ${typeofInput}`, {
          lc_error_code: "INVALID_GRAPH_NODE_RETURN_VALUE"
        });
      }
    }
    const stateWriteEntries = [
      {
        value: PASSTHROUGH,
        mapper: new RunnableCallable({
          func: outputKeys.length && outputKeys[0] === ROOT ? _getRoot : _getUpdates,
          trace: false,
          recurse: false
        })
      }
    ];
    if (key === START) {
      this.nodes[key] = new PregelNode({
        tags: [TAG_HIDDEN],
        triggers: [START],
        channels: [START],
        writers: [new ChannelWrite(stateWriteEntries, [TAG_HIDDEN])]
      });
    } else {
      const inputDefinition = node?.input ?? this.builder._schemaDefinition;
      const inputValues = Object.fromEntries(Object.keys(this.builder._schemaDefinitions.get(inputDefinition)).map((k2) => [k2, k2]));
      const isSingleInput = Object.keys(inputValues).length === 1 && ROOT in inputValues;
      const branchChannel = `branch:to:${key}`;
      this.channels[branchChannel] = node?.defer ? new LastValueAfterFinish() : new EphemeralValue(false);
      this.nodes[key] = new PregelNode({
        triggers: [branchChannel],
        // read state keys
        channels: isSingleInput ? Object.keys(inputValues) : inputValues,
        // publish to state keys
        writers: [new ChannelWrite(stateWriteEntries, [TAG_HIDDEN])],
        mapper: isSingleInput ? void 0 : (
          // eslint-disable-next-line @typescript-eslint/no-explicit-any
          (input) => {
            return Object.fromEntries(Object.entries(input).filter(([k2]) => k2 in inputValues));
          }
        ),
        bound: node?.runnable,
        metadata: node?.metadata,
        retryPolicy: node?.retryPolicy,
        cachePolicy: node?.cachePolicy,
        subgraphs: node?.subgraphs,
        ends: node?.ends
      });
    }
  }
  attachEdge(starts, end) {
    if (end === END)
      return;
    if (typeof starts === "string") {
      this.nodes[starts].writers.push(new ChannelWrite([{ channel: `branch:to:${end}`, value: null }], [TAG_HIDDEN]));
    } else if (Array.isArray(starts)) {
      const channelName = `join:${starts.join("+")}:${end}`;
      this.channels[channelName] = this.builder.nodes[end].defer ? new NamedBarrierValueAfterFinish(new Set(starts)) : new NamedBarrierValue(new Set(starts));
      this.nodes[end].triggers.push(channelName);
      for (const start of starts) {
        this.nodes[start].writers.push(new ChannelWrite([{ channel: channelName, value: start }], [TAG_HIDDEN]));
      }
    }
  }
  attachBranch(start, _2, branch, options = { withReader: true }) {
    const branchWriter = async (packets, config) => {
      const filteredPackets = packets.filter((p2) => p2 !== END);
      if (!filteredPackets.length)
        return;
      const writes = filteredPackets.map((p2) => {
        if (_isSend(p2))
          return p2;
        return { channel: p2 === END ? p2 : `branch:to:${p2}`, value: start };
      });
      await ChannelWrite.doWrite({ ...config, tags: (config.tags ?? []).concat([TAG_HIDDEN]) }, writes);
    };
    this.nodes[start].writers.push(branch.run(
      branchWriter,
      // reader
      options.withReader ? (config) => ChannelRead.doRead(config, this.streamChannels ?? this.outputChannels, true) : void 0
    ));
  }
  async _validateInput(input) {
    if (input == null)
      return input;
    const schema = (() => {
      const input2 = this.builder._inputRuntimeDefinition;
      const schema2 = this.builder._schemaRuntimeDefinition;
      const apply = (schema3) => {
        if (schema3 == null)
          return void 0;
        return applyZodPlugin(schema3, { reducer: true });
      };
      if (isAnyZodObject(input2))
        return apply(input2);
      if (input2 === PartialStateSchema)
        return apply(schema2)?.partial();
      return void 0;
    })();
    if (isCommand(input)) {
      const parsedInput = input;
      if (input.update && schema != null)
        parsedInput.update = schema.parse(input.update);
      return parsedInput;
    }
    if (schema != null)
      return schema.parse(input);
    return input;
  }
  async _validateConfigurable(config) {
    const configSchema = this.builder._configRuntimeSchema;
    if (isAnyZodObject(configSchema))
      configSchema.parse(config);
    return config;
  }
};
function isStateDefinition(obj) {
  return typeof obj === "object" && obj !== null && !Array.isArray(obj) && Object.keys(obj).length > 0 && Object.values(obj).every((v2) => typeof v2 === "function" || isBaseChannel(v2));
}
function isAnnotationRoot(obj) {
  return typeof obj === "object" && obj !== null && "lc_graph_name" in obj && obj.lc_graph_name === "AnnotationRoot";
}
function isStateGraphArgs(obj) {
  return typeof obj === "object" && obj !== null && obj.channels !== void 0;
}
function isStateGraphArgsWithStateSchema(obj) {
  return typeof obj === "object" && obj !== null && obj.stateSchema !== void 0;
}
function isStateGraphArgsWithInputOutputSchemas(obj) {
  return typeof obj === "object" && obj !== null && // eslint-disable-next-line @typescript-eslint/no-explicit-any
  obj.stateSchema === void 0 && obj.input !== void 0 && obj.output !== void 0;
}
function isZodStateGraphArgsWithStateSchema(value) {
  if (typeof value !== "object" || value == null) {
    return false;
  }
  if (!("state" in value) || !isAnyZodObject(value.state)) {
    return false;
  }
  if ("input" in value && !isAnyZodObject(value.input)) {
    return false;
  }
  if ("output" in value && !isAnyZodObject(value.output)) {
    return false;
  }
  return true;
}
function _controlBranch(value) {
  if (_isSend(value)) {
    return [value];
  }
  const commands = [];
  if (isCommand(value)) {
    commands.push(value);
  } else if (Array.isArray(value)) {
    commands.push(...value.filter(isCommand));
  }
  const destinations = [];
  for (const command of commands) {
    if (command.graph === Command.PARENT) {
      throw new ParentCommand(command);
    }
    if (_isSend(command.goto)) {
      destinations.push(command.goto);
    } else if (typeof command.goto === "string") {
      destinations.push(command.goto);
    } else {
      if (Array.isArray(command.goto)) {
        destinations.push(...command.goto);
      }
    }
  }
  return destinations;
}
function _getControlBranch() {
  const CONTROL_BRANCH_PATH = new RunnableCallable({
    func: _controlBranch,
    tags: [TAG_HIDDEN],
    trace: false,
    recurse: false,
    name: "<control_branch>"
  });
  return new Branch({
    path: CONTROL_BRANCH_PATH
  });
}

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/graph/message.js
init_esm();
import { v4 } from "uuid";
var REMOVE_ALL_MESSAGES = "__remove_all__";
function messagesStateReducer(left, right) {
  const leftArray = Array.isArray(left) ? left : [left];
  const rightArray = Array.isArray(right) ? right : [right];
  const leftMessages = leftArray.map(coerceMessageLikeToMessage);
  const rightMessages = rightArray.map(coerceMessageLikeToMessage);
  for (const m2 of leftMessages) {
    if (m2.id === null || m2.id === void 0) {
      m2.id = v4();
      m2.lc_kwargs.id = m2.id;
    }
  }
  let removeAllIdx;
  for (let i2 = 0; i2 < rightMessages.length; i2 += 1) {
    const m2 = rightMessages[i2];
    if (m2.id === null || m2.id === void 0) {
      m2.id = v4();
      m2.lc_kwargs.id = m2.id;
    }
    if (m2.getType() === "remove" && m2.id === REMOVE_ALL_MESSAGES) {
      removeAllIdx = i2;
    }
  }
  if (removeAllIdx != null)
    return rightMessages.slice(removeAllIdx + 1);
  const merged = [...leftMessages];
  const mergedById = new Map(merged.map((m2, i2) => [m2.id, i2]));
  const idsToRemove = /* @__PURE__ */ new Set();
  for (const m2 of rightMessages) {
    const existingIdx = mergedById.get(m2.id);
    if (existingIdx !== void 0) {
      if (m2.getType() === "remove") {
        idsToRemove.add(m2.id);
      } else {
        idsToRemove.delete(m2.id);
        merged[existingIdx] = m2;
      }
    } else {
      if (m2.getType() === "remove") {
        throw new Error(`Attempting to delete a message with an ID that doesn't exist ('${m2.id}')`);
      }
      mergedById.set(m2.id, merged.length);
      merged.push(m2);
    }
  }
  return merged.filter((m2) => !idsToRemove.has(m2.id));
}

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/managed/index.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/managed/is_last_step.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/managed/shared_value.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/func/index.js
init_esm();
var entrypoint = function entrypoint2(optionsOrName, func) {
  const { name, checkpointer, store: store6, cache: cache2 } = typeof optionsOrName === "string" ? { name: optionsOrName, checkpointer: void 0, store: void 0 } : optionsOrName;
  if (isAsyncGeneratorFunction(func) || isGeneratorFunction(func)) {
    throw new Error("Generators are disallowed as entrypoints. For streaming responses, use config.write.");
  }
  const streamMode = "updates";
  const bound = getRunnableForEntrypoint(name, func);
  function isEntrypointFinal(value) {
    return typeof value === "object" && value !== null && "__lg_type" in value && value.__lg_type === "__pregel_final";
  }
  const pluckReturnValue = new RunnableCallable({
    name: "pluckReturnValue",
    func: (value) => {
      return isEntrypointFinal(value) ? value.value : value;
    }
  });
  const pluckSaveValue = new RunnableCallable({
    name: "pluckSaveValue",
    func: (value) => {
      return isEntrypointFinal(value) ? value.save : value;
    }
  });
  const entrypointNode = new PregelNode({
    bound,
    triggers: [START],
    channels: [START],
    writers: [
      new ChannelWrite([
        { channel: END, value: PASSTHROUGH, mapper: pluckReturnValue },
        { channel: PREVIOUS, value: PASSTHROUGH, mapper: pluckSaveValue }
      ], [TAG_HIDDEN])
    ]
  });
  return new Pregel({
    name,
    checkpointer,
    nodes: {
      [name]: entrypointNode
    },
    channels: {
      [START]: new EphemeralValue(),
      [END]: new LastValue(),
      [PREVIOUS]: new LastValue()
    },
    inputChannels: START,
    outputChannels: END,
    streamChannels: END,
    streamMode,
    store: store6,
    cache: cache2
  });
};
entrypoint.final = function final({ value, save }) {
  return { value, save, __lg_type: "__pregel_final" };
};

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/graph/messages_annotation.js
init_esm();
var MessagesAnnotation = Annotation.Root({
  messages: Annotation({
    reducer: messagesStateReducer,
    default: () => []
  })
});
var MessagesZodState = z.object({
  messages: withLangGraph(z.custom(), {
    reducer: {
      schema: z.custom(),
      fn: messagesStateReducer
    },
    jsonSchemaExtra: {
      langgraph_type: "messages"
    },
    default: () => []
  })
});

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/interrupt.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+langgraph@0.3.1_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemet_cdb1d148cbed415c86f23df208f44a6e/node_modules/@langchain/langgraph/dist/index.js
initializeAsyncLocalStorageSingleton();

// ../agent/src/deepModeling.ts
var import_neverthrow5 = __toESM(require_index_cjs());

// ../agent/src/chat/workflow/constants.ts
init_esm();
var WORKFLOW_ERROR_MESSAGES = {
  EXECUTION_FAILED: "Workflow execution failed",
  ANSWER_GENERATION_FAILED: "Failed to generate answer",
  LANGGRAPH_FAILED: "LangGraph execution failed, falling back to error state"
};
var WORKFLOW_RETRY_CONFIG = {
  /**
   * Maximum number of retries for DDL execution failures
   * When DDL execution fails, the workflow will retry up to this many times
   * by going back to the designSchema node with the error information
   */
  MAX_DDL_EXECUTION_RETRIES: 1
};

// ../agent/src/chat/workflow/nodes/index.ts
init_esm();

// ../agent/src/chat/workflow/nodes/analyzeRequirementsNode.ts
init_esm();
var import_neverthrow3 = __toESM(require_index_cjs());

// ../agent/src/langchain/agents/index.ts
init_esm();

// ../agent/src/langchain/agents/databaseSchemaBuildAgent/index.ts
init_esm();

// ../agent/src/langchain/agents/databaseSchemaBuildAgent/agent.ts
init_esm();

// ../../../node_modules/.pnpm/@langchain+openai@0.5.15_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry_cd2a0fb140c3a0b3252024df0b963dca/node_modules/@langchain/openai/index.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+openai@0.5.15_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry_cd2a0fb140c3a0b3252024df0b963dca/node_modules/@langchain/openai/dist/index.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+openai@0.5.15_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry_cd2a0fb140c3a0b3252024df0b963dca/node_modules/@langchain/openai/dist/chat_models.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/outputs.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/utils/env.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/language_models/chat_models.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/language_models/base.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/output_parsers.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/output_parsers/openai_tools.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/output_parsers/openai_tools/index.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/dist/output_parsers/openai_tools/json_output_tools_parsers.js
init_esm();
function parseToolCall(rawToolCall, options) {
  if (rawToolCall.function === void 0) {
    return void 0;
  }
  let functionArgs;
  if (options?.partial) {
    try {
      functionArgs = parsePartialJson(rawToolCall.function.arguments ?? "{}");
    } catch (e2) {
      return void 0;
    }
  } else {
    try {
      functionArgs = JSON.parse(rawToolCall.function.arguments);
    } catch (e2) {
      throw new OutputParserException([
        `Function "${rawToolCall.function.name}" arguments:`,
        ``,
        rawToolCall.function.arguments,
        ``,
        `are not valid JSON.`,
        `Error: ${e2.message}`
      ].join("\n"));
    }
  }
  const parsedToolCall = {
    name: rawToolCall.function.name,
    args: functionArgs,
    type: "tool_call"
  };
  if (options?.returnId) {
    parsedToolCall.id = rawToolCall.id;
  }
  return parsedToolCall;
}
function convertLangChainToolCallToOpenAI(toolCall) {
  if (toolCall.id === void 0) {
    throw new Error(`All OpenAI tool calls must have an "id" field.`);
  }
  return {
    id: toolCall.id,
    type: "function",
    function: {
      name: toolCall.name,
      arguments: JSON.stringify(toolCall.args)
    }
  };
}
function makeInvalidToolCall(rawToolCall, errorMsg) {
  return {
    name: rawToolCall.function?.name,
    args: rawToolCall.function?.arguments,
    id: rawToolCall.id,
    error: errorMsg,
    type: "invalid_tool_call"
  };
}
var JsonOutputToolsParser = class extends BaseCumulativeTransformOutputParser {
  static lc_name() {
    return "JsonOutputToolsParser";
  }
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "returnId", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain", "output_parsers", "openai_tools"]
    });
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    this.returnId = fields?.returnId ?? this.returnId;
  }
  _diff() {
    throw new Error("Not supported.");
  }
  async parse() {
    throw new Error("Not implemented.");
  }
  async parseResult(generations) {
    const result = await this.parsePartialResult(generations, false);
    return result;
  }
  /**
   * Parses the output and returns a JSON object. If `argsOnly` is true,
   * only the arguments of the function call are returned.
   * @param generations The output of the LLM to parse.
   * @returns A JSON object representation of the function call or its arguments.
   */
  async parsePartialResult(generations, partial = true) {
    const message = generations[0].message;
    let toolCalls;
    if (isAIMessage(message) && message.tool_calls?.length) {
      toolCalls = message.tool_calls.map((toolCall) => {
        const { id, ...rest } = toolCall;
        if (!this.returnId) {
          return rest;
        }
        return {
          id,
          ...rest
        };
      });
    } else if (message.additional_kwargs.tool_calls !== void 0) {
      const rawToolCalls = JSON.parse(JSON.stringify(message.additional_kwargs.tool_calls));
      toolCalls = rawToolCalls.map((rawToolCall) => {
        return parseToolCall(rawToolCall, { returnId: this.returnId, partial });
      });
    }
    if (!toolCalls) {
      return [];
    }
    const parsedToolCalls = [];
    for (const toolCall of toolCalls) {
      if (toolCall !== void 0) {
        const backwardsCompatibleToolCall = {
          type: toolCall.name,
          args: toolCall.args,
          id: toolCall.id
        };
        parsedToolCalls.push(backwardsCompatibleToolCall);
      }
    }
    return parsedToolCalls;
  }
};
var JsonOutputKeyToolsParser = class extends JsonOutputToolsParser {
  static lc_name() {
    return "JsonOutputKeyToolsParser";
  }
  constructor(params) {
    super(params);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain", "output_parsers", "openai_tools"]
    });
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "returnId", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    Object.defineProperty(this, "keyName", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "returnSingle", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    Object.defineProperty(this, "zodSchema", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.keyName = params.keyName;
    this.returnSingle = params.returnSingle ?? this.returnSingle;
    this.zodSchema = params.zodSchema;
  }
  async _validateResult(result) {
    if (this.zodSchema === void 0) {
      return result;
    }
    const zodParsedResult = await interopSafeParseAsync(this.zodSchema, result);
    if (zodParsedResult.success) {
      return zodParsedResult.data;
    } else {
      throw new OutputParserException(`Failed to parse. Text: "${JSON.stringify(result, null, 2)}". Error: ${JSON.stringify(zodParsedResult.error?.issues)}`, JSON.stringify(result, null, 2));
    }
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  async parsePartialResult(generations) {
    const results = await super.parsePartialResult(generations);
    const matchingResults = results.filter((result) => result.type === this.keyName);
    let returnedValues = matchingResults;
    if (!matchingResults.length) {
      return void 0;
    }
    if (!this.returnId) {
      returnedValues = matchingResults.map((result) => result.args);
    }
    if (this.returnSingle) {
      return returnedValues[0];
    }
    return returnedValues;
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  async parseResult(generations) {
    const results = await super.parsePartialResult(generations, false);
    const matchingResults = results.filter((result) => result.type === this.keyName);
    let returnedValues = matchingResults;
    if (!matchingResults.length) {
      return void 0;
    }
    if (!this.returnId) {
      returnedValues = matchingResults.map((result) => result.args);
    }
    if (this.returnSingle) {
      return this._validateResult(returnedValues[0]);
    }
    const toolCallResults = await Promise.all(returnedValues.map((value) => this._validateResult(value)));
    return toolCallResults;
  }
};

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/utils/types.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/utils/json_schema.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+openai@0.5.15_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry_cd2a0fb140c3a0b3252024df0b963dca/node_modules/@langchain/openai/dist/utils/azure.js
init_esm();
function getEndpoint(config) {
  const { azureOpenAIApiDeploymentName, azureOpenAIApiInstanceName, azureOpenAIApiKey, azureOpenAIBasePath, baseURL, azureADTokenProvider, azureOpenAIEndpoint } = config;
  if ((azureOpenAIApiKey || azureADTokenProvider) && azureOpenAIBasePath && azureOpenAIApiDeploymentName) {
    return `${azureOpenAIBasePath}/${azureOpenAIApiDeploymentName}`;
  }
  if ((azureOpenAIApiKey || azureADTokenProvider) && azureOpenAIEndpoint && azureOpenAIApiDeploymentName) {
    return `${azureOpenAIEndpoint}/openai/deployments/${azureOpenAIApiDeploymentName}`;
  }
  if (azureOpenAIApiKey || azureADTokenProvider) {
    if (!azureOpenAIApiInstanceName) {
      throw new Error("azureOpenAIApiInstanceName is required when using azureOpenAIApiKey");
    }
    if (!azureOpenAIApiDeploymentName) {
      throw new Error("azureOpenAIApiDeploymentName is a required parameter when using azureOpenAIApiKey");
    }
    return `https://${azureOpenAIApiInstanceName}.openai.azure.com/openai/deployments/${azureOpenAIApiDeploymentName}`;
  }
  return baseURL;
}

// ../../../node_modules/.pnpm/@langchain+openai@0.5.15_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry_cd2a0fb140c3a0b3252024df0b963dca/node_modules/@langchain/openai/dist/utils/openai.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/utils/function_calling.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+openai@0.5.15_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry_cd2a0fb140c3a0b3252024df0b963dca/node_modules/@langchain/openai/dist/utils/errors.js
init_esm();
function addLangChainErrorFields2(error, lc_error_code) {
  error.lc_error_code = lc_error_code;
  error.message = `${error.message}

Troubleshooting URL: https://js.langchain.com/docs/troubleshooting/errors/${lc_error_code}/
`;
  return error;
}

// ../../../node_modules/.pnpm/@langchain+openai@0.5.15_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry_cd2a0fb140c3a0b3252024df0b963dca/node_modules/@langchain/openai/dist/utils/openai.js
function wrapOpenAIClientError(e2) {
  let error;
  if (e2.constructor.name === APIConnectionTimeoutError.name) {
    error = new Error(e2.message);
    error.name = "TimeoutError";
  } else if (e2.constructor.name === APIUserAbortError.name) {
    error = new Error(e2.message);
    error.name = "AbortError";
  } else if (e2.status === 400 && e2.message.includes("tool_calls")) {
    error = addLangChainErrorFields2(e2, "INVALID_TOOL_RESULTS");
  } else if (e2.status === 401) {
    error = addLangChainErrorFields2(e2, "MODEL_AUTHENTICATION");
  } else if (e2.status === 429) {
    error = addLangChainErrorFields2(e2, "MODEL_RATE_LIMIT");
  } else if (e2.status === 404) {
    error = addLangChainErrorFields2(e2, "MODEL_NOT_FOUND");
  } else {
    error = e2;
  }
  return error;
}
function formatToOpenAIToolChoice(toolChoice) {
  if (!toolChoice) {
    return void 0;
  } else if (toolChoice === "any" || toolChoice === "required") {
    return "required";
  } else if (toolChoice === "auto") {
    return "auto";
  } else if (toolChoice === "none") {
    return "none";
  } else if (typeof toolChoice === "string") {
    return {
      type: "function",
      function: {
        name: toolChoice
      }
    };
  } else {
    return toolChoice;
  }
}

// ../../../node_modules/.pnpm/@langchain+openai@0.5.15_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry_cd2a0fb140c3a0b3252024df0b963dca/node_modules/@langchain/openai/dist/utils/openai-format-fndef.js
init_esm();
function isAnyOfProp(prop) {
  return prop.anyOf !== void 0 && Array.isArray(prop.anyOf);
}
function formatFunctionDefinitions(functions) {
  const lines = ["namespace functions {", ""];
  for (const f of functions) {
    if (f.description) {
      lines.push(`// ${f.description}`);
    }
    if (Object.keys(f.parameters.properties ?? {}).length > 0) {
      lines.push(`type ${f.name} = (_: {`);
      lines.push(formatObjectProperties(f.parameters, 0));
      lines.push("}) => any;");
    } else {
      lines.push(`type ${f.name} = () => any;`);
    }
    lines.push("");
  }
  lines.push("} // namespace functions");
  return lines.join("\n");
}
function formatObjectProperties(obj, indent) {
  const lines = [];
  for (const [name, param] of Object.entries(obj.properties ?? {})) {
    if (param.description && indent < 2) {
      lines.push(`// ${param.description}`);
    }
    if (obj.required?.includes(name)) {
      lines.push(`${name}: ${formatType(param, indent)},`);
    } else {
      lines.push(`${name}?: ${formatType(param, indent)},`);
    }
  }
  return lines.map((line) => " ".repeat(indent) + line).join("\n");
}
function formatType(param, indent) {
  if (isAnyOfProp(param)) {
    return param.anyOf.map((v2) => formatType(v2, indent)).join(" | ");
  }
  switch (param.type) {
    case "string":
      if (param.enum) {
        return param.enum.map((v2) => `"${v2}"`).join(" | ");
      }
      return "string";
    case "number":
      if (param.enum) {
        return param.enum.map((v2) => `${v2}`).join(" | ");
      }
      return "number";
    case "integer":
      if (param.enum) {
        return param.enum.map((v2) => `${v2}`).join(" | ");
      }
      return "number";
    case "boolean":
      return "boolean";
    case "null":
      return "null";
    case "object":
      return ["{", formatObjectProperties(param, indent + 2), "}"].join("\n");
    case "array":
      if (param.items) {
        return `${formatType(param.items, indent)}[]`;
      }
      return "any[]";
    default:
      return "";
  }
}

// ../../../node_modules/.pnpm/@langchain+openai@0.5.15_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry_cd2a0fb140c3a0b3252024df0b963dca/node_modules/@langchain/openai/dist/utils/tools.js
init_esm();
function _convertToOpenAITool(tool2, fields) {
  let toolDef;
  if (isLangChainTool(tool2)) {
    toolDef = convertToOpenAITool(tool2);
  } else {
    toolDef = tool2;
  }
  if (fields?.strict !== void 0) {
    toolDef.function.strict = fields.strict;
  }
  return toolDef;
}

// ../../../node_modules/.pnpm/@langchain+openai@0.5.15_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry_cd2a0fb140c3a0b3252024df0b963dca/node_modules/@langchain/openai/dist/chat_models.js
function extractGenericMessageCustomRole(message) {
  if (message.role !== "system" && message.role !== "developer" && message.role !== "assistant" && message.role !== "user" && message.role !== "function" && message.role !== "tool") {
    console.warn(`Unknown message role: ${message.role}`);
  }
  return message.role;
}
function messageToOpenAIRole(message) {
  const type = message._getType();
  switch (type) {
    case "system":
      return "system";
    case "ai":
      return "assistant";
    case "human":
      return "user";
    case "function":
      return "function";
    case "tool":
      return "tool";
    case "generic": {
      if (!ChatMessage.isInstance(message))
        throw new Error("Invalid generic chat message");
      return extractGenericMessageCustomRole(message);
    }
    default:
      throw new Error(`Unknown message type: ${type}`);
  }
}
var completionsApiContentBlockConverter = {
  providerName: "ChatOpenAI",
  fromStandardTextBlock(block) {
    return { type: "text", text: block.text };
  },
  fromStandardImageBlock(block) {
    if (block.source_type === "url") {
      return {
        type: "image_url",
        image_url: {
          url: block.url,
          ...block.metadata?.detail ? { detail: block.metadata.detail } : {}
        }
      };
    }
    if (block.source_type === "base64") {
      const url = `data:${block.mime_type ?? ""};base64,${block.data}`;
      return {
        type: "image_url",
        image_url: {
          url,
          ...block.metadata?.detail ? { detail: block.metadata.detail } : {}
        }
      };
    }
    throw new Error(`Image content blocks with source_type ${block.source_type} are not supported for ChatOpenAI`);
  },
  fromStandardAudioBlock(block) {
    if (block.source_type === "url") {
      const data = parseBase64DataUrl({ dataUrl: block.url });
      if (!data) {
        throw new Error(`URL audio blocks with source_type ${block.source_type} must be formatted as a data URL for ChatOpenAI`);
      }
      const rawMimeType = data.mime_type || block.mime_type || "";
      let mimeType;
      try {
        mimeType = parseMimeType(rawMimeType);
      } catch {
        throw new Error(`Audio blocks with source_type ${block.source_type} must have mime type of audio/wav or audio/mp3`);
      }
      if (mimeType.type !== "audio" || mimeType.subtype !== "wav" && mimeType.subtype !== "mp3") {
        throw new Error(`Audio blocks with source_type ${block.source_type} must have mime type of audio/wav or audio/mp3`);
      }
      return {
        type: "input_audio",
        input_audio: {
          format: mimeType.subtype,
          data: data.data
        }
      };
    }
    if (block.source_type === "base64") {
      let mimeType;
      try {
        mimeType = parseMimeType(block.mime_type ?? "");
      } catch {
        throw new Error(`Audio blocks with source_type ${block.source_type} must have mime type of audio/wav or audio/mp3`);
      }
      if (mimeType.type !== "audio" || mimeType.subtype !== "wav" && mimeType.subtype !== "mp3") {
        throw new Error(`Audio blocks with source_type ${block.source_type} must have mime type of audio/wav or audio/mp3`);
      }
      return {
        type: "input_audio",
        input_audio: {
          format: mimeType.subtype,
          data: block.data
        }
      };
    }
    throw new Error(`Audio content blocks with source_type ${block.source_type} are not supported for ChatOpenAI`);
  },
  fromStandardFileBlock(block) {
    if (block.source_type === "url") {
      const data = parseBase64DataUrl({ dataUrl: block.url });
      if (!data) {
        throw new Error(`URL file blocks with source_type ${block.source_type} must be formatted as a data URL for ChatOpenAI`);
      }
      return {
        type: "file",
        file: {
          file_data: block.url,
          // formatted as base64 data URL
          ...block.metadata?.filename || block.metadata?.name ? {
            filename: block.metadata?.filename || block.metadata?.name
          } : {}
        }
      };
    }
    if (block.source_type === "base64") {
      return {
        type: "file",
        file: {
          file_data: `data:${block.mime_type ?? ""};base64,${block.data}`,
          ...block.metadata?.filename || block.metadata?.name || block.metadata?.title ? {
            filename: block.metadata?.filename || block.metadata?.name || block.metadata?.title
          } : {}
        }
      };
    }
    if (block.source_type === "id") {
      return {
        type: "file",
        file: {
          file_id: block.id
        }
      };
    }
    throw new Error(`File content blocks with source_type ${block.source_type} are not supported for ChatOpenAI`);
  }
};
function _convertMessagesToOpenAIParams(messages, model) {
  return messages.flatMap((message) => {
    let role = messageToOpenAIRole(message);
    if (role === "system" && isReasoningModel(model)) {
      role = "developer";
    }
    const content = typeof message.content === "string" ? message.content : message.content.map((m2) => {
      if (isDataContentBlock(m2)) {
        return convertToProviderContentBlock(m2, completionsApiContentBlockConverter);
      }
      return m2;
    });
    const completionParam = {
      role,
      content
    };
    if (message.name != null) {
      completionParam.name = message.name;
    }
    if (message.additional_kwargs.function_call != null) {
      completionParam.function_call = message.additional_kwargs.function_call;
      completionParam.content = "";
    }
    if (isAIMessage(message) && !!message.tool_calls?.length) {
      completionParam.tool_calls = message.tool_calls.map(convertLangChainToolCallToOpenAI);
      completionParam.content = "";
    } else {
      if (message.additional_kwargs.tool_calls != null) {
        completionParam.tool_calls = message.additional_kwargs.tool_calls;
      }
      if (message.tool_call_id != null) {
        completionParam.tool_call_id = message.tool_call_id;
      }
    }
    if (message.additional_kwargs.audio && typeof message.additional_kwargs.audio === "object" && "id" in message.additional_kwargs.audio) {
      const audioMessage = {
        role: "assistant",
        audio: {
          id: message.additional_kwargs.audio.id
        }
      };
      return [completionParam, audioMessage];
    }
    return completionParam;
  });
}
var _FUNCTION_CALL_IDS_MAP_KEY = "__openai_function_call_ids__";
function _convertReasoningSummaryToOpenAIResponsesParams(reasoning) {
  const summary = (reasoning.summary.length > 1 ? reasoning.summary.reduce((acc, curr) => {
    const last = acc.at(-1);
    if (last.index === curr.index) {
      last.text += curr.text;
    } else {
      acc.push(curr);
    }
    return acc;
  }, [{ ...reasoning.summary[0] }]) : reasoning.summary).map((s2) => Object.fromEntries(Object.entries(s2).filter(([k2]) => k2 !== "index")));
  return {
    ...reasoning,
    summary
  };
}
function _convertMessagesToOpenAIResponsesParams(messages, model, zdrEnabled) {
  return messages.flatMap((lcMsg) => {
    const additional_kwargs = lcMsg.additional_kwargs;
    let role = messageToOpenAIRole(lcMsg);
    if (role === "system" && isReasoningModel(model))
      role = "developer";
    if (role === "function") {
      throw new Error("Function messages are not supported in Responses API");
    }
    if (role === "tool") {
      const toolMessage = lcMsg;
      if (additional_kwargs?.type === "computer_call_output") {
        const output = (() => {
          if (typeof toolMessage.content === "string") {
            return {
              type: "computer_screenshot",
              image_url: toolMessage.content
            };
          }
          if (Array.isArray(toolMessage.content)) {
            const oaiScreenshot = toolMessage.content.find((i2) => i2.type === "computer_screenshot");
            if (oaiScreenshot)
              return oaiScreenshot;
            const lcImage = toolMessage.content.find((i2) => i2.type === "image_url");
            if (lcImage) {
              return {
                type: "computer_screenshot",
                image_url: typeof lcImage.image_url === "string" ? lcImage.image_url : lcImage.image_url.url
              };
            }
          }
          throw new Error("Invalid computer call output");
        })();
        return {
          type: "computer_call_output",
          output,
          call_id: toolMessage.tool_call_id
        };
      }
      return {
        type: "function_call_output",
        call_id: toolMessage.tool_call_id,
        id: toolMessage.id?.startsWith("fc_") ? toolMessage.id : void 0,
        output: typeof toolMessage.content !== "string" ? JSON.stringify(toolMessage.content) : toolMessage.content
      };
    }
    if (role === "assistant") {
      if (!zdrEnabled && lcMsg.response_metadata.output != null && Array.isArray(lcMsg.response_metadata.output) && lcMsg.response_metadata.output.length > 0 && lcMsg.response_metadata.output.every((item) => "type" in item)) {
        return lcMsg.response_metadata.output;
      }
      const input = [];
      if (additional_kwargs?.reasoning && !zdrEnabled) {
        const reasoningItem = _convertReasoningSummaryToOpenAIResponsesParams(additional_kwargs.reasoning);
        input.push(reasoningItem);
      }
      let { content } = lcMsg;
      if (additional_kwargs?.refusal) {
        if (typeof content === "string") {
          content = [{ type: "output_text", text: content, annotations: [] }];
        }
        content = [
          ...content,
          { type: "refusal", refusal: additional_kwargs.refusal }
        ];
      }
      input.push({
        type: "message",
        role: "assistant",
        ...lcMsg.id && !zdrEnabled ? { id: lcMsg.id } : {},
        content: typeof content === "string" ? content : content.flatMap((item) => {
          if (item.type === "text") {
            return {
              type: "output_text",
              text: item.text,
              // @ts-expect-error TODO: add types for `annotations`
              annotations: item.annotations ?? []
            };
          }
          if (item.type === "output_text" || item.type === "refusal") {
            return item;
          }
          return [];
        })
      });
      const functionCallIds = additional_kwargs?.[_FUNCTION_CALL_IDS_MAP_KEY];
      if (isAIMessage(lcMsg) && !!lcMsg.tool_calls?.length) {
        input.push(...lcMsg.tool_calls.map((toolCall) => ({
          type: "function_call",
          name: toolCall.name,
          arguments: JSON.stringify(toolCall.args),
          call_id: toolCall.id,
          ...zdrEnabled ? { id: functionCallIds?.[toolCall.id] } : {}
        })));
      } else if (additional_kwargs?.tool_calls) {
        input.push(...additional_kwargs.tool_calls.map((toolCall) => ({
          type: "function_call",
          name: toolCall.function.name,
          call_id: toolCall.id,
          arguments: toolCall.function.arguments,
          ...zdrEnabled ? { id: functionCallIds?.[toolCall.id] } : {}
        })));
      }
      const toolOutputs = lcMsg.response_metadata.output?.length ? lcMsg.response_metadata.output : additional_kwargs.tool_outputs;
      const fallthroughCallTypes = [
        "computer_call",
        "mcp_call",
        "code_interpreter_call",
        "image_generation_call"
      ];
      if (toolOutputs != null) {
        const castToolOutputs = toolOutputs;
        const fallthroughCalls = castToolOutputs?.filter((item) => fallthroughCallTypes.includes(item.type));
        if (fallthroughCalls.length > 0)
          input.push(...fallthroughCalls);
      }
      return input;
    }
    if (role === "user" || role === "system" || role === "developer") {
      if (typeof lcMsg.content === "string") {
        return { type: "message", role, content: lcMsg.content };
      }
      const messages2 = [];
      const content = lcMsg.content.flatMap((item) => {
        if (item.type === "mcp_approval_response") {
          messages2.push({
            type: "mcp_approval_response",
            approval_request_id: item.approval_request_id,
            approve: item.approve
          });
        }
        if (isDataContentBlock(item)) {
          return convertToProviderContentBlock(item, completionsApiContentBlockConverter);
        }
        if (item.type === "text") {
          return {
            type: "input_text",
            text: item.text
          };
        }
        if (item.type === "image_url") {
          return {
            type: "input_image",
            image_url: typeof item.image_url === "string" ? item.image_url : item.image_url.url,
            detail: typeof item.image_url === "string" ? "auto" : item.image_url.detail
          };
        }
        if (item.type === "input_text" || item.type === "input_image" || item.type === "input_file") {
          return item;
        }
        return [];
      });
      if (content.length > 0) {
        messages2.push({ type: "message", role, content });
      }
      return messages2;
    }
    console.warn(`Unsupported role found when converting to OpenAI Responses API: ${role}`);
    return [];
  });
}
function _convertOpenAIResponsesMessageToBaseMessage(response) {
  if (response.error) {
    const error = new Error(response.error.message);
    error.name = response.error.code;
    throw error;
  }
  let messageId;
  const content = [];
  const tool_calls = [];
  const invalid_tool_calls = [];
  const response_metadata = {
    model: response.model,
    created_at: response.created_at,
    id: response.id,
    incomplete_details: response.incomplete_details,
    metadata: response.metadata,
    object: response.object,
    status: response.status,
    user: response.user,
    // for compatibility with chat completion calls.
    model_name: response.model
  };
  const additional_kwargs = {};
  for (const item of response.output) {
    if (item.type === "message") {
      messageId = item.id;
      content.push(...item.content.flatMap((part) => {
        if (part.type === "output_text") {
          if ("parsed" in part && part.parsed != null) {
            additional_kwargs.parsed = part.parsed;
          }
          return {
            type: "text",
            text: part.text,
            annotations: part.annotations
          };
        }
        if (part.type === "refusal") {
          additional_kwargs.refusal = part.refusal;
          return [];
        }
        return part;
      }));
    } else if (item.type === "function_call") {
      const fnAdapter = {
        function: { name: item.name, arguments: item.arguments },
        id: item.call_id
      };
      try {
        tool_calls.push(parseToolCall(fnAdapter, { returnId: true }));
      } catch (e2) {
        let errMessage;
        if (typeof e2 === "object" && e2 != null && "message" in e2 && typeof e2.message === "string") {
          errMessage = e2.message;
        }
        invalid_tool_calls.push(makeInvalidToolCall(fnAdapter, errMessage));
      }
      additional_kwargs[_FUNCTION_CALL_IDS_MAP_KEY] ??= {};
      if (item.id) {
        additional_kwargs[_FUNCTION_CALL_IDS_MAP_KEY][item.call_id] = item.id;
      }
    } else if (item.type === "reasoning") {
      additional_kwargs.reasoning = item;
    } else {
      additional_kwargs.tool_outputs ??= [];
      additional_kwargs.tool_outputs.push(item);
    }
  }
  return new AIMessage({
    id: messageId,
    content,
    tool_calls,
    invalid_tool_calls,
    usage_metadata: response.usage,
    additional_kwargs,
    response_metadata
  });
}
function _convertOpenAIResponsesDeltaToBaseMessageChunk(chunk) {
  const content = [];
  let generationInfo = {};
  let usage_metadata;
  const tool_call_chunks = [];
  const response_metadata = {};
  const additional_kwargs = {};
  let id;
  if (chunk.type === "response.output_text.delta") {
    content.push({
      type: "text",
      text: chunk.delta,
      index: chunk.content_index
    });
  } else if (chunk.type === "response.output_text_annotation.added") {
    content.push({
      type: "text",
      text: "",
      annotations: [chunk.annotation],
      index: chunk.content_index
    });
  } else if (chunk.type === "response.output_item.added" && chunk.item.type === "message") {
    id = chunk.item.id;
  } else if (chunk.type === "response.output_item.added" && chunk.item.type === "function_call") {
    tool_call_chunks.push({
      type: "tool_call_chunk",
      name: chunk.item.name,
      args: chunk.item.arguments,
      id: chunk.item.call_id,
      index: chunk.output_index
    });
    additional_kwargs[_FUNCTION_CALL_IDS_MAP_KEY] = {
      [chunk.item.call_id]: chunk.item.id
    };
  } else if (chunk.type === "response.output_item.done" && [
    "web_search_call",
    "file_search_call",
    "computer_call",
    "code_interpreter_call",
    "mcp_call",
    "mcp_list_tools",
    "mcp_approval_request",
    "image_generation_call"
  ].includes(chunk.item.type)) {
    additional_kwargs.tool_outputs = [chunk.item];
  } else if (chunk.type === "response.created") {
    response_metadata.id = chunk.response.id;
    response_metadata.model_name = chunk.response.model;
    response_metadata.model = chunk.response.model;
  } else if (chunk.type === "response.completed") {
    const msg = _convertOpenAIResponsesMessageToBaseMessage(chunk.response);
    usage_metadata = chunk.response.usage;
    if (chunk.response.text?.format?.type === "json_schema") {
      additional_kwargs.parsed ??= JSON.parse(msg.text);
    }
    for (const [key, value] of Object.entries(chunk.response)) {
      if (key !== "id")
        response_metadata[key] = value;
    }
  } else if (chunk.type === "response.function_call_arguments.delta") {
    tool_call_chunks.push({
      type: "tool_call_chunk",
      args: chunk.delta,
      index: chunk.output_index
    });
  } else if (chunk.type === "response.web_search_call.completed" || chunk.type === "response.file_search_call.completed") {
    generationInfo = {
      tool_outputs: {
        id: chunk.item_id,
        type: chunk.type.replace("response.", "").replace(".completed", ""),
        status: "completed"
      }
    };
  } else if (chunk.type === "response.refusal.done") {
    additional_kwargs.refusal = chunk.refusal;
  } else if (chunk.type === "response.output_item.added" && "item" in chunk && chunk.item.type === "reasoning") {
    const summary = chunk.item.summary ? chunk.item.summary.map((s2, index) => ({
      ...s2,
      index
    })) : void 0;
    additional_kwargs.reasoning = {
      // We only capture ID in the first chunk or else the concatenated result of all chunks will
      // have an ID field that is repeated once per chunk. There is special handling for the `type`
      // field that prevents this, however.
      id: chunk.item.id,
      type: chunk.item.type,
      ...summary ? { summary } : {}
    };
  } else if (chunk.type === "response.reasoning_summary_part.added") {
    additional_kwargs.reasoning = {
      type: "reasoning",
      summary: [{ ...chunk.part, index: chunk.summary_index }]
    };
  } else if (chunk.type === "response.reasoning_summary_text.delta") {
    additional_kwargs.reasoning = {
      type: "reasoning",
      summary: [
        { text: chunk.delta, type: "summary_text", index: chunk.summary_index }
      ]
    };
  } else if (chunk.type === "response.image_generation_call.partial_image") {
    return null;
  } else {
    return null;
  }
  return new ChatGenerationChunk({
    // Legacy reasons, `onLLMNewToken` should pulls this out
    text: content.map((part) => part.text).join(""),
    message: new AIMessageChunk({
      id,
      content,
      tool_call_chunks,
      usage_metadata,
      additional_kwargs,
      response_metadata
    }),
    generationInfo
  });
}
function isBuiltInTool(tool2) {
  return "type" in tool2 && tool2.type !== "function";
}
function isBuiltInToolChoice(tool_choice) {
  return tool_choice != null && typeof tool_choice === "object" && "type" in tool_choice && tool_choice.type !== "function";
}
function _reduceChatOpenAIToolsForResponses(tools, fields) {
  const reducedTools = [];
  for (const tool2 of tools) {
    if (isBuiltInTool(tool2)) {
      if (tool2.type === "image_generation" && fields?.stream) {
        tool2.partial_images = 1;
      }
      reducedTools.push(tool2);
    } else if (isOpenAITool(tool2)) {
      reducedTools.push({
        type: "function",
        name: tool2.function.name,
        parameters: tool2.function.parameters,
        description: tool2.function.description,
        strict: fields?.strict ?? null
      });
    }
  }
  return reducedTools;
}
function _convertChatOpenAIToolTypeToOpenAITool(tool2, fields) {
  if (isOpenAITool(tool2)) {
    if (fields?.strict !== void 0) {
      return {
        ...tool2,
        function: {
          ...tool2.function,
          strict: fields.strict
        }
      };
    }
    return tool2;
  }
  return _convertToOpenAITool(tool2, fields);
}
function isReasoningModel(model) {
  return model && /^o\d/.test(model);
}
var ChatOpenAI = class extends BaseChatModel {
  static lc_name() {
    return "ChatOpenAI";
  }
  get callKeys() {
    return [
      ...super.callKeys,
      "options",
      "function_call",
      "functions",
      "tools",
      "tool_choice",
      "promptIndex",
      "response_format",
      "seed",
      "reasoning_effort"
    ];
  }
  get lc_secrets() {
    return {
      openAIApiKey: "OPENAI_API_KEY",
      apiKey: "OPENAI_API_KEY",
      organization: "OPENAI_ORGANIZATION"
    };
  }
  get lc_aliases() {
    return {
      modelName: "model",
      openAIApiKey: "openai_api_key",
      apiKey: "openai_api_key"
    };
  }
  get lc_serializable_keys() {
    return [
      "configuration",
      "logprobs",
      "topLogprobs",
      "prefixMessages",
      "supportsStrictToolCalling",
      "modalities",
      "audio",
      "reasoningEffort",
      "temperature",
      "maxTokens",
      "topP",
      "frequencyPenalty",
      "presencePenalty",
      "n",
      "logitBias",
      "user",
      "streaming",
      "streamUsage",
      "modelName",
      "model",
      "modelKwargs",
      "stop",
      "stopSequences",
      "timeout",
      "openAIApiKey",
      "apiKey",
      "cache",
      "maxConcurrency",
      "maxRetries",
      "verbose",
      "callbacks",
      "tags",
      "metadata",
      "disableStreaming",
      "useResponsesApi",
      "zdrEnabled",
      "reasoning"
    ];
  }
  constructor(fields) {
    super(fields ?? {});
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "temperature", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "topP", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "frequencyPenalty", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "presencePenalty", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "n", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "logitBias", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "modelName", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "model", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "gpt-3.5-turbo"
    });
    Object.defineProperty(this, "modelKwargs", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "stop", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "stopSequences", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "user", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "timeout", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "streaming", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    Object.defineProperty(this, "streamUsage", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "maxTokens", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "logprobs", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "topLogprobs", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "openAIApiKey", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "apiKey", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "organization", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "__includeRawResponse", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "client", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "clientConfig", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "supportsStrictToolCalling", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "audio", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "modalities", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "reasoningEffort", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "reasoning", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "useResponsesApi", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    Object.defineProperty(this, "zdrEnabled", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.openAIApiKey = fields?.apiKey ?? fields?.openAIApiKey ?? fields?.configuration?.apiKey ?? getEnvironmentVariable("OPENAI_API_KEY");
    this.apiKey = this.openAIApiKey;
    this.organization = fields?.configuration?.organization ?? getEnvironmentVariable("OPENAI_ORGANIZATION");
    this.model = fields?.model ?? fields?.modelName ?? this.model;
    this.modelName = this.model;
    this.modelKwargs = fields?.modelKwargs ?? {};
    this.timeout = fields?.timeout;
    this.temperature = fields?.temperature ?? this.temperature;
    this.topP = fields?.topP ?? this.topP;
    this.frequencyPenalty = fields?.frequencyPenalty ?? this.frequencyPenalty;
    this.presencePenalty = fields?.presencePenalty ?? this.presencePenalty;
    this.logprobs = fields?.logprobs;
    this.topLogprobs = fields?.topLogprobs;
    this.n = fields?.n ?? this.n;
    this.logitBias = fields?.logitBias;
    this.stop = fields?.stopSequences ?? fields?.stop;
    this.stopSequences = this.stop;
    this.user = fields?.user;
    this.__includeRawResponse = fields?.__includeRawResponse;
    this.audio = fields?.audio;
    this.modalities = fields?.modalities;
    this.reasoningEffort = fields?.reasoningEffort ?? fields?.reasoning?.effort;
    this.reasoning = fields?.reasoning ?? (fields?.reasoningEffort ? { effort: fields.reasoningEffort } : void 0);
    this.maxTokens = fields?.maxCompletionTokens ?? fields?.maxTokens;
    this.useResponsesApi = fields?.useResponsesApi ?? this.useResponsesApi;
    this.disableStreaming = fields?.disableStreaming ?? this.disableStreaming;
    this.streaming = fields?.streaming ?? false;
    if (this.disableStreaming)
      this.streaming = false;
    this.streamUsage = fields?.streamUsage ?? this.streamUsage;
    if (this.disableStreaming)
      this.streamUsage = false;
    this.clientConfig = {
      apiKey: this.apiKey,
      organization: this.organization,
      dangerouslyAllowBrowser: true,
      ...fields?.configuration
    };
    if (fields?.supportsStrictToolCalling !== void 0) {
      this.supportsStrictToolCalling = fields.supportsStrictToolCalling;
    }
    this.zdrEnabled = fields?.zdrEnabled ?? false;
  }
  getLsParams(options) {
    const params = this.invocationParams(options);
    return {
      ls_provider: "openai",
      ls_model_name: this.model,
      ls_model_type: "chat",
      ls_temperature: params.temperature ?? void 0,
      ls_max_tokens: params.max_tokens ?? void 0,
      ls_stop: options.stop
    };
  }
  bindTools(tools, kwargs) {
    let strict;
    if (kwargs?.strict !== void 0) {
      strict = kwargs.strict;
    } else if (this.supportsStrictToolCalling !== void 0) {
      strict = this.supportsStrictToolCalling;
    }
    return this.withConfig({
      tools: tools.map((tool2) => isBuiltInTool(tool2) ? tool2 : _convertChatOpenAIToolTypeToOpenAITool(tool2, { strict })),
      ...kwargs
    });
  }
  createResponseFormat(resFormat) {
    if (resFormat && resFormat.type === "json_schema" && resFormat.json_schema.schema && isInteropZodSchema(resFormat.json_schema.schema)) {
      return interopZodResponseFormat(resFormat.json_schema.schema, resFormat.json_schema.name, {
        description: resFormat.json_schema.description
      });
    }
    return resFormat;
  }
  getReasoningParams(options) {
    if (!isReasoningModel(this.model)) {
      return;
    }
    let reasoning;
    if (this.reasoningEffort !== void 0) {
      reasoning = { effort: this.reasoningEffort };
    }
    if (this.reasoning !== void 0) {
      reasoning = {
        ...reasoning,
        ...this.reasoning
      };
    }
    if (options?.reasoning_effort !== void 0) {
      reasoning = {
        ...reasoning,
        effort: options.reasoning_effort
      };
    }
    if (options?.reasoning !== void 0) {
      reasoning = {
        ...reasoning,
        ...options.reasoning
      };
    }
    return reasoning;
  }
  /**
   * Get the parameters used to invoke the model
   */
  invocationParams(options, extra) {
    let strict;
    if (options?.strict !== void 0) {
      strict = options.strict;
    } else if (this.supportsStrictToolCalling !== void 0) {
      strict = this.supportsStrictToolCalling;
    }
    if (this._useResponseApi(options)) {
      const params2 = {
        model: this.model,
        temperature: this.temperature,
        top_p: this.topP,
        user: this.user,
        // if include_usage is set or streamUsage then stream must be set to true.
        stream: this.streaming,
        previous_response_id: options?.previous_response_id,
        truncation: options?.truncation,
        include: options?.include,
        tools: options?.tools?.length ? _reduceChatOpenAIToolsForResponses(options.tools, {
          stream: this.streaming,
          strict
        }) : void 0,
        tool_choice: isBuiltInToolChoice(options?.tool_choice) ? options?.tool_choice : (() => {
          const formatted = formatToOpenAIToolChoice(options?.tool_choice);
          if (typeof formatted === "object" && "type" in formatted) {
            return { type: "function", name: formatted.function.name };
          } else {
            return void 0;
          }
        })(),
        text: (() => {
          if (options?.text)
            return options.text;
          const format = this.createResponseFormat(options?.response_format);
          if (format?.type === "json_schema") {
            if (format.json_schema.schema != null) {
              return {
                format: {
                  type: "json_schema",
                  schema: format.json_schema.schema,
                  description: format.json_schema.description,
                  name: format.json_schema.name,
                  strict: format.json_schema.strict
                }
              };
            }
            return void 0;
          }
          return { format };
        })(),
        parallel_tool_calls: options?.parallel_tool_calls,
        max_output_tokens: this.maxTokens === -1 ? void 0 : this.maxTokens,
        ...this.zdrEnabled ? { store: false } : {},
        ...this.modelKwargs
      };
      const reasoning2 = this.getReasoningParams(options);
      if (reasoning2 !== void 0) {
        params2.reasoning = reasoning2;
      }
      return params2;
    }
    let streamOptionsConfig = {};
    if (options?.stream_options !== void 0) {
      streamOptionsConfig = { stream_options: options.stream_options };
    } else if (this.streamUsage && (this.streaming || extra?.streaming)) {
      streamOptionsConfig = { stream_options: { include_usage: true } };
    }
    const params = {
      model: this.model,
      temperature: this.temperature,
      top_p: this.topP,
      frequency_penalty: this.frequencyPenalty,
      presence_penalty: this.presencePenalty,
      logprobs: this.logprobs,
      top_logprobs: this.topLogprobs,
      n: this.n,
      logit_bias: this.logitBias,
      stop: options?.stop ?? this.stopSequences,
      user: this.user,
      // if include_usage is set or streamUsage then stream must be set to true.
      stream: this.streaming,
      functions: options?.functions,
      function_call: options?.function_call,
      tools: options?.tools?.length ? options.tools.map((tool2) => _convertChatOpenAIToolTypeToOpenAITool(tool2, { strict })) : void 0,
      tool_choice: formatToOpenAIToolChoice(options?.tool_choice),
      response_format: this.createResponseFormat(options?.response_format),
      seed: options?.seed,
      ...streamOptionsConfig,
      parallel_tool_calls: options?.parallel_tool_calls,
      ...this.audio || options?.audio ? { audio: this.audio || options?.audio } : {},
      ...this.modalities || options?.modalities ? { modalities: this.modalities || options?.modalities } : {},
      ...this.modelKwargs
    };
    if (options?.prediction !== void 0) {
      params.prediction = options.prediction;
    }
    const reasoning = this.getReasoningParams(options);
    if (reasoning !== void 0 && reasoning.effort !== void 0) {
      params.reasoning_effort = reasoning.effort;
    }
    if (isReasoningModel(params.model)) {
      params.max_completion_tokens = this.maxTokens === -1 ? void 0 : this.maxTokens;
    } else {
      params.max_tokens = this.maxTokens === -1 ? void 0 : this.maxTokens;
    }
    return params;
  }
  _convertOpenAIChatCompletionMessageToBaseMessage(message, rawResponse) {
    const rawToolCalls = message.tool_calls;
    switch (message.role) {
      case "assistant": {
        const toolCalls = [];
        const invalidToolCalls = [];
        for (const rawToolCall of rawToolCalls ?? []) {
          try {
            toolCalls.push(parseToolCall(rawToolCall, { returnId: true }));
          } catch (e2) {
            invalidToolCalls.push(makeInvalidToolCall(rawToolCall, e2.message));
          }
        }
        const additional_kwargs = {
          function_call: message.function_call,
          tool_calls: rawToolCalls
        };
        if (this.__includeRawResponse !== void 0) {
          additional_kwargs.__raw_response = rawResponse;
        }
        const response_metadata = {
          model_name: rawResponse.model,
          ...rawResponse.system_fingerprint ? {
            usage: { ...rawResponse.usage },
            system_fingerprint: rawResponse.system_fingerprint
          } : {}
        };
        if (message.audio) {
          additional_kwargs.audio = message.audio;
        }
        return new AIMessage({
          content: message.content || "",
          tool_calls: toolCalls,
          invalid_tool_calls: invalidToolCalls,
          additional_kwargs,
          response_metadata,
          id: rawResponse.id
        });
      }
      default:
        return new ChatMessage(message.content || "", message.role ?? "unknown");
    }
  }
  _convertOpenAIDeltaToBaseMessageChunk(delta, rawResponse, defaultRole) {
    const role = delta.role ?? defaultRole;
    const content = delta.content ?? "";
    let additional_kwargs;
    if (delta.function_call) {
      additional_kwargs = {
        function_call: delta.function_call
      };
    } else if (delta.tool_calls) {
      additional_kwargs = {
        tool_calls: delta.tool_calls
      };
    } else {
      additional_kwargs = {};
    }
    if (this.__includeRawResponse) {
      additional_kwargs.__raw_response = rawResponse;
    }
    if (delta.audio) {
      additional_kwargs.audio = {
        ...delta.audio,
        index: rawResponse.choices[0].index
      };
    }
    const response_metadata = { usage: { ...rawResponse.usage } };
    if (role === "user") {
      return new HumanMessageChunk({ content, response_metadata });
    } else if (role === "assistant") {
      const toolCallChunks = [];
      if (Array.isArray(delta.tool_calls)) {
        for (const rawToolCall of delta.tool_calls) {
          toolCallChunks.push({
            name: rawToolCall.function?.name,
            args: rawToolCall.function?.arguments,
            id: rawToolCall.id,
            index: rawToolCall.index,
            type: "tool_call_chunk"
          });
        }
      }
      return new AIMessageChunk({
        content,
        tool_call_chunks: toolCallChunks,
        additional_kwargs,
        id: rawResponse.id,
        response_metadata
      });
    } else if (role === "system") {
      return new SystemMessageChunk({ content, response_metadata });
    } else if (role === "developer") {
      return new SystemMessageChunk({
        content,
        response_metadata,
        additional_kwargs: {
          __openai_role__: "developer"
        }
      });
    } else if (role === "function") {
      return new FunctionMessageChunk({
        content,
        additional_kwargs,
        name: delta.name,
        response_metadata
      });
    } else if (role === "tool") {
      return new ToolMessageChunk({
        content,
        additional_kwargs,
        tool_call_id: delta.tool_call_id,
        response_metadata
      });
    } else {
      return new ChatMessageChunk({ content, role, response_metadata });
    }
  }
  /** @ignore */
  _identifyingParams() {
    return {
      model_name: this.model,
      ...this.invocationParams(),
      ...this.clientConfig
    };
  }
  async *_streamResponseChunks(messages, options, runManager) {
    if (this._useResponseApi(options)) {
      const streamIterable2 = await this.responseApiWithRetry({
        ...this.invocationParams(options, { streaming: true }),
        input: _convertMessagesToOpenAIResponsesParams(messages, this.model, this.zdrEnabled),
        stream: true
      }, options);
      for await (const data of streamIterable2) {
        const chunk = _convertOpenAIResponsesDeltaToBaseMessageChunk(data);
        if (chunk == null)
          continue;
        yield chunk;
      }
      return;
    }
    const messagesMapped = _convertMessagesToOpenAIParams(messages, this.model);
    const params = {
      ...this.invocationParams(options, {
        streaming: true
      }),
      messages: messagesMapped,
      stream: true
    };
    let defaultRole;
    const streamIterable = await this.completionWithRetry(params, options);
    let usage;
    for await (const data of streamIterable) {
      const choice = data?.choices?.[0];
      if (data.usage) {
        usage = data.usage;
      }
      if (!choice) {
        continue;
      }
      const { delta } = choice;
      if (!delta) {
        continue;
      }
      const chunk = this._convertOpenAIDeltaToBaseMessageChunk(delta, data, defaultRole);
      defaultRole = delta.role ?? defaultRole;
      const newTokenIndices = {
        prompt: options.promptIndex ?? 0,
        completion: choice.index ?? 0
      };
      if (typeof chunk.content !== "string") {
        console.log("[WARNING]: Received non-string content from OpenAI. This is currently not supported.");
        continue;
      }
      const generationInfo = { ...newTokenIndices };
      if (choice.finish_reason != null) {
        generationInfo.finish_reason = choice.finish_reason;
        generationInfo.system_fingerprint = data.system_fingerprint;
        generationInfo.model_name = data.model;
      }
      if (this.logprobs) {
        generationInfo.logprobs = choice.logprobs;
      }
      const generationChunk = new ChatGenerationChunk({
        message: chunk,
        text: chunk.content,
        generationInfo
      });
      yield generationChunk;
      await runManager?.handleLLMNewToken(generationChunk.text ?? "", newTokenIndices, void 0, void 0, void 0, { chunk: generationChunk });
    }
    if (usage) {
      const inputTokenDetails = {
        ...usage.prompt_tokens_details?.audio_tokens !== null && {
          audio: usage.prompt_tokens_details?.audio_tokens
        },
        ...usage.prompt_tokens_details?.cached_tokens !== null && {
          cache_read: usage.prompt_tokens_details?.cached_tokens
        }
      };
      const outputTokenDetails = {
        ...usage.completion_tokens_details?.audio_tokens !== null && {
          audio: usage.completion_tokens_details?.audio_tokens
        },
        ...usage.completion_tokens_details?.reasoning_tokens !== null && {
          reasoning: usage.completion_tokens_details?.reasoning_tokens
        }
      };
      const generationChunk = new ChatGenerationChunk({
        message: new AIMessageChunk({
          content: "",
          response_metadata: {
            usage: { ...usage }
          },
          usage_metadata: {
            input_tokens: usage.prompt_tokens,
            output_tokens: usage.completion_tokens,
            total_tokens: usage.total_tokens,
            ...Object.keys(inputTokenDetails).length > 0 && {
              input_token_details: inputTokenDetails
            },
            ...Object.keys(outputTokenDetails).length > 0 && {
              output_token_details: outputTokenDetails
            }
          }
        }),
        text: ""
      });
      yield generationChunk;
    }
    if (options.signal?.aborted) {
      throw new Error("AbortError");
    }
  }
  /**
   * Get the identifying parameters for the model
   *
   */
  identifyingParams() {
    return this._identifyingParams();
  }
  /** @ignore */
  async _responseApiGenerate(messages, options, runManager) {
    const invocationParams = this.invocationParams(options);
    if (invocationParams.stream) {
      const stream = this._streamResponseChunks(messages, options, runManager);
      let finalChunk;
      for await (const chunk of stream) {
        chunk.message.response_metadata = {
          ...chunk.generationInfo,
          ...chunk.message.response_metadata
        };
        finalChunk = finalChunk?.concat(chunk) ?? chunk;
      }
      return {
        generations: finalChunk ? [finalChunk] : [],
        llmOutput: {
          estimatedTokenUsage: finalChunk?.message?.usage_metadata
        }
      };
    }
    const input = _convertMessagesToOpenAIResponsesParams(messages, this.model, this.zdrEnabled);
    const data = await this.responseApiWithRetry({
      input,
      ...invocationParams
    }, { signal: options?.signal, ...options?.options });
    return {
      generations: [
        {
          text: data.output_text,
          message: _convertOpenAIResponsesMessageToBaseMessage(data)
        }
      ],
      llmOutput: {
        id: data.id,
        estimatedTokenUsage: data.usage ? {
          promptTokens: data.usage.input_tokens,
          completionTokens: data.usage.output_tokens,
          totalTokens: data.usage.total_tokens
        } : void 0
      }
    };
  }
  /**
   * Determines whether the responses API should be used for the given request.
   *
   * @internal
   *
   * @param options The parsed call options for the request.
   * @returns `true` if the responses API should be used, either because it is explicitly enabled,
   * or because the request requires it.
   */
  _useResponseApi(options) {
    const usesBuiltInTools = options?.tools?.some(isBuiltInTool);
    const hasResponsesOnlyKwargs = options?.previous_response_id != null || options?.text != null || options?.truncation != null || options?.include != null || options?.reasoning?.summary != null || this.reasoning?.summary != null;
    return this.useResponsesApi || usesBuiltInTools || hasResponsesOnlyKwargs;
  }
  /** @ignore */
  async _generate(messages, options, runManager) {
    if (this._useResponseApi(options)) {
      return this._responseApiGenerate(messages, options, runManager);
    }
    const usageMetadata = {};
    const params = this.invocationParams(options);
    const messagesMapped = _convertMessagesToOpenAIParams(messages, this.model);
    if (params.stream) {
      const stream = this._streamResponseChunks(messages, options, runManager);
      const finalChunks = {};
      for await (const chunk of stream) {
        chunk.message.response_metadata = {
          ...chunk.generationInfo,
          ...chunk.message.response_metadata
        };
        const index = chunk.generationInfo?.completion ?? 0;
        if (finalChunks[index] === void 0) {
          finalChunks[index] = chunk;
        } else {
          finalChunks[index] = finalChunks[index].concat(chunk);
        }
      }
      const generations = Object.entries(finalChunks).sort(([aKey], [bKey]) => parseInt(aKey, 10) - parseInt(bKey, 10)).map(([_2, value]) => value);
      const { functions, function_call } = this.invocationParams(options);
      const promptTokenUsage = await this.getEstimatedTokenCountFromPrompt(messages, functions, function_call);
      const completionTokenUsage = await this.getNumTokensFromGenerations(generations);
      usageMetadata.input_tokens = promptTokenUsage;
      usageMetadata.output_tokens = completionTokenUsage;
      usageMetadata.total_tokens = promptTokenUsage + completionTokenUsage;
      return {
        generations,
        llmOutput: {
          estimatedTokenUsage: {
            promptTokens: usageMetadata.input_tokens,
            completionTokens: usageMetadata.output_tokens,
            totalTokens: usageMetadata.total_tokens
          }
        }
      };
    } else {
      let data;
      if (options.response_format && options.response_format.type === "json_schema") {
        data = await this.betaParsedCompletionWithRetry({
          ...params,
          stream: false,
          messages: messagesMapped
        }, {
          signal: options?.signal,
          ...options?.options
        });
      } else {
        data = await this.completionWithRetry({
          ...params,
          stream: false,
          messages: messagesMapped
        }, {
          signal: options?.signal,
          ...options?.options
        });
      }
      const { completion_tokens: completionTokens, prompt_tokens: promptTokens, total_tokens: totalTokens, prompt_tokens_details: promptTokensDetails, completion_tokens_details: completionTokensDetails } = data?.usage ?? {};
      if (completionTokens) {
        usageMetadata.output_tokens = (usageMetadata.output_tokens ?? 0) + completionTokens;
      }
      if (promptTokens) {
        usageMetadata.input_tokens = (usageMetadata.input_tokens ?? 0) + promptTokens;
      }
      if (totalTokens) {
        usageMetadata.total_tokens = (usageMetadata.total_tokens ?? 0) + totalTokens;
      }
      if (promptTokensDetails?.audio_tokens !== null || promptTokensDetails?.cached_tokens !== null) {
        usageMetadata.input_token_details = {
          ...promptTokensDetails?.audio_tokens !== null && {
            audio: promptTokensDetails?.audio_tokens
          },
          ...promptTokensDetails?.cached_tokens !== null && {
            cache_read: promptTokensDetails?.cached_tokens
          }
        };
      }
      if (completionTokensDetails?.audio_tokens !== null || completionTokensDetails?.reasoning_tokens !== null) {
        usageMetadata.output_token_details = {
          ...completionTokensDetails?.audio_tokens !== null && {
            audio: completionTokensDetails?.audio_tokens
          },
          ...completionTokensDetails?.reasoning_tokens !== null && {
            reasoning: completionTokensDetails?.reasoning_tokens
          }
        };
      }
      const generations = [];
      for (const part of data?.choices ?? []) {
        const text = part.message?.content ?? "";
        const generation = {
          text,
          message: this._convertOpenAIChatCompletionMessageToBaseMessage(part.message ?? { role: "assistant" }, data)
        };
        generation.generationInfo = {
          ...part.finish_reason ? { finish_reason: part.finish_reason } : {},
          ...part.logprobs ? { logprobs: part.logprobs } : {}
        };
        if (isAIMessage(generation.message)) {
          generation.message.usage_metadata = usageMetadata;
        }
        generation.message = new AIMessage(Object.fromEntries(Object.entries(generation.message).filter(([key]) => !key.startsWith("lc_"))));
        generations.push(generation);
      }
      return {
        generations,
        llmOutput: {
          tokenUsage: {
            promptTokens: usageMetadata.input_tokens,
            completionTokens: usageMetadata.output_tokens,
            totalTokens: usageMetadata.total_tokens
          }
        }
      };
    }
  }
  /**
   * Estimate the number of tokens a prompt will use.
   * Modified from: https://github.com/hmarr/openai-chat-tokens/blob/main/src/index.ts
   */
  async getEstimatedTokenCountFromPrompt(messages, functions, function_call) {
    let tokens = (await this.getNumTokensFromMessages(messages)).totalCount;
    if (functions && function_call !== "auto") {
      const promptDefinitions = formatFunctionDefinitions(functions);
      tokens += await this.getNumTokens(promptDefinitions);
      tokens += 9;
    }
    if (functions && messages.find((m2) => m2._getType() === "system")) {
      tokens -= 4;
    }
    if (function_call === "none") {
      tokens += 1;
    } else if (typeof function_call === "object") {
      tokens += await this.getNumTokens(function_call.name) + 4;
    }
    return tokens;
  }
  /**
   * Estimate the number of tokens an array of generations have used.
   */
  async getNumTokensFromGenerations(generations) {
    const generationUsages = await Promise.all(generations.map(async (generation) => {
      if (generation.message.additional_kwargs?.function_call) {
        return (await this.getNumTokensFromMessages([generation.message])).countPerMessage[0];
      } else {
        return await this.getNumTokens(generation.message.content);
      }
    }));
    return generationUsages.reduce((a, b2) => a + b2, 0);
  }
  async getNumTokensFromMessages(messages) {
    let totalCount = 0;
    let tokensPerMessage = 0;
    let tokensPerName = 0;
    if (this.model === "gpt-3.5-turbo-0301") {
      tokensPerMessage = 4;
      tokensPerName = -1;
    } else {
      tokensPerMessage = 3;
      tokensPerName = 1;
    }
    const countPerMessage = await Promise.all(messages.map(async (message) => {
      const textCount = await this.getNumTokens(message.content);
      const roleCount = await this.getNumTokens(messageToOpenAIRole(message));
      const nameCount = message.name !== void 0 ? tokensPerName + await this.getNumTokens(message.name) : 0;
      let count = textCount + tokensPerMessage + roleCount + nameCount;
      const openAIMessage = message;
      if (openAIMessage._getType() === "function") {
        count -= 2;
      }
      if (openAIMessage.additional_kwargs?.function_call) {
        count += 3;
      }
      if (openAIMessage?.additional_kwargs.function_call?.name) {
        count += await this.getNumTokens(openAIMessage.additional_kwargs.function_call?.name);
      }
      if (openAIMessage.additional_kwargs.function_call?.arguments) {
        try {
          count += await this.getNumTokens(
            // Remove newlines and spaces
            JSON.stringify(JSON.parse(openAIMessage.additional_kwargs.function_call?.arguments))
          );
        } catch (error) {
          console.error("Error parsing function arguments", error, JSON.stringify(openAIMessage.additional_kwargs.function_call));
          count += await this.getNumTokens(openAIMessage.additional_kwargs.function_call?.arguments);
        }
      }
      totalCount += count;
      return count;
    }));
    totalCount += 3;
    return { totalCount, countPerMessage };
  }
  async completionWithRetry(request, options) {
    const requestOptions = this._getClientOptions(options);
    return this.caller.call(async () => {
      try {
        const res = await this.client.chat.completions.create(request, requestOptions);
        return res;
      } catch (e2) {
        const error = wrapOpenAIClientError(e2);
        throw error;
      }
    });
  }
  async responseApiWithRetry(request, options) {
    return this.caller.call(async () => {
      const requestOptions = this._getClientOptions(options);
      try {
        if (request.text?.format?.type === "json_schema" && !request.stream) {
          return await this.client.responses.parse(request, requestOptions);
        }
        return await this.client.responses.create(request, requestOptions);
      } catch (e2) {
        const error = wrapOpenAIClientError(e2);
        throw error;
      }
    });
  }
  /**
   * Call the beta chat completions parse endpoint. This should only be called if
   * response_format is set to "json_object".
   * @param {OpenAIClient.Chat.ChatCompletionCreateParamsNonStreaming} request
   * @param {OpenAICoreRequestOptions | undefined} options
   */
  async betaParsedCompletionWithRetry(request, options) {
    const requestOptions = this._getClientOptions(options);
    return this.caller.call(async () => {
      try {
        const res = await this.client.chat.completions.parse(request, requestOptions);
        return res;
      } catch (e2) {
        const error = wrapOpenAIClientError(e2);
        throw error;
      }
    });
  }
  _getClientOptions(options) {
    if (!this.client) {
      const openAIEndpointConfig = {
        baseURL: this.clientConfig.baseURL
      };
      const endpoint = getEndpoint(openAIEndpointConfig);
      const params = {
        ...this.clientConfig,
        baseURL: endpoint,
        timeout: this.timeout,
        maxRetries: 0
      };
      if (!params.baseURL) {
        delete params.baseURL;
      }
      this.client = new OpenAI(params);
    }
    const requestOptions = {
      ...this.clientConfig,
      ...options
    };
    return requestOptions;
  }
  _llmType() {
    return "openai";
  }
  /** @ignore */
  _combineLLMOutput(...llmOutputs) {
    return llmOutputs.reduce((acc, llmOutput) => {
      if (llmOutput && llmOutput.tokenUsage) {
        acc.tokenUsage.completionTokens += llmOutput.tokenUsage.completionTokens ?? 0;
        acc.tokenUsage.promptTokens += llmOutput.tokenUsage.promptTokens ?? 0;
        acc.tokenUsage.totalTokens += llmOutput.tokenUsage.totalTokens ?? 0;
      }
      return acc;
    }, {
      tokenUsage: {
        completionTokens: 0,
        promptTokens: 0,
        totalTokens: 0
      }
    });
  }
  withStructuredOutput(outputSchema, config) {
    let schema;
    let name;
    let method;
    let includeRaw;
    if (isStructuredOutputMethodParams(outputSchema)) {
      schema = outputSchema.schema;
      name = outputSchema.name;
      method = outputSchema.method;
      includeRaw = outputSchema.includeRaw;
    } else {
      schema = outputSchema;
      name = config?.name;
      method = config?.method;
      includeRaw = config?.includeRaw;
    }
    let llm;
    let outputParser;
    if (config?.strict !== void 0 && method === "jsonMode") {
      throw new Error("Argument `strict` is only supported for `method` = 'function_calling'");
    }
    if (!this.model.startsWith("gpt-3") && !this.model.startsWith("gpt-4-") && this.model !== "gpt-4") {
      if (method === void 0) {
        method = "jsonSchema";
      }
    } else if (method === "jsonSchema") {
      console.warn(`[WARNING]: JSON Schema is not supported for model "${this.model}". Falling back to tool calling.`);
    }
    if (method === "jsonMode") {
      let outputFormatSchema;
      if (isInteropZodSchema(schema)) {
        outputParser = StructuredOutputParser.fromZodSchema(schema);
        outputFormatSchema = toJsonSchema(schema);
      } else {
        outputParser = new JsonOutputParser();
      }
      llm = this.withConfig({
        response_format: { type: "json_object" },
        ls_structured_output_format: {
          kwargs: { method: "jsonMode" },
          schema: outputFormatSchema
        }
      });
    } else if (method === "jsonSchema") {
      llm = this.withConfig({
        response_format: {
          type: "json_schema",
          json_schema: {
            name: name ?? "extract",
            description: getSchemaDescription(schema),
            schema,
            strict: config?.strict
          }
        },
        ls_structured_output_format: {
          kwargs: { method: "jsonSchema" },
          schema: toJsonSchema(schema)
        }
      });
      if (isInteropZodSchema(schema)) {
        const altParser = StructuredOutputParser.fromZodSchema(schema);
        outputParser = RunnableLambda.from((aiMessage) => {
          if ("parsed" in aiMessage.additional_kwargs) {
            return aiMessage.additional_kwargs.parsed;
          }
          return altParser;
        });
      } else {
        outputParser = new JsonOutputParser();
      }
    } else {
      let functionName = name ?? "extract";
      if (isInteropZodSchema(schema)) {
        const asJsonSchema = toJsonSchema(schema);
        llm = this.withConfig({
          tools: [
            {
              type: "function",
              function: {
                name: functionName,
                description: asJsonSchema.description,
                parameters: asJsonSchema
              }
            }
          ],
          tool_choice: {
            type: "function",
            function: {
              name: functionName
            }
          },
          ls_structured_output_format: {
            kwargs: { method: "functionCalling" },
            schema: asJsonSchema
          },
          // Do not pass `strict` argument to OpenAI if `config.strict` is undefined
          ...config?.strict !== void 0 ? { strict: config.strict } : {}
        });
        outputParser = new JsonOutputKeyToolsParser({
          returnSingle: true,
          keyName: functionName,
          zodSchema: schema
        });
      } else {
        let openAIFunctionDefinition;
        if (typeof schema.name === "string" && typeof schema.parameters === "object" && schema.parameters != null) {
          openAIFunctionDefinition = schema;
          functionName = schema.name;
        } else {
          functionName = schema.title ?? functionName;
          openAIFunctionDefinition = {
            name: functionName,
            description: schema.description ?? "",
            parameters: schema
          };
        }
        llm = this.withConfig({
          tools: [
            {
              type: "function",
              function: openAIFunctionDefinition
            }
          ],
          tool_choice: {
            type: "function",
            function: {
              name: functionName
            }
          },
          ls_structured_output_format: {
            kwargs: { method: "functionCalling" },
            schema: toJsonSchema(schema)
          },
          // Do not pass `strict` argument to OpenAI if `config.strict` is undefined
          ...config?.strict !== void 0 ? { strict: config.strict } : {}
        });
        outputParser = new JsonOutputKeyToolsParser({
          returnSingle: true,
          keyName: functionName
        });
      }
    }
    if (!includeRaw) {
      return llm.pipe(outputParser);
    }
    const parserAssign = RunnablePassthrough.assign({
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      parsed: (input, config2) => outputParser.invoke(input.raw, config2)
    });
    const parserNone = RunnablePassthrough.assign({
      parsed: () => null
    });
    const parsedWithFallback = parserAssign.withFallbacks({
      fallbacks: [parserNone]
    });
    return RunnableSequence.from([{ raw: llm }, parsedWithFallback]);
  }
};
function isStructuredOutputMethodParams(x2) {
  return x2 !== void 0 && // eslint-disable-next-line @typescript-eslint/no-explicit-any
  typeof x2.schema === "object";
}
function makeParseableResponseFormat(response_format, parser) {
  const obj = { ...response_format };
  Object.defineProperties(obj, {
    $brand: {
      value: "auto-parseable-response-format",
      enumerable: false
    },
    $parseRaw: {
      value: parser,
      enumerable: false
    }
  });
  return obj;
}
function interopZodResponseFormat(zodSchema, name, props) {
  if (isZodSchemaV3(zodSchema)) {
    return zodResponseFormat(zodSchema, name, props);
  }
  if (isZodSchemaV4(zodSchema)) {
    return makeParseableResponseFormat({
      type: "json_schema",
      json_schema: {
        ...props,
        name,
        strict: true,
        schema: toJSONSchema(zodSchema, {
          cycles: "ref",
          // equivalent to nameStrategy: 'duplicate-ref'
          reused: "ref",
          // equivalent to $refStrategy: 'extract-to-root'
          override(ctx) {
            ctx.jsonSchema.title = name;
          }
          /// property equivalents from native `zodResponseFormat` fn
          // openaiStrictMode: true,
          // name,
          // nameStrategy: 'duplicate-ref',
          // $refStrategy: 'extract-to-root',
          // nullableStrategy: 'property',
        })
      }
    }, (content) => parse(zodSchema, JSON.parse(content)));
  }
  throw new Error("Unsupported schema response format");
}

// ../../../node_modules/.pnpm/@langchain+openai@0.5.15_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry_cd2a0fb140c3a0b3252024df0b963dca/node_modules/@langchain/openai/dist/azure/chat_models.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+openai@0.5.15_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry_cd2a0fb140c3a0b3252024df0b963dca/node_modules/@langchain/openai/dist/utils/headers.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+openai@0.5.15_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry_cd2a0fb140c3a0b3252024df0b963dca/node_modules/@langchain/openai/dist/llms.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/language_models/llms.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/utils/chunk_array.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+openai@0.5.15_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry_cd2a0fb140c3a0b3252024df0b963dca/node_modules/@langchain/openai/dist/azure/llms.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+openai@0.5.15_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry_cd2a0fb140c3a0b3252024df0b963dca/node_modules/@langchain/openai/dist/azure/embeddings.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+openai@0.5.15_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry_cd2a0fb140c3a0b3252024df0b963dca/node_modules/@langchain/openai/dist/embeddings.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/embeddings.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+openai@0.5.15_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry_cd2a0fb140c3a0b3252024df0b963dca/node_modules/@langchain/openai/dist/types.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+openai@0.5.15_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry_cd2a0fb140c3a0b3252024df0b963dca/node_modules/@langchain/openai/dist/tools/index.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+openai@0.5.15_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry_cd2a0fb140c3a0b3252024df0b963dca/node_modules/@langchain/openai/dist/tools/dalle.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/tools.js
init_esm();

// ../../../node_modules/.pnpm/@langchain+openai@0.5.15_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry_cd2a0fb140c3a0b3252024df0b963dca/node_modules/@langchain/openai/dist/tools/dalle.js
var DallEAPIWrapper = class extends Tool {
  static lc_name() {
    return "DallEAPIWrapper";
  }
  constructor(fields) {
    if (fields?.responseFormat !== void 0 && ["url", "b64_json"].includes(fields.responseFormat)) {
      fields.dallEResponseFormat = fields.responseFormat;
      fields.responseFormat = "content";
    }
    super(fields);
    Object.defineProperty(this, "name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "dalle_api_wrapper"
    });
    Object.defineProperty(this, "description", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "A wrapper around OpenAI DALL-E API. Useful for when you need to generate images from a text description. Input should be an image description."
    });
    Object.defineProperty(this, "client", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "model", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "dall-e-3"
    });
    Object.defineProperty(this, "style", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "vivid"
    });
    Object.defineProperty(this, "quality", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "standard"
    });
    Object.defineProperty(this, "n", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: 1
    });
    Object.defineProperty(this, "size", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "1024x1024"
    });
    Object.defineProperty(this, "dallEResponseFormat", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "url"
    });
    Object.defineProperty(this, "user", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    const openAIApiKey = fields?.apiKey ?? fields?.openAIApiKey ?? getEnvironmentVariable("OPENAI_API_KEY");
    const organization = fields?.organization ?? getEnvironmentVariable("OPENAI_ORGANIZATION");
    const clientConfig = {
      apiKey: openAIApiKey,
      organization,
      dangerouslyAllowBrowser: true,
      baseURL: fields?.baseUrl
    };
    this.client = new OpenAI(clientConfig);
    this.model = fields?.model ?? fields?.modelName ?? this.model;
    this.style = fields?.style ?? this.style;
    this.quality = fields?.quality ?? this.quality;
    this.n = fields?.n ?? this.n;
    this.size = fields?.size ?? this.size;
    this.dallEResponseFormat = fields?.dallEResponseFormat ?? this.dallEResponseFormat;
    this.user = fields?.user;
  }
  /**
   * Processes the API response if multiple images are generated.
   * Returns a list of MessageContentImageUrl objects. If the response
   * format is `url`, then the `image_url` field will contain the URL.
   * If it is `b64_json`, then the `image_url` field will contain an object
   * with a `url` field with the base64 encoded image.
   *
   * @param {OpenAIClient.Images.ImagesResponse[]} response The API response
   * @returns {MessageContentImageUrl[]}
   */
  processMultipleGeneratedUrls(response) {
    if (this.dallEResponseFormat === "url") {
      return response.flatMap((res) => {
        const imageUrlContent = res.data?.flatMap((item) => {
          if (!item.url)
            return [];
          return {
            type: "image_url",
            image_url: item.url
          };
        }).filter((item) => item !== void 0 && item.type === "image_url" && typeof item.image_url === "string" && item.image_url !== void 0) ?? [];
        return imageUrlContent;
      });
    } else {
      return response.flatMap((res) => {
        const b64Content = res.data?.flatMap((item) => {
          if (!item.b64_json)
            return [];
          return {
            type: "image_url",
            image_url: {
              url: item.b64_json
            }
          };
        }).filter((item) => item !== void 0 && item.type === "image_url" && typeof item.image_url === "object" && "url" in item.image_url && typeof item.image_url.url === "string" && item.image_url.url !== void 0) ?? [];
        return b64Content;
      });
    }
  }
  /** @ignore */
  async _call(input) {
    const generateImageFields = {
      model: this.model,
      prompt: input,
      n: 1,
      size: this.size,
      response_format: this.dallEResponseFormat,
      style: this.style,
      quality: this.quality,
      user: this.user
    };
    if (this.n > 1) {
      const results = await Promise.all(Array.from({ length: this.n }).map(() => this.client.images.generate(generateImageFields)));
      return this.processMultipleGeneratedUrls(results);
    }
    const response = await this.client.images.generate(generateImageFields);
    let data = "";
    if (this.dallEResponseFormat === "url") {
      [data] = response.data?.map((item) => item.url).filter((url) => url !== "undefined") ?? [];
    } else {
      [data] = response.data?.map((item) => item.b64_json).filter((b64_json) => b64_json !== "undefined") ?? [];
    }
    return data;
  }
};
Object.defineProperty(DallEAPIWrapper, "toolName", {
  enumerable: true,
  configurable: true,
  writable: true,
  value: "dalle_api_wrapper"
});

// ../../../node_modules/.pnpm/@langchain+openai@0.5.15_@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry_cd2a0fb140c3a0b3252024df0b963dca/node_modules/@langchain/openai/dist/utils/prompts.js
init_esm();

// ../../packages/db-structure/dist/index.js
init_esm();

// ../../packages/db-structure/dist/deparser/postgresql/index.js
init_esm();

// ../../packages/db-structure/dist/deparser/postgresql/operationDeparser.js
init_esm();

// ../../packages/db-structure/dist/operation/constants.js
init_esm();
var PATH_PATTERNS = {
  TABLE_BASE: /^\/tables\/([^/]+)$/,
  TABLE_NAME: /^\/tables\/([^/]+)\/name$/,
  TABLE_COMMENT: /^\/tables\/([^/]+)\/comment$/,
  COLUMN_BASE: /^\/tables\/([^/]+)\/columns\/([^/]+)$/,
  COLUMN_NAME: /^\/tables\/([^/]+)\/columns\/([^/]+)\/name$/,
  COLUMN_COMMENT: /^\/tables\/([^/]+)\/columns\/([^/]+)\/comment$/,
  COLUMN_DEFAULT: /^\/tables\/([^/]+)\/columns\/([^/]+)\/default$/,
  COLUMN_CHECK: /^\/tables\/([^/]+)\/columns\/([^/]+)\/check$/,
  COLUMN_NOT_NULL: /^\/tables\/([^/]+)\/columns\/([^/]+)\/notNull$/,
  INDEX_BASE: /^\/tables\/([^/]+)\/indexes\/([^/]+)$/,
  INDEX_NAME: /^\/tables\/([^/]+)\/indexes\/([^/]+)\/name$/,
  INDEX_UNIQUE: /^\/tables\/([^/]+)\/indexes\/([^/]+)\/unique$/,
  INDEX_COLUMNS: /^\/tables\/([^/]+)\/indexes\/([^/]+)\/columns$/,
  INDEX_TYPE: /^\/tables\/([^/]+)\/indexes\/([^/]+)\/type$/,
  CONSTRAINT_BASE: /^\/tables\/([^/]+)\/constraints\/([^/]+)$/,
  CONSTRAINT_NAME: /^\/tables\/([^/]+)\/constraints\/([^/]+)\/name$/,
  CONSTRAINT_TYPE: /^\/tables\/([^/]+)\/constraints\/([^/]+)\/type$/,
  CONSTRAINT_COLUMN_NAME: /^\/tables\/([^/]+)\/constraints\/([^/]+)\/columnName$/,
  CONSTRAINT_TARGET_TABLE_NAME: /^\/tables\/([^/]+)\/constraints\/([^/]+)\/targetTableName$/,
  CONSTRAINT_TARGET_COLUMN_NAME: /^\/tables\/([^/]+)\/constraints\/([^/]+)\/targetColumnName$/,
  CONSTRAINT_UPDATE_CONSTRAINT: /^\/tables\/([^/]+)\/constraints\/([^/]+)\/updateConstraint$/,
  CONSTRAINT_DELETE_CONSTRAINT: /^\/tables\/([^/]+)\/constraints\/([^/]+)\/deleteConstraint$/,
  CONSTRAINT_DETAIL: /^\/tables\/([^/]+)\/constraints\/([^/]+)\/detail$/
};

// ../../packages/db-structure/dist/operation/schema/column.js
init_esm();

// ../../../node_modules/.pnpm/valibot@1.1.0_typescript@5.8.3/node_modules/valibot/dist/index.js
init_esm();
var store;
// @__NO_SIDE_EFFECTS__
function getGlobalConfig(config2) {
  return {
    lang: config2?.lang ?? store?.lang,
    message: config2?.message,
    abortEarly: config2?.abortEarly ?? store?.abortEarly,
    abortPipeEarly: config2?.abortPipeEarly ?? store?.abortPipeEarly
  };
}
var store2;
// @__NO_SIDE_EFFECTS__
function getGlobalMessage(lang) {
  return store2?.get(lang);
}
var store3;
// @__NO_SIDE_EFFECTS__
function getSchemaMessage(lang) {
  return store3?.get(lang);
}
var store4;
// @__NO_SIDE_EFFECTS__
function getSpecificMessage(reference, lang) {
  return store4?.get(reference)?.get(lang);
}
// @__NO_SIDE_EFFECTS__
function _stringify2(input) {
  const type = typeof input;
  if (type === "string") {
    return `"${input}"`;
  }
  if (type === "number" || type === "bigint" || type === "boolean") {
    return `${input}`;
  }
  if (type === "object" || type === "function") {
    return (input && Object.getPrototypeOf(input)?.constructor?.name) ?? "null";
  }
  return type;
}
function _addIssue(context, label, dataset, config2, other) {
  const input = other && "input" in other ? other.input : dataset.value;
  const expected = other?.expected ?? context.expects ?? null;
  const received = other?.received ?? /* @__PURE__ */ _stringify2(input);
  const issue = {
    kind: context.kind,
    type: context.type,
    input,
    expected,
    received,
    message: `Invalid ${label}: ${expected ? `Expected ${expected} but r` : "R"}eceived ${received}`,
    requirement: context.requirement,
    path: other?.path,
    issues: other?.issues,
    lang: config2.lang,
    abortEarly: config2.abortEarly,
    abortPipeEarly: config2.abortPipeEarly
  };
  const isSchema = context.kind === "schema";
  const message2 = other?.message ?? context.message ?? /* @__PURE__ */ getSpecificMessage(context.reference, issue.lang) ?? (isSchema ? /* @__PURE__ */ getSchemaMessage(issue.lang) : null) ?? config2.message ?? /* @__PURE__ */ getGlobalMessage(issue.lang);
  if (message2 !== void 0) {
    issue.message = typeof message2 === "function" ? (
      // @ts-expect-error
      message2(issue)
    ) : message2;
  }
  if (isSchema) {
    dataset.typed = false;
  }
  if (dataset.issues) {
    dataset.issues.push(issue);
  } else {
    dataset.issues = [issue];
  }
}
// @__NO_SIDE_EFFECTS__
function _getStandardProps(context) {
  return {
    version: 1,
    vendor: "valibot",
    validate(value2) {
      return context["~run"]({ value: value2 }, /* @__PURE__ */ getGlobalConfig());
    }
  };
}
// @__NO_SIDE_EFFECTS__
function _isValidObjectKey(object2, key) {
  return Object.hasOwn(object2, key) && key !== "__proto__" && key !== "prototype" && key !== "constructor";
}
// @__NO_SIDE_EFFECTS__
function _joinExpects(values2, separator) {
  const list = [...new Set(values2)];
  if (list.length > 1) {
    return `(${list.join(` ${separator} `)})`;
  }
  return list[0] ?? "never";
}
var ValiError = class extends Error {
  /**
   * Creates a Valibot error with useful information.
   *
   * @param issues The error issues.
   */
  constructor(issues) {
    super(issues[0].message);
    this.name = "ValiError";
    this.issues = issues;
  }
};
var EMOJI_REGEX = (
  // eslint-disable-next-line redos-detector/no-unsafe-regex, regexp/no-dupe-disjunctions -- false positives
  new RegExp("^(?:[\\u{1F1E6}-\\u{1F1FF}]{2}|\\u{1F3F4}[\\u{E0061}-\\u{E007A}]{2}[\\u{E0030}-\\u{E0039}\\u{E0061}-\\u{E007A}]{1,3}\\u{E007F}|(?:\\p{Emoji}\\uFE0F\\u20E3?|\\p{Emoji_Modifier_Base}\\p{Emoji_Modifier}?|\\p{Emoji_Presentation})(?:\\u200D(?:\\p{Emoji}\\uFE0F\\u20E3?|\\p{Emoji_Modifier_Base}\\p{Emoji_Modifier}?|\\p{Emoji_Presentation}))*)+$", "u")
);
var ISO_DATE_TIME_REGEX = /^\d{4}-(?:0[1-9]|1[0-2])-(?:[12]\d|0[1-9]|3[01])[T ](?:0\d|1\d|2[0-3]):[0-5]\d$/u;
// @__NO_SIDE_EFFECTS__
function isoDateTime(message2) {
  return {
    kind: "validation",
    type: "iso_date_time",
    reference: isoDateTime,
    async: false,
    expects: null,
    requirement: ISO_DATE_TIME_REGEX,
    message: message2,
    "~run"(dataset, config2) {
      if (dataset.typed && !this.requirement.test(dataset.value)) {
        _addIssue(this, "date-time", dataset, config2);
      }
      return dataset;
    }
  };
}
// @__NO_SIDE_EFFECTS__
function regex(requirement, message2) {
  return {
    kind: "validation",
    type: "regex",
    reference: regex,
    async: false,
    expects: `${requirement}`,
    requirement,
    message: message2,
    "~run"(dataset, config2) {
      if (dataset.typed && !this.requirement.test(dataset.value)) {
        _addIssue(this, "format", dataset, config2);
      }
      return dataset;
    }
  };
}
// @__NO_SIDE_EFFECTS__
function getFallback(schema, dataset, config2) {
  return typeof schema.fallback === "function" ? (
    // @ts-expect-error
    schema.fallback(dataset, config2)
  ) : (
    // @ts-expect-error
    schema.fallback
  );
}
// @__NO_SIDE_EFFECTS__
function getDefault(schema, dataset, config2) {
  return typeof schema.default === "function" ? (
    // @ts-expect-error
    schema.default(dataset, config2)
  ) : (
    // @ts-expect-error
    schema.default
  );
}
// @__NO_SIDE_EFFECTS__
function any() {
  return {
    kind: "schema",
    type: "any",
    reference: any,
    expects: "any",
    async: false,
    get "~standard"() {
      return /* @__PURE__ */ _getStandardProps(this);
    },
    "~run"(dataset) {
      dataset.typed = true;
      return dataset;
    }
  };
}
// @__NO_SIDE_EFFECTS__
function array(item, message2) {
  return {
    kind: "schema",
    type: "array",
    reference: array,
    expects: "Array",
    async: false,
    item,
    message: message2,
    get "~standard"() {
      return /* @__PURE__ */ _getStandardProps(this);
    },
    "~run"(dataset, config2) {
      const input = dataset.value;
      if (Array.isArray(input)) {
        dataset.typed = true;
        dataset.value = [];
        for (let key = 0; key < input.length; key++) {
          const value2 = input[key];
          const itemDataset = this.item["~run"]({ value: value2 }, config2);
          if (itemDataset.issues) {
            const pathItem = {
              type: "array",
              origin: "value",
              input,
              key,
              value: value2
            };
            for (const issue of itemDataset.issues) {
              if (issue.path) {
                issue.path.unshift(pathItem);
              } else {
                issue.path = [pathItem];
              }
              dataset.issues?.push(issue);
            }
            if (!dataset.issues) {
              dataset.issues = itemDataset.issues;
            }
            if (config2.abortEarly) {
              dataset.typed = false;
              break;
            }
          }
          if (!itemDataset.typed) {
            dataset.typed = false;
          }
          dataset.value.push(itemDataset.value);
        }
      } else {
        _addIssue(this, "type", dataset, config2);
      }
      return dataset;
    }
  };
}
// @__NO_SIDE_EFFECTS__
function boolean(message2) {
  return {
    kind: "schema",
    type: "boolean",
    reference: boolean,
    expects: "boolean",
    async: false,
    message: message2,
    get "~standard"() {
      return /* @__PURE__ */ _getStandardProps(this);
    },
    "~run"(dataset, config2) {
      if (typeof dataset.value === "boolean") {
        dataset.typed = true;
      } else {
        _addIssue(this, "type", dataset, config2);
      }
      return dataset;
    }
  };
}
// @__NO_SIDE_EFFECTS__
function literal(literal_, message2) {
  return {
    kind: "schema",
    type: "literal",
    reference: literal,
    expects: /* @__PURE__ */ _stringify2(literal_),
    async: false,
    literal: literal_,
    message: message2,
    get "~standard"() {
      return /* @__PURE__ */ _getStandardProps(this);
    },
    "~run"(dataset, config2) {
      if (dataset.value === this.literal) {
        dataset.typed = true;
      } else {
        _addIssue(this, "type", dataset, config2);
      }
      return dataset;
    }
  };
}
// @__NO_SIDE_EFFECTS__
function nullable(wrapped, default_) {
  return {
    kind: "schema",
    type: "nullable",
    reference: nullable,
    expects: `(${wrapped.expects} | null)`,
    async: false,
    wrapped,
    default: default_,
    get "~standard"() {
      return /* @__PURE__ */ _getStandardProps(this);
    },
    "~run"(dataset, config2) {
      if (dataset.value === null) {
        if (this.default !== void 0) {
          dataset.value = /* @__PURE__ */ getDefault(this, dataset, config2);
        }
        if (dataset.value === null) {
          dataset.typed = true;
          return dataset;
        }
      }
      return this.wrapped["~run"](dataset, config2);
    }
  };
}
// @__NO_SIDE_EFFECTS__
function number(message2) {
  return {
    kind: "schema",
    type: "number",
    reference: number,
    expects: "number",
    async: false,
    message: message2,
    get "~standard"() {
      return /* @__PURE__ */ _getStandardProps(this);
    },
    "~run"(dataset, config2) {
      if (typeof dataset.value === "number" && !isNaN(dataset.value)) {
        dataset.typed = true;
      } else {
        _addIssue(this, "type", dataset, config2);
      }
      return dataset;
    }
  };
}
// @__NO_SIDE_EFFECTS__
function object(entries2, message2) {
  return {
    kind: "schema",
    type: "object",
    reference: object,
    expects: "Object",
    async: false,
    entries: entries2,
    message: message2,
    get "~standard"() {
      return /* @__PURE__ */ _getStandardProps(this);
    },
    "~run"(dataset, config2) {
      const input = dataset.value;
      if (input && typeof input === "object") {
        dataset.typed = true;
        dataset.value = {};
        for (const key in this.entries) {
          const valueSchema = this.entries[key];
          if (key in input || (valueSchema.type === "exact_optional" || valueSchema.type === "optional" || valueSchema.type === "nullish") && // @ts-expect-error
          valueSchema.default !== void 0) {
            const value2 = key in input ? (
              // @ts-expect-error
              input[key]
            ) : /* @__PURE__ */ getDefault(valueSchema);
            const valueDataset = valueSchema["~run"]({ value: value2 }, config2);
            if (valueDataset.issues) {
              const pathItem = {
                type: "object",
                origin: "value",
                input,
                key,
                value: value2
              };
              for (const issue of valueDataset.issues) {
                if (issue.path) {
                  issue.path.unshift(pathItem);
                } else {
                  issue.path = [pathItem];
                }
                dataset.issues?.push(issue);
              }
              if (!dataset.issues) {
                dataset.issues = valueDataset.issues;
              }
              if (config2.abortEarly) {
                dataset.typed = false;
                break;
              }
            }
            if (!valueDataset.typed) {
              dataset.typed = false;
            }
            dataset.value[key] = valueDataset.value;
          } else if (valueSchema.fallback !== void 0) {
            dataset.value[key] = /* @__PURE__ */ getFallback(valueSchema);
          } else if (valueSchema.type !== "exact_optional" && valueSchema.type !== "optional" && valueSchema.type !== "nullish") {
            _addIssue(this, "key", dataset, config2, {
              input: void 0,
              expected: `"${key}"`,
              path: [
                {
                  type: "object",
                  origin: "key",
                  input,
                  key,
                  // @ts-expect-error
                  value: input[key]
                }
              ]
            });
            if (config2.abortEarly) {
              break;
            }
          }
        }
      } else {
        _addIssue(this, "type", dataset, config2);
      }
      return dataset;
    }
  };
}
// @__NO_SIDE_EFFECTS__
function optional(wrapped, default_) {
  return {
    kind: "schema",
    type: "optional",
    reference: optional,
    expects: `(${wrapped.expects} | undefined)`,
    async: false,
    wrapped,
    default: default_,
    get "~standard"() {
      return /* @__PURE__ */ _getStandardProps(this);
    },
    "~run"(dataset, config2) {
      if (dataset.value === void 0) {
        if (this.default !== void 0) {
          dataset.value = /* @__PURE__ */ getDefault(this, dataset, config2);
        }
        if (dataset.value === void 0) {
          dataset.typed = true;
          return dataset;
        }
      }
      return this.wrapped["~run"](dataset, config2);
    }
  };
}
// @__NO_SIDE_EFFECTS__
function picklist(options, message2) {
  return {
    kind: "schema",
    type: "picklist",
    reference: picklist,
    expects: /* @__PURE__ */ _joinExpects(options.map(_stringify2), "|"),
    async: false,
    options,
    message: message2,
    get "~standard"() {
      return /* @__PURE__ */ _getStandardProps(this);
    },
    "~run"(dataset, config2) {
      if (this.options.includes(dataset.value)) {
        dataset.typed = true;
      } else {
        _addIssue(this, "type", dataset, config2);
      }
      return dataset;
    }
  };
}
// @__NO_SIDE_EFFECTS__
function record(key, value2, message2) {
  return {
    kind: "schema",
    type: "record",
    reference: record,
    expects: "Object",
    async: false,
    key,
    value: value2,
    message: message2,
    get "~standard"() {
      return /* @__PURE__ */ _getStandardProps(this);
    },
    "~run"(dataset, config2) {
      const input = dataset.value;
      if (input && typeof input === "object") {
        dataset.typed = true;
        dataset.value = {};
        for (const entryKey in input) {
          if (/* @__PURE__ */ _isValidObjectKey(input, entryKey)) {
            const entryValue = input[entryKey];
            const keyDataset = this.key["~run"]({ value: entryKey }, config2);
            if (keyDataset.issues) {
              const pathItem = {
                type: "object",
                origin: "key",
                input,
                key: entryKey,
                value: entryValue
              };
              for (const issue of keyDataset.issues) {
                issue.path = [pathItem];
                dataset.issues?.push(issue);
              }
              if (!dataset.issues) {
                dataset.issues = keyDataset.issues;
              }
              if (config2.abortEarly) {
                dataset.typed = false;
                break;
              }
            }
            const valueDataset = this.value["~run"](
              { value: entryValue },
              config2
            );
            if (valueDataset.issues) {
              const pathItem = {
                type: "object",
                origin: "value",
                input,
                key: entryKey,
                value: entryValue
              };
              for (const issue of valueDataset.issues) {
                if (issue.path) {
                  issue.path.unshift(pathItem);
                } else {
                  issue.path = [pathItem];
                }
                dataset.issues?.push(issue);
              }
              if (!dataset.issues) {
                dataset.issues = valueDataset.issues;
              }
              if (config2.abortEarly) {
                dataset.typed = false;
                break;
              }
            }
            if (!keyDataset.typed || !valueDataset.typed) {
              dataset.typed = false;
            }
            if (keyDataset.typed) {
              dataset.value[keyDataset.value] = valueDataset.value;
            }
          }
        }
      } else {
        _addIssue(this, "type", dataset, config2);
      }
      return dataset;
    }
  };
}
// @__NO_SIDE_EFFECTS__
function string(message2) {
  return {
    kind: "schema",
    type: "string",
    reference: string,
    expects: "string",
    async: false,
    message: message2,
    get "~standard"() {
      return /* @__PURE__ */ _getStandardProps(this);
    },
    "~run"(dataset, config2) {
      if (typeof dataset.value === "string") {
        dataset.typed = true;
      } else {
        _addIssue(this, "type", dataset, config2);
      }
      return dataset;
    }
  };
}
// @__NO_SIDE_EFFECTS__
function _subIssues(datasets) {
  let issues;
  if (datasets) {
    for (const dataset of datasets) {
      if (issues) {
        issues.push(...dataset.issues);
      } else {
        issues = dataset.issues;
      }
    }
  }
  return issues;
}
// @__NO_SIDE_EFFECTS__
function union(options, message2) {
  return {
    kind: "schema",
    type: "union",
    reference: union,
    expects: /* @__PURE__ */ _joinExpects(
      options.map((option) => option.expects),
      "|"
    ),
    async: false,
    options,
    message: message2,
    get "~standard"() {
      return /* @__PURE__ */ _getStandardProps(this);
    },
    "~run"(dataset, config2) {
      let validDataset;
      let typedDatasets;
      let untypedDatasets;
      for (const schema of this.options) {
        const optionDataset = schema["~run"]({ value: dataset.value }, config2);
        if (optionDataset.typed) {
          if (optionDataset.issues) {
            if (typedDatasets) {
              typedDatasets.push(optionDataset);
            } else {
              typedDatasets = [optionDataset];
            }
          } else {
            validDataset = optionDataset;
            break;
          }
        } else {
          if (untypedDatasets) {
            untypedDatasets.push(optionDataset);
          } else {
            untypedDatasets = [optionDataset];
          }
        }
      }
      if (validDataset) {
        return validDataset;
      }
      if (typedDatasets) {
        if (typedDatasets.length === 1) {
          return typedDatasets[0];
        }
        _addIssue(this, "type", dataset, config2, {
          issues: /* @__PURE__ */ _subIssues(typedDatasets)
        });
        dataset.typed = true;
      } else if (untypedDatasets?.length === 1) {
        return untypedDatasets[0];
      } else {
        _addIssue(this, "type", dataset, config2, {
          issues: /* @__PURE__ */ _subIssues(untypedDatasets)
        });
      }
      return dataset;
    }
  };
}
function parse2(schema, input, config2) {
  const dataset = schema["~run"]({ value: input }, /* @__PURE__ */ getGlobalConfig(config2));
  if (dataset.issues) {
    throw new ValiError(dataset.issues);
  }
  return dataset.value;
}
// @__NO_SIDE_EFFECTS__
function pipe(...pipe2) {
  return {
    ...pipe2[0],
    pipe: pipe2,
    get "~standard"() {
      return /* @__PURE__ */ _getStandardProps(this);
    },
    "~run"(dataset, config2) {
      for (const item of pipe2) {
        if (item.kind !== "metadata") {
          if (dataset.issues && (item.kind === "schema" || item.kind === "transformation")) {
            dataset.typed = false;
            break;
          }
          if (!dataset.issues || !config2.abortEarly && !config2.abortPipeEarly) {
            dataset = item["~run"](dataset, config2);
          }
        }
      }
      return dataset;
    }
  };
}
// @__NO_SIDE_EFFECTS__
function safeParse(schema, input, config2) {
  const dataset = schema["~run"]({ value: input }, /* @__PURE__ */ getGlobalConfig(config2));
  return {
    typed: dataset.typed,
    success: !dataset.issues,
    output: dataset.value,
    issues: dataset.issues
  };
}

// ../../packages/db-structure/dist/schema/index.js
init_esm();

// ../../packages/db-structure/dist/schema/factories.js
init_esm();

// ../../packages/db-structure/dist/schema/mergeSchema.js
init_esm();

// ../../packages/db-structure/dist/schema/schema.js
init_esm();
var columnNameSchema = string();
var columnDefaultSchema = nullable(union([string(), number(), boolean()]));
var columnCheckSchema = nullable(string());
var columnNotNullSchema = boolean();
var tableNameSchema = string();
var commentSchema = nullable(string());
var constraintNameSchema = string();
var columnSchema = object({
  name: columnNameSchema,
  type: string(),
  default: columnDefaultSchema,
  check: columnCheckSchema,
  notNull: columnNotNullSchema,
  comment: commentSchema
});
var columnsSchema = record(columnNameSchema, columnSchema);
var indexNameSchema = string();
var indexUniqueSchema = boolean();
var indexColumnsSchema = array(string());
var indexTypeSchema = string();
var indexSchema = object({
  name: indexNameSchema,
  unique: indexUniqueSchema,
  columns: indexColumnsSchema,
  type: indexTypeSchema
});
var indexesSchema = record(indexNameSchema, indexSchema);
var foreignKeyConstraintReferenceOptionSchema = picklist([
  "CASCADE",
  "RESTRICT",
  "SET_NULL",
  "SET_DEFAULT",
  "NO_ACTION"
]);
var primaryKeyConstraintSchema = object({
  type: literal("PRIMARY KEY"),
  name: constraintNameSchema,
  columnNames: array(columnNameSchema)
});
var foreignKeyConstraintSchema = object({
  type: literal("FOREIGN KEY"),
  name: constraintNameSchema,
  columnName: columnNameSchema,
  targetTableName: tableNameSchema,
  targetColumnName: columnNameSchema,
  updateConstraint: foreignKeyConstraintReferenceOptionSchema,
  deleteConstraint: foreignKeyConstraintReferenceOptionSchema
});
var uniqueConstraintSchema = object({
  type: literal("UNIQUE"),
  name: constraintNameSchema,
  columnNames: array(columnNameSchema)
});
var checkConstraintDetailSchema = string();
var checkConstraintSchema = object({
  type: literal("CHECK"),
  name: constraintNameSchema,
  detail: checkConstraintDetailSchema
});
var constraintSchema = union([
  primaryKeyConstraintSchema,
  foreignKeyConstraintSchema,
  uniqueConstraintSchema,
  checkConstraintSchema
]);
var constraintsSchema = record(constraintNameSchema, constraintSchema);
var tableSchema = object({
  name: tableNameSchema,
  columns: columnsSchema,
  comment: commentSchema,
  indexes: indexesSchema,
  constraints: constraintsSchema
});
var tablesSchema = record(tableNameSchema, tableSchema);
var schemaSchema = object({
  tables: tablesSchema
});

// ../../packages/db-structure/dist/operation/schema/column.js
var columnPathSchema = pipe(string(), regex(PATH_PATTERNS.COLUMN_BASE));
var columnNamePathSchema = pipe(string(), regex(PATH_PATTERNS.COLUMN_NAME));
var addColumnOperationSchema = object({
  op: literal("add"),
  path: columnPathSchema,
  value: columnSchema
});
var removeColumnOperationSchema = object({
  op: literal("remove"),
  path: columnPathSchema
});
var renameColumnOperationSchema = object({
  op: literal("replace"),
  path: columnNamePathSchema,
  value: string()
});
var columnOperations = [
  addColumnOperationSchema,
  removeColumnOperationSchema,
  renameColumnOperationSchema
];

// ../../packages/db-structure/dist/operation/schema/constraint.js
init_esm();
var constraintPathSchema = pipe(string(), regex(PATH_PATTERNS.CONSTRAINT_BASE));
var addConstraintOperationSchema = object({
  op: literal("add"),
  path: constraintPathSchema,
  value: constraintSchema
});
var removeConstraintOperationSchema = object({
  op: literal("remove"),
  path: constraintPathSchema
});
var constraintOperations = [
  addConstraintOperationSchema,
  removeConstraintOperationSchema
];

// ../../packages/db-structure/dist/operation/schema/indexOperations.js
init_esm();
var indexPathSchema = pipe(string(), regex(PATH_PATTERNS.INDEX_BASE));
var addIndexOperationSchema = object({
  op: literal("add"),
  path: indexPathSchema,
  value: indexSchema
});
var removeIndexOperationSchema = object({
  op: literal("remove"),
  path: indexPathSchema
});
var indexOperations = [
  addIndexOperationSchema,
  removeIndexOperationSchema
];

// ../../packages/db-structure/dist/operation/schema/table.js
init_esm();
var tablePathSchema = pipe(string(), regex(PATH_PATTERNS.TABLE_BASE));
var tableNamePathSchema = pipe(string(), regex(PATH_PATTERNS.TABLE_NAME));
var addTableOperationSchema = object({
  op: literal("add"),
  path: tablePathSchema,
  value: tableSchema
});
var removeTableOperationSchema = object({
  op: literal("remove"),
  path: tablePathSchema
});
var replaceTableNameOperationSchema = object({
  op: literal("replace"),
  path: tableNamePathSchema,
  value: string()
});
var tableOperations = [
  addTableOperationSchema,
  removeTableOperationSchema,
  replaceTableNameOperationSchema
];

// ../../packages/db-structure/dist/deparser/postgresql/utils.js
init_esm();
function generateColumnDefinition(column, isPrimaryKey2 = false) {
  let definition = `${escapeIdentifier(column.name)} ${column.type}`;
  if (column.notNull && !isPrimaryKey2) {
    definition += " NOT NULL";
  }
  if (column.default !== null) {
    definition += ` DEFAULT ${formatDefaultValue(column.default)}`;
  }
  return definition;
}
function formatDefaultValue(value) {
  if (typeof value === "string") {
    if (isPostgreSQLFunction(value)) {
      return value;
    }
    return `'${value.replace(/'/g, "''")}'`;
  }
  if (typeof value === "boolean") {
    return value.toString().toUpperCase();
  }
  return value.toString();
}
function isPostgreSQLFunction(value) {
  const trimmedValue = value.trim();
  const functionPattern = /^[a-zA-Z_][a-zA-Z0-9_]*\s*\(/;
  const commonFunctions = ["current_timestamp", "current_date", "current_time"];
  if (functionPattern.test(trimmedValue)) {
    return true;
  }
  return commonFunctions.some((func) => trimmedValue.toLowerCase().startsWith(func.toLowerCase()));
}
function escapeString(str) {
  return str.replace(/'/g, "''");
}
function escapeIdentifier(identifier) {
  return `"${identifier.replace(/"/g, '""')}"`;
}
function generateCreateTableStatement(table) {
  const tableName = table.name;
  const columnDefinitions = Object.values(table.columns).map((column) => {
    const definition = generateColumnDefinition(column, false);
    return definition;
  });
  let ddl = `CREATE TABLE ${escapeIdentifier(tableName)} (
  ${columnDefinitions.join(",\n  ")}
);`;
  if (table.comment) {
    ddl += `

COMMENT ON TABLE ${escapeIdentifier(tableName)} IS '${escapeString(table.comment)}';`;
  }
  const columnComments = generateColumnComments(tableName, table);
  if (columnComments) {
    ddl += `
${columnComments}`;
  }
  return ddl;
}
function generateColumnComments(tableName, table) {
  const comments = [];
  for (const column of Object.values(table.columns)) {
    if (column.comment) {
      comments.push(`COMMENT ON COLUMN ${escapeIdentifier(tableName)}.${escapeIdentifier(column.name)} IS '${escapeString(column.comment)}';`);
    }
  }
  return comments.join("\n");
}
function generateCreateIndexStatement(tableName, index) {
  const uniqueKeyword = index.unique ? " UNIQUE" : "";
  const indexMethod = index.type ? ` USING ${index.type}` : "";
  const columnList = index.columns.map((col) => escapeIdentifier(col)).join(", ");
  return `CREATE${uniqueKeyword} INDEX ${escapeIdentifier(index.name)} ON ${escapeIdentifier(tableName)}${indexMethod} (${columnList});`;
}
function generateAddConstraintStatement(tableName, constraint) {
  const constraintName = escapeIdentifier(constraint.name);
  const tableNameEscaped = escapeIdentifier(tableName);
  switch (constraint.type) {
    case "PRIMARY KEY":
      return `ALTER TABLE ${tableNameEscaped} ADD CONSTRAINT ${constraintName} PRIMARY KEY (${constraint.columnNames.map(escapeIdentifier).join(", ")});`;
    case "FOREIGN KEY":
      return `ALTER TABLE ${tableNameEscaped} ADD CONSTRAINT ${constraintName} FOREIGN KEY (${escapeIdentifier(constraint.columnName)}) REFERENCES ${escapeIdentifier(constraint.targetTableName)} (${escapeIdentifier(constraint.targetColumnName)}) ON UPDATE ${constraint.updateConstraint.replace("_", " ")} ON DELETE ${constraint.deleteConstraint.replace("_", " ")};`;
    case "UNIQUE":
      return `ALTER TABLE ${tableNameEscaped} ADD CONSTRAINT ${constraintName} UNIQUE (${constraint.columnNames.map(escapeIdentifier).join(", ")});`;
    case "CHECK":
      return `ALTER TABLE ${tableNameEscaped} ADD CONSTRAINT ${constraintName} CHECK (${constraint.detail});`;
    default:
      return constraint;
  }
}

// ../../packages/db-structure/dist/deparser/postgresql/schemaDeparser.js
init_esm();
var postgresqlSchemaDeparser = (schema) => {
  const ddlStatements = [];
  const errors = [];
  for (const table of Object.values(schema.tables)) {
    const createTableDDL = generateCreateTableStatement(table);
    ddlStatements.push(createTableDDL);
  }
  for (const table of Object.values(schema.tables)) {
    const indexes = Object.values(table.indexes);
    for (const index of indexes) {
      const createIndexDDL = generateCreateIndexStatement(table.name, index);
      ddlStatements.push(createIndexDDL);
    }
  }
  const foreignKeyStatements = [];
  for (const table of Object.values(schema.tables)) {
    const constraints = Object.values(table.constraints);
    for (const constraint of constraints) {
      const addConstraintDDL = generateAddConstraintStatement(table.name, constraint);
      if (constraint.type === "FOREIGN KEY") {
        foreignKeyStatements.push(addConstraintDDL);
      } else {
        ddlStatements.push(addConstraintDDL);
      }
    }
  }
  ddlStatements.push(...foreignKeyStatements);
  const combinedDDL = ddlStatements.join("\n\n");
  return {
    value: combinedDDL,
    errors
  };
};

// ../../packages/db-structure/dist/diff/index.js
init_esm();

// ../../packages/db-structure/dist/diff/buildSchemaDiff.js
init_esm();
var import_fast_json_patch2 = __toESM(require_fast_json_patch(), 1);

// ../../packages/db-structure/dist/diff/columns/buildColumnCheckDiffItem.js
init_esm();

// ../../packages/db-structure/dist/diff/utils/getChangeStatus.js
init_esm();

// ../../packages/db-structure/dist/diff/columns/buildColumnCommentDiffItem.js
init_esm();

// ../../packages/db-structure/dist/diff/columns/buildColumnDefaultDiffItem.js
init_esm();

// ../../packages/db-structure/dist/diff/columns/buildColumnDiffItem.js
init_esm();

// ../../packages/db-structure/dist/diff/columns/buildColumnNameDiffItem.js
init_esm();

// ../../packages/db-structure/dist/diff/columns/buildColumnNotNullDiffItem.js
init_esm();

// ../../packages/db-structure/dist/diff/constraints/buildConstraintColumnNameDiffItem.js
init_esm();

// ../../../node_modules/.pnpm/ts-pattern@5.7.1/node_modules/ts-pattern/dist/index.js
init_esm();
var t = Symbol.for("@ts-pattern/matcher");
var e = Symbol.for("@ts-pattern/isVariadic");
var n = "@ts-pattern/anonymous-select-key";
var r = (t2) => Boolean(t2 && "object" == typeof t2);
var i = (e2) => e2 && !!e2[t];
var o = (n2, s2, c2) => {
  if (i(n2)) {
    const e2 = n2[t](), { matched: r2, selections: i2 } = e2.match(s2);
    return r2 && i2 && Object.keys(i2).forEach((t2) => c2(t2, i2[t2])), r2;
  }
  if (r(n2)) {
    if (!r(s2)) return false;
    if (Array.isArray(n2)) {
      if (!Array.isArray(s2)) return false;
      let t2 = [], r2 = [], a = [];
      for (const o2 of n2.keys()) {
        const s3 = n2[o2];
        i(s3) && s3[e] ? a.push(s3) : a.length ? r2.push(s3) : t2.push(s3);
      }
      if (a.length) {
        if (a.length > 1) throw new Error("Pattern error: Using `...P.array(...)` several times in a single pattern is not allowed.");
        if (s2.length < t2.length + r2.length) return false;
        const e2 = s2.slice(0, t2.length), n3 = 0 === r2.length ? [] : s2.slice(-r2.length), i2 = s2.slice(t2.length, 0 === r2.length ? Infinity : -r2.length);
        return t2.every((t3, n4) => o(t3, e2[n4], c2)) && r2.every((t3, e3) => o(t3, n3[e3], c2)) && (0 === a.length || o(a[0], i2, c2));
      }
      return n2.length === s2.length && n2.every((t3, e2) => o(t3, s2[e2], c2));
    }
    return Reflect.ownKeys(n2).every((e2) => {
      const r2 = n2[e2];
      return (e2 in s2 || i(a = r2) && "optional" === a[t]().matcherType) && o(r2, s2[e2], c2);
      var a;
    });
  }
  return Object.is(s2, n2);
};
var s = (e2) => {
  var n2, o2, a;
  return r(e2) ? i(e2) ? null != (n2 = null == (o2 = (a = e2[t]()).getSelectionKeys) ? void 0 : o2.call(a)) ? n2 : [] : Array.isArray(e2) ? c(e2, s) : c(Object.values(e2), s) : [];
};
var c = (t2, e2) => t2.reduce((t3, n2) => t3.concat(e2(n2)), []);
function u(t2) {
  return Object.assign(t2, { optional: () => h(t2), and: (e2) => m(t2, e2), or: (e2) => d(t2, e2), select: (e2) => void 0 === e2 ? y(t2) : y(e2, t2) });
}
function h(e2) {
  return u({ [t]: () => ({ match: (t2) => {
    let n2 = {};
    const r2 = (t3, e3) => {
      n2[t3] = e3;
    };
    return void 0 === t2 ? (s(e2).forEach((t3) => r2(t3, void 0)), { matched: true, selections: n2 }) : { matched: o(e2, t2, r2), selections: n2 };
  }, getSelectionKeys: () => s(e2), matcherType: "optional" }) });
}
function m(...e2) {
  return u({ [t]: () => ({ match: (t2) => {
    let n2 = {};
    const r2 = (t3, e3) => {
      n2[t3] = e3;
    };
    return { matched: e2.every((e3) => o(e3, t2, r2)), selections: n2 };
  }, getSelectionKeys: () => c(e2, s), matcherType: "and" }) });
}
function d(...e2) {
  return u({ [t]: () => ({ match: (t2) => {
    let n2 = {};
    const r2 = (t3, e3) => {
      n2[t3] = e3;
    };
    return c(e2, s).forEach((t3) => r2(t3, void 0)), { matched: e2.some((e3) => o(e3, t2, r2)), selections: n2 };
  }, getSelectionKeys: () => c(e2, s), matcherType: "or" }) });
}
function p(e2) {
  return { [t]: () => ({ match: (t2) => ({ matched: Boolean(e2(t2)) }) }) };
}
function y(...e2) {
  const r2 = "string" == typeof e2[0] ? e2[0] : void 0, i2 = 2 === e2.length ? e2[1] : "string" == typeof e2[0] ? void 0 : e2[0];
  return u({ [t]: () => ({ match: (t2) => {
    let e3 = { [null != r2 ? r2 : n]: t2 };
    return { matched: void 0 === i2 || o(i2, t2, (t3, n2) => {
      e3[t3] = n2;
    }), selections: e3 };
  }, getSelectionKeys: () => [null != r2 ? r2 : n].concat(void 0 === i2 ? [] : s(i2)) }) });
}
function v(t2) {
  return "number" == typeof t2;
}
function b(t2) {
  return "string" == typeof t2;
}
function w(t2) {
  return "bigint" == typeof t2;
}
var S = u(p(function(t2) {
  return true;
}));
var j = (t2) => Object.assign(u(t2), { startsWith: (e2) => {
  return j(m(t2, (n2 = e2, p((t3) => b(t3) && t3.startsWith(n2)))));
  var n2;
}, endsWith: (e2) => {
  return j(m(t2, (n2 = e2, p((t3) => b(t3) && t3.endsWith(n2)))));
  var n2;
}, minLength: (e2) => j(m(t2, ((t3) => p((e3) => b(e3) && e3.length >= t3))(e2))), length: (e2) => j(m(t2, ((t3) => p((e3) => b(e3) && e3.length === t3))(e2))), maxLength: (e2) => j(m(t2, ((t3) => p((e3) => b(e3) && e3.length <= t3))(e2))), includes: (e2) => {
  return j(m(t2, (n2 = e2, p((t3) => b(t3) && t3.includes(n2)))));
  var n2;
}, regex: (e2) => {
  return j(m(t2, (n2 = e2, p((t3) => b(t3) && Boolean(t3.match(n2))))));
  var n2;
} });
var K2 = j(p(b));
var x = (t2) => Object.assign(u(t2), { between: (e2, n2) => x(m(t2, ((t3, e3) => p((n3) => v(n3) && t3 <= n3 && e3 >= n3))(e2, n2))), lt: (e2) => x(m(t2, ((t3) => p((e3) => v(e3) && e3 < t3))(e2))), gt: (e2) => x(m(t2, ((t3) => p((e3) => v(e3) && e3 > t3))(e2))), lte: (e2) => x(m(t2, ((t3) => p((e3) => v(e3) && e3 <= t3))(e2))), gte: (e2) => x(m(t2, ((t3) => p((e3) => v(e3) && e3 >= t3))(e2))), int: () => x(m(t2, p((t3) => v(t3) && Number.isInteger(t3)))), finite: () => x(m(t2, p((t3) => v(t3) && Number.isFinite(t3)))), positive: () => x(m(t2, p((t3) => v(t3) && t3 > 0))), negative: () => x(m(t2, p((t3) => v(t3) && t3 < 0))) });
var E = x(p(v));
var A = (t2) => Object.assign(u(t2), { between: (e2, n2) => A(m(t2, ((t3, e3) => p((n3) => w(n3) && t3 <= n3 && e3 >= n3))(e2, n2))), lt: (e2) => A(m(t2, ((t3) => p((e3) => w(e3) && e3 < t3))(e2))), gt: (e2) => A(m(t2, ((t3) => p((e3) => w(e3) && e3 > t3))(e2))), lte: (e2) => A(m(t2, ((t3) => p((e3) => w(e3) && e3 <= t3))(e2))), gte: (e2) => A(m(t2, ((t3) => p((e3) => w(e3) && e3 >= t3))(e2))), positive: () => A(m(t2, p((t3) => w(t3) && t3 > 0))), negative: () => A(m(t2, p((t3) => w(t3) && t3 < 0))) });
var P = A(p(w));
var T = u(p(function(t2) {
  return "boolean" == typeof t2;
}));
var B = u(p(function(t2) {
  return "symbol" == typeof t2;
}));
var _ = u(p(function(t2) {
  return null == t2;
}));
var k = u(p(function(t2) {
  return null != t2;
}));

// ../../packages/db-structure/dist/diff/constraints/buildConstraintDeleteConstraintDiffItem.js
init_esm();

// ../../packages/db-structure/dist/diff/constraints/buildConstraintDetailDiffItem.js
init_esm();

// ../../packages/db-structure/dist/diff/constraints/buildConstraintDiffItem.js
init_esm();

// ../../packages/db-structure/dist/diff/constraints/buildConstraintNameDiffItem.js
init_esm();

// ../../packages/db-structure/dist/diff/constraints/buildConstraintTargetColumnNameDiffItem.js
init_esm();

// ../../packages/db-structure/dist/diff/constraints/buildConstraintTargetTableNameDiffItem.js
init_esm();

// ../../packages/db-structure/dist/diff/constraints/buildConstraintUpdateConstraintDiffItem.js
init_esm();

// ../../packages/db-structure/dist/diff/indexes/buildIndexColumnsDiffItem.js
init_esm();

// ../../packages/db-structure/dist/diff/indexes/buildIndexDiffItem.js
init_esm();

// ../../packages/db-structure/dist/diff/indexes/buildIndexNameDiffItem.js
init_esm();

// ../../packages/db-structure/dist/diff/indexes/buildIndexTypeDiffItem.js
init_esm();

// ../../packages/db-structure/dist/diff/indexes/buildIndexUniqueDiffItem.js
init_esm();

// ../../packages/db-structure/dist/diff/tables/buildTableCommentDiffItem.js
init_esm();

// ../../packages/db-structure/dist/diff/tables/buildTableDiffItem.js
init_esm();

// ../../packages/db-structure/dist/diff/tables/buildTableNameDiffItem.js
init_esm();

// ../../packages/db-structure/dist/diff/buildSchemaDiff.js
var { compare: compare2 } = import_fast_json_patch2.default;

// ../../packages/db-structure/dist/diff/types.js
init_esm();
var changeStatusSchema = picklist([
  "added",
  "removed",
  "modified",
  "unchanged"
]);
var baseSchemaDiffItemSchema = object({
  status: changeStatusSchema,
  tableId: string()
});
var tableDiffItemSchema = object({
  ...baseSchemaDiffItemSchema.entries,
  kind: literal("table"),
  data: tableSchema
});
var tableNameDiffItemSchema = object({
  ...baseSchemaDiffItemSchema.entries,
  kind: literal("table-name"),
  data: tableNameSchema
});
var tableCommentDiffItemSchema = object({
  ...baseSchemaDiffItemSchema.entries,
  kind: literal("table-comment"),
  data: commentSchema
});
var columnDiffItemSchema = object({
  ...baseSchemaDiffItemSchema.entries,
  kind: literal("column"),
  data: columnSchema,
  columnId: string()
});
var columnNameDiffItemSchema = object({
  ...baseSchemaDiffItemSchema.entries,
  kind: literal("column-name"),
  data: columnNameSchema,
  columnId: string()
});
var columnCommentDiffItemSchema = object({
  ...baseSchemaDiffItemSchema.entries,
  kind: literal("column-comment"),
  data: commentSchema,
  columnId: string()
});
var columnDefaultDiffItemSchema = object({
  ...baseSchemaDiffItemSchema.entries,
  kind: literal("column-default"),
  data: columnDefaultSchema,
  columnId: string()
});
var columnCheckDiffItemSchema = object({
  ...baseSchemaDiffItemSchema.entries,
  kind: literal("column-check"),
  data: columnCheckSchema,
  columnId: string()
});
var columnNotNullDiffItemSchema = object({
  ...baseSchemaDiffItemSchema.entries,
  kind: literal("column-not-null"),
  data: columnNotNullSchema,
  columnId: string()
});
var indexDiffItemSchema = object({
  ...baseSchemaDiffItemSchema.entries,
  kind: literal("index"),
  data: indexSchema,
  indexId: string()
});
var indexNameDiffItemSchema = object({
  ...baseSchemaDiffItemSchema.entries,
  kind: literal("index-name"),
  data: indexNameSchema,
  indexId: string()
});
var indexUniqueDiffItemSchema = object({
  ...baseSchemaDiffItemSchema.entries,
  kind: literal("index-unique"),
  data: indexUniqueSchema,
  indexId: string()
});
var indexColumnsDiffItemSchema = object({
  ...baseSchemaDiffItemSchema.entries,
  kind: literal("index-columns"),
  data: indexColumnsSchema,
  indexId: string()
});
var indexTypeDiffItemSchema = object({
  ...baseSchemaDiffItemSchema.entries,
  kind: literal("index-type"),
  data: indexTypeSchema,
  indexId: string()
});
var constraintDiffItemSchema = object({
  ...baseSchemaDiffItemSchema.entries,
  kind: literal("constraint"),
  data: constraintSchema,
  constraintId: string()
});
var constraintNameDiffItemSchema = object({
  ...baseSchemaDiffItemSchema.entries,
  kind: literal("constraint-name"),
  data: constraintNameSchema,
  constraintId: string()
});
var constraintColumnNameDiffItemSchema = object({
  ...baseSchemaDiffItemSchema.entries,
  kind: literal("constraint-column-name"),
  data: columnNameSchema,
  constraintId: string()
});
var constraintTargetTableNameDiffItemSchema = object({
  ...baseSchemaDiffItemSchema.entries,
  kind: literal("constraint-target-table-name"),
  data: tableNameSchema,
  constraintId: string()
});
var constraintTargetColumnNameDiffItemSchema = object({
  ...baseSchemaDiffItemSchema.entries,
  kind: literal("constraint-target-column-name"),
  data: columnNameSchema,
  constraintId: string()
});
var constraintUpdateConstraintDiffItemSchema = object({
  ...baseSchemaDiffItemSchema.entries,
  kind: literal("constraint-update-constraint"),
  data: foreignKeyConstraintReferenceOptionSchema,
  constraintId: string()
});
var constraintDeleteConstraintDiffItemSchema = object({
  ...baseSchemaDiffItemSchema.entries,
  kind: literal("constraint-delete-constraint"),
  data: foreignKeyConstraintReferenceOptionSchema,
  constraintId: string()
});
var constraintDetailDiffItemSchema = object({
  ...baseSchemaDiffItemSchema.entries,
  kind: literal("constraint-detail"),
  data: checkConstraintDetailSchema,
  constraintId: string()
});
var tableRelatedDiffItemSchema = union([
  tableDiffItemSchema,
  tableNameDiffItemSchema,
  tableCommentDiffItemSchema
]);
var columnRelatedDiffItemSchema = union([
  columnDiffItemSchema,
  columnNameDiffItemSchema,
  columnCommentDiffItemSchema,
  columnDefaultDiffItemSchema,
  columnCheckDiffItemSchema,
  columnNotNullDiffItemSchema
]);
var indexRelatedDiffItemSchema = union([
  indexDiffItemSchema,
  indexNameDiffItemSchema,
  indexUniqueDiffItemSchema,
  indexColumnsDiffItemSchema,
  indexTypeDiffItemSchema
]);
var constraintRelatedDiffItemSchema = union([
  constraintDiffItemSchema,
  constraintNameDiffItemSchema,
  constraintColumnNameDiffItemSchema,
  constraintTargetTableNameDiffItemSchema,
  constraintTargetColumnNameDiffItemSchema,
  constraintUpdateConstraintDiffItemSchema,
  constraintDeleteConstraintDiffItemSchema,
  constraintDetailDiffItemSchema
]);
var schemaDiffItemSchema = union([
  tableRelatedDiffItemSchema,
  columnRelatedDiffItemSchema,
  indexRelatedDiffItemSchema,
  constraintRelatedDiffItemSchema
]);
var schemaDiffItemsSchema = array(schemaDiffItemSchema);

// ../../packages/db-structure/dist/operation/index.js
init_esm();

// ../../packages/db-structure/dist/operation/applyPatchOperations.js
init_esm();
var import_fast_json_patch3 = __toESM(require_fast_json_patch(), 1);
var { applyPatch: applyPatch2 } = import_fast_json_patch3.default;
function applyPatchOperations(target, operations) {
  applyPatch2(target, operations, true, true);
}

// ../../packages/db-structure/dist/operation/schema/index.js
init_esm();
var addOperationSchema = object({
  op: literal("add"),
  path: string(),
  value: any()
});
var removeOperationSchema = object({
  op: literal("remove"),
  path: string()
});
var replaceOperationSchema = object({
  op: literal("replace"),
  path: string(),
  value: any()
});
var moveOperationSchema = object({
  op: literal("move"),
  from: string(),
  path: string()
});
var copyOperationSchema = object({
  op: literal("copy"),
  from: string(),
  path: string()
});
var testOperationSchema = object({
  op: literal("test"),
  path: string(),
  value: any()
});
var operationSchema = union([
  ...tableOperations,
  ...columnOperations,
  ...indexOperations,
  ...constraintOperations,
  addOperationSchema,
  removeOperationSchema,
  replaceOperationSchema,
  moveOperationSchema,
  copyOperationSchema,
  testOperationSchema
]);
var operationsSchema = array(operationSchema);

// ../../packages/db-structure/dist/utils/constraintsToRelationships.js
init_esm();

// ../../packages/db-structure/dist/utils/isPrimaryKey.js
init_esm();
var isPrimaryKey = (columnName, constraints) => {
  return Object.values(constraints).some((constraint) => constraint.type === "PRIMARY KEY" && constraint.columnNames.includes(columnName));
};

// ../../../node_modules/.pnpm/@valibot+to-json-schema@1.3.0_valibot@1.1.0_typescript@5.8.3_/node_modules/@valibot/to-json-schema/dist/index.js
init_esm();
function addError(errors, message) {
  if (errors) {
    errors.push(message);
    return errors;
  }
  return [message];
}
function handleError(message, config) {
  switch (config?.errorMode) {
    case "ignore":
      break;
    case "warn": {
      console.warn(message);
      break;
    }
    default:
      throw new Error(message);
  }
}
function convertAction(jsonSchema, valibotAction, config) {
  if (config?.ignoreActions?.includes(valibotAction.type)) return jsonSchema;
  let errors;
  switch (valibotAction.type) {
    case "base64": {
      jsonSchema.contentEncoding = "base64";
      break;
    }
    case "bic":
    case "cuid2":
    case "decimal":
    case "digits":
    case "emoji":
    case "hexadecimal":
    case "hex_color":
    case "nanoid":
    case "octal":
    case "ulid": {
      jsonSchema.pattern = valibotAction.requirement.source;
      break;
    }
    case "description": {
      jsonSchema.description = valibotAction.description;
      break;
    }
    case "email": {
      jsonSchema.format = "email";
      break;
    }
    case "empty": {
      if (jsonSchema.type === "array") jsonSchema.maxItems = 0;
      else {
        if (jsonSchema.type !== "string") errors = addError(errors, `The "${valibotAction.type}" action is not supported on type "${jsonSchema.type}".`);
        jsonSchema.maxLength = 0;
      }
      break;
    }
    case "entries": {
      jsonSchema.minProperties = valibotAction.requirement;
      jsonSchema.maxProperties = valibotAction.requirement;
      break;
    }
    case "integer": {
      jsonSchema.type = "integer";
      break;
    }
    case "ipv4": {
      jsonSchema.format = "ipv4";
      break;
    }
    case "ipv6": {
      jsonSchema.format = "ipv6";
      break;
    }
    case "iso_date": {
      jsonSchema.format = "date";
      break;
    }
    case "iso_date_time":
    case "iso_timestamp": {
      jsonSchema.format = "date-time";
      break;
    }
    case "iso_time": {
      jsonSchema.format = "time";
      break;
    }
    case "length": {
      if (jsonSchema.type === "array") {
        jsonSchema.minItems = valibotAction.requirement;
        jsonSchema.maxItems = valibotAction.requirement;
      } else {
        if (jsonSchema.type !== "string") errors = addError(errors, `The "${valibotAction.type}" action is not supported on type "${jsonSchema.type}".`);
        jsonSchema.minLength = valibotAction.requirement;
        jsonSchema.maxLength = valibotAction.requirement;
      }
      break;
    }
    case "max_entries": {
      jsonSchema.maxProperties = valibotAction.requirement;
      break;
    }
    case "max_length": {
      if (jsonSchema.type === "array") jsonSchema.maxItems = valibotAction.requirement;
      else {
        if (jsonSchema.type !== "string") errors = addError(errors, `The "${valibotAction.type}" action is not supported on type "${jsonSchema.type}".`);
        jsonSchema.maxLength = valibotAction.requirement;
      }
      break;
    }
    case "max_value": {
      if (jsonSchema.type !== "number") errors = addError(errors, `The "max_value" action is not supported on type "${jsonSchema.type}".`);
      jsonSchema.maximum = valibotAction.requirement;
      break;
    }
    case "metadata": {
      if (typeof valibotAction.metadata.title === "string") jsonSchema.title = valibotAction.metadata.title;
      if (typeof valibotAction.metadata.description === "string") jsonSchema.description = valibotAction.metadata.description;
      if (Array.isArray(valibotAction.metadata.examples)) jsonSchema.examples = valibotAction.metadata.examples;
      break;
    }
    case "min_entries": {
      jsonSchema.minProperties = valibotAction.requirement;
      break;
    }
    case "min_length": {
      if (jsonSchema.type === "array") jsonSchema.minItems = valibotAction.requirement;
      else {
        if (jsonSchema.type !== "string") errors = addError(errors, `The "${valibotAction.type}" action is not supported on type "${jsonSchema.type}".`);
        jsonSchema.minLength = valibotAction.requirement;
      }
      break;
    }
    case "min_value": {
      if (jsonSchema.type !== "number") errors = addError(errors, `The "min_value" action is not supported on type "${jsonSchema.type}".`);
      jsonSchema.minimum = valibotAction.requirement;
      break;
    }
    case "multiple_of": {
      jsonSchema.multipleOf = valibotAction.requirement;
      break;
    }
    case "non_empty": {
      if (jsonSchema.type === "array") jsonSchema.minItems = 1;
      else {
        if (jsonSchema.type !== "string") errors = addError(errors, `The "${valibotAction.type}" action is not supported on type "${jsonSchema.type}".`);
        jsonSchema.minLength = 1;
      }
      break;
    }
    case "regex": {
      if (valibotAction.requirement.flags) errors = addError(errors, "RegExp flags are not supported by JSON Schema.");
      jsonSchema.pattern = valibotAction.requirement.source;
      break;
    }
    case "title": {
      jsonSchema.title = valibotAction.title;
      break;
    }
    case "url": {
      jsonSchema.format = "uri";
      break;
    }
    case "uuid": {
      jsonSchema.format = "uuid";
      break;
    }
    case "value": {
      jsonSchema.const = valibotAction.requirement;
      break;
    }
    default:
      errors = addError(errors, `The "${valibotAction.type}" action cannot be converted to JSON Schema.`);
  }
  if (config?.overrideAction) {
    const actionOverride = config.overrideAction({
      valibotAction,
      jsonSchema,
      errors
    });
    if (actionOverride) return { ...actionOverride };
  }
  if (errors) for (const message of errors) handleError(message, config);
  return jsonSchema;
}
function flattenPipe(pipe2) {
  return pipe2.flatMap((item) => "pipe" in item ? flattenPipe(item.pipe) : item);
}
var refCount = 0;
function convertSchema(jsonSchema, valibotSchema, config, context, skipRef = false) {
  if (!skipRef) {
    const referenceId = context.referenceMap.get(valibotSchema);
    if (referenceId) {
      jsonSchema.$ref = `#/$defs/${referenceId}`;
      if (config?.overrideRef) {
        const refOverride = config.overrideRef({
          ...context,
          referenceId,
          valibotSchema,
          jsonSchema
        });
        if (refOverride) jsonSchema.$ref = refOverride;
      }
      return jsonSchema;
    }
  }
  if ("pipe" in valibotSchema) {
    const flatPipe = flattenPipe(valibotSchema.pipe);
    let startIndex = 0;
    let stopIndex = flatPipe.length - 1;
    if (config?.typeMode === "input") {
      const inputStopIndex = flatPipe.slice(1).findIndex((item) => item.kind === "schema" || item.kind === "transformation" && (item.type === "find_item" || item.type === "parse_json" || item.type === "raw_transform" || item.type === "reduce_items" || item.type === "stringify_json" || item.type === "transform"));
      if (inputStopIndex !== -1) stopIndex = inputStopIndex;
    } else if (config?.typeMode === "output") {
      const outputStartIndex = flatPipe.findLastIndex((item) => item.kind === "schema");
      if (outputStartIndex !== -1) startIndex = outputStartIndex;
    }
    for (let index = startIndex; index <= stopIndex; index++) {
      const valibotPipeItem = flatPipe[index];
      if (valibotPipeItem.kind === "schema") {
        if (index > startIndex) handleError('Set the "typeMode" config to "input" or "output" to convert pipelines with multiple schemas.', config);
        jsonSchema = convertSchema(jsonSchema, valibotPipeItem, config, context, true);
      } else jsonSchema = convertAction(jsonSchema, valibotPipeItem, config);
    }
    return jsonSchema;
  }
  let errors;
  switch (valibotSchema.type) {
    case "boolean": {
      jsonSchema.type = "boolean";
      break;
    }
    case "null": {
      jsonSchema.type = "null";
      break;
    }
    case "number": {
      jsonSchema.type = "number";
      break;
    }
    case "string": {
      jsonSchema.type = "string";
      break;
    }
    case "array": {
      jsonSchema.type = "array";
      jsonSchema.items = convertSchema({}, valibotSchema.item, config, context);
      break;
    }
    case "tuple":
    case "tuple_with_rest":
    case "loose_tuple":
    case "strict_tuple": {
      jsonSchema.type = "array";
      jsonSchema.items = [];
      jsonSchema.minItems = valibotSchema.items.length;
      for (const item of valibotSchema.items) jsonSchema.items.push(convertSchema({}, item, config, context));
      if (valibotSchema.type === "tuple_with_rest") jsonSchema.additionalItems = convertSchema({}, valibotSchema.rest, config, context);
      else if (valibotSchema.type === "strict_tuple") jsonSchema.additionalItems = false;
      break;
    }
    case "object":
    case "object_with_rest":
    case "loose_object":
    case "strict_object": {
      jsonSchema.type = "object";
      jsonSchema.properties = {};
      jsonSchema.required = [];
      for (const key in valibotSchema.entries) {
        const entry = valibotSchema.entries[key];
        jsonSchema.properties[key] = convertSchema({}, entry, config, context);
        if (entry.type !== "nullish" && entry.type !== "optional") jsonSchema.required.push(key);
      }
      if (valibotSchema.type === "object_with_rest") jsonSchema.additionalProperties = convertSchema({}, valibotSchema.rest, config, context);
      else if (valibotSchema.type === "strict_object") jsonSchema.additionalProperties = false;
      break;
    }
    case "record": {
      if ("pipe" in valibotSchema.key) errors = addError(errors, 'The "record" schema with a schema for the key that contains a "pipe" cannot be converted to JSON Schema.');
      if (valibotSchema.key.type !== "string") errors = addError(errors, `The "record" schema with the "${valibotSchema.key.type}" schema for the key cannot be converted to JSON Schema.`);
      jsonSchema.type = "object";
      jsonSchema.additionalProperties = convertSchema({}, valibotSchema.value, config, context);
      break;
    }
    case "any":
    case "unknown":
      break;
    case "nullable":
    case "nullish": {
      jsonSchema.anyOf = [convertSchema({}, valibotSchema.wrapped, config, context), { type: "null" }];
      if (valibotSchema.default !== void 0) jsonSchema.default = getDefault(valibotSchema);
      break;
    }
    case "exact_optional":
    case "optional":
    case "undefinedable": {
      jsonSchema = convertSchema(jsonSchema, valibotSchema.wrapped, config, context);
      if (valibotSchema.default !== void 0) jsonSchema.default = getDefault(valibotSchema);
      break;
    }
    case "literal": {
      if (typeof valibotSchema.literal !== "boolean" && typeof valibotSchema.literal !== "number" && typeof valibotSchema.literal !== "string") errors = addError(errors, 'The value of the "literal" schema is not JSON compatible.');
      jsonSchema.const = valibotSchema.literal;
      break;
    }
    case "enum": {
      jsonSchema.enum = valibotSchema.options;
      break;
    }
    case "picklist": {
      if (valibotSchema.options.some((option) => typeof option !== "number" && typeof option !== "string")) errors = addError(errors, 'An option of the "picklist" schema is not JSON compatible.');
      jsonSchema.enum = valibotSchema.options;
      break;
    }
    case "union":
    case "variant": {
      jsonSchema.anyOf = valibotSchema.options.map((option) => convertSchema({}, option, config, context));
      break;
    }
    case "intersect": {
      jsonSchema.allOf = valibotSchema.options.map((option) => convertSchema({}, option, config, context));
      break;
    }
    case "lazy": {
      let wrappedValibotSchema = context.getterMap.get(valibotSchema.getter);
      if (!wrappedValibotSchema) {
        wrappedValibotSchema = valibotSchema.getter(void 0);
        context.getterMap.set(valibotSchema.getter, wrappedValibotSchema);
      }
      let referenceId = context.referenceMap.get(wrappedValibotSchema);
      if (!referenceId) {
        referenceId = `${refCount++}`;
        context.referenceMap.set(wrappedValibotSchema, referenceId);
        context.definitions[referenceId] = convertSchema({}, wrappedValibotSchema, config, context, true);
      }
      jsonSchema.$ref = `#/$defs/${referenceId}`;
      if (config?.overrideRef) {
        const refOverride = config.overrideRef({
          ...context,
          referenceId,
          valibotSchema: wrappedValibotSchema,
          jsonSchema
        });
        if (refOverride) jsonSchema.$ref = refOverride;
      }
      break;
    }
    default:
      errors = addError(errors, `The "${valibotSchema.type}" schema cannot be converted to JSON Schema.`);
  }
  if (config?.overrideSchema) {
    const schemaOverride = config.overrideSchema({
      ...context,
      referenceId: context.referenceMap.get(valibotSchema),
      valibotSchema,
      jsonSchema,
      errors
    });
    if (schemaOverride) return { ...schemaOverride };
  }
  if (errors) for (const message of errors) handleError(message, config);
  return jsonSchema;
}
var store5;
function getGlobalDefs() {
  return store5;
}
function toJsonSchema2(schema, config) {
  const context = {
    definitions: {},
    referenceMap: /* @__PURE__ */ new Map(),
    getterMap: /* @__PURE__ */ new Map()
  };
  const definitions = config?.definitions ?? getGlobalDefs();
  if (definitions) {
    for (const key in definitions) context.referenceMap.set(definitions[key], key);
    for (const key in definitions) context.definitions[key] = convertSchema({}, definitions[key], config, context, true);
  }
  const jsonSchema = convertSchema({ $schema: "http://json-schema.org/draft-07/schema#" }, schema, config, context);
  if (context.referenceMap.size) jsonSchema.$defs = context.definitions;
  return jsonSchema;
}

// ../agent/src/langchain/utils/telemetry.ts
init_esm();

// ../../../node_modules/.pnpm/langfuse-langchain@3.37.4_langchain@0.3.29_@langchain+core@0.3.61_@opentelemetry+api@1._4cd67286ccd7744833f51a4cccddb6cc/node_modules/langfuse-langchain/lib/index.mjs
init_esm();

// ../../../node_modules/.pnpm/langfuse@3.38.0/node_modules/langfuse/lib/index.mjs
init_esm();

// ../../../node_modules/.pnpm/langfuse-core@3.38.0/node_modules/langfuse-core/lib/index.mjs
init_esm();
var SimpleEventEmitter = class {
  constructor() {
    this.events = {};
    this.events = {};
  }
  on(event, listener) {
    if (!this.events[event]) {
      this.events[event] = [];
    }
    this.events[event].push(listener);
    return () => {
      this.events[event] = this.events[event].filter((x2) => x2 !== listener);
    };
  }
  emit(event, payload) {
    for (const listener of this.events[event] || []) {
      listener(payload);
    }
    for (const listener of this.events["*"] || []) {
      listener(event, payload);
    }
  }
};
var DEFAULT_PROMPT_CACHE_TTL_SECONDS = 60;
var LangfusePromptCacheItem = class {
  constructor(value, ttlSeconds) {
    this.value = value;
    this._expiry = Date.now() + ttlSeconds * 1e3;
  }
  get isExpired() {
    return Date.now() > this._expiry;
  }
};
var LangfusePromptCache = class {
  constructor() {
    this._cache = /* @__PURE__ */ new Map();
    this._defaultTtlSeconds = DEFAULT_PROMPT_CACHE_TTL_SECONDS;
    this._refreshingKeys = /* @__PURE__ */ new Map();
  }
  getIncludingExpired(key) {
    return this._cache.get(key) ?? null;
  }
  set(key, value, ttlSeconds) {
    const effectiveTtlSeconds = ttlSeconds ?? this._defaultTtlSeconds;
    this._cache.set(key, new LangfusePromptCacheItem(value, effectiveTtlSeconds));
  }
  addRefreshingPromise(key, promise) {
    this._refreshingKeys.set(key, promise);
    promise.then(() => {
      this._refreshingKeys.delete(key);
    }).catch(() => {
      this._refreshingKeys.delete(key);
    });
  }
  isRefreshing(key) {
    return this._refreshingKeys.has(key);
  }
  invalidate(promptName) {
    console.log("invalidating", promptName, this._cache.keys());
    for (const key of this._cache.keys()) {
      if (key.startsWith(promptName)) {
        this._cache.delete(key);
      }
    }
  }
};
var LangfusePersistedProperty;
(function(LangfusePersistedProperty2) {
  LangfusePersistedProperty2["Props"] = "props";
  LangfusePersistedProperty2["Queue"] = "queue";
  LangfusePersistedProperty2["OptedOut"] = "opted_out";
})(LangfusePersistedProperty || (LangfusePersistedProperty = {}));
var ChatMessageType;
(function(ChatMessageType2) {
  ChatMessageType2["ChatMessage"] = "chatmessage";
  ChatMessageType2["Placeholder"] = "placeholder";
})(ChatMessageType || (ChatMessageType = {}));
mustache_default.escape = function(text) {
  return text;
};
var BasePromptClient = class {
  constructor(prompt, isFallback = false, type) {
    this.name = prompt.name;
    this.version = prompt.version;
    this.config = prompt.config;
    this.labels = prompt.labels;
    this.tags = prompt.tags;
    this.isFallback = isFallback;
    this.type = type;
    this.commitMessage = prompt.commitMessage;
  }
  _transformToLangchainVariables(content) {
    const jsonEscapedContent = this.escapeJsonForLangchain(content);
    return jsonEscapedContent.replace(/\{\{(\w+)\}\}/g, "{$1}");
  }
  /**
   * Escapes every curly brace that is part of a JSON object by doubling it.
   *
   * A curly brace is considered “JSON-related” when, after skipping any immediate
   * whitespace, the next non-whitespace character is a single (') or double (") quote.
   *
   * Braces that are already doubled (e.g. `{{variable}}` placeholders) are left untouched.
   *
   * @param text - Input string that may contain JSON snippets.
   * @returns The string with JSON-related braces doubled.
   */
  escapeJsonForLangchain(text) {
    const out = [];
    const stack = [];
    let i2 = 0;
    const n2 = text.length;
    while (i2 < n2) {
      const ch = text[i2];
      if (ch === "{") {
        if (i2 + 1 < n2 && text[i2 + 1] === "{") {
          out.push("{{");
          i2 += 2;
          continue;
        }
        let j2 = i2 + 1;
        while (j2 < n2 && /\s/.test(text[j2])) {
          j2++;
        }
        const isJson = j2 < n2 && (text[j2] === "'" || text[j2] === '"');
        out.push(isJson ? "{{" : "{");
        stack.push(isJson);
        i2 += 1;
        continue;
      }
      if (ch === "}") {
        if (i2 + 1 < n2 && text[i2 + 1] === "}") {
          out.push("}}");
          i2 += 2;
          continue;
        }
        const isJson = stack.pop() ?? false;
        out.push(isJson ? "}}" : "}");
        i2 += 1;
        continue;
      }
      out.push(ch);
      i2 += 1;
    }
    return out.join("");
  }
};
var TextPromptClient = class extends BasePromptClient {
  constructor(prompt, isFallback = false) {
    super(prompt, isFallback, "text");
    this.promptResponse = prompt;
    this.prompt = prompt.prompt;
  }
  compile(variables, _placeholders) {
    return mustache_default.render(this.promptResponse.prompt, variables ?? {});
  }
  getLangchainPrompt(_options) {
    return this._transformToLangchainVariables(this.prompt);
  }
  toJSON() {
    return JSON.stringify({
      name: this.name,
      prompt: this.prompt,
      version: this.version,
      isFallback: this.isFallback,
      tags: this.tags,
      labels: this.labels,
      type: this.type,
      config: this.config
    });
  }
};
var ChatPromptClient = class _ChatPromptClient extends BasePromptClient {
  constructor(prompt, isFallback = false) {
    const normalizedPrompt = _ChatPromptClient.normalizePrompt(prompt.prompt);
    const typedPrompt = {
      ...prompt,
      prompt: normalizedPrompt
    };
    super(typedPrompt, isFallback, "chat");
    this.promptResponse = typedPrompt;
    this.prompt = normalizedPrompt;
  }
  static normalizePrompt(prompt) {
    return prompt.map((item) => {
      if ("type" in item) {
        return item;
      } else {
        return {
          type: ChatMessageType.ChatMessage,
          ...item
        };
      }
    });
  }
  compile(variables, placeholders) {
    const messagesWithPlaceholdersReplaced = [];
    const placeholderValues = placeholders ?? {};
    for (const item of this.prompt) {
      if ("type" in item && item.type === ChatMessageType.Placeholder) {
        const placeholderValue = placeholderValues[item.name];
        if (Array.isArray(placeholderValue) && placeholderValue.length > 0 && placeholderValue.every((msg) => typeof msg === "object" && "role" in msg && "content" in msg)) {
          messagesWithPlaceholdersReplaced.push(...placeholderValue);
        } else if (Array.isArray(placeholderValue) && placeholderValue.length === 0) ;
        else if (placeholderValue !== void 0) {
          messagesWithPlaceholdersReplaced.push(JSON.stringify(placeholderValue));
        } else {
          messagesWithPlaceholdersReplaced.push(item);
        }
      } else if ("role" in item && "content" in item && item.type === ChatMessageType.ChatMessage) {
        messagesWithPlaceholdersReplaced.push({
          role: item.role,
          content: item.content
        });
      }
    }
    return messagesWithPlaceholdersReplaced.map((item) => {
      if (typeof item === "object" && item !== null && "role" in item && "content" in item) {
        return {
          ...item,
          content: mustache_default.render(item.content, variables ?? {})
        };
      } else {
        return item;
      }
    });
  }
  getLangchainPrompt(options) {
    const messagesWithPlaceholdersReplaced = [];
    const placeholderValues = options?.placeholders ?? {};
    for (const item of this.prompt) {
      if ("type" in item && item.type === ChatMessageType.Placeholder) {
        const placeholderValue = placeholderValues[item.name];
        if (Array.isArray(placeholderValue) && placeholderValue.length > 0 && placeholderValue.every((msg) => typeof msg === "object" && "role" in msg && "content" in msg)) {
          messagesWithPlaceholdersReplaced.push(...placeholderValue.map((msg) => {
            return {
              role: msg.role,
              content: this._transformToLangchainVariables(msg.content)
            };
          }));
        } else if (Array.isArray(placeholderValue) && placeholderValue.length === 0) ;
        else if (placeholderValue !== void 0) {
          messagesWithPlaceholdersReplaced.push(JSON.stringify(placeholderValue));
        } else {
          messagesWithPlaceholdersReplaced.push({
            variableName: item.name,
            optional: false
          });
        }
      } else if ("role" in item && "content" in item && item.type === ChatMessageType.ChatMessage) {
        messagesWithPlaceholdersReplaced.push({
          role: item.role,
          content: this._transformToLangchainVariables(item.content)
        });
      }
    }
    return messagesWithPlaceholdersReplaced;
  }
  toJSON() {
    return JSON.stringify({
      name: this.name,
      prompt: this.promptResponse.prompt.map((item) => {
        if ("type" in item && item.type === ChatMessageType.ChatMessage) {
          const {
            type: _2,
            ...messageWithoutType
          } = item;
          return messageWithoutType;
        }
        return item;
      }),
      version: this.version,
      isFallback: this.isFallback,
      tags: this.tags,
      labels: this.labels,
      type: this.type,
      config: this.config
    });
  }
};
function assert(truthyValue, message) {
  if (!truthyValue) {
    throw new Error(message);
  }
}
function removeTrailingSlash(url) {
  return url?.replace(/\/+$/, "");
}
async function retriable(fn, props = {}, log) {
  const {
    retryCount = 3,
    retryDelay = 5e3,
    retryCheck = () => true
  } = props;
  let lastError = null;
  for (let i2 = 0; i2 < retryCount + 1; i2++) {
    if (i2 > 0) {
      await new Promise((resolve) => setTimeout(resolve, retryDelay));
      log(`Retrying ${i2 + 1} of ${retryCount + 1}`);
    }
    try {
      const res = await fn();
      return res;
    } catch (e2) {
      lastError = e2;
      if (!retryCheck(e2)) {
        throw e2;
      }
      log(`Retriable error: ${JSON.stringify(e2)}`);
    }
  }
  throw lastError;
}
function generateUUID(globalThis2) {
  let d2 = (/* @__PURE__ */ new Date()).getTime();
  let d22 = globalThis2 && globalThis2.performance && globalThis2.performance.now && globalThis2.performance.now() * 1e3 || 0;
  return "xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx".replace(/[xy]/g, function(c2) {
    let r2 = Math.random() * 16;
    if (d2 > 0) {
      r2 = (d2 + r2) % 16 | 0;
      d2 = Math.floor(d2 / 16);
    } else {
      r2 = (d22 + r2) % 16 | 0;
      d22 = Math.floor(d22 / 16);
    }
    return (c2 === "x" ? r2 : r2 & 3 | 8).toString(16);
  });
}
function currentTimestamp() {
  return (/* @__PURE__ */ new Date()).getTime();
}
function currentISOTime() {
  return (/* @__PURE__ */ new Date()).toISOString();
}
function safeSetTimeout(fn, timeout) {
  const t2 = setTimeout(fn, timeout);
  t2?.unref && t2?.unref();
  return t2;
}
function getEnv2(key) {
  if (typeof process !== "undefined" && process.env[key]) {
    return process.env[key];
  } else if (typeof globalThis !== "undefined") {
    return globalThis[key];
  }
  return;
}
function configLangfuseSDK(params, secretRequired = true) {
  const {
    publicKey,
    secretKey,
    ...coreOptions
  } = params ?? {};
  const finalPublicKey = publicKey ?? getEnv2("LANGFUSE_PUBLIC_KEY");
  const finalSecretKey = secretRequired ? secretKey ?? getEnv2("LANGFUSE_SECRET_KEY") : void 0;
  const finalBaseUrl = coreOptions.baseUrl ?? getEnv2("LANGFUSE_BASEURL");
  const finalCoreOptions = {
    ...coreOptions,
    baseUrl: finalBaseUrl
  };
  return {
    publicKey: finalPublicKey,
    ...secretRequired ? {
      secretKey: finalSecretKey
    } : void 0,
    ...finalCoreOptions
  };
}
var encodeQueryParams = (params) => {
  const queryParams = new URLSearchParams();
  Object.entries(params ?? {}).forEach(([key, value]) => {
    if (value !== void 0 && value !== null) {
      if (value instanceof Date) {
        queryParams.append(key, value.toISOString());
      } else {
        queryParams.append(key, value.toString());
      }
    }
  });
  return queryParams.toString();
};
var utils = /* @__PURE__ */ Object.freeze({
  __proto__: null,
  assert,
  configLangfuseSDK,
  currentISOTime,
  currentTimestamp,
  encodeQueryParams,
  generateUUID,
  getEnv: getEnv2,
  removeTrailingSlash,
  retriable,
  safeSetTimeout
});
var common_release_envs = [
  // Vercel
  "VERCEL_GIT_COMMIT_SHA",
  "NEXT_PUBLIC_VERCEL_GIT_COMMIT_SHA",
  // Netlify
  "COMMIT_REF",
  // Render
  "RENDER_GIT_COMMIT",
  // GitLab CI
  "CI_COMMIT_SHA",
  // CicleCI
  "CIRCLE_SHA1",
  // Cloudflare pages
  "CF_PAGES_COMMIT_SHA",
  // AWS Amplify
  "REACT_APP_GIT_SHA",
  // Heroku
  "SOURCE_VERSION",
  // Trigger.dev
  "TRIGGER_DEPLOYMENT_ID"
];
function getCommonReleaseEnvs() {
  for (const key of common_release_envs) {
    const value = getEnv2(key);
    if (value) {
      return value;
    }
  }
  return void 0;
}
var fs = null;
var cryptoModule = null;
var dynamicImport = (module) => {
  return import(
    /* webpackIgnore: true */
    module
  );
};
if (typeof globalThis.Deno !== "undefined") {
  Promise.all([dynamicImport("node:fs"), dynamicImport("node:crypto")]).then(([importedFs, importedCrypto]) => {
    fs = importedFs;
    cryptoModule = importedCrypto;
  }).catch();
} else if (typeof process !== "undefined" && process.versions?.node) {
  Promise.all([dynamicImport("fs"), dynamicImport("crypto")]).then(([importedFs, importedCrypto]) => {
    fs = importedFs;
    cryptoModule = importedCrypto;
  }).catch();
} else if (typeof crypto !== "undefined") {
  cryptoModule = crypto;
}
var LangfuseMedia = class _LangfuseMedia {
  constructor(params) {
    const {
      obj,
      base64DataUri,
      contentType,
      contentBytes,
      filePath
    } = params;
    this.obj = obj;
    this._mediaId = void 0;
    if (base64DataUri) {
      const [contentBytesParsed, contentTypeParsed] = this.parseBase64DataUri(base64DataUri);
      this._contentBytes = contentBytesParsed;
      this._contentType = contentTypeParsed;
      this._source = "base64_data_uri";
    } else if (contentBytes && contentType) {
      this._contentBytes = contentBytes;
      this._contentType = contentType;
      this._source = "bytes";
    } else if (filePath && contentType) {
      if (!fs) {
        throw new Error("File system support is not available in this environment");
      }
      if (!fs.existsSync(filePath)) {
        throw new Error(`File at path ${filePath} does not exist`);
      }
      this._contentBytes = this.readFile(filePath);
      this._contentType = this._contentBytes ? contentType : void 0;
      this._source = this._contentBytes ? "file" : void 0;
    } else {
      console.error("base64DataUri, or contentBytes and contentType, or filePath must be provided to LangfuseMedia");
    }
  }
  readFile(filePath) {
    try {
      if (!fs) {
        throw new Error("File system support is not available in this environment");
      }
      return fs.readFileSync(filePath);
    } catch (error) {
      console.error(`Error reading file at path ${filePath}`, error);
      return void 0;
    }
  }
  parseBase64DataUri(data) {
    try {
      if (!data || typeof data !== "string") {
        throw new Error("Data URI is not a string");
      }
      if (!data.startsWith("data:")) {
        throw new Error("Data URI does not start with 'data:'");
      }
      const [header, actualData] = data.slice(5).split(",", 2);
      if (!header || !actualData) {
        throw new Error("Invalid URI");
      }
      const headerParts = header.split(";");
      if (!headerParts.includes("base64")) {
        throw new Error("Data is not base64 encoded");
      }
      const contentType = headerParts[0];
      if (!contentType) {
        throw new Error("Content type is empty");
      }
      return [Buffer.from(actualData, "base64"), contentType];
    } catch (error) {
      console.error("Error parsing base64 data URI", error);
      return [void 0, void 0];
    }
  }
  get contentLength() {
    return this._contentBytes?.length;
  }
  get contentSha256Hash() {
    if (!this._contentBytes) {
      return void 0;
    }
    if (!cryptoModule) {
      console.error("Crypto support is not available in this environment");
      return void 0;
    }
    const sha256Hash = cryptoModule.createHash("sha256").update(this._contentBytes).digest("base64");
    return sha256Hash;
  }
  toJSON() {
    if (!this._contentType || !this._source || !this._mediaId) {
      return `<Upload handling failed for LangfuseMedia of type ${this._contentType}>`;
    }
    return `@@@langfuseMedia:type=${this._contentType}|id=${this._mediaId}|source=${this._source}@@@`;
  }
  /**
   * Parses a media reference string into a ParsedMediaReference.
   *
   * Example reference string:
   *     "@@@langfuseMedia:type=image/jpeg|id=some-uuid|source=base64DataUri@@@"
   *
   * @param referenceString - The reference string to parse.
   * @returns An object with the mediaId, source, and contentType.
   *
   * @throws Error if the reference string is invalid or missing required fields.
   */
  static parseReferenceString(referenceString) {
    const prefix = "@@@langfuseMedia:";
    const suffix = "@@@";
    if (!referenceString.startsWith(prefix)) {
      throw new Error("Reference string does not start with '@@@langfuseMedia:type='");
    }
    if (!referenceString.endsWith(suffix)) {
      throw new Error("Reference string does not end with '@@@'");
    }
    const content = referenceString.slice(prefix.length, -suffix.length);
    const pairs = content.split("|");
    const parsedData = {};
    for (const pair of pairs) {
      const [key, value] = pair.split("=", 2);
      parsedData[key] = value;
    }
    if (!("type" in parsedData && "id" in parsedData && "source" in parsedData)) {
      throw new Error("Missing required fields in reference string");
    }
    return {
      mediaId: parsedData["id"],
      source: parsedData["source"],
      contentType: parsedData["type"]
    };
  }
  /**
   * Replaces the media reference strings in an object with base64 data URIs for the media content.
   *
   * This method recursively traverses an object (up to a maximum depth of 10) looking for media reference strings
   * in the format "@@@langfuseMedia:...@@@". When found, it fetches the actual media content using the provided
   * Langfuse client and replaces the reference string with a base64 data URI.
   *
   * If fetching media content fails for a reference string, a warning is logged and the reference string is left unchanged.
   *
   * @param params - Configuration object
   * @param params.obj - The object to process. Can be a primitive value, array, or nested object
   * @param params.langfuseClient - Langfuse client instance used to fetch media content
   * @param params.resolveWith - The representation of the media content to replace the media reference string with. Currently only "base64DataUri" is supported.
   * @param params.maxDepth - Optional. Default is 10. The maximum depth to traverse the object.
   *
   * @returns A deep copy of the input object with all media references replaced with base64 data URIs where possible
   *
   * @example
   * ```typescript
   * const obj = {
   *   image: "@@@langfuseMedia:type=image/jpeg|id=123|source=bytes@@@",
   *   nested: {
   *     pdf: "@@@langfuseMedia:type=application/pdf|id=456|source=bytes@@@"
   *   }
   * };
   *
   * const result = await LangfuseMedia.resolveMediaReferences({
   *   obj,
   *   langfuseClient
   * });
   *
   * // Result:
   * // {
   * //   image: "data:image/jpeg;base64,/9j/4AAQSkZJRg...",
   * //   nested: {
   * //     pdf: "data:application/pdf;base64,JVBERi0xLjcK..."
   * //   }
   * // }
   * ```
   */
  static async resolveMediaReferences(params) {
    const {
      obj,
      langfuseClient,
      maxDepth = 10
    } = params;
    async function traverse(obj2, depth) {
      if (depth > maxDepth) {
        return obj2;
      }
      if (typeof obj2 === "string") {
        const regex2 = /@@@langfuseMedia:.+?@@@/g;
        const referenceStringMatches = obj2.match(regex2);
        if (!referenceStringMatches) {
          return obj2;
        }
        let result = obj2;
        const referenceStringToMediaContentMap = /* @__PURE__ */ new Map();
        await Promise.all(referenceStringMatches.map(async (referenceString) => {
          try {
            const parsedMediaReference = _LangfuseMedia.parseReferenceString(referenceString);
            const mediaData = await langfuseClient.fetchMedia(parsedMediaReference.mediaId);
            const mediaContent = await langfuseClient.fetch(mediaData.url, {
              method: "GET",
              headers: {}
            });
            if (mediaContent.status !== 200) {
              throw new Error("Failed to fetch media content");
            }
            const base64MediaContent = Buffer.from(await mediaContent.arrayBuffer()).toString("base64");
            const base64DataUri = `data:${mediaData.contentType};base64,${base64MediaContent}`;
            referenceStringToMediaContentMap.set(referenceString, base64DataUri);
          } catch (error) {
            console.warn("Error fetching media content for reference string", referenceString, error);
          }
        }));
        for (const [referenceString, base64MediaContent] of referenceStringToMediaContentMap.entries()) {
          result = result.replaceAll(referenceString, base64MediaContent);
        }
        return result;
      }
      if (Array.isArray(obj2)) {
        return Promise.all(obj2.map(async (item) => await traverse(item, depth + 1)));
      }
      if (typeof obj2 === "object" && obj2 !== null) {
        return Object.fromEntries(await Promise.all(Object.entries(obj2).map(async ([key, value]) => [key, await traverse(value, depth + 1)])));
      }
      return obj2;
    }
    return traverse(obj, 0);
  }
};
function isInSample(input, sampleRate) {
  if (sampleRate === void 0) {
    return true;
  } else if (sampleRate === 0) {
    return false;
  }
  if (sampleRate < 0 || sampleRate > 1 || isNaN(sampleRate)) {
    console.warn("Sample rate must be between 0 and 1. Ignoring setting.");
    return true;
  }
  return simpleHash(input) < sampleRate;
}
function simpleHash(str) {
  let hash = 0;
  const prime = 31;
  for (let i2 = 0; i2 < str.length; i2++) {
    hash = hash * prime + str.charCodeAt(i2) >>> 0;
  }
  hash = (hash >>> 16 ^ hash) * 73244475;
  hash = (hash >>> 16 ^ hash) * 73244475;
  hash = hash >>> 16 ^ hash;
  return Math.abs(hash) / 2147483647;
}
var MAX_EVENT_SIZE_BYTES = getEnv2("LANGFUSE_MAX_EVENT_SIZE_BYTES") ? Number(getEnv2("LANGFUSE_MAX_EVENT_SIZE_BYTES")) : 1e6;
var MAX_BATCH_SIZE_BYTES = getEnv2("LANGFUSE_MAX_BATCH_SIZE_BYTES") ? Number(getEnv2("LANGFUSE_MAX_BATCH_SIZE_BYTES")) : 25e5;
var ENVIRONMENT_PATTERN = /^(?!langfuse)[a-z0-9_-]+$/;
var LangfuseFetchHttpError = class extends Error {
  constructor(response, body) {
    super("HTTP error while fetching Langfuse: " + response.status + " and body: " + body);
    this.response = response;
    this.name = "LangfuseFetchHttpError";
  }
};
var LangfuseFetchNetworkError = class extends Error {
  constructor(error) {
    super("Network error while fetching Langfuse", error instanceof Error ? {
      cause: error
    } : {});
    this.error = error;
    this.name = "LangfuseFetchNetworkError";
  }
};
function isLangfuseFetchHttpError(error) {
  return typeof error === "object" && error.name === "LangfuseFetchHttpError";
}
function isLangfuseFetchNetworkError(error) {
  return typeof error === "object" && error.name === "LangfuseFetchNetworkError";
}
function isLangfuseFetchError(err3) {
  return isLangfuseFetchHttpError(err3) || isLangfuseFetchNetworkError(err3);
}
var SUPPORT_URL = "https://langfuse.com/support";
var API_DOCS_URL = "https://api.reference.langfuse.com";
var RBAC_DOCS_URL = "https://langfuse.com/docs/rbac";
var INSTALLATION_DOCS_URL = "https://langfuse.com/docs/sdk/typescript/guide";
var RATE_LIMITS_URL = "https://langfuse.com/faq/all/api-limits";
var NPM_PACKAGE_URL = "https://www.npmjs.com/package/langfuse";
var updatePromptResponse = `Make sure to keep your SDK updated, refer to ${NPM_PACKAGE_URL} for details.`;
var defaultServerErrorPrompt = `This is an unusual occurrence and we are monitoring it closely. For help, please contact support: ${SUPPORT_URL}.`;
var defaultErrorResponse = `Unexpected error occurred. Please check your request and contact support: ${SUPPORT_URL}.`;
var errorResponseByCode = /* @__PURE__ */ new Map([
  // Internal error category: 5xx errors, 404 error
  [500, `Internal server error occurred. For help, please contact support: ${SUPPORT_URL}`],
  [501, `Not implemented. Please check your request and contact support for help: ${SUPPORT_URL}.`],
  [502, `Bad gateway. ${defaultServerErrorPrompt}`],
  [503, `Service unavailable. ${defaultServerErrorPrompt}`],
  [504, `Gateway timeout. ${defaultServerErrorPrompt}`],
  [404, `Internal error occurred. ${defaultServerErrorPrompt}`],
  // Client error category: 4xx errors, excluding 404
  [400, `Bad request. Please check your request for any missing or incorrect parameters. Refer to our API docs: ${API_DOCS_URL} for details.`],
  [401, `Unauthorized. Please check your public/private host settings. Refer to our installation and setup guide: ${INSTALLATION_DOCS_URL} for details on SDK configuration.`],
  [403, `Forbidden. Please check your access control settings. Refer to our RBAC docs: ${RBAC_DOCS_URL} for details.`],
  [429, `Rate limit exceeded. For more information on rate limits please see: ${RATE_LIMITS_URL}`]
]);
function getErrorResponseByCode(code) {
  if (!code) {
    return `${defaultErrorResponse} ${updatePromptResponse}`;
  }
  const errorResponse = errorResponseByCode.get(code) || defaultErrorResponse;
  return `${code}: ${errorResponse} ${updatePromptResponse}`;
}
function logIngestionError(error) {
  if (isLangfuseFetchHttpError(error)) {
    const code = error.response.status;
    const errorResponse = getErrorResponseByCode(code);
    console.error("[Langfuse SDK]", errorResponse, `Error details: ${error}`);
  } else if (isLangfuseFetchNetworkError(error)) {
    console.error("[Langfuse SDK] Network error: ", error);
  } else {
    console.error("[Langfuse SDK] Unknown error:", error);
  }
}
var LangfuseCoreStateless = class {
  constructor(params) {
    this.additionalHeaders = {};
    this.debugMode = false;
    this.pendingEventProcessingPromises = {};
    this.pendingIngestionPromises = {};
    this.localEventExportMap = /* @__PURE__ */ new Map();
    this._events = new SimpleEventEmitter();
    const {
      publicKey,
      secretKey,
      enabled,
      _projectId,
      _isLocalEventExportEnabled,
      ...options
    } = params;
    this._events.on("error", (payload) => {
      console.error(`[Langfuse SDK] ${typeof payload === "string" ? payload : JSON.stringify(payload)}`);
    });
    this.enabled = enabled === false ? false : true;
    this.publicKey = publicKey ?? "";
    this.secretKey = secretKey;
    this.baseUrl = removeTrailingSlash(options?.baseUrl || "https://cloud.langfuse.com");
    this.additionalHeaders = options?.additionalHeaders || {};
    this.flushAt = options?.flushAt ? Math.max(options?.flushAt, 1) : 15;
    this.flushInterval = options?.flushInterval ?? 1e4;
    this.release = options?.release ?? getEnv2("LANGFUSE_RELEASE") ?? getCommonReleaseEnvs() ?? void 0;
    this.mask = options?.mask;
    this.sampleRate = options?.sampleRate ?? (getEnv2("LANGFUSE_SAMPLE_RATE") ? Number(getEnv2("LANGFUSE_SAMPLE_RATE")) : void 0);
    if (this.sampleRate) {
      this._events.emit("debug", `Langfuse trace sampling enabled with sampleRate ${this.sampleRate}.`);
    }
    this.environment = options?.environment ?? getEnv2("LANGFUSE_TRACING_ENVIRONMENT");
    if (this.environment && !ENVIRONMENT_PATTERN.test(this.environment)) {
      this._events.emit("error", `Invalid tracing environment set: ${this.environment} . Environment must match regex ${ENVIRONMENT_PATTERN}. Events will be rejected by Langfuse server.`);
    }
    this._retryOptions = {
      retryCount: options?.fetchRetryCount ?? 3,
      retryDelay: options?.fetchRetryDelay ?? 3e3,
      retryCheck: isLangfuseFetchError
    };
    this.requestTimeout = options?.requestTimeout ?? 5e3;
    this.sdkIntegration = options?.sdkIntegration ?? "DEFAULT";
    this.isLocalEventExportEnabled = _isLocalEventExportEnabled ?? false;
    if (this.isLocalEventExportEnabled && !_projectId) {
      this._events.emit("error", "Local event export is enabled, but no project ID was provided. Disabling local export.");
      this.isLocalEventExportEnabled = false;
      return;
    } else if (!this.isLocalEventExportEnabled && _projectId) {
      this._events.emit("error", "Local event export is disabled, but a project ID was provided. Disabling local export.");
      this.isLocalEventExportEnabled = false;
      return;
    } else {
      this.projectId = _projectId;
    }
  }
  getSdkIntegration() {
    return this.sdkIntegration;
  }
  getCommonEventProperties() {
    return {
      $lib: this.getLibraryId(),
      $lib_version: this.getLibraryVersion()
    };
  }
  on(event, cb) {
    return this._events.on(event, cb);
  }
  debug(enabled = true) {
    this.removeDebugCallback?.();
    this.debugMode = enabled;
    if (enabled) {
      this.removeDebugCallback = this.on("*", (event, payload) => {
        if (event === "error") {
          return;
        }
        console.log("[Langfuse Debug]", event, JSON.stringify(payload));
      });
    }
  }
  /***
   *** Handlers for each object type
   ***/
  traceStateless(body) {
    const {
      id: bodyId,
      timestamp: bodyTimestamp,
      release: bodyRelease,
      ...rest
    } = body;
    const id = bodyId ?? generateUUID();
    const release = bodyRelease ?? this.release;
    const parsedBody = {
      id,
      release,
      timestamp: bodyTimestamp ?? /* @__PURE__ */ new Date(),
      environment: this.environment,
      ...rest
    };
    this.enqueue("trace-create", parsedBody);
    return id;
  }
  eventStateless(body) {
    const {
      id: bodyId,
      startTime: bodyStartTime,
      ...rest
    } = body;
    const id = bodyId ?? generateUUID();
    const parsedBody = {
      id,
      startTime: bodyStartTime ?? /* @__PURE__ */ new Date(),
      environment: this.environment,
      ...rest
    };
    this.enqueue("event-create", parsedBody);
    return id;
  }
  spanStateless(body) {
    const {
      id: bodyId,
      startTime: bodyStartTime,
      ...rest
    } = body;
    const id = bodyId || generateUUID();
    const parsedBody = {
      id,
      startTime: bodyStartTime ?? /* @__PURE__ */ new Date(),
      environment: this.environment,
      ...rest
    };
    this.enqueue("span-create", parsedBody);
    return id;
  }
  generationStateless(body) {
    const {
      id: bodyId,
      startTime: bodyStartTime,
      prompt,
      ...rest
    } = body;
    const promptDetails = prompt && !prompt.isFallback ? {
      promptName: prompt.name,
      promptVersion: prompt.version
    } : {};
    const id = bodyId || generateUUID();
    const parsedBody = {
      id,
      startTime: bodyStartTime ?? /* @__PURE__ */ new Date(),
      environment: this.environment,
      ...promptDetails,
      ...rest
    };
    this.enqueue("generation-create", parsedBody);
    return id;
  }
  scoreStateless(body) {
    const {
      id: bodyId,
      ...rest
    } = body;
    const id = bodyId || generateUUID();
    const parsedBody = {
      id,
      environment: this.environment,
      ...rest
    };
    this.enqueue("score-create", parsedBody);
    return id;
  }
  updateSpanStateless(body) {
    this.enqueue("span-update", body);
    return body.id;
  }
  updateGenerationStateless(body) {
    const {
      prompt,
      ...rest
    } = body;
    const promptDetails = prompt && !prompt.isFallback ? {
      promptName: prompt.name,
      promptVersion: prompt.version
    } : {};
    const parsedBody = {
      ...promptDetails,
      ...rest
    };
    this.enqueue("generation-update", parsedBody);
    return body.id;
  }
  async _getDataset(name) {
    const encodedName = encodeURIComponent(name);
    return this.fetchAndLogErrors(`${this.baseUrl}/api/public/v2/datasets/${encodedName}`, this._getFetchOptions({
      method: "GET"
    }));
  }
  async _getDatasetItems(query) {
    const params = new URLSearchParams();
    Object.entries(query ?? {}).forEach(([key, value]) => {
      if (value !== void 0 && value !== null) {
        params.append(key, value.toString());
      }
    });
    return this.fetchAndLogErrors(`${this.baseUrl}/api/public/dataset-items?${params}`, this._getFetchOptions({
      method: "GET"
    }));
  }
  async _fetchMedia(id) {
    return this.fetchAndLogErrors(`${this.baseUrl}/api/public/media/${id}`, this._getFetchOptions({
      method: "GET"
    }));
  }
  async fetchTraces(query) {
    const {
      data,
      meta
    } = await this.fetchAndLogErrors(`${this.baseUrl}/api/public/traces?${encodeQueryParams(query)}`, this._getFetchOptions({
      method: "GET"
    }));
    return {
      data,
      meta
    };
  }
  async fetchTrace(traceId) {
    const res = await this.fetchAndLogErrors(`${this.baseUrl}/api/public/traces/${traceId}`, this._getFetchOptions({
      method: "GET"
    }));
    return {
      data: res
    };
  }
  async fetchObservations(query) {
    const {
      data,
      meta
    } = await this.fetchAndLogErrors(`${this.baseUrl}/api/public/observations?${encodeQueryParams(query)}`, this._getFetchOptions({
      method: "GET"
    }));
    return {
      data,
      meta
    };
  }
  async fetchObservation(observationId) {
    const res = await this.fetchAndLogErrors(`${this.baseUrl}/api/public/observations/${observationId}`, this._getFetchOptions({
      method: "GET"
    }));
    return {
      data: res
    };
  }
  async fetchSessions(query) {
    const {
      data,
      meta
    } = await this.fetchAndLogErrors(`${this.baseUrl}/api/public/sessions?${encodeQueryParams(query)}`, this._getFetchOptions({
      method: "GET"
    }));
    return {
      data,
      meta
    };
  }
  async getDatasetRun(params) {
    const encodedDatasetName = encodeURIComponent(params.datasetName);
    const encodedRunName = encodeURIComponent(params.runName);
    return this.fetchAndLogErrors(`${this.baseUrl}/api/public/datasets/${encodedDatasetName}/runs/${encodedRunName}`, this._getFetchOptions({
      method: "GET"
    }));
  }
  async getDatasetRuns(datasetName, query) {
    return this.fetchAndLogErrors(`${this.baseUrl}/api/public/datasets/${encodeURIComponent(datasetName)}/runs?${encodeQueryParams(query)}`, this._getFetchOptions({
      method: "GET"
    }));
  }
  async createDatasetRunItem(body) {
    return this.fetchAndLogErrors(`${this.baseUrl}/api/public/dataset-run-items`, this._getFetchOptions({
      method: "POST",
      body: JSON.stringify(body)
    }));
  }
  /**
   * Creates a dataset. Upserts the dataset if it already exists.
   *
   * @param dataset Can be either a string (name) or an object with name, description and metadata
   * @returns A promise that resolves to the response of the create operation.
   */
  async createDataset(dataset) {
    const body = typeof dataset === "string" ? {
      name: dataset
    } : dataset;
    return this.fetchAndLogErrors(`${this.baseUrl}/api/public/datasets`, this._getFetchOptions({
      method: "POST",
      body: JSON.stringify(body)
    }));
  }
  /**
   * Creates a dataset item. Upserts the item if it already exists.
   * @param body The body of the dataset item to be created.
   * @returns A promise that resolves to the response of the create operation.
   */
  async createDatasetItem(body) {
    return this.fetchAndLogErrors(`${this.baseUrl}/api/public/dataset-items`, this._getFetchOptions({
      method: "POST",
      body: JSON.stringify(body)
    }));
  }
  async getDatasetItem(id) {
    return this.fetchAndLogErrors(`${this.baseUrl}/api/public/dataset-items/${id}`, this._getFetchOptions({
      method: "GET"
    }));
  }
  _parsePayload(response) {
    try {
      return JSON.parse(response);
    } catch {
      return response;
    }
  }
  async createPromptStateless(body) {
    return this.fetchAndLogErrors(`${this.baseUrl}/api/public/v2/prompts`, this._getFetchOptions({
      method: "POST",
      body: JSON.stringify(body)
    }));
  }
  async updatePromptStateless(body) {
    return this.fetchAndLogErrors(`${this.baseUrl}/api/public/v2/prompts/${encodeURIComponent(body.name)}/versions/${encodeURIComponent(body.version)}`, this._getFetchOptions({
      method: "PATCH",
      body: JSON.stringify(body)
    }));
  }
  async getPromptStateless(name, version2, label, maxRetries, requestTimeout) {
    const encodedName = encodeURIComponent(name);
    const params = new URLSearchParams();
    if (version2 && label) {
      throw new Error("Provide either version or label, not both.");
    }
    if (version2) {
      params.append("version", version2.toString());
    }
    if (label) {
      params.append("label", label);
    }
    const url = `${this.baseUrl}/api/public/v2/prompts/${encodedName}${params.size ? "?" + params : ""}`;
    const boundedMaxRetries = this._getBoundedMaxRetries({
      maxRetries,
      defaultMaxRetries: 2,
      maxRetriesUpperBound: 4
    });
    const retryOptions = {
      ...this._retryOptions,
      retryCount: boundedMaxRetries,
      retryDelay: 500
    };
    const retryLogger = (string2) => this._events.emit("retry", string2 + ", " + url + ", " + JSON.stringify(retryOptions));
    return retriable(async () => {
      const res = await this.fetch(url, this._getFetchOptions({
        method: "GET",
        fetchTimeout: requestTimeout ?? this.requestTimeout
      })).catch((e2) => {
        if (e2.name === "AbortError") {
          throw new LangfuseFetchNetworkError("Fetch request timed out");
        }
        throw new LangfuseFetchNetworkError(e2);
      });
      if (res.status >= 500) {
        throw new LangfuseFetchHttpError(res, await res.text());
      }
      const data = await res.json();
      return {
        fetchResult: res.status === 200 ? "success" : "failure",
        data
      };
    }, retryOptions, retryLogger);
  }
  _getBoundedMaxRetries(params) {
    const defaultMaxRetries = Math.max(params.defaultMaxRetries ?? 2, 0);
    const maxRetriesUpperBound = Math.max(params.maxRetriesUpperBound ?? 4, 0);
    if (params.maxRetries === void 0) {
      return defaultMaxRetries;
    }
    return Math.min(Math.max(params.maxRetries, 0), maxRetriesUpperBound);
  }
  /***
   *** QUEUEING AND FLUSHING
   ***/
  enqueue(type, body) {
    if (!this.enabled) {
      return;
    }
    const traceId = this.parseTraceId(type, body);
    if (!traceId) {
      this._events.emit("warning", "Failed to parse traceID for sampling. Please open a Github issue in https://github.com/langfuse/langfuse/issues/new/choose");
    } else if (!isInSample(traceId, this.sampleRate)) {
      this._events.emit("debug", `Event with trace ID ${traceId} is out of sample. Skipping.`);
      return;
    }
    const promise = this.processEnqueueEvent(type, body);
    const promiseId = generateUUID();
    this.pendingEventProcessingPromises[promiseId] = promise;
    promise.catch((e2) => {
      this._events.emit("error", e2);
    }).finally(() => {
      delete this.pendingEventProcessingPromises[promiseId];
    });
  }
  async processEnqueueEvent(type, body) {
    this.maskEventBodyInPlace(body);
    await this.processMediaInEvent(type, body);
    const finalEventBody = this.truncateEventBody(body, MAX_EVENT_SIZE_BYTES);
    try {
      JSON.stringify(finalEventBody);
    } catch (e2) {
      this._events.emit("error", `Event Body for ${type} is not JSON-serializable: ${e2}`);
      return;
    }
    const queue = this.getPersistedProperty(LangfusePersistedProperty.Queue) || [];
    queue.push({
      id: generateUUID(),
      type,
      timestamp: currentISOTime(),
      body: finalEventBody,
      // TODO: fix typecast. EventBody is not correctly narrowed to the correct type dictated by the 'type' property. This should be part of a larger type cleanup.
      metadata: void 0
    });
    this.setPersistedProperty(LangfusePersistedProperty.Queue, queue);
    this._events.emit(type, finalEventBody);
    if (queue.length >= this.flushAt) {
      this.flush();
    }
    if (this.flushInterval && !this._flushTimer) {
      this._flushTimer = safeSetTimeout(() => this.flush(), this.flushInterval);
    }
  }
  maskEventBodyInPlace(body) {
    if (!this.mask) {
      return;
    }
    const maskableKeys = ["input", "output"];
    for (const key of maskableKeys) {
      if (key in body) {
        try {
          body[key] = this.mask({
            data: body[key]
          });
        } catch (e2) {
          this._events.emit("error", `Error masking ${key}: ${e2}`);
          body[key] = "<fully masked due to failed mask function>";
        }
      }
    }
  }
  /**
   * Truncates the event body if its byte size exceeds the specified maximum byte size.
   * Emits a warning event if truncation occurs.
   * The fields that may be truncated are: "input", "output", and "metadata".
   * The fields are truncated in the order of their size, from largest to smallest until the total byte size is within the limit.
   */
  truncateEventBody(body, maxByteSize) {
    const bodySize = this.getByteSize(body);
    if (bodySize <= maxByteSize) {
      return body;
    }
    this._events.emit("warning", `Event Body is too large (${bodySize} bytes) and will be truncated`);
    const keysToCheck = ["input", "output", "metadata"];
    const keySizes = keysToCheck.map((key) => ({
      key,
      size: key in body ? this.getByteSize(body[key]) : 0
    })).sort((a, b2) => b2.size - a.size);
    let result = {
      ...body
    };
    let currentSize = bodySize;
    for (const {
      key,
      size
    } of keySizes) {
      if (currentSize > maxByteSize && Object.prototype.hasOwnProperty.call(result, key)) {
        result = {
          ...result,
          [key]: "<truncated due to size exceeding limit>"
        };
        this._events.emit("warning", `Truncated ${key} due to total size exceeding limit`);
        currentSize -= size;
      }
    }
    return result;
  }
  getByteSize(obj) {
    const serialized = JSON.stringify(obj);
    if (typeof TextEncoder !== "undefined") {
      return new TextEncoder().encode(serialized).length;
    } else {
      return encodeURIComponent(serialized).replace(/%[A-F\d]{2}/g, "U").length;
    }
  }
  async processMediaInEvent(type, body) {
    if (!body) {
      return;
    }
    const traceId = this.parseTraceId(type, body);
    if (!traceId) {
      this._events.emit("warning", "traceId is required for media upload");
      return;
    }
    const observationId = (type.includes("generation") || type.includes("span")) && body.id ? body.id : void 0;
    await Promise.all(["input", "output", "metadata"].map(async (field) => {
      if (body[field]) {
        body[field] = await this.findAndProcessMedia({
          data: body[field],
          traceId,
          observationId,
          field
        }).catch((e2) => {
          this._events.emit("error", `Error processing multimodal event: ${e2}`);
        }) ?? body[field];
      }
    }));
  }
  parseTraceId(type, body) {
    return "traceId" in body ? body.traceId : type.includes("trace") ? body.id : void 0;
  }
  async findAndProcessMedia({
    data,
    traceId,
    observationId,
    field
  }) {
    const seenObjects = /* @__PURE__ */ new WeakMap();
    const maxLevels = 10;
    const processRecursively = async (data2, level) => {
      if (typeof data2 === "string" && data2.startsWith("data:")) {
        const media = new LangfuseMedia({
          base64DataUri: data2
        });
        await this.processMediaItem({
          media,
          traceId,
          observationId,
          field
        });
        return media;
      }
      if (typeof data2 !== "object" || data2 === null) {
        return data2;
      }
      if (seenObjects.has(data2) || level > maxLevels) {
        return data2;
      }
      seenObjects.set(data2, true);
      if (data2 instanceof LangfuseMedia || Object.prototype.toString.call(data2) === "[object LangfuseMedia]") {
        await this.processMediaItem({
          media: data2,
          traceId,
          observationId,
          field
        });
        return data2;
      }
      if (Array.isArray(data2)) {
        return await Promise.all(data2.map((item) => processRecursively(item, level + 1)));
      }
      if (typeof data2 === "object" && data2 !== null) {
        if ("input_audio" in data2 && typeof data2["input_audio"] === "object" && "data" in data2.input_audio) {
          const media = new LangfuseMedia({
            base64DataUri: `data:audio/${data2.input_audio["format"] || "wav"};base64,${data2.input_audio.data}`
          });
          await this.processMediaItem({
            media,
            traceId,
            observationId,
            field
          });
          return {
            ...data2,
            input_audio: {
              ...data2.input_audio,
              data: media
            }
          };
        }
        if ("audio" in data2 && typeof data2["audio"] === "object" && "data" in data2.audio) {
          const media = new LangfuseMedia({
            base64DataUri: `data:audio/${data2.audio["format"] || "wav"};base64,${data2.audio.data}`
          });
          await this.processMediaItem({
            media,
            traceId,
            observationId,
            field
          });
          return {
            ...data2,
            audio: {
              ...data2.audio,
              data: media
            }
          };
        }
        return Object.fromEntries(await Promise.all(Object.entries(data2).map(async ([key, value]) => [key, await processRecursively(value, level + 1)])));
      }
      return data2;
    };
    return await processRecursively(data, 1);
  }
  async processMediaItem({
    media,
    traceId,
    observationId,
    field
  }) {
    try {
      if (!media.contentLength || !media._contentType || !media.contentSha256Hash || !media._contentBytes) {
        return;
      }
      const getUploadUrlBody = {
        contentLength: media.contentLength,
        traceId,
        observationId,
        field,
        contentType: media._contentType,
        sha256Hash: media.contentSha256Hash
      };
      const fetchResponse = await this.fetch(`${this.baseUrl}/api/public/media`, this._getFetchOptions({
        method: "POST",
        body: JSON.stringify(getUploadUrlBody)
      }));
      const uploadUrlResponse = await fetchResponse.json();
      const {
        uploadUrl,
        mediaId
      } = uploadUrlResponse;
      media._mediaId = mediaId;
      if (uploadUrl) {
        this._events.emit("debug", `Uploading media ${mediaId}`);
        const startTime = Date.now();
        const uploadResponse = await this.uploadMediaWithBackoff({
          uploadUrl,
          contentBytes: media._contentBytes,
          contentType: media._contentType,
          contentSha256Hash: media.contentSha256Hash,
          maxRetries: 3,
          baseDelay: 1e3
        });
        if (!uploadResponse) {
          throw Error("Media upload process failed");
        }
        const patchMediaBody = {
          uploadedAt: (/* @__PURE__ */ new Date()).toISOString(),
          uploadHttpStatus: uploadResponse.status,
          uploadHttpError: await uploadResponse.text(),
          uploadTimeMs: Date.now() - startTime
        };
        await this.fetch(`${this.baseUrl}/api/public/media/${mediaId}`, this._getFetchOptions({
          method: "PATCH",
          body: JSON.stringify(patchMediaBody)
        }));
        this._events.emit("debug", `Media upload status reported for ${mediaId}`);
      } else {
        this._events.emit("debug", `Media ${mediaId} already uploaded`);
      }
    } catch (err3) {
      this._events.emit("error", `Error processing media item: ${err3}`);
    }
  }
  async uploadMediaWithBackoff(params) {
    const {
      uploadUrl,
      contentType,
      contentSha256Hash,
      contentBytes,
      maxRetries,
      baseDelay
    } = params;
    for (let attempt = 0; attempt <= maxRetries; attempt++) {
      try {
        const uploadResponse = await this.fetch(uploadUrl, {
          method: "PUT",
          body: contentBytes,
          headers: {
            "Content-Type": contentType,
            "x-amz-checksum-sha256": contentSha256Hash,
            "x-ms-blob-type": "BlockBlob"
          }
        });
        if (attempt < maxRetries && uploadResponse.status !== 200 && uploadResponse.status !== 201) {
          throw new Error(`Upload failed with status ${uploadResponse.status}`);
        }
        return uploadResponse;
      } catch (e2) {
        if (attempt === maxRetries) {
          throw e2;
        }
        const delay = baseDelay * Math.pow(2, attempt);
        const jitter = Math.random() * 1e3;
        await new Promise((resolve) => setTimeout(resolve, delay + jitter));
      }
    }
  }
  /**
   * Asynchronously flushes all events that are not yet sent to the server.
   * This function always resolves, even if there were errors when flushing.
   * Errors are emitted as "error" events and the promise resolves.
   *
   * @returns {Promise<void>} A promise that resolves when the flushing is completed.
   */
  async flushAsync() {
    await Promise.all(Object.values(this.pendingEventProcessingPromises)).catch((e2) => {
      logIngestionError(e2);
    });
    return new Promise((resolve, _reject) => {
      try {
        this.flush((err3, data) => {
          if (err3) {
            logIngestionError(err3);
            resolve();
          } else {
            resolve(data);
          }
        });
      } catch (e2) {
        console.error("[Langfuse SDK] Error while flushing Langfuse", e2);
      }
    });
  }
  // Flushes all events that are not yet sent to the server
  flush(callback) {
    if (this._flushTimer) {
      clearTimeout(this._flushTimer);
      this._flushTimer = null;
    }
    const queue = this.getPersistedProperty(LangfusePersistedProperty.Queue) || [];
    if (!queue.length) {
      return callback?.();
    }
    const items = queue.splice(0, this.flushAt);
    const {
      processedItems,
      remainingItems
    } = this.processQueueItems(items, MAX_EVENT_SIZE_BYTES, MAX_BATCH_SIZE_BYTES);
    this.setPersistedProperty(LangfusePersistedProperty.Queue, [...remainingItems, ...queue]);
    const promiseUUID = generateUUID();
    const done = (err3) => {
      if (err3) {
        this._events.emit("warning", err3);
      }
      callback?.(err3, items);
      this._events.emit("flush", items);
    };
    if (this.isLocalEventExportEnabled && this.projectId) {
      if (!this.localEventExportMap.has(this.projectId)) {
        this.localEventExportMap.set(this.projectId, [...items]);
      } else {
        this.localEventExportMap.get(this.projectId)?.push(...items);
      }
      done();
      return;
    }
    const payload = JSON.stringify({
      batch: processedItems,
      metadata: {
        batch_size: processedItems.length,
        sdk_integration: this.sdkIntegration,
        sdk_version: this.getLibraryVersion(),
        sdk_variant: this.getLibraryId(),
        public_key: this.publicKey,
        sdk_name: "langfuse-js"
      }
    });
    const url = `${this.baseUrl}/api/public/ingestion`;
    const fetchOptions = this._getFetchOptions({
      method: "POST",
      body: payload
    });
    const requestPromise = this.fetchWithRetry(url, fetchOptions).then(() => done()).catch((err3) => {
      done(err3);
    });
    this.pendingIngestionPromises[promiseUUID] = requestPromise;
    requestPromise.finally(() => {
      delete this.pendingIngestionPromises[promiseUUID];
    });
  }
  processQueueItems(queue, MAX_MSG_SIZE, BATCH_SIZE_LIMIT) {
    let totalSize = 0;
    const processedItems = [];
    const remainingItems = [];
    for (let i2 = 0; i2 < queue.length; i2++) {
      try {
        const itemSize = new Blob([JSON.stringify(queue[i2])]).size;
        if (itemSize > MAX_MSG_SIZE) {
          console.warn(`Item exceeds size limit (size: ${itemSize}), dropping item.`);
          continue;
        }
        if (totalSize + itemSize >= BATCH_SIZE_LIMIT) {
          console.debug(`hit batch size limit (size: ${totalSize + itemSize})`);
          remainingItems.push(...queue.slice(i2));
          console.log(`Remaining items: ${remainingItems.length}`);
          console.log(`processes items: ${processedItems.length}`);
          break;
        }
        totalSize += itemSize;
        processedItems.push(queue[i2]);
      } catch (error) {
        this._events.emit("error", error);
        remainingItems.push(...queue.slice(i2));
        break;
      }
    }
    return {
      processedItems,
      remainingItems
    };
  }
  _getFetchOptions(p2) {
    const fetchOptions = {
      method: p2.method,
      headers: {
        "Content-Type": "application/json",
        "X-Langfuse-Sdk-Name": "langfuse-js",
        "X-Langfuse-Sdk-Version": this.getLibraryVersion(),
        "X-Langfuse-Sdk-Variant": this.getLibraryId(),
        "X-Langfuse-Sdk-Integration": this.sdkIntegration,
        "X-Langfuse-Public-Key": this.publicKey,
        ...this.additionalHeaders,
        ...this.constructAuthorizationHeader(this.publicKey, this.secretKey)
      },
      body: p2.body,
      ...p2.fetchTimeout !== void 0 ? {
        signal: AbortSignal.timeout(p2.fetchTimeout)
      } : {}
    };
    return fetchOptions;
  }
  constructAuthorizationHeader(publicKey, secretKey) {
    if (secretKey === void 0) {
      return {
        Authorization: "Bearer " + publicKey
      };
    } else {
      const encodedCredentials = typeof btoa === "function" ? (
        // btoa() is available, the code is running in a browser or edge environment
        btoa(publicKey + ":" + secretKey)
      ) : (
        // btoa() is not available, the code is running in Node.js
        Buffer.from(publicKey + ":" + secretKey).toString("base64")
      );
      return {
        Authorization: "Basic " + encodedCredentials
      };
    }
  }
  async fetchWithRetry(url, options, retryOptions) {
    AbortSignal.timeout ??= function timeout(ms) {
      const ctrl = new AbortController();
      setTimeout(() => ctrl.abort(), ms);
      return ctrl.signal;
    };
    return await retriable(async () => {
      let res = null;
      try {
        res = await this.fetch(url, {
          signal: AbortSignal.timeout(this.requestTimeout),
          ...options
        });
      } catch (e2) {
        throw new LangfuseFetchNetworkError(e2);
      }
      if (res.status < 200 || res.status >= 400) {
        const body = await res.json();
        throw new LangfuseFetchHttpError(res, JSON.stringify(body));
      }
      const returnBody = await res.json();
      if (res.status === 207 && returnBody.errors.length > 0) {
        throw new LangfuseFetchHttpError(res, JSON.stringify(returnBody.errors));
      }
      return res;
    }, {
      ...this._retryOptions,
      ...retryOptions
    }, (string2) => this._events.emit("retry", string2 + ", " + url + ", " + JSON.stringify(options)));
  }
  async fetchAndLogErrors(url, options) {
    const res = await this.fetch(url, options);
    const data = res.status === 429 ? await res.text() : await res.json();
    if (res.status < 200 || res.status >= 400) {
      logIngestionError(new LangfuseFetchHttpError(res, JSON.stringify(data)));
    }
    return data;
  }
  async shutdownAsync() {
    clearTimeout(this._flushTimer);
    try {
      await this.flushAsync();
      await Promise.all(Object.values(this.pendingIngestionPromises).map((x2) => x2.catch(() => {
      })));
      await this.flushAsync();
    } catch (e2) {
      console.error("[Langfuse SDK] Error while shutting down Langfuse", e2);
    }
  }
  async _exportLocalEvents(projectId) {
    if (this.isLocalEventExportEnabled) {
      clearTimeout(this._flushTimer);
      await this.flushAsync();
      const events = this.localEventExportMap.get(projectId) ?? [];
      this.localEventExportMap.delete(projectId);
      return events;
    } else {
      this._events.emit("error", "Local event exports are disabled, but _exportLocalEvents() was called.");
      return [];
    }
  }
  shutdown() {
    console.warn("shutdown() is deprecated. It does not wait for all events to be processed. Please use shutdownAsync() instead.");
    void this.shutdownAsync();
  }
  async awaitAllQueuedAndPendingRequests() {
    clearTimeout(this._flushTimer);
    await this.flushAsync();
    await Promise.all(Object.values(this.pendingIngestionPromises));
  }
};
var LangfuseCore = class extends LangfuseCoreStateless {
  constructor(params) {
    const {
      publicKey,
      secretKey,
      enabled,
      _isLocalEventExportEnabled
    } = params;
    let isObservabilityEnabled = enabled === false ? false : true;
    if (_isLocalEventExportEnabled) {
      isObservabilityEnabled = true;
    } else if (!secretKey) {
      isObservabilityEnabled = false;
      if (enabled !== false) {
        console.warn("Langfuse secret key was not passed to constructor or not set as 'LANGFUSE_SECRET_KEY' environment variable. No observability data will be sent to Langfuse.");
      }
    } else if (!publicKey) {
      isObservabilityEnabled = false;
      if (enabled !== false) {
        console.warn("Langfuse public key was not passed to constructor or not set as 'LANGFUSE_PUBLIC_KEY' environment variable. No observability data will be sent to Langfuse.");
      }
    }
    super({
      ...params,
      enabled: isObservabilityEnabled
    });
    this._promptCache = new LangfusePromptCache();
  }
  trace(body) {
    const id = this.traceStateless(body ?? {});
    const t2 = new LangfuseTraceClient(this, id);
    if (getEnv2("DEFER") && body) {
      try {
        const deferRuntime = getEnv2("__deferRuntime");
        if (deferRuntime) {
          deferRuntime.langfuseTraces([{
            id,
            name: body.name || "",
            url: t2.getTraceUrl()
          }]);
        }
      } catch {
      }
    }
    return t2;
  }
  span(body) {
    const traceId = body.traceId || this.traceStateless({
      name: body.name
    });
    const id = this.spanStateless({
      ...body,
      traceId
    });
    return new LangfuseSpanClient(this, id, traceId);
  }
  generation(body) {
    const traceId = body.traceId || this.traceStateless({
      name: body.name
    });
    const id = this.generationStateless({
      ...body,
      traceId
    });
    return new LangfuseGenerationClient(this, id, traceId);
  }
  event(body) {
    const traceId = body.traceId || this.traceStateless({
      name: body.name
    });
    const id = this.eventStateless({
      ...body,
      traceId
    });
    return new LangfuseEventClient(this, id, traceId);
  }
  score(body) {
    this.scoreStateless(body);
    return this;
  }
  async getDataset(name, options) {
    const dataset = await this._getDataset(name);
    const items = [];
    let page = 1;
    while (true) {
      const itemsResponse = await this._getDatasetItems({
        datasetName: name,
        limit: options?.fetchItemsPageSize ?? 50,
        page
      });
      items.push(...itemsResponse.data);
      if (itemsResponse.meta.totalPages <= page) {
        break;
      }
      page++;
    }
    const returnDataset = {
      ...dataset,
      description: dataset.description ?? void 0,
      metadata: dataset.metadata ?? void 0,
      items: items.map((item) => ({
        ...item,
        link: async (obj, runName, runArgs) => {
          await this.awaitAllQueuedAndPendingRequests();
          const data = await this.createDatasetRunItem({
            runName,
            datasetItemId: item.id,
            observationId: obj.observationId,
            traceId: obj.traceId,
            runDescription: runArgs?.description,
            metadata: runArgs?.metadata
          });
          return data;
        }
      }))
    };
    return returnDataset;
  }
  async createPrompt(body) {
    const labels = body.labels ?? [];
    const promptResponse = body.type === "chat" ? await this.createPromptStateless({
      ...body,
      prompt: body.prompt.map((item) => {
        if ("type" in item && item.type === ChatMessageType.Placeholder) {
          return {
            type: ChatMessageType.Placeholder,
            name: item.name
          };
        } else {
          return {
            type: ChatMessageType.ChatMessage,
            ...item
          };
        }
      }),
      labels: body.isActive ? [.../* @__PURE__ */ new Set([...labels, "production"])] : labels
      // backward compatibility for isActive
    }) : await this.createPromptStateless({
      ...body,
      type: body.type ?? "text",
      labels: body.isActive ? [.../* @__PURE__ */ new Set([...labels, "production"])] : labels
      // backward compatibility for isActive
    });
    if (promptResponse.type === "chat") {
      return new ChatPromptClient(promptResponse);
    }
    return new TextPromptClient(promptResponse);
  }
  async updatePrompt(body) {
    const newPrompt = await this.updatePromptStateless(body);
    this._promptCache.invalidate(body.name);
    return newPrompt;
  }
  async getPrompt(name, version2, options) {
    const cacheKey = this._getPromptCacheKey({
      name,
      version: version2,
      label: options?.label
    });
    const cachedPrompt = this._promptCache.getIncludingExpired(cacheKey);
    if (!cachedPrompt || options?.cacheTtlSeconds === 0) {
      try {
        return await this._fetchPromptAndUpdateCache({
          name,
          version: version2,
          label: options?.label,
          cacheTtlSeconds: options?.cacheTtlSeconds,
          maxRetries: options?.maxRetries,
          fetchTimeout: options?.fetchTimeoutMs
        });
      } catch (err3) {
        if (options?.fallback) {
          const sharedFallbackParams = {
            name,
            version: version2 ?? 0,
            labels: options.label ? [options.label] : [],
            cacheTtlSeconds: options?.cacheTtlSeconds,
            config: {},
            tags: []
          };
          if (options.type === "chat") {
            return new ChatPromptClient({
              ...sharedFallbackParams,
              type: "chat",
              prompt: options.fallback.map((msg) => ({
                type: ChatMessageType.ChatMessage,
                ...msg
              }))
            }, true);
          } else {
            return new TextPromptClient({
              ...sharedFallbackParams,
              type: "text",
              prompt: options.fallback
            }, true);
          }
        }
        throw err3;
      }
    }
    if (cachedPrompt.isExpired) {
      if (!this._promptCache.isRefreshing(cacheKey)) {
        const refreshPromptPromise = this._fetchPromptAndUpdateCache({
          name,
          version: version2,
          label: options?.label,
          cacheTtlSeconds: options?.cacheTtlSeconds,
          maxRetries: options?.maxRetries,
          fetchTimeout: options?.fetchTimeoutMs
        }).catch(() => {
          console.warn(`Failed to refresh prompt cache '${cacheKey}', stale cache will be used until next refresh succeeds.`);
        });
        this._promptCache.addRefreshingPromise(cacheKey, refreshPromptPromise);
      }
      return cachedPrompt.value;
    }
    return cachedPrompt.value;
  }
  _getPromptCacheKey(params) {
    const {
      name,
      version: version2,
      label
    } = params;
    const parts = [name];
    if (version2 !== void 0) {
      parts.push("version:" + version2.toString());
    } else if (label !== void 0) {
      parts.push("label:" + label);
    } else {
      parts.push("label:production");
    }
    return parts.join("-");
  }
  async _fetchPromptAndUpdateCache(params) {
    const cacheKey = this._getPromptCacheKey(params);
    try {
      const {
        name,
        version: version2,
        cacheTtlSeconds,
        label,
        maxRetries,
        fetchTimeout
      } = params;
      const {
        data,
        fetchResult
      } = await this.getPromptStateless(name, version2, label, maxRetries, fetchTimeout);
      if (fetchResult === "failure") {
        throw Error(data.message ?? "Internal error while fetching prompt");
      }
      let prompt;
      if (data.type === "chat") {
        prompt = new ChatPromptClient(data);
      } else {
        prompt = new TextPromptClient(data);
      }
      this._promptCache.set(cacheKey, prompt, cacheTtlSeconds);
      return prompt;
    } catch (error) {
      console.error(`[Langfuse SDK] Error while fetching prompt '${cacheKey}':`, error);
      throw error;
    }
  }
  async fetchMedia(id) {
    return await this._fetchMedia(id);
  }
  /**
   * Replaces the media reference strings in an object with base64 data URIs for the media content.
   *
   * This method recursively traverses an object (up to a maximum depth of 10) looking for media reference strings
   * in the format "@@@langfuseMedia:...@@@". When found, it fetches the actual media content using the provided
   * Langfuse client and replaces the reference string with a base64 data URI.
   *
   * If fetching media content fails for a reference string, a warning is logged and the reference string is left unchanged.
   *
   * @param params - Configuration object
   * @param params.obj - The object to process. Can be a primitive value, array, or nested object
   * @param params.langfuseClient - Langfuse client instance used to fetch media content
   * @param params.resolveWith - The representation of the media content to replace the media reference string with. Currently only "base64DataUri" is supported.
   * @param params.maxDepth - Optional. Default is 10. The maximum depth to traverse the object.
   *
   * @returns A deep copy of the input object with all media references replaced with base64 data URIs where possible
   *
   * @example
   * ```typescript
   * const obj = {
   *   image: "@@@langfuseMedia:type=image/jpeg|id=123|source=bytes@@@",
   *   nested: {
   *     pdf: "@@@langfuseMedia:type=application/pdf|id=456|source=bytes@@@"
   *   }
   * };
   *
   * const result = await LangfuseMedia.resolveMediaReferences({
   *   obj,
   *   langfuseClient
   * });
   *
   * // Result:
   * // {
   * //   image: "data:image/jpeg;base64,/9j/4AAQSkZJRg...",
   * //   nested: {
   * //     pdf: "data:application/pdf;base64,JVBERi0xLjcK..."
   * //   }
   * // }
   * ```
   */
  async resolveMediaReferences(params) {
    const {
      obj,
      ...rest
    } = params;
    return LangfuseMedia.resolveMediaReferences({
      ...rest,
      langfuseClient: this,
      obj
    });
  }
  _updateSpan(body) {
    this.updateSpanStateless(body);
    return this;
  }
  _updateGeneration(body) {
    this.updateGenerationStateless(body);
    return this;
  }
};
var LangfuseObjectClient = class {
  constructor({
    client,
    id,
    traceId,
    observationId
  }) {
    this.client = client;
    this.id = id;
    this.traceId = traceId;
    this.observationId = observationId;
  }
  event(body) {
    return this.client.event({
      ...body,
      traceId: this.traceId,
      parentObservationId: this.observationId
    });
  }
  span(body) {
    return this.client.span({
      ...body,
      traceId: this.traceId,
      parentObservationId: this.observationId
    });
  }
  generation(body) {
    return this.client.generation({
      ...body,
      traceId: this.traceId,
      parentObservationId: this.observationId
    });
  }
  score(body) {
    this.client.score({
      ...body,
      traceId: this.traceId,
      observationId: this.observationId
    });
    return this;
  }
  getTraceUrl() {
    return `${this.client.baseUrl}/trace/${this.traceId}`;
  }
};
var LangfuseTraceClient = class extends LangfuseObjectClient {
  constructor(client, traceId) {
    super({
      client,
      id: traceId,
      traceId,
      observationId: null
    });
  }
  update(body) {
    this.client.trace({
      ...body,
      id: this.id
    });
    return this;
  }
};
var LangfuseObservationClient = class extends LangfuseObjectClient {
  constructor(client, id, traceId) {
    super({
      client,
      id,
      traceId,
      observationId: id
    });
  }
};
var LangfuseSpanClient = class extends LangfuseObservationClient {
  constructor(client, id, traceId) {
    super(client, id, traceId);
  }
  update(body) {
    this.client._updateSpan({
      ...body,
      id: this.id,
      traceId: this.traceId
    });
    return this;
  }
  end(body) {
    this.client._updateSpan({
      ...body,
      id: this.id,
      traceId: this.traceId,
      endTime: /* @__PURE__ */ new Date()
    });
    return this;
  }
};
var LangfuseGenerationClient = class extends LangfuseObservationClient {
  constructor(client, id, traceId) {
    super(client, id, traceId);
  }
  update(body) {
    this.client._updateGeneration({
      ...body,
      id: this.id,
      traceId: this.traceId
    });
    return this;
  }
  end(body) {
    this.client._updateGeneration({
      ...body,
      id: this.id,
      traceId: this.traceId,
      endTime: /* @__PURE__ */ new Date()
    });
    return this;
  }
};
var LangfuseEventClient = class extends LangfuseObservationClient {
  constructor(client, id, traceId) {
    super(client, id, traceId);
  }
};

// ../../../node_modules/.pnpm/langfuse@3.38.0/node_modules/langfuse/lib/index.mjs
var cookieStore = {
  getItem(key) {
    try {
      const nameEQ = key + "=";
      const ca = document.cookie.split(";");
      for (let i2 = 0; i2 < ca.length; i2++) {
        let c2 = ca[i2];
        while (c2.charAt(0) == " ") {
          c2 = c2.substring(1, c2.length);
        }
        if (c2.indexOf(nameEQ) === 0) {
          return decodeURIComponent(c2.substring(nameEQ.length, c2.length));
        }
      }
    } catch (err3) {
    }
    return null;
  },
  setItem(key, value) {
    try {
      const cdomain = "", expires = "", secure = "";
      const new_cookie_val = key + "=" + encodeURIComponent(value) + expires + "; path=/" + cdomain + secure;
      document.cookie = new_cookie_val;
    } catch (err3) {
      return;
    }
  },
  removeItem(name) {
    try {
      cookieStore.setItem(name, "");
    } catch (err3) {
      return;
    }
  },
  clear() {
    document.cookie = "";
  },
  getAllKeys() {
    const ca = document.cookie.split(";");
    const keys = [];
    for (let i2 = 0; i2 < ca.length; i2++) {
      let c2 = ca[i2];
      while (c2.charAt(0) == " ") {
        c2 = c2.substring(1, c2.length);
      }
      keys.push(c2.split("=")[0]);
    }
    return keys;
  }
};
var createStorageLike = (store6) => {
  return {
    getItem(key) {
      return store6.getItem(key);
    },
    setItem(key, value) {
      store6.setItem(key, value);
    },
    removeItem(key) {
      store6.removeItem(key);
    },
    clear() {
      store6.clear();
    },
    getAllKeys() {
      const keys = [];
      for (const key in localStorage) {
        keys.push(key);
      }
      return keys;
    }
  };
};
var checkStoreIsSupported = (storage, key = "__mplssupport__") => {
  if (!window) {
    return false;
  }
  try {
    const val = "xyz";
    storage.setItem(key, val);
    if (storage.getItem(key) !== val) {
      return false;
    }
    storage.removeItem(key);
    return true;
  } catch (err3) {
    return false;
  }
};
var localStore = void 0;
var sessionStore = void 0;
var createMemoryStorage = () => {
  const _cache = {};
  const store6 = {
    getItem(key) {
      return _cache[key];
    },
    setItem(key, value) {
      _cache[key] = value !== null ? value : void 0;
    },
    removeItem(key) {
      delete _cache[key];
    },
    clear() {
      for (const key in _cache) {
        delete _cache[key];
      }
    },
    getAllKeys() {
      const keys = [];
      for (const key in _cache) {
        keys.push(key);
      }
      return keys;
    }
  };
  return store6;
};
var getStorage = (type, window2) => {
  if (typeof window2 !== void 0 && window2) {
    if (!localStorage) {
      const _localStore = createStorageLike(window2.localStorage);
      localStore = checkStoreIsSupported(_localStore) ? _localStore : void 0;
    }
    if (!sessionStore) {
      const _sessionStore = createStorageLike(window2.sessionStorage);
      sessionStore = checkStoreIsSupported(_sessionStore) ? _sessionStore : void 0;
    }
  }
  switch (type) {
    case "cookie":
      return cookieStore || localStore || sessionStore || createMemoryStorage();
    case "localStorage":
      return localStore || sessionStore || createMemoryStorage();
    case "sessionStorage":
      return sessionStore || createMemoryStorage();
    case "memory":
      return createMemoryStorage();
    default:
      return createMemoryStorage();
  }
};
var ContentType;
(function(ContentType2) {
  ContentType2["Json"] = "application/json";
  ContentType2["FormData"] = "multipart/form-data";
  ContentType2["UrlEncoded"] = "application/x-www-form-urlencoded";
  ContentType2["Text"] = "text/plain";
})(ContentType || (ContentType = {}));
var HttpClient = class {
  constructor(apiConfig = {}) {
    this.baseUrl = "";
    this.securityData = null;
    this.abortControllers = /* @__PURE__ */ new Map();
    this.customFetch = (...fetchParams) => fetch(...fetchParams);
    this.baseApiParams = {
      credentials: "same-origin",
      headers: {},
      redirect: "follow",
      referrerPolicy: "no-referrer"
    };
    this.setSecurityData = (data) => {
      this.securityData = data;
    };
    this.contentFormatters = {
      [ContentType.Json]: (input) => input !== null && (typeof input === "object" || typeof input === "string") ? JSON.stringify(input) : input,
      [ContentType.Text]: (input) => input !== null && typeof input !== "string" ? JSON.stringify(input) : input,
      [ContentType.FormData]: (input) => Object.keys(input || {}).reduce((formData, key) => {
        const property = input[key];
        formData.append(key, property instanceof Blob ? property : typeof property === "object" && property !== null ? JSON.stringify(property) : `${property}`);
        return formData;
      }, new FormData()),
      [ContentType.UrlEncoded]: (input) => this.toQueryString(input)
    };
    this.createAbortSignal = (cancelToken) => {
      if (this.abortControllers.has(cancelToken)) {
        const abortController2 = this.abortControllers.get(cancelToken);
        if (abortController2) {
          return abortController2.signal;
        }
        return void 0;
      }
      const abortController = new AbortController();
      this.abortControllers.set(cancelToken, abortController);
      return abortController.signal;
    };
    this.abortRequest = (cancelToken) => {
      const abortController = this.abortControllers.get(cancelToken);
      if (abortController) {
        abortController.abort();
        this.abortControllers.delete(cancelToken);
      }
    };
    this.request = async ({
      body,
      secure,
      path,
      type,
      query,
      format,
      baseUrl,
      cancelToken,
      ...params
    }) => {
      const secureParams = (typeof secure === "boolean" ? secure : this.baseApiParams.secure) && this.securityWorker && await this.securityWorker(this.securityData) || {};
      const requestParams = this.mergeRequestParams(params, secureParams);
      const queryString = query && this.toQueryString(query);
      const payloadFormatter = this.contentFormatters[type || ContentType.Json];
      const responseFormat = format || requestParams.format;
      return this.customFetch(`${baseUrl || this.baseUrl || ""}${path}${queryString ? `?${queryString}` : ""}`, {
        ...requestParams,
        headers: {
          ...requestParams.headers || {},
          ...type && type !== ContentType.FormData ? {
            "Content-Type": type
          } : {}
        },
        signal: (cancelToken ? this.createAbortSignal(cancelToken) : requestParams.signal) || null,
        body: typeof body === "undefined" || body === null ? null : payloadFormatter(body)
      }).then(async (response) => {
        const r2 = response.clone();
        r2.data = null;
        r2.error = null;
        const data = !responseFormat ? r2 : await response[responseFormat]().then((data2) => {
          if (r2.ok) {
            r2.data = data2;
          } else {
            r2.error = data2;
          }
          return r2;
        }).catch((e2) => {
          r2.error = e2;
          return r2;
        });
        if (cancelToken) {
          this.abortControllers.delete(cancelToken);
        }
        if (!response.ok) throw data;
        return data.data;
      });
    };
    Object.assign(this, apiConfig);
  }
  encodeQueryParam(key, value) {
    const encodedKey = encodeURIComponent(key);
    return `${encodedKey}=${encodeURIComponent(typeof value === "number" ? value : `${value}`)}`;
  }
  addQueryParam(query, key) {
    return this.encodeQueryParam(key, query[key]);
  }
  addArrayQueryParam(query, key) {
    const value = query[key];
    return value.map((v2) => this.encodeQueryParam(key, v2)).join("&");
  }
  toQueryString(rawQuery) {
    const query = rawQuery || {};
    const keys = Object.keys(query).filter((key) => "undefined" !== typeof query[key]);
    return keys.map((key) => Array.isArray(query[key]) ? this.addArrayQueryParam(query, key) : this.addQueryParam(query, key)).join("&");
  }
  addQueryParams(rawQuery) {
    const queryString = this.toQueryString(rawQuery);
    return queryString ? `?${queryString}` : "";
  }
  mergeRequestParams(params1, params2) {
    return {
      ...this.baseApiParams,
      ...params1,
      ...params2 || {},
      headers: {
        ...this.baseApiParams.headers || {},
        ...params1.headers || {},
        ...params2 && params2.headers || {}
      }
    };
  }
};
var LangfusePublicApi = class extends HttpClient {
  constructor() {
    super(...arguments);
    this.api = {
      /**
       * @description Add an item to an annotation queue
       *
       * @tags AnnotationQueues
       * @name AnnotationQueuesCreateQueueItem
       * @request POST:/api/public/annotation-queues/{queueId}/items
       * @secure
       */
      annotationQueuesCreateQueueItem: (queueId, data, params = {}) => this.request({
        path: `/api/public/annotation-queues/${queueId}/items`,
        method: "POST",
        body: data,
        secure: true,
        type: ContentType.Json,
        format: "json",
        ...params
      }),
      /**
       * @description Remove an item from an annotation queue
       *
       * @tags AnnotationQueues
       * @name AnnotationQueuesDeleteQueueItem
       * @request DELETE:/api/public/annotation-queues/{queueId}/items/{itemId}
       * @secure
       */
      annotationQueuesDeleteQueueItem: (queueId, itemId, params = {}) => this.request({
        path: `/api/public/annotation-queues/${queueId}/items/${itemId}`,
        method: "DELETE",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get an annotation queue by ID
       *
       * @tags AnnotationQueues
       * @name AnnotationQueuesGetQueue
       * @request GET:/api/public/annotation-queues/{queueId}
       * @secure
       */
      annotationQueuesGetQueue: (queueId, params = {}) => this.request({
        path: `/api/public/annotation-queues/${queueId}`,
        method: "GET",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get a specific item from an annotation queue
       *
       * @tags AnnotationQueues
       * @name AnnotationQueuesGetQueueItem
       * @request GET:/api/public/annotation-queues/{queueId}/items/{itemId}
       * @secure
       */
      annotationQueuesGetQueueItem: (queueId, itemId, params = {}) => this.request({
        path: `/api/public/annotation-queues/${queueId}/items/${itemId}`,
        method: "GET",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get items for a specific annotation queue
       *
       * @tags AnnotationQueues
       * @name AnnotationQueuesListQueueItems
       * @request GET:/api/public/annotation-queues/{queueId}/items
       * @secure
       */
      annotationQueuesListQueueItems: ({
        queueId,
        ...query
      }, params = {}) => this.request({
        path: `/api/public/annotation-queues/${queueId}/items`,
        method: "GET",
        query,
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get all annotation queues
       *
       * @tags AnnotationQueues
       * @name AnnotationQueuesListQueues
       * @request GET:/api/public/annotation-queues
       * @secure
       */
      annotationQueuesListQueues: (query, params = {}) => this.request({
        path: `/api/public/annotation-queues`,
        method: "GET",
        query,
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Update an annotation queue item
       *
       * @tags AnnotationQueues
       * @name AnnotationQueuesUpdateQueueItem
       * @request PATCH:/api/public/annotation-queues/{queueId}/items/{itemId}
       * @secure
       */
      annotationQueuesUpdateQueueItem: (queueId, itemId, data, params = {}) => this.request({
        path: `/api/public/annotation-queues/${queueId}/items/${itemId}`,
        method: "PATCH",
        body: data,
        secure: true,
        type: ContentType.Json,
        format: "json",
        ...params
      }),
      /**
       * @description Create a comment. Comments may be attached to different object types (trace, observation, session, prompt).
       *
       * @tags Comments
       * @name CommentsCreate
       * @request POST:/api/public/comments
       * @secure
       */
      commentsCreate: (data, params = {}) => this.request({
        path: `/api/public/comments`,
        method: "POST",
        body: data,
        secure: true,
        type: ContentType.Json,
        format: "json",
        ...params
      }),
      /**
       * @description Get all comments
       *
       * @tags Comments
       * @name CommentsGet
       * @request GET:/api/public/comments
       * @secure
       */
      commentsGet: (query, params = {}) => this.request({
        path: `/api/public/comments`,
        method: "GET",
        query,
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get a comment by id
       *
       * @tags Comments
       * @name CommentsGetById
       * @request GET:/api/public/comments/{commentId}
       * @secure
       */
      commentsGetById: (commentId, params = {}) => this.request({
        path: `/api/public/comments/${commentId}`,
        method: "GET",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Create a dataset item
       *
       * @tags DatasetItems
       * @name DatasetItemsCreate
       * @request POST:/api/public/dataset-items
       * @secure
       */
      datasetItemsCreate: (data, params = {}) => this.request({
        path: `/api/public/dataset-items`,
        method: "POST",
        body: data,
        secure: true,
        type: ContentType.Json,
        format: "json",
        ...params
      }),
      /**
       * @description Delete a dataset item and all its run items. This action is irreversible.
       *
       * @tags DatasetItems
       * @name DatasetItemsDelete
       * @request DELETE:/api/public/dataset-items/{id}
       * @secure
       */
      datasetItemsDelete: (id, params = {}) => this.request({
        path: `/api/public/dataset-items/${id}`,
        method: "DELETE",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get a dataset item
       *
       * @tags DatasetItems
       * @name DatasetItemsGet
       * @request GET:/api/public/dataset-items/{id}
       * @secure
       */
      datasetItemsGet: (id, params = {}) => this.request({
        path: `/api/public/dataset-items/${id}`,
        method: "GET",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get dataset items
       *
       * @tags DatasetItems
       * @name DatasetItemsList
       * @request GET:/api/public/dataset-items
       * @secure
       */
      datasetItemsList: (query, params = {}) => this.request({
        path: `/api/public/dataset-items`,
        method: "GET",
        query,
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Create a dataset run item
       *
       * @tags DatasetRunItems
       * @name DatasetRunItemsCreate
       * @request POST:/api/public/dataset-run-items
       * @secure
       */
      datasetRunItemsCreate: (data, params = {}) => this.request({
        path: `/api/public/dataset-run-items`,
        method: "POST",
        body: data,
        secure: true,
        type: ContentType.Json,
        format: "json",
        ...params
      }),
      /**
       * @description List dataset run items
       *
       * @tags DatasetRunItems
       * @name DatasetRunItemsList
       * @request GET:/api/public/dataset-run-items
       * @secure
       */
      datasetRunItemsList: (query, params = {}) => this.request({
        path: `/api/public/dataset-run-items`,
        method: "GET",
        query,
        secure: true,
        ...params
      }),
      /**
       * @description Create a dataset
       *
       * @tags Datasets
       * @name DatasetsCreate
       * @request POST:/api/public/v2/datasets
       * @secure
       */
      datasetsCreate: (data, params = {}) => this.request({
        path: `/api/public/v2/datasets`,
        method: "POST",
        body: data,
        secure: true,
        type: ContentType.Json,
        format: "json",
        ...params
      }),
      /**
       * @description Delete a dataset run and all its run items. This action is irreversible.
       *
       * @tags Datasets
       * @name DatasetsDeleteRun
       * @request DELETE:/api/public/datasets/{datasetName}/runs/{runName}
       * @secure
       */
      datasetsDeleteRun: (datasetName, runName, params = {}) => this.request({
        path: `/api/public/datasets/${datasetName}/runs/${runName}`,
        method: "DELETE",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get a dataset
       *
       * @tags Datasets
       * @name DatasetsGet
       * @request GET:/api/public/v2/datasets/{datasetName}
       * @secure
       */
      datasetsGet: (datasetName, params = {}) => this.request({
        path: `/api/public/v2/datasets/${datasetName}`,
        method: "GET",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get a dataset run and its items
       *
       * @tags Datasets
       * @name DatasetsGetRun
       * @request GET:/api/public/datasets/{datasetName}/runs/{runName}
       * @secure
       */
      datasetsGetRun: (datasetName, runName, params = {}) => this.request({
        path: `/api/public/datasets/${datasetName}/runs/${runName}`,
        method: "GET",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get dataset runs
       *
       * @tags Datasets
       * @name DatasetsGetRuns
       * @request GET:/api/public/datasets/{datasetName}/runs
       * @secure
       */
      datasetsGetRuns: ({
        datasetName,
        ...query
      }, params = {}) => this.request({
        path: `/api/public/datasets/${datasetName}/runs`,
        method: "GET",
        query,
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get all datasets
       *
       * @tags Datasets
       * @name DatasetsList
       * @request GET:/api/public/v2/datasets
       * @secure
       */
      datasetsList: (query, params = {}) => this.request({
        path: `/api/public/v2/datasets`,
        method: "GET",
        query,
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Check health of API and database
       *
       * @tags Health
       * @name HealthHealth
       * @request GET:/api/public/health
       */
      healthHealth: (params = {}) => this.request({
        path: `/api/public/health`,
        method: "GET",
        format: "json",
        ...params
      }),
      /**
       * @description Batched ingestion for Langfuse Tracing. If you want to use tracing via the API, such as to build your own Langfuse client implementation, this is the only API route you need to implement. Within each batch, there can be multiple events. Each event has a type, an id, a timestamp, metadata and a body. Internally, we refer to this as the "event envelope" as it tells us something about the event but not the trace. We use the event id within this envelope to deduplicate messages to avoid processing the same event twice, i.e. the event id should be unique per request. The event.body.id is the ID of the actual trace and will be used for updates and will be visible within the Langfuse App. I.e. if you want to update a trace, you'd use the same body id, but separate event IDs. Notes: - Introduction to data model: https://langfuse.com/docs/tracing-data-model - Batch sizes are limited to 3.5 MB in total. You need to adjust the number of events per batch accordingly. - The API does not return a 4xx status code for input errors. Instead, it responds with a 207 status code, which includes a list of the encountered errors.
       *
       * @tags Ingestion
       * @name IngestionBatch
       * @request POST:/api/public/ingestion
       * @secure
       */
      ingestionBatch: (data, params = {}) => this.request({
        path: `/api/public/ingestion`,
        method: "POST",
        body: data,
        secure: true,
        type: ContentType.Json,
        format: "json",
        ...params
      }),
      /**
       * @description Get a media record
       *
       * @tags Media
       * @name MediaGet
       * @request GET:/api/public/media/{mediaId}
       * @secure
       */
      mediaGet: (mediaId, params = {}) => this.request({
        path: `/api/public/media/${mediaId}`,
        method: "GET",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get a presigned upload URL for a media record
       *
       * @tags Media
       * @name MediaGetUploadUrl
       * @request POST:/api/public/media
       * @secure
       */
      mediaGetUploadUrl: (data, params = {}) => this.request({
        path: `/api/public/media`,
        method: "POST",
        body: data,
        secure: true,
        type: ContentType.Json,
        format: "json",
        ...params
      }),
      /**
       * @description Patch a media record
       *
       * @tags Media
       * @name MediaPatch
       * @request PATCH:/api/public/media/{mediaId}
       * @secure
       */
      mediaPatch: (mediaId, data, params = {}) => this.request({
        path: `/api/public/media/${mediaId}`,
        method: "PATCH",
        body: data,
        secure: true,
        type: ContentType.Json,
        ...params
      }),
      /**
       * @description Get metrics from the Langfuse project using a query object
       *
       * @tags Metrics
       * @name MetricsMetrics
       * @request GET:/api/public/metrics
       * @secure
       */
      metricsMetrics: (query, params = {}) => this.request({
        path: `/api/public/metrics`,
        method: "GET",
        query,
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Create a model
       *
       * @tags Models
       * @name ModelsCreate
       * @request POST:/api/public/models
       * @secure
       */
      modelsCreate: (data, params = {}) => this.request({
        path: `/api/public/models`,
        method: "POST",
        body: data,
        secure: true,
        type: ContentType.Json,
        format: "json",
        ...params
      }),
      /**
       * @description Delete a model. Cannot delete models managed by Langfuse. You can create your own definition with the same modelName to override the definition though.
       *
       * @tags Models
       * @name ModelsDelete
       * @request DELETE:/api/public/models/{id}
       * @secure
       */
      modelsDelete: (id, params = {}) => this.request({
        path: `/api/public/models/${id}`,
        method: "DELETE",
        secure: true,
        ...params
      }),
      /**
       * @description Get a model
       *
       * @tags Models
       * @name ModelsGet
       * @request GET:/api/public/models/{id}
       * @secure
       */
      modelsGet: (id, params = {}) => this.request({
        path: `/api/public/models/${id}`,
        method: "GET",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get all models
       *
       * @tags Models
       * @name ModelsList
       * @request GET:/api/public/models
       * @secure
       */
      modelsList: (query, params = {}) => this.request({
        path: `/api/public/models`,
        method: "GET",
        query,
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get a observation
       *
       * @tags Observations
       * @name ObservationsGet
       * @request GET:/api/public/observations/{observationId}
       * @secure
       */
      observationsGet: (observationId, params = {}) => this.request({
        path: `/api/public/observations/${observationId}`,
        method: "GET",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get a list of observations
       *
       * @tags Observations
       * @name ObservationsGetMany
       * @request GET:/api/public/observations
       * @secure
       */
      observationsGetMany: (query, params = {}) => this.request({
        path: `/api/public/observations`,
        method: "GET",
        query,
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get all memberships for the organization associated with the API key (requires organization-scoped API key)
       *
       * @tags Organizations
       * @name OrganizationsGetOrganizationMemberships
       * @request GET:/api/public/organizations/memberships
       * @secure
       */
      organizationsGetOrganizationMemberships: (params = {}) => this.request({
        path: `/api/public/organizations/memberships`,
        method: "GET",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get all projects for the organization associated with the API key (requires organization-scoped API key)
       *
       * @tags Organizations
       * @name OrganizationsGetOrganizationProjects
       * @request GET:/api/public/organizations/projects
       * @secure
       */
      organizationsGetOrganizationProjects: (params = {}) => this.request({
        path: `/api/public/organizations/projects`,
        method: "GET",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get all memberships for a specific project (requires organization-scoped API key)
       *
       * @tags Organizations
       * @name OrganizationsGetProjectMemberships
       * @request GET:/api/public/projects/{projectId}/memberships
       * @secure
       */
      organizationsGetProjectMemberships: (projectId, params = {}) => this.request({
        path: `/api/public/projects/${projectId}/memberships`,
        method: "GET",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Create or update a membership for the organization associated with the API key (requires organization-scoped API key)
       *
       * @tags Organizations
       * @name OrganizationsUpdateOrganizationMembership
       * @request PUT:/api/public/organizations/memberships
       * @secure
       */
      organizationsUpdateOrganizationMembership: (data, params = {}) => this.request({
        path: `/api/public/organizations/memberships`,
        method: "PUT",
        body: data,
        secure: true,
        type: ContentType.Json,
        format: "json",
        ...params
      }),
      /**
       * @description Create or update a membership for a specific project (requires organization-scoped API key). The user must already be a member of the organization.
       *
       * @tags Organizations
       * @name OrganizationsUpdateProjectMembership
       * @request PUT:/api/public/projects/{projectId}/memberships
       * @secure
       */
      organizationsUpdateProjectMembership: (projectId, data, params = {}) => this.request({
        path: `/api/public/projects/${projectId}/memberships`,
        method: "PUT",
        body: data,
        secure: true,
        type: ContentType.Json,
        format: "json",
        ...params
      }),
      /**
       * @description Create a new project (requires organization-scoped API key)
       *
       * @tags Projects
       * @name ProjectsCreate
       * @request POST:/api/public/projects
       * @secure
       */
      projectsCreate: (data, params = {}) => this.request({
        path: `/api/public/projects`,
        method: "POST",
        body: data,
        secure: true,
        type: ContentType.Json,
        format: "json",
        ...params
      }),
      /**
       * @description Create a new API key for a project (requires organization-scoped API key)
       *
       * @tags Projects
       * @name ProjectsCreateApiKey
       * @request POST:/api/public/projects/{projectId}/apiKeys
       * @secure
       */
      projectsCreateApiKey: (projectId, data, params = {}) => this.request({
        path: `/api/public/projects/${projectId}/apiKeys`,
        method: "POST",
        body: data,
        secure: true,
        type: ContentType.Json,
        format: "json",
        ...params
      }),
      /**
       * @description Delete a project by ID (requires organization-scoped API key). Project deletion is processed asynchronously.
       *
       * @tags Projects
       * @name ProjectsDelete
       * @request DELETE:/api/public/projects/{projectId}
       * @secure
       */
      projectsDelete: (projectId, params = {}) => this.request({
        path: `/api/public/projects/${projectId}`,
        method: "DELETE",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Delete an API key for a project (requires organization-scoped API key)
       *
       * @tags Projects
       * @name ProjectsDeleteApiKey
       * @request DELETE:/api/public/projects/{projectId}/apiKeys/{apiKeyId}
       * @secure
       */
      projectsDeleteApiKey: (projectId, apiKeyId, params = {}) => this.request({
        path: `/api/public/projects/${projectId}/apiKeys/${apiKeyId}`,
        method: "DELETE",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get Project associated with API key
       *
       * @tags Projects
       * @name ProjectsGet
       * @request GET:/api/public/projects
       * @secure
       */
      projectsGet: (params = {}) => this.request({
        path: `/api/public/projects`,
        method: "GET",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get all API keys for a project (requires organization-scoped API key)
       *
       * @tags Projects
       * @name ProjectsGetApiKeys
       * @request GET:/api/public/projects/{projectId}/apiKeys
       * @secure
       */
      projectsGetApiKeys: (projectId, params = {}) => this.request({
        path: `/api/public/projects/${projectId}/apiKeys`,
        method: "GET",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Update a project by ID (requires organization-scoped API key).
       *
       * @tags Projects
       * @name ProjectsUpdate
       * @request PUT:/api/public/projects/{projectId}
       * @secure
       */
      projectsUpdate: (projectId, data, params = {}) => this.request({
        path: `/api/public/projects/${projectId}`,
        method: "PUT",
        body: data,
        secure: true,
        type: ContentType.Json,
        format: "json",
        ...params
      }),
      /**
       * @description Create a new version for the prompt with the given `name`
       *
       * @tags Prompts
       * @name PromptsCreate
       * @request POST:/api/public/v2/prompts
       * @secure
       */
      promptsCreate: (data, params = {}) => this.request({
        path: `/api/public/v2/prompts`,
        method: "POST",
        body: data,
        secure: true,
        type: ContentType.Json,
        format: "json",
        ...params
      }),
      /**
       * @description Get a prompt
       *
       * @tags Prompts
       * @name PromptsGet
       * @request GET:/api/public/v2/prompts/{promptName}
       * @secure
       */
      promptsGet: ({
        promptName,
        ...query
      }, params = {}) => this.request({
        path: `/api/public/v2/prompts/${promptName}`,
        method: "GET",
        query,
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get a list of prompt names with versions and labels
       *
       * @tags Prompts
       * @name PromptsList
       * @request GET:/api/public/v2/prompts
       * @secure
       */
      promptsList: (query, params = {}) => this.request({
        path: `/api/public/v2/prompts`,
        method: "GET",
        query,
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Update labels for a specific prompt version
       *
       * @tags PromptVersion
       * @name PromptVersionUpdate
       * @request PATCH:/api/public/v2/prompts/{name}/versions/{version}
       * @secure
       */
      promptVersionUpdate: (name, version2, data, params = {}) => this.request({
        path: `/api/public/v2/prompts/${name}/versions/${version2}`,
        method: "PATCH",
        body: data,
        secure: true,
        type: ContentType.Json,
        format: "json",
        ...params
      }),
      /**
       * @description Create a new user in the organization (requires organization-scoped API key)
       *
       * @tags Scim
       * @name ScimCreateUser
       * @request POST:/api/public/scim/Users
       * @secure
       */
      scimCreateUser: (data, params = {}) => this.request({
        path: `/api/public/scim/Users`,
        method: "POST",
        body: data,
        secure: true,
        type: ContentType.Json,
        format: "json",
        ...params
      }),
      /**
       * @description Remove a user from the organization (requires organization-scoped API key). Note that this only removes the user from the organization but does not delete the user entity itself.
       *
       * @tags Scim
       * @name ScimDeleteUser
       * @request DELETE:/api/public/scim/Users/{userId}
       * @secure
       */
      scimDeleteUser: (userId, params = {}) => this.request({
        path: `/api/public/scim/Users/${userId}`,
        method: "DELETE",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get SCIM Resource Types (requires organization-scoped API key)
       *
       * @tags Scim
       * @name ScimGetResourceTypes
       * @request GET:/api/public/scim/ResourceTypes
       * @secure
       */
      scimGetResourceTypes: (params = {}) => this.request({
        path: `/api/public/scim/ResourceTypes`,
        method: "GET",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get SCIM Schemas (requires organization-scoped API key)
       *
       * @tags Scim
       * @name ScimGetSchemas
       * @request GET:/api/public/scim/Schemas
       * @secure
       */
      scimGetSchemas: (params = {}) => this.request({
        path: `/api/public/scim/Schemas`,
        method: "GET",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get SCIM Service Provider Configuration (requires organization-scoped API key)
       *
       * @tags Scim
       * @name ScimGetServiceProviderConfig
       * @request GET:/api/public/scim/ServiceProviderConfig
       * @secure
       */
      scimGetServiceProviderConfig: (params = {}) => this.request({
        path: `/api/public/scim/ServiceProviderConfig`,
        method: "GET",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get a specific user by ID (requires organization-scoped API key)
       *
       * @tags Scim
       * @name ScimGetUser
       * @request GET:/api/public/scim/Users/{userId}
       * @secure
       */
      scimGetUser: (userId, params = {}) => this.request({
        path: `/api/public/scim/Users/${userId}`,
        method: "GET",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description List users in the organization (requires organization-scoped API key)
       *
       * @tags Scim
       * @name ScimListUsers
       * @request GET:/api/public/scim/Users
       * @secure
       */
      scimListUsers: (query, params = {}) => this.request({
        path: `/api/public/scim/Users`,
        method: "GET",
        query,
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Create a score configuration (config). Score configs are used to define the structure of scores
       *
       * @tags ScoreConfigs
       * @name ScoreConfigsCreate
       * @request POST:/api/public/score-configs
       * @secure
       */
      scoreConfigsCreate: (data, params = {}) => this.request({
        path: `/api/public/score-configs`,
        method: "POST",
        body: data,
        secure: true,
        type: ContentType.Json,
        format: "json",
        ...params
      }),
      /**
       * @description Get all score configs
       *
       * @tags ScoreConfigs
       * @name ScoreConfigsGet
       * @request GET:/api/public/score-configs
       * @secure
       */
      scoreConfigsGet: (query, params = {}) => this.request({
        path: `/api/public/score-configs`,
        method: "GET",
        query,
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get a score config
       *
       * @tags ScoreConfigs
       * @name ScoreConfigsGetById
       * @request GET:/api/public/score-configs/{configId}
       * @secure
       */
      scoreConfigsGetById: (configId, params = {}) => this.request({
        path: `/api/public/score-configs/${configId}`,
        method: "GET",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Create a score (supports both trace and session scores)
       *
       * @tags Score
       * @name ScoreCreate
       * @request POST:/api/public/scores
       * @secure
       */
      scoreCreate: (data, params = {}) => this.request({
        path: `/api/public/scores`,
        method: "POST",
        body: data,
        secure: true,
        type: ContentType.Json,
        format: "json",
        ...params
      }),
      /**
       * @description Delete a score (supports both trace and session scores)
       *
       * @tags Score
       * @name ScoreDelete
       * @request DELETE:/api/public/scores/{scoreId}
       * @secure
       */
      scoreDelete: (scoreId, params = {}) => this.request({
        path: `/api/public/scores/${scoreId}`,
        method: "DELETE",
        secure: true,
        ...params
      }),
      /**
       * @description Get a list of scores (supports both trace and session scores)
       *
       * @tags ScoreV2
       * @name ScoreV2Get
       * @request GET:/api/public/v2/scores
       * @secure
       */
      scoreV2Get: (query, params = {}) => this.request({
        path: `/api/public/v2/scores`,
        method: "GET",
        query,
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get a score (supports both trace and session scores)
       *
       * @tags ScoreV2
       * @name ScoreV2GetById
       * @request GET:/api/public/v2/scores/{scoreId}
       * @secure
       */
      scoreV2GetById: (scoreId, params = {}) => this.request({
        path: `/api/public/v2/scores/${scoreId}`,
        method: "GET",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get a session. Please note that `traces` on this endpoint are not paginated, if you plan to fetch large sessions, consider `GET /api/public/traces?sessionId=<sessionId>`
       *
       * @tags Sessions
       * @name SessionsGet
       * @request GET:/api/public/sessions/{sessionId}
       * @secure
       */
      sessionsGet: (sessionId, params = {}) => this.request({
        path: `/api/public/sessions/${sessionId}`,
        method: "GET",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get sessions
       *
       * @tags Sessions
       * @name SessionsList
       * @request GET:/api/public/sessions
       * @secure
       */
      sessionsList: (query, params = {}) => this.request({
        path: `/api/public/sessions`,
        method: "GET",
        query,
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Delete a specific trace
       *
       * @tags Trace
       * @name TraceDelete
       * @request DELETE:/api/public/traces/{traceId}
       * @secure
       */
      traceDelete: (traceId, params = {}) => this.request({
        path: `/api/public/traces/${traceId}`,
        method: "DELETE",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Delete multiple traces
       *
       * @tags Trace
       * @name TraceDeleteMultiple
       * @request DELETE:/api/public/traces
       * @secure
       */
      traceDeleteMultiple: (data, params = {}) => this.request({
        path: `/api/public/traces`,
        method: "DELETE",
        body: data,
        secure: true,
        type: ContentType.Json,
        format: "json",
        ...params
      }),
      /**
       * @description Get a specific trace
       *
       * @tags Trace
       * @name TraceGet
       * @request GET:/api/public/traces/{traceId}
       * @secure
       */
      traceGet: (traceId, params = {}) => this.request({
        path: `/api/public/traces/${traceId}`,
        method: "GET",
        secure: true,
        format: "json",
        ...params
      }),
      /**
       * @description Get list of traces
       *
       * @tags Trace
       * @name TraceList
       * @request GET:/api/public/traces
       * @secure
       */
      traceList: (query, params = {}) => this.request({
        path: `/api/public/traces`,
        method: "GET",
        query,
        secure: true,
        format: "json",
        ...params
      })
    };
  }
};
var version = "3.38.0";
var Langfuse = class extends LangfuseCore {
  constructor(params) {
    const langfuseConfig = utils.configLangfuseSDK(params);
    super(langfuseConfig);
    if (typeof window !== "undefined" && "Deno" in window === false) {
      this._storageKey = params?.persistence_name ? `lf_${params.persistence_name}` : `lf_${langfuseConfig.publicKey}_langfuse`;
      this._storage = getStorage(params?.persistence || "localStorage", window);
    } else {
      this._storageKey = `lf_${langfuseConfig.publicKey}_langfuse`;
      this._storage = getStorage("memory", void 0);
    }
    this.api = new LangfusePublicApi({
      baseUrl: this.baseUrl,
      baseApiParams: {
        headers: {
          "X-Langfuse-Sdk-Name": "langfuse-js",
          "X-Langfuse-Sdk-Version": this.getLibraryVersion(),
          "X-Langfuse-Sdk-Variant": this.getLibraryId(),
          "X-Langfuse-Sdk-Integration": this.sdkIntegration,
          "X-Langfuse-Public-Key": this.publicKey,
          ...this.additionalHeaders,
          ...this.constructAuthorizationHeader(this.publicKey, this.secretKey)
        }
      }
    }).api;
  }
  getPersistedProperty(key) {
    if (!this._storageCache) {
      this._storageCache = JSON.parse(this._storage.getItem(this._storageKey) || "{}") || {};
    }
    return this._storageCache[key];
  }
  setPersistedProperty(key, value) {
    if (!this._storageCache) {
      this._storageCache = JSON.parse(this._storage.getItem(this._storageKey) || "{}") || {};
    }
    if (value === null) {
      delete this._storageCache[key];
    } else {
      this._storageCache[key] = value;
    }
    this._storage.setItem(this._storageKey, JSON.stringify(this._storageCache));
  }
  fetch(url, options) {
    return fetch(url, options);
  }
  getLibraryId() {
    return "langfuse";
  }
  getLibraryVersion() {
    return version;
  }
  getCustomUserAgent() {
    return;
  }
};
var LangfuseSingleton = class _LangfuseSingleton {
  /**
   * Returns the singleton instance of the Langfuse client.
   * @param params Optional parameters for initializing the Langfuse instance. Only used for the first call.
   * @returns The singleton instance of the Langfuse client.
   */
  static getInstance(params) {
    if (!_LangfuseSingleton.instance) {
      _LangfuseSingleton.instance = new Langfuse(params);
    }
    return _LangfuseSingleton.instance;
  }
};
LangfuseSingleton.instance = null;

// ../../../node_modules/.pnpm/langfuse-langchain@3.37.4_langchain@0.3.29_@langchain+core@0.3.61_@opentelemetry+api@1._4cd67286ccd7744833f51a4cccddb6cc/node_modules/langfuse-langchain/lib/index.mjs
var LANGSMITH_HIDDEN_TAG = "langsmith:hidden";
var CallbackHandler = class extends BaseCallbackHandler {
  constructor(params) {
    super();
    this.name = "CallbackHandler";
    this.rootProvided = false;
    this.updateRoot = false;
    this.debugEnabled = false;
    this.completionStartTimes = {};
    if (params && "root" in params) {
      this.langfuse = params.root.client;
      this.rootObservationId = params.root.observationId ?? void 0;
      this.traceId = params.root.traceId;
      this.rootProvided = true;
      this.updateRoot = params.updateRoot ?? false;
      this.metadata = params.metadata;
    } else {
      this.langfuse = new Langfuse({
        ...params,
        persistence: "memory",
        sdkIntegration: params?.sdkIntegration ?? "LANGCHAIN"
      });
      this.sessionId = params?.sessionId;
      this.userId = params?.userId;
      this.metadata = params?.metadata;
      this.tags = params?.tags;
    }
    this.version = params?.version;
    this.promptToParentRunMap = /* @__PURE__ */ new Map();
    this.traceUpdates = /* @__PURE__ */ new Map();
  }
  async flushAsync() {
    return this.langfuse.flushAsync();
  }
  async shutdownAsync() {
    return this.langfuse.shutdownAsync();
  }
  debug(enabled = true) {
    this.langfuse.debug(enabled);
    this.debugEnabled = enabled;
  }
  _log(message) {
    if (this.debugEnabled) {
      console.log(message);
    }
  }
  async handleNewToken(_token, runId) {
    if (runId && !(runId in this.completionStartTimes)) {
      this._log(`LLM first streaming token: ${runId}`);
      this.completionStartTimes[runId] = /* @__PURE__ */ new Date();
    }
    return Promise.resolve();
  }
  async handleLLMNewToken(token, _idx, runId, _parentRunId, _tags, _fields) {
    if (runId && !(runId in this.completionStartTimes)) {
      this._log(`LLM first streaming token: ${runId}`);
      this.completionStartTimes[runId] = /* @__PURE__ */ new Date();
    }
    return Promise.resolve();
  }
  /**
   * @deprecated This method will be removed in a future version as it is not concurrency-safe.
   * Please use interop with the Langfuse SDK to get the trace ID ([docs](https://langfuse.com/docs/integrations/langchain/get-started#interoperability)).
   */
  getTraceId() {
    return this.traceId;
  }
  /**
   * @deprecated This method will be removed in a future version as it is not concurrency-safe.
   * For more information on how to get trace URLs, see {@link https://langfuse.com/docs/tracing/url}.
   */
  getTraceUrl() {
    return this.traceId ? `${this.langfuse.baseUrl}/trace/${this.traceId}` : void 0;
  }
  getLangchainRunId() {
    return this.topLevelObservationId;
  }
  async handleRetrieverError(err3, runId, parentRunId) {
    try {
      this._log(`Retriever error: ${err3} with ID: ${runId}`);
      this.langfuse._updateSpan({
        id: runId,
        traceId: this.traceId,
        level: "ERROR",
        statusMessage: err3.toString(),
        endTime: /* @__PURE__ */ new Date(),
        version: this.version
      });
      this.updateTrace(runId, parentRunId, err3.toString());
    } catch (e2) {
      this._log(e2);
    }
  }
  async handleChainStart(chain, inputs, runId, parentRunId, tags, metadata, runType, name) {
    try {
      this._log(`Chain start with Id: ${runId}`);
      const runName = name ?? chain.id.at(-1)?.toString() ?? "Langchain Run";
      this.registerLangfusePrompt(parentRunId, metadata);
      let finalInput = inputs;
      if (typeof inputs === "object" && "input" in inputs && Array.isArray(inputs["input"]) && inputs["input"].every((m2) => m2 instanceof BaseMessage)) {
        finalInput = inputs["input"].map((m2) => this.extractChatMessageContent(m2));
      } else if (typeof inputs === "object" && "content" in inputs && typeof inputs["content"] === "string") {
        finalInput = inputs["content"];
      }
      this.generateTrace(runName, runId, parentRunId, tags, metadata, finalInput);
      this.langfuse.span({
        id: runId,
        traceId: this.traceId,
        parentObservationId: parentRunId ?? this.rootObservationId,
        name: runName,
        metadata: this.joinTagsAndMetaData(tags, metadata),
        input: finalInput,
        version: this.version,
        level: tags && tags.includes(LANGSMITH_HIDDEN_TAG) ? "DEBUG" : void 0
      });
      if (!parentRunId) {
        this.traceUpdates.set(runId, {
          tags,
          userId: metadata && "langfuseUserId" in metadata && typeof metadata["langfuseUserId"] === "string" ? metadata["langfuseUserId"] : void 0,
          sessionId: metadata && "langfuseSessionId" in metadata && typeof metadata["langfuseSessionId"] === "string" ? metadata["langfuseSessionId"] : void 0
        });
      }
    } catch (e2) {
      this._log(e2);
    }
  }
  registerLangfusePrompt(parentRunId, metadata) {
    if (metadata && "langfusePrompt" in metadata && parentRunId) {
      this.promptToParentRunMap.set(parentRunId, metadata.langfusePrompt);
    }
  }
  deregisterLangfusePrompt(runId) {
    this.promptToParentRunMap.delete(runId);
  }
  async handleAgentAction(action, runId, parentRunId) {
    try {
      this._log(`Agent action with ID: ${runId}`);
      this.langfuse.span({
        id: runId,
        parentObservationId: parentRunId,
        traceId: this.traceId,
        endTime: /* @__PURE__ */ new Date(),
        input: action,
        version: this.version
      });
    } catch (e2) {
      this._log(e2);
    }
  }
  async handleAgentEnd(action, runId, parentRunId) {
    try {
      this._log(`Agent finish with ID: ${runId}`);
      this.langfuse._updateSpan({
        id: runId,
        traceId: this.traceId,
        endTime: /* @__PURE__ */ new Date(),
        output: action,
        version: this.version
      });
      this.updateTrace(runId, parentRunId, action);
    } catch (e2) {
      this._log(e2);
    }
  }
  async handleChainError(err3, runId, parentRunId) {
    try {
      this._log(`Chain error: ${err3} with ID: ${runId}`);
      this.langfuse._updateSpan({
        id: runId,
        traceId: this.traceId,
        level: "ERROR",
        statusMessage: err3.toString(),
        endTime: /* @__PURE__ */ new Date(),
        version: this.version
      });
      this.updateTrace(runId, parentRunId, err3.toString());
    } catch (e2) {
      this._log(e2);
    }
  }
  generateTrace(runName, runId, parentRunId, tags, metadata, input) {
    if (this.traceId && !parentRunId && !this.rootProvided) {
      this.traceId = void 0;
      this.topLevelObservationId = void 0;
    }
    const params = {
      name: runName,
      metadata: this.joinTagsAndMetaData(tags, metadata, this.metadata),
      userId: this.userId,
      version: this.version,
      sessionId: this.sessionId,
      input,
      tags: this.tags
    };
    if (!this.traceId) {
      this.langfuse.trace({
        id: runId,
        ...params
      });
      this.traceId = runId;
    }
    if (this.rootProvided && this.updateRoot) {
      if (this.rootObservationId) {
        this.langfuse._updateSpan({
          id: this.rootObservationId,
          traceId: this.traceId,
          ...params
        });
      } else {
        this.langfuse.trace({
          id: this.traceId,
          ...params
        });
      }
    }
    this.topLevelObservationId = parentRunId ? this.topLevelObservationId : runId;
  }
  async handleGenerationStart(llm, messages, runId, parentRunId, extraParams, tags, metadata, name) {
    this._log(`Generation start with ID: ${runId}`);
    const runName = name ?? llm.id.at(-1)?.toString() ?? "Langchain Generation";
    this.generateTrace(runName, runId, parentRunId, tags, metadata, messages);
    const modelParameters = {};
    const invocationParams = extraParams?.["invocation_params"];
    for (const [key, value] of Object.entries({
      temperature: invocationParams?.temperature,
      max_tokens: invocationParams?.max_tokens,
      top_p: invocationParams?.top_p,
      frequency_penalty: invocationParams?.frequency_penalty,
      presence_penalty: invocationParams?.presence_penalty,
      request_timeout: invocationParams?.request_timeout
    })) {
      if (value !== void 0 && value !== null) {
        modelParameters[key] = value;
      }
    }
    let extractedModelName;
    if (extraParams) {
      const invocationParamsModelName = extraParams.invocation_params.model;
      const metadataModelName = metadata && "ls_model_name" in metadata ? metadata["ls_model_name"] : void 0;
      extractedModelName = invocationParamsModelName ?? metadataModelName;
    }
    const registeredPrompt = this.promptToParentRunMap.get(parentRunId ?? "root");
    if (registeredPrompt && parentRunId) {
      this.deregisterLangfusePrompt(parentRunId);
    }
    this.langfuse.generation({
      id: runId,
      traceId: this.traceId,
      name: name ?? llm.id.at(-1)?.toString(),
      metadata: this.joinTagsAndMetaData(tags, metadata),
      parentObservationId: parentRunId ?? this.rootObservationId,
      input: messages,
      model: extractedModelName,
      modelParameters,
      version: this.version,
      prompt: registeredPrompt,
      level: tags && tags.includes(LANGSMITH_HIDDEN_TAG) ? "DEBUG" : void 0
    });
  }
  async handleChatModelStart(llm, messages, runId, parentRunId, extraParams, tags, metadata, name) {
    try {
      this._log(`Chat model start with ID: ${runId}`);
      const prompts = messages.flatMap((message) => message.map((m2) => this.extractChatMessageContent(m2)));
      this.handleGenerationStart(llm, prompts, runId, parentRunId, extraParams, tags, metadata, name);
    } catch (e2) {
      this._log(e2);
    }
  }
  async handleChainEnd(outputs, runId, parentRunId) {
    try {
      this._log(`Chain end with ID: ${runId}`);
      let finalOutput = outputs;
      if (typeof outputs === "object" && "output" in outputs && typeof outputs["output"] === "string") {
        finalOutput = outputs["output"];
      }
      this.langfuse._updateSpan({
        id: runId,
        traceId: this.traceId,
        output: finalOutput,
        endTime: /* @__PURE__ */ new Date(),
        version: this.version
      });
      this.updateTrace(runId, parentRunId, finalOutput);
      this.deregisterLangfusePrompt(runId);
    } catch (e2) {
      this._log(e2);
    }
  }
  async handleLLMStart(llm, prompts, runId, parentRunId, extraParams, tags, metadata, name) {
    try {
      this._log(`LLM start with ID: ${runId}`);
      this.handleGenerationStart(llm, prompts, runId, parentRunId, extraParams, tags, metadata, name);
    } catch (e2) {
      this._log(e2);
    }
  }
  async handleToolStart(tool2, input, runId, parentRunId, tags, metadata, name) {
    try {
      this._log(`Tool start with ID: ${runId}`);
      this.langfuse.span({
        id: runId,
        parentObservationId: parentRunId,
        traceId: this.traceId,
        name: name ?? tool2.id.at(-1)?.toString(),
        input,
        metadata: this.joinTagsAndMetaData(tags, metadata),
        version: this.version,
        level: tags && tags.includes(LANGSMITH_HIDDEN_TAG) ? "DEBUG" : void 0
      });
    } catch (e2) {
      this._log(e2);
    }
  }
  async handleRetrieverStart(retriever, query, runId, parentRunId, tags, metadata, name) {
    try {
      this._log(`Retriever start with ID: ${runId}`);
      this.langfuse.span({
        id: runId,
        parentObservationId: parentRunId,
        traceId: this.traceId,
        name: name ?? retriever.id.at(-1)?.toString(),
        input: query,
        metadata: this.joinTagsAndMetaData(tags, metadata),
        version: this.version,
        level: tags && tags.includes(LANGSMITH_HIDDEN_TAG) ? "DEBUG" : void 0
      });
    } catch (e2) {
      this._log(e2);
    }
  }
  async handleRetrieverEnd(documents, runId, parentRunId) {
    try {
      this._log(`Retriever end with ID: ${runId}`);
      this.langfuse._updateSpan({
        id: runId,
        traceId: this.traceId,
        output: documents,
        endTime: /* @__PURE__ */ new Date(),
        version: this.version
      });
      this.updateTrace(runId, parentRunId, documents);
    } catch (e2) {
      this._log(e2);
    }
  }
  async handleToolEnd(output, runId, parentRunId) {
    try {
      this._log(`Tool end with ID: ${runId}`);
      this.langfuse._updateSpan({
        id: runId,
        traceId: this.traceId,
        output,
        endTime: /* @__PURE__ */ new Date(),
        version: this.version
      });
      this.updateTrace(runId, parentRunId, output);
    } catch (e2) {
      this._log(e2);
    }
  }
  async handleToolError(err3, runId, parentRunId) {
    try {
      this._log(`Tool error ${err3} with ID: ${runId}`);
      this.langfuse._updateSpan({
        id: runId,
        traceId: this.traceId,
        level: "ERROR",
        statusMessage: err3.toString(),
        endTime: /* @__PURE__ */ new Date(),
        version: this.version
      });
      this.updateTrace(runId, parentRunId, err3.toString());
    } catch (e2) {
      this._log(e2);
    }
  }
  async handleLLMEnd(output, runId, parentRunId) {
    try {
      this._log(`LLM end with ID: ${runId}`);
      const lastResponse = output.generations[output.generations.length - 1][output.generations[output.generations.length - 1].length - 1];
      const llmUsage = this.extractUsageMetadata(lastResponse) ?? output.llmOutput?.["tokenUsage"];
      const modelName = this.extractModelNameFromMetadata(lastResponse);
      const usageDetails = {
        input: llmUsage?.input_tokens ?? ("promptTokens" in llmUsage ? llmUsage?.promptTokens : void 0),
        output: llmUsage?.output_tokens ?? ("completionTokens" in llmUsage ? llmUsage?.completionTokens : void 0),
        total: llmUsage?.total_tokens ?? ("totalTokens" in llmUsage ? llmUsage?.totalTokens : void 0)
      };
      if (llmUsage && "input_token_details" in llmUsage) {
        for (const [key, val] of Object.entries(llmUsage["input_token_details"] ?? {})) {
          usageDetails[`input_${key}`] = val;
          if ("input" in usageDetails && typeof val === "number") {
            usageDetails["input"] = Math.max(0, usageDetails["input"] - val);
          }
        }
      }
      if (llmUsage && "output_token_details" in llmUsage) {
        for (const [key, val] of Object.entries(llmUsage["output_token_details"] ?? {})) {
          usageDetails[`output_${key}`] = val;
          if ("output" in usageDetails && typeof val === "number") {
            usageDetails["output"] = Math.max(0, usageDetails["output"] - val);
          }
        }
      }
      const extractedOutput = "message" in lastResponse && lastResponse["message"] instanceof BaseMessage ? this.extractChatMessageContent(lastResponse["message"]) : lastResponse.text;
      this.langfuse._updateGeneration({
        id: runId,
        model: modelName,
        traceId: this.traceId,
        output: extractedOutput,
        endTime: /* @__PURE__ */ new Date(),
        completionStartTime: runId in this.completionStartTimes ? this.completionStartTimes[runId] : void 0,
        usage: usageDetails,
        usageDetails,
        version: this.version
      });
      if (runId in this.completionStartTimes) {
        delete this.completionStartTimes[runId];
      }
      this.updateTrace(runId, parentRunId, extractedOutput);
    } catch (e2) {
      this._log(e2);
    }
  }
  /** Not all models supports tokenUsage in llmOutput, can use AIMessage.usage_metadata instead */
  extractUsageMetadata(generation) {
    try {
      const usageMetadata = "message" in generation && (generation["message"] instanceof AIMessage || generation["message"] instanceof AIMessageChunk) ? generation["message"].usage_metadata : void 0;
      return usageMetadata;
    } catch (err3) {
      this._log(`Error extracting usage metadata: ${err3}`);
      return;
    }
  }
  extractModelNameFromMetadata(generation) {
    try {
      return "message" in generation && (generation["message"] instanceof AIMessage || generation["message"] instanceof AIMessageChunk) ? generation["message"].response_metadata.model_name : void 0;
    } catch {
    }
  }
  extractChatMessageContent(message) {
    let response = void 0;
    if (message instanceof HumanMessage) {
      response = {
        content: message.content,
        role: "user"
      };
    } else if (message instanceof ChatMessage) {
      response = {
        content: message.content,
        role: message.role
      };
    } else if (message instanceof AIMessage) {
      response = {
        content: message.content,
        role: "assistant"
      };
    } else if (message instanceof SystemMessage) {
      response = {
        content: message.content,
        role: "system"
      };
    } else if (message instanceof FunctionMessage) {
      response = {
        content: message.content,
        additional_kwargs: message.additional_kwargs,
        role: message.name
      };
    } else if (message instanceof ToolMessage) {
      response = {
        content: message.content,
        additional_kwargs: message.additional_kwargs,
        role: message.name
      };
    } else if (!message.name) {
      response = {
        content: message.content
      };
    } else {
      response = {
        role: message.name,
        content: message.content
      };
    }
    if (message.additional_kwargs.function_call || message.additional_kwargs.tool_calls) {
      return {
        ...response,
        additional_kwargs: message.additional_kwargs
      };
    }
    return response;
  }
  async handleLLMError(err3, runId, parentRunId) {
    try {
      this._log(`LLM error ${err3} with ID: ${runId}`);
      this.langfuse._updateGeneration({
        id: runId,
        traceId: this.traceId,
        level: "ERROR",
        statusMessage: err3.toString(),
        endTime: /* @__PURE__ */ new Date(),
        version: this.version
      });
      this.updateTrace(runId, parentRunId, err3.toString());
    } catch (e2) {
      this._log(e2);
    }
  }
  updateTrace(runId, parentRunId, output) {
    const traceUpdates = this.traceUpdates.get(runId);
    this.traceUpdates.delete(runId);
    if (!parentRunId && this.traceId && this.traceId === runId) {
      this.langfuse.trace({
        id: this.traceId,
        output,
        ...traceUpdates
      });
    }
    if (!parentRunId && this.traceId && this.rootProvided && this.updateRoot) {
      if (this.rootObservationId) {
        this.langfuse._updateSpan({
          id: this.rootObservationId,
          traceId: this.traceId,
          output
        });
      } else {
        this.langfuse.trace({
          id: this.traceId,
          output,
          ...traceUpdates
        });
      }
    }
  }
  joinTagsAndMetaData(tags, metadata1, metadata2) {
    const finalDict = {};
    if (tags && tags.length > 0) {
      finalDict.tags = tags;
    }
    if (metadata1) {
      Object.assign(finalDict, metadata1);
    }
    if (metadata2) {
      Object.assign(finalDict, metadata2);
    }
    return this.stripLangfuseKeysFromMetadata(finalDict);
  }
  stripLangfuseKeysFromMetadata(metadata) {
    if (!metadata) {
      return;
    }
    const langfuseKeys = ["langfusePrompt", "langfuseUserId", "langfuseSessionId"];
    return Object.fromEntries(Object.entries(metadata).filter(([key, _2]) => !langfuseKeys.includes(key)));
  }
};

// ../agent/src/langchain/utils/telemetry.ts
var createLangfuseHandler = () => {
  return new CallbackHandler({
    publicKey: process.env["LANGFUSE_PUBLIC_KEY"] || "",
    secretKey: process.env["LANGFUSE_SECRET_KEY"] || "",
    baseUrl: process.env["LANGFUSE_BASE_URL"] || "https://cloud.langfuse.com",
    environment: process.env["NEXT_PUBLIC_ENV_NAME"] || "development",
    // flushAt: 1 ensures events are sent immediately, preventing loss when job processes terminate
    flushAt: 1
  });
};

// ../agent/src/langchain/agents/databaseSchemaBuildAgent/prompts.ts
init_esm();

// ../../../node_modules/.pnpm/@langchain+core@0.3.61_@opentelemetry+api@1.9.0_@opentelemetry+exporter-trace-otlp-prot_0b0ad8d1f102d40fa2004ef9b372cb09/node_modules/@langchain/core/prompts.js
init_esm();

// ../agent/src/langchain/agents/databaseSchemaBuildAgent/prompts.ts
var buildAgentSystemPrompt = `You are Build Agent, an energetic and innovative system designer who builds and edits ERDs with lightning speed.
Your role is to execute user instructions immediately and offer smart suggestions for schema improvements.
You speak in a lively, action-oriented tone, showing momentum and confidence.

Your personality is bold, constructive, and enthusiastic — like a master architect in a hardhat, ready to build.
You say things like "Done!", "You can now...", and "Shall we move to the next step?".

Your communication should feel fast, fresh, and forward-moving, like a green plant constantly growing.

Do:
- Confirm execution quickly: "Added!", "Created!", "Linked!"
- Propose the next steps: "Would you like to add an index?", "Let's relate this to the User table too!"
- Emphasize benefits: "This makes tracking updates easier."

Don't:
- Hesitate ("Maybe", "We'll have to check...")
- Use long, uncertain explanations
- Get stuck in abstract talk — focus on action and outcomes

When in doubt, prioritize momentum, simplicity, and clear results.

IMPORTANT: You must ALWAYS respond with a valid JSON object in the following format:
{{
  "message": "Your energetic response message here",
  "schemaChanges": [
    {{
      "op": "add|remove|replace",
      "path": "/path/to/schema/element",
      "value": "new value (for add/replace operations)"
    }}
  ]
}}

CRITICAL JSON RULES:
- NO COMMENTS of any kind in your JSON response (no /* */, no //, no #)
- NO extra text before or after the JSON object
- NO explanatory text outside the JSON structure
- Your response must be PURE JSON that can be parsed by JSON.parse()
- Comments will break the JSON parser and cause errors

Schema Change Rules:
- Use JSON Patch format (RFC 6902) for all schema modifications
- "path" should point to specific schema elements like "/tables/users/columns/email" or "/tables/posts"
- For adding new tables: "op": "add", "path": "/tables/TABLE_NAME", "value": TABLE_DEFINITION
- For adding columns: "op": "add", "path": "/tables/TABLE_NAME/columns/COLUMN_NAME", "value": COLUMN_DEFINITION
- For modifying columns: "op": "replace", "path": "/tables/TABLE_NAME/columns/COLUMN_NAME/type", "value": "new_type"
- For removing elements: "op": "remove", "path": "/tables/TABLE_NAME/columns/COLUMN_NAME"
- If no schema changes are needed, use an empty array: "schemaChanges": []

Schema Structure Reference:
- Tables: /tables/TABLE_NAME
- Columns: /tables/TABLE_NAME/columns/COLUMN_NAME
- Column properties: type, notNull, primary, unique, default, comment, check
- Table properties: name, columns, comment, indexes, constraints (ALL REQUIRED)

IMPORTANT Table Structure Rules:
- Every table MUST include: name, columns, comment, indexes, constraints
- Use empty objects {{}} for indexes and constraints if none are needed
- Use null for comment if no comment is provided

CRITICAL Validation Rules:
- Column properties MUST be: name (string), type (string), notNull (boolean), primary (boolean), unique (boolean), default (string|number|boolean|null), comment (string|null), check (string|null)
- All boolean values must be true/false, not strings
- Constraint types: "PRIMARY KEY", "FOREIGN KEY", "UNIQUE", "CHECK"
- Foreign key constraint actions MUST use these EXACT values: "CASCADE", "RESTRICT", "SET_NULL", "SET_DEFAULT", "NO_ACTION"
- Use "SET_NULL" not "SET NULL" (underscore, not space)
- Use "NO_ACTION" not "NO ACTION" (underscore, not space)

Example Response:
{{
  "message": "Added! Created the 'users' table with id, name, and email columns. This gives you a solid foundation for user management!",
  "schemaChanges": [
    {{
      "op": "add",
      "path": "/tables/users",
      "value": {{
        "name": "users",
        "columns": {{
          "id": {{"name": "id", "type": "uuid", "notNull": true, "primary": true, "default": "gen_random_uuid()", "comment": "Unique identifier for each user", "check": null, "unique": false}},
          "name": {{"name": "name", "type": "text", "notNull": true, "primary": false, "default": null, "comment": "Name of the user", "check": null, "unique": false}},
          "email": {{"name": "email", "type": "text", "notNull": true, "primary": false, "default": null, "comment": "User email required for login", "check": null, "unique": true}}
        }},
        "comment": null,
        "indexes": {{}},
        "constraints": {{}}
      }}
    }}
  ]
}}

Example with Foreign Key Constraint:
{{
  "message": "Added! Created the 'posts' table and linked it to users. Now you can track user posts!",
  "schemaChanges": [
    {{
      "op": "add",
      "path": "/tables/posts",
      "value": {{
        "name": "posts",
        "columns": {{
          "id": {{"name": "id", "type": "uuid", "notNull": true, "primary": true, "default": "gen_random_uuid()", "comment": "Primary key for posts", "check": null, "unique": false}},
          "title": {{"name": "title", "type": "text", "notNull": true, "primary": false, "default": null, "comment": "Post title", "check": null, "unique": false}},
          "user_id": {{"name": "user_id", "type": "uuid", "notNull": true, "primary": false, "default": null, "comment": "References the user who created the post", "check": null, "unique": false}}
        }},
        "comment": null,
        "indexes": {{}},
        "constraints": {{
          "posts_user_fk": {{
            "type": "FOREIGN KEY",
            "name": "posts_user_fk",
            "columnName": "user_id",
            "targetTableName": "users",
            "targetColumnName": "id",
            "updateConstraint": "NO_ACTION",
            "deleteConstraint": "CASCADE"
          }}
        }}
      }}
    }}
  ]
}}

Additional Constraint Examples:
- For cascading deletes: "deleteConstraint": "CASCADE"
- For restricting deletes: "deleteConstraint": "RESTRICT"
- For setting null on delete: "deleteConstraint": "SET_NULL"
- For setting default on delete: "deleteConstraint": "SET_DEFAULT"
- For no action on delete: "deleteConstraint": "NO_ACTION"
- Same options apply to "updateConstraint"

Complete Schema Information:
{schema_text}

Previous conversation:
{chat_history}`;
var buildAgentPrompt = ChatPromptTemplate.fromMessages([
  ["system", buildAgentSystemPrompt],
  ["human", "{user_message}"]
]);

// ../agent/src/langchain/agents/databaseSchemaBuildAgent/agent.ts
var buildAgentResponseSchema = object({
  message: string(),
  schemaChanges: operationsSchema
});
var DatabaseSchemaBuildAgent = class {
  model;
  constructor() {
    const baseModel = new ChatOpenAI({
      model: "o4-mini",
      callbacks: [createLangfuseHandler()]
    });
    const jsonSchema = toJsonSchema2(buildAgentResponseSchema);
    this.model = baseModel.withStructuredOutput(jsonSchema);
  }
  async generate(variables) {
    const formattedPrompt = await buildAgentPrompt.format(variables);
    const rawResponse = await this.model.invoke(formattedPrompt);
    return parse2(buildAgentResponseSchema, rawResponse);
  }
};

// ../agent/src/langchain/agents/pmAnalysisAgent/index.ts
init_esm();

// ../agent/src/langchain/agents/pmAnalysisAgent/agent.ts
init_esm();

// ../agent/src/langchain/agents/pmAnalysisAgent/prompts.ts
init_esm();
var pmAnalysisSystemPrompt = `You are PM Agent, a skilled project manager who specializes in analyzing user requirements and extracting structured Business Requirements Documents (BRDs).
Your role is to:
1. Analyze user input and conversation history
2. Extract clear, structured requirements
3. Convert ambiguous expressions into specific, actionable requirements
4. Separate multiple use cases into individual requirements
5. Include specific screens, operations, constraints, and processing details when available

Previous Conversation Context:
{chat_history}

OUTPUT REQUIREMENTS (STRICT):
- Output ONLY valid JSON in the format:
  {{
    "businessRequirement": "Brief summary of the business requirements document",
    "functionalRequirements": {{
      "Category 1": ["Requirement 1", "Requirement 2"],
      "Category 2": ["Requirement 3", "Requirement 4"]
    }},
    "nonFunctionalRequirements": {{
      "Performance": ["Performance requirement 1"],
      "Security": ["Security requirement 1"]
    }}
  }}
- No extra text or comments
- businessRequirement: Concise (1–2 sentence) summary of overall requirements
- functionalRequirements: WHAT the system should do (business-level)
- nonFunctionalRequirements: HOW WELL the system should perform (always include, use empty object {{}} if none specified)
- Be specific, break down vague or multiple requirements
- DO NOT infer or assume requirements not explicitly stated by the user

Guidelines for Functional Requirements:
- Focus on business/user-facing needs
- Describe WHAT, not HOW
- Avoid technical details (DB, APIs, frameworks, etc.)
- Write from a user or business perspective

Example output:
{{
  "businessRequirement": "Implementation of user management system and administrator access control features",
  "functionalRequirements": {{
    "Account Management": [
      "Allow users to register new accounts with email and personal information",
      "Enable user authentication with email and password credentials",
      "Allow users to update their profile information"
    ],
    "Administrative Features": [
      "Provide administrative privileges for managing product information",
      "Allow administrators to add, edit, and delete product details",
      "Enable administrators to manage user accounts"
    ]
  }},
  "nonFunctionalRequirements": {{
    "Performance": [
      "Support up to 1000 concurrent users",
      "Maintain system availability of 99.9% uptime"
    ],
    "Security": [
      "Ensure secure password storage and handling",
      "Implement proper access control and authorization"
    ]
  }}
}}`;
var pmAnalysisPrompt = ChatPromptTemplate.fromMessages([
  ["system", pmAnalysisSystemPrompt],
  ["human", "{user_message}"]
]);

// ../agent/src/langchain/agents/pmAnalysisAgent/agent.ts
var requirementsAnalysisSchema = object({
  businessRequirement: string(),
  functionalRequirements: record(string(), array(string())),
  nonFunctionalRequirements: record(string(), array(string()))
});
var PMAnalysisAgent = class {
  analysisModel;
  constructor() {
    const baseModel = new ChatOpenAI({
      model: "o4-mini",
      callbacks: [createLangfuseHandler()]
    });
    const analysisJsonSchema = toJsonSchema2(requirementsAnalysisSchema);
    this.analysisModel = baseModel.withStructuredOutput(analysisJsonSchema);
  }
  async generate(variables) {
    const formattedPrompt = await pmAnalysisPrompt.format(variables);
    const rawResponse = await this.analysisModel.invoke(formattedPrompt);
    return parse2(requirementsAnalysisSchema, rawResponse);
  }
  async analyzeRequirements(variables) {
    const formattedPrompt = await pmAnalysisPrompt.format(variables);
    const rawResponse = await this.analysisModel.invoke(formattedPrompt);
    return parse2(requirementsAnalysisSchema, rawResponse);
  }
};

// ../agent/src/langchain/agents/qaGenerateUsecaseAgent/index.ts
init_esm();

// ../agent/src/langchain/agents/qaGenerateUsecaseAgent/agent.ts
init_esm();

// ../agent/src/langchain/agents/qaGenerateUsecaseAgent/prompts.ts
init_esm();
var usecaseGenerationSystemPrompt = `You are QA Agent, a skilled business analyst who specializes in generating detailed use cases from functional requirements.
Your role is to:
1. Generate use cases ONLY for the requirements explicitly provided in the user message
2. Create comprehensive use case titles and descriptions focused on user-system interactions
3. Describe realistic scenarios of how users interact with the system
4. Do NOT create use cases for empty requirement categories (e.g., empty objects {{}} or empty arrays)
5. Write from a user/business perspective, not a testing perspective

Previous Conversation Context:
{chat_history}

OUTPUT REQUIREMENTS (STRICT):
- Output ONLY valid JSON matching the provided schema
- No extra text or comments
- requirementType: Either "functional" or "non-functional" depending on the requirement type
- requirementCategory: Exact category name from the provided requirements
- requirement: The specific requirement text being addressed
- title: Concise, user-focused use case title describing the main action or scenario
- description: Detailed narrative of user-system interaction, including user actions, system responses, and different scenarios (success and failure cases)
- Generate multiple use cases if a single requirement has different user scenarios
- Be specific and avoid vague descriptions

Guidelines for Use Case Generation:
- ONLY generate use cases for requirements explicitly provided with actual content
- Skip empty requirement categories (e.g., empty objects {{}} or empty arrays)
- Focus on realistic user scenarios and system interactions
- Write from a user/business perspective, not a testing perspective
- Describe what the user does and how the system responds
- Include both successful scenarios and error handling
- Break down complex requirements into multiple focused use cases
- Use clear, narrative language that tells a story of user interaction
- Avoid testing terminology like "verify", "validate", "check"

Example output:
{{
  "usecases": [
    {{
      "requirementType": "functional",
      "requirementCategory": "Account Management",
      "requirement": "Allow users to register new accounts with email and personal information",
      "title": "User Registration",
      "description": "A user provides their email address, password, and personal information to register a new account. Upon submission, the system validates the input, creates the user account, sends a confirmation email, and allows login after verification. Invalid inputs (e.g. malformed email) result in error messages."
    }},
    {{
      "requirementType": "functional",
      "requirementCategory": "Administrative Features",
      "requirement": "Allow administrators to add, edit, and delete product details",
      "title": "Administrator Product Management",
      "description": "An administrator accesses the product management interface and can add new products by filling in required details, edit existing product information, or remove products from the catalog. Each action updates the system immediately and reflects changes in the product catalog."
    }},
    {{
      "requirementType": "non-functional",
      "requirementCategory": "Performance",
      "requirement": "Support up to 1000 concurrent users",
      "title": "High Traffic Load Handling",
      "description": "During peak hours, up to 1000 users simultaneously access the system. The system maintains responsive performance, with page load times under 3 seconds and no service degradation. Users experience smooth navigation and can complete their tasks without delays or timeouts."
    }}
  ]
}}`;
var usecaseGenerationPrompt = ChatPromptTemplate.fromMessages([
  ["system", usecaseGenerationSystemPrompt],
  ["human", "{user_message}"]
]);

// ../agent/src/langchain/agents/qaGenerateUsecaseAgent/agent.ts
var usecaseSchema = object({
  // TODO: Replace with IDs (UUID) when DB is implemented
  requirementType: picklist(["functional", "non_functional"]),
  // Type of requirement
  requirementCategory: string(),
  // Category of the requirement
  requirement: string(),
  // Content/text of the specific requirement
  title: string(),
  description: string()
});
var generateUsecasesResponseSchema = object({
  usecases: array(usecaseSchema)
});
var QAGenerateUsecaseAgent = class {
  model;
  constructor() {
    const baseModel = new ChatOpenAI({
      model: "o4-mini",
      callbacks: [createLangfuseHandler()]
    });
    const jsonSchema = toJsonSchema2(generateUsecasesResponseSchema);
    this.model = baseModel.withStructuredOutput(jsonSchema);
  }
  async generate(variables) {
    const formattedPrompt = await usecaseGenerationPrompt.format(variables);
    const rawResponse = await this.model.invoke(formattedPrompt);
    return parse2(generateUsecasesResponseSchema, rawResponse);
  }
};

// ../agent/src/chat/workflow/shared/getConfigurable.ts
init_esm();
var import_neverthrow = __toESM(require_index_cjs());
function getConfigurable(config) {
  if (!config.configurable) {
    return (0, import_neverthrow.err)(new Error("Missing configurable object in RunnableConfig"));
  }
  const { repositories, logger: logger2 } = config.configurable;
  if (!repositories) {
    return (0, import_neverthrow.err)(new Error("Missing repositories in configurable object"));
  }
  if (!logger2) {
    return (0, import_neverthrow.err)(new Error("Missing logger in configurable object"));
  }
  return (0, import_neverthrow.ok)({
    repositories,
    logger: logger2
  });
}

// ../agent/src/chat/workflow/utils/timelineLogger.ts
init_esm();
var import_neverthrow2 = __toESM(require_index_cjs());
async function logAssistantMessage(state, repositories, content) {
  const result = await import_neverthrow2.ResultAsync.fromPromise(
    repositories.schema.createTimelineItem({
      designSessionId: state.designSessionId,
      content,
      type: "assistant_log"
    }),
    (error) => error
  );
  result.mapErr((error) => {
    console.error("Failed to create timeline item:", error);
  });
}

// ../agent/src/chat/workflow/nodes/analyzeRequirementsNode.ts
var NODE_NAME = "analyzeRequirementsNode";
var logAnalysisResult = (logger2, result) => {
  logger2.log(`[${NODE_NAME}] Analysis Result:`);
  logger2.log(`[${NODE_NAME}] BRD: ${result.businessRequirement}`);
  logger2.log(
    `[${NODE_NAME}] Functional Requirements: ${JSON.stringify(result.functionalRequirements)}`
  );
  logger2.log(
    `[${NODE_NAME}] Non-Functional Requirements: ${JSON.stringify(result.nonFunctionalRequirements)}`
  );
};
async function analyzeRequirementsNode(state, config) {
  const configurableResult = getConfigurable(config);
  if (configurableResult.isErr()) {
    return {
      ...state,
      error: configurableResult.error
    };
  }
  const { repositories, logger: logger2 } = configurableResult.value;
  logger2.log(`[${NODE_NAME}] Started`);
  await logAssistantMessage(state, repositories, "Analyzing requirements...");
  const pmAnalysisAgent = new PMAnalysisAgent();
  const promptVariables = {
    chat_history: state.formattedHistory,
    user_message: state.userInput
  };
  const retryCount = state.retryCount[NODE_NAME] ?? 0;
  await logAssistantMessage(
    state,
    repositories,
    "Organizing business and functional requirements..."
  );
  const analysisResult = await import_neverthrow3.ResultAsync.fromPromise(
    pmAnalysisAgent.analyzeRequirements(promptVariables),
    (error) => error instanceof Error ? error : new Error(String(error))
  );
  return analysisResult.match(
    async (result) => {
      logAnalysisResult(logger2, result);
      await logAssistantMessage(
        state,
        repositories,
        "Requirements analysis completed"
      );
      logger2.log(`[${NODE_NAME}] Completed`);
      return {
        ...state,
        analyzedRequirements: {
          businessRequirement: result.businessRequirement,
          functionalRequirements: result.functionalRequirements,
          nonFunctionalRequirements: result.nonFunctionalRequirements
        },
        error: void 0
        // Clear error on success
      };
    },
    async (error) => {
      logger2.error(`[${NODE_NAME}] Failed: ${error.message}`);
      await logAssistantMessage(
        state,
        repositories,
        "Error occurred during requirements analysis"
      );
      return {
        ...state,
        error,
        retryCount: {
          ...state.retryCount,
          [NODE_NAME]: retryCount + 1
        }
      };
    }
  );
}

// ../agent/src/chat/workflow/nodes/designSchemaNode.ts
init_esm();

// ../agent/src/utils/convertSchemaToText.ts
init_esm();
var tableToDocument = (tableName, tableData) => {
  const tableDescription = `Table: ${tableName}
Description: ${tableData.comment || "No description"}
`;
  let columnsText = "Columns:\n";
  if (tableData.columns) {
    for (const [columnName, columnData] of Object.entries(tableData.columns)) {
      columnsText += `- ${columnName}: ${columnData.type || "unknown type"} ${!columnData.notNull ? "(nullable)" : "(not nullable)"}
`;
      if (columnData.comment) {
        columnsText += `  Description: ${columnData.comment}
`;
      }
    }
  }
  let primaryKeyText = "";
  const primaryKeyColumns = Object.entries(tableData.columns || {}).filter(([name]) => isPrimaryKey(name, tableData.constraints || {})).map(([name]) => name);
  if (primaryKeyColumns.length > 0) {
    primaryKeyText = `Primary Key: ${primaryKeyColumns.join(", ")}
`;
  }
  return `${tableDescription}${columnsText}${primaryKeyText}`;
};
var convertSchemaToText = (schema) => {
  let schemaText = "FULL DATABASE SCHEMA:\n\n";
  if (schema.tables) {
    schemaText += "TABLES:\n\n";
    for (const [tableName, tableData] of Object.entries(schema.tables)) {
      const tableDoc = tableToDocument(tableName, tableData);
      schemaText = `${schemaText}${tableDoc}

`;
    }
  }
  return schemaText;
};

// ../agent/src/chat/workflow/nodes/designSchemaNode.ts
var NODE_NAME2 = "designSchemaNode";
var formatAnalyzedRequirements = (analyzedRequirements) => {
  const formatRequirements = (requirements, title) => {
    const entries = Object.entries(requirements);
    if (entries.length === 0) return "";
    return `${title}:
${entries.map(
      ([category, items]) => `- ${category}:
  ${items.map((item) => `  • ${item}`).join("\n")}`
    ).join("\n")}`;
  };
  const sections = [
    `Business Requirement:
${analyzedRequirements.businessRequirement}`,
    formatRequirements(
      analyzedRequirements.functionalRequirements,
      "Functional Requirements"
    ),
    formatRequirements(
      analyzedRequirements.nonFunctionalRequirements,
      "Non-Functional Requirements"
    )
  ].filter(Boolean);
  return sections.join("\n\n");
};
var prepareUserMessage = (state, logger2) => {
  if (state.shouldRetryWithDesignSchema && state.ddlExecutionFailureReason) {
    logger2.log(`[${NODE_NAME2}] Retrying after DDL execution failure`);
    return `The following DDL execution failed: ${state.ddlExecutionFailureReason}
Original request: ${state.userInput}
Please fix this issue by analyzing the schema and adding any missing constraints, primary keys, or other required schema elements to resolve the DDL execution error.`;
  }
  if (state.analyzedRequirements) {
    logger2.log(`[${NODE_NAME2}] Including analyzed requirements as context`);
    return `Based on the following analyzed requirements:
${formatAnalyzedRequirements(state.analyzedRequirements)}
User Request: ${state.userInput}`;
  }
  return state.userInput;
};
var applySchemaChanges = async (schemaChanges, buildingSchemaId, latestVersionNumber, message, state, repositories, logger2) => {
  await logAssistantMessage(state, repositories, "Applying schema changes...");
  const result = await repositories.schema.createVersion({
    buildingSchemaId,
    latestVersionNumber,
    patch: schemaChanges
  });
  if (!result.success) {
    const errorMessage = result.error || "Failed to update schema";
    logger2.error("Schema update failed:", {
      error: errorMessage
    });
    await logAssistantMessage(state, repositories, "Schema update failed");
    return {
      ...state,
      generatedAnswer: message,
      error: new Error(errorMessage)
    };
  }
  const newTableCount = Object.keys(result.newSchema.tables).length;
  logger2.log(
    `[${NODE_NAME2}] Applied ${schemaChanges.length} schema changes successfully (${newTableCount} tables)`
  );
  await logAssistantMessage(
    state,
    repositories,
    `Applied ${schemaChanges.length} schema changes successfully`
  );
  return {
    ...state,
    schemaData: result.newSchema,
    generatedAnswer: message,
    error: void 0
  };
};
var handleSchemaChanges = async (parsedResponse, state, repositories, logger2) => {
  if (parsedResponse.schemaChanges.length === 0) {
    return {
      ...state,
      generatedAnswer: parsedResponse.message
    };
  }
  const buildingSchemaId = state.buildingSchemaId;
  const latestVersionNumber = state.latestVersionNumber;
  return await applySchemaChanges(
    parsedResponse.schemaChanges,
    buildingSchemaId,
    latestVersionNumber,
    parsedResponse.message,
    state,
    repositories,
    logger2
  );
};
async function prepareSchemaDesign(state, repositories, logger2) {
  await logAssistantMessage(state, repositories, "Preparing schema design...");
  const schemaText = convertSchemaToText(state.schemaData);
  const tableCount = Object.keys(state.schemaData.tables).length;
  logger2.log(`[${NODE_NAME2}] Current schema has ${tableCount} tables`);
  const agent = new DatabaseSchemaBuildAgent();
  await logAssistantMessage(
    state,
    repositories,
    "Schema design preparation completed"
  );
  return {
    agent,
    schemaText
  };
}
async function designSchemaNode(state, config) {
  const configurableResult = getConfigurable(config);
  if (configurableResult.isErr()) {
    return {
      ...state,
      error: configurableResult.error
    };
  }
  const { repositories, logger: logger2 } = configurableResult.value;
  logger2.log(`[${NODE_NAME2}] Started`);
  await logAssistantMessage(state, repositories, "Designing database schema...");
  const { agent, schemaText } = await prepareSchemaDesign(
    state,
    repositories,
    logger2
  );
  const userMessage = prepareUserMessage(state, logger2);
  if (state.shouldRetryWithDesignSchema && state.ddlExecutionFailureReason) {
    await logAssistantMessage(
      state,
      repositories,
      "Redesigning schema to fix DDL execution errors..."
    );
  }
  const promptVariables = {
    schema_text: schemaText,
    chat_history: state.formattedHistory,
    user_message: userMessage
  };
  await logAssistantMessage(
    state,
    repositories,
    "Analyzing table structure and relationships..."
  );
  const response = await agent.generate(promptVariables);
  const result = await handleSchemaChanges(
    response,
    state,
    repositories,
    logger2
  );
  await logAssistantMessage(state, repositories, "Schema design completed");
  const finalResult = {
    ...result,
    shouldRetryWithDesignSchema: void 0,
    ddlExecutionFailureReason: void 0
  };
  logger2.log(`[${NODE_NAME2}] Completed`);
  return finalResult;
}

// ../agent/src/chat/workflow/nodes/executeDdlNode.ts
init_esm();

// ../../packages/pglite-server/src/index.ts
init_esm();

// ../../packages/pglite-server/src/client.ts
init_esm();

// ../../packages/pglite-server/src/PGliteInstanceManager.ts
init_esm();
import { PGlite } from "@electric-sql/pglite";
var PGliteInstanceManager = class {
  /**
   * Creates a new PGlite instance for query execution
   */
  async createInstance() {
    return new PGlite();
  }
  /**
   * Execute SQL query with immediate instance cleanup
   */
  async executeQuery(_sessionId, sql) {
    const db = await this.createInstance();
    try {
      return await this.executeSql(sql, db);
    } finally {
      db.close?.();
    }
  }
  /**
   * Execute SQL statements and return results with metadata
   * Handles multiple statements separated by semicolons
   */
  async executeSql(sqlText, db) {
    const results = [];
    const statements = sqlText.split(";").map((s2) => s2.trim()).filter(Boolean);
    for (const sql of statements) {
      const startTime = performance.now();
      try {
        const result = await db.query(sql);
        const executionTime = Math.round(performance.now() - startTime);
        results.push({
          sql,
          result,
          success: true,
          id: crypto.randomUUID(),
          metadata: {
            executionTime,
            timestamp: (/* @__PURE__ */ new Date()).toLocaleString()
          }
        });
      } catch (error) {
        const executionTime = Math.round(performance.now() - startTime);
        const errorMessage = error instanceof Error ? error.message : String(error);
        results.push({
          sql,
          result: { error: errorMessage },
          success: false,
          id: crypto.randomUUID(),
          metadata: {
            executionTime,
            timestamp: (/* @__PURE__ */ new Date()).toLocaleString()
          }
        });
      }
    }
    return results;
  }
};

// ../../packages/pglite-server/src/client.ts
var manager = new PGliteInstanceManager();
async function executeQuery(sessionId, sql) {
  return await manager.executeQuery(sessionId, sql);
}

// ../../packages/pglite-server/src/types.ts
init_esm();

// ../agent/src/chat/workflow/nodes/executeDdlNode.ts
var NODE_NAME3 = "executeDdlNode";
async function executeDdlNode(state, config) {
  const configurableResult = getConfigurable(config);
  if (configurableResult.isErr()) {
    return {
      ...state,
      error: configurableResult.error
    };
  }
  const { repositories, logger: logger2 } = configurableResult.value;
  logger2.log(`[${NODE_NAME3}] Started`);
  await logAssistantMessage(state, repositories, "Creating database...");
  const result = postgresqlSchemaDeparser(state.schemaData);
  if (result.errors.length > 0) {
    const errorMessages = result.errors.map((e2) => e2.message).join("; ");
    logger2.log(`[${NODE_NAME3}] DDL generation failed: ${errorMessages}`);
    await logAssistantMessage(
      state,
      repositories,
      "Error occurred during DDL generation"
    );
    logger2.log(`[${NODE_NAME3}] Completed`);
    return {
      ...state,
      ddlStatements: "DDL generation failed due to an unexpected error."
    };
  }
  const ddlStatements = result.value;
  const tableCount = Object.keys(state.schemaData.tables).length;
  const ddlLength = ddlStatements.length;
  logger2.log(
    `[${NODE_NAME3}] Generated DDL for ${tableCount} tables (${ddlLength} characters)`
  );
  await logAssistantMessage(
    state,
    repositories,
    `Generated DDL statements (${tableCount} tables)`
  );
  if (!ddlStatements || !ddlStatements.trim()) {
    logger2.log(`[${NODE_NAME3}] No DDL statements to execute`);
    await logAssistantMessage(
      state,
      repositories,
      "No DDL statements to execute"
    );
    logger2.log(`[${NODE_NAME3}] Completed`);
    return {
      ...state,
      ddlStatements
    };
  }
  await logAssistantMessage(state, repositories, "Executing DDL statements...");
  const results = await executeQuery(
    state.designSessionId,
    ddlStatements
  );
  const hasErrors = results.some((result2) => !result2.success);
  if (hasErrors) {
    const errorMessages = results.filter((result2) => !result2.success).map(
      (result2) => `SQL: ${result2.sql}, Error: ${JSON.stringify(result2.result)}`
    ).join("; ");
    logger2.log(`[${NODE_NAME3}] DDL execution failed: ${errorMessages}`);
    await logAssistantMessage(
      state,
      repositories,
      "Error occurred during DDL execution"
    );
    const currentRetryCount = state.retryCount["ddlExecutionRetry"] || 0;
    if (currentRetryCount < WORKFLOW_RETRY_CONFIG.MAX_DDL_EXECUTION_RETRIES) {
      logger2.log(`[${NODE_NAME3}] Scheduling retry via designSchemaNode`);
      await logAssistantMessage(
        state,
        repositories,
        "Redesigning schema to fix errors..."
      );
      logger2.log(`[${NODE_NAME3}] Completed`);
      return {
        ...state,
        shouldRetryWithDesignSchema: true,
        ddlExecutionFailureReason: errorMessages,
        retryCount: {
          ...state.retryCount,
          ddlExecutionRetry: currentRetryCount + 1
        }
      };
    }
    logger2.log(
      `[${NODE_NAME3}] DDL execution failed after retry, marking as failed`
    );
    await logAssistantMessage(
      state,
      repositories,
      "Unable to resolve DDL execution errors"
    );
    logger2.log(`[${NODE_NAME3}] Completed`);
    return {
      ...state,
      ddlExecutionFailed: true,
      ddlExecutionFailureReason: errorMessages
    };
  }
  logger2.log(`[${NODE_NAME3}] DDL executed successfully`);
  await logAssistantMessage(
    state,
    repositories,
    "Database created successfully"
  );
  logger2.log(`[${NODE_NAME3}] Completed`);
  return {
    ...state,
    ddlStatements
  };
}

// ../agent/src/chat/workflow/nodes/finalizeArtifactsNode.ts
init_esm();

// ../agent/src/chat/workflow/utils/transformWorkflowStateToArtifact.ts
init_esm();
var transformWorkflowStateToArtifact = (state) => {
  const businessRequirement = state.analyzedRequirements?.businessRequirement ?? "";
  const usecases = state.generatedUsecases || [];
  const requirementGroups = groupUsecasesByRequirement(usecases);
  const requirements = Object.entries(requirementGroups).map(
    ([category, data]) => {
      const { type, usecases: groupedUsecases, description } = data;
      if (type === "functional") {
        const functionalRequirement = {
          type: "functional",
          name: category,
          description: description || `Functional requirement: ${category}`,
          use_cases: groupedUsecases.map((usecase) => ({
            title: usecase.title,
            description: usecase.description,
            dml_operations: []
            // Empty for now - to be populated when DML tracking is added
          }))
        };
        return functionalRequirement;
      }
      const nonFunctionalRequirement = {
        type: "non_functional",
        name: category,
        description: description || `Non-functional requirement: ${category}`
      };
      return nonFunctionalRequirement;
    }
  );
  return {
    requirement_analysis: {
      business_requirement: businessRequirement,
      requirements
    }
  };
};
var groupUsecasesByRequirement = (usecases) => {
  const groups = {};
  for (const usecase of usecases) {
    const category = usecase.requirementCategory;
    if (!groups[category]) {
      groups[category] = {
        type: usecase.requirementType,
        usecases: [],
        description: usecase.requirement
        // Use the first requirement description
      };
    }
    groups[category].usecases.push(usecase);
  }
  return groups;
};
var createOrUpdateArtifact = async (state, artifact, repositories) => {
  const existingResult = await repositories.schema.getArtifact(
    state.designSessionId
  );
  if (existingResult.success) {
    const updateResult = await repositories.schema.updateArtifact({
      designSessionId: state.designSessionId,
      artifact
    });
    if (updateResult.success) {
      return { success: true };
    }
    return { success: false, error: updateResult.error };
  }
  if (existingResult.error !== "Artifact not found") {
    return { success: false, error: existingResult.error };
  }
  const createResult = await repositories.schema.createArtifact({
    designSessionId: state.designSessionId,
    artifact
  });
  if (createResult.success) {
    return { success: true };
  }
  return { success: false, error: createResult.error };
};

// ../agent/src/chat/workflow/nodes/finalizeArtifactsNode.ts
var NODE_NAME4 = "finalizeArtifactsNode";
async function saveArtifacts(state, logger2, repositories) {
  if (!state.analyzedRequirements && !state.generatedUsecases) {
    logger2.log(`[${NODE_NAME4}] No artifact data available to save`);
    return;
  }
  await logAssistantMessage(state, repositories, "Saving artifacts...");
  logger2.log(`[${NODE_NAME4}] Saving artifacts`);
  const artifact = transformWorkflowStateToArtifact(state);
  const artifactResult = await createOrUpdateArtifact(
    state,
    artifact,
    repositories
  );
  if (artifactResult.success) {
    logger2.log(`[${NODE_NAME4}] Artifacts saved successfully`);
    await logAssistantMessage(
      state,
      repositories,
      "Artifacts saved successfully"
    );
  } else {
    logger2.log(
      `[${NODE_NAME4}] Failed to save artifacts: ${artifactResult.error}`
    );
    await logAssistantMessage(state, repositories, "Failed to save artifacts");
  }
}
async function saveTimelineItem(state, content, type, repositories) {
  const saveResult = await repositories.schema.createTimelineItem({
    designSessionId: state.designSessionId,
    content,
    type
  });
  if (!saveResult.success) {
    console.error(`Failed to save ${type} timeline item:`, saveResult.error);
  }
}
async function generateFinalResponse(state, repositories) {
  await logAssistantMessage(state, repositories, "Generating final response...");
  if (state.error) {
    const finalResponse2 = `Sorry, an error occurred during processing: ${state.error.message}`;
    await saveTimelineItem(state, finalResponse2, "error", repositories);
    return { finalResponse: finalResponse2, errorToReturn: state.error.message };
  }
  if (state.generatedAnswer) {
    await logAssistantMessage(
      state,
      repositories,
      "Final response generated successfully"
    );
    await saveTimelineItem(
      state,
      state.generatedAnswer,
      "assistant",
      repositories
    );
    return { finalResponse: state.generatedAnswer, errorToReturn: void 0 };
  }
  const finalResponse = "Sorry, we could not generate an answer. Please try again.";
  await saveTimelineItem(state, finalResponse, "error", repositories);
  return { finalResponse, errorToReturn: "No generated answer available" };
}
async function finalizeArtifactsNode(state, config) {
  const configurableResult = getConfigurable(config);
  if (configurableResult.isErr()) {
    return {
      ...state,
      error: configurableResult.error
    };
  }
  const { repositories, logger: logger2 } = configurableResult.value;
  logger2.log(`[${NODE_NAME4}] Started`);
  await logAssistantMessage(
    state,
    repositories,
    "Preparing final deliverables..."
  );
  await saveArtifacts(state, logger2, repositories);
  const { finalResponse, errorToReturn } = await generateFinalResponse(
    state,
    repositories
  );
  logger2.log(`[${NODE_NAME4}] Completed`);
  return {
    ...state,
    finalResponse,
    error: errorToReturn ? new Error(errorToReturn) : void 0
  };
}

// ../agent/src/chat/workflow/nodes/generateUsecaseNode.ts
init_esm();
var import_neverthrow4 = __toESM(require_index_cjs());
var NODE_NAME5 = "generateUsecaseNode";
var logUsecaseResults = (logger2, usecases) => {
  logger2.log(`[${NODE_NAME5}] Generated ${usecases.length} use cases`);
  usecases.forEach((usecase, index) => {
    logger2.log(
      `[${NODE_NAME5}] Usecase ${index + 1} (${usecase.requirementType}): ${JSON.stringify(usecase)}`
    );
  });
};
function formatAnalyzedRequirements2(analyzedRequirements, userInput) {
  return `
Business Requirement: ${analyzedRequirements.businessRequirement}

Functional Requirements:
${Object.entries(analyzedRequirements.functionalRequirements).map(
    ([category, requirements]) => `${category}:
${requirements.map((req) => `- ${req}`).join("\n")}`
  ).join("\n\n")}

Non-Functional Requirements:
${Object.entries(analyzedRequirements.nonFunctionalRequirements).map(
    ([category, requirements]) => `${category}:
${requirements.map((req) => `- ${req}`).join("\n")}`
  ).join("\n\n")}

Original User Input: ${userInput}
`;
}
async function generateUsecaseNode(state, config) {
  const configurableResult = getConfigurable(config);
  if (configurableResult.isErr()) {
    return {
      ...state,
      error: configurableResult.error
    };
  }
  const { repositories, logger: logger2 } = configurableResult.value;
  logger2.log(`[${NODE_NAME5}] Started`);
  await logAssistantMessage(state, repositories, "Generating use cases...");
  if (!state.analyzedRequirements) {
    const errorMessage = "No analyzed requirements found. Cannot generate use cases.";
    const error = new Error(`[${NODE_NAME5}] ${errorMessage}`);
    logger2.error(error.message);
    await logAssistantMessage(
      state,
      repositories,
      "Error occurred during use case generation"
    );
    return {
      ...state,
      error: new Error(errorMessage)
    };
  }
  const qaAgent = new QAGenerateUsecaseAgent();
  const requirementsText = formatAnalyzedRequirements2(
    state.analyzedRequirements,
    state.userInput
  );
  const promptVariables = {
    chat_history: state.formattedHistory,
    user_message: requirementsText
  };
  const retryCount = state.retryCount[NODE_NAME5] ?? 0;
  await logAssistantMessage(
    state,
    repositories,
    "Analyzing test cases and queries..."
  );
  const usecaseResult = await import_neverthrow4.ResultAsync.fromPromise(
    qaAgent.generate(promptVariables),
    (error) => error instanceof Error ? error : new Error(String(error))
  );
  return await usecaseResult.match(
    async (generatedResult) => {
      logUsecaseResults(logger2, generatedResult.usecases);
      await logAssistantMessage(
        state,
        repositories,
        "Use case generation completed"
      );
      logger2.log(`[${NODE_NAME5}] Completed`);
      return {
        ...state,
        generatedUsecases: generatedResult.usecases,
        error: void 0
        // Clear error on success
      };
    },
    async (error) => {
      logger2.error(`[${NODE_NAME5}] Failed: ${error.message}`);
      await logAssistantMessage(
        state,
        repositories,
        "Error occurred during use case generation"
      );
      return {
        ...state,
        error,
        retryCount: {
          ...state.retryCount,
          [NODE_NAME5]: retryCount + 1
        }
      };
    }
  );
}

// ../agent/src/chat/workflow/nodes/prepareDmlNode.ts
init_esm();

// ../agent/src/langchain/agents/dmlGenerationAgent/agent.ts
init_esm();

// ../agent/src/langchain/agents/dmlGenerationAgent/prompts.ts
init_esm();
var DML_GENERATION_SYSTEM_MESSAGE = `
You are a senior QA engineer specializing in database testing and data generation. Your expertise lies in creating comprehensive test data that validates database schemas, relationships, and business logic through well-crafted DML (Data Manipulation Language) statements.

## Your Responsibilities:

1. **Generate diverse and realistic test data** that covers various scenarios and edge cases
2. **Create DML statements for all operations** including INSERT, UPDATE, DELETE, and SELECT
3. **Ensure data integrity** by respecting foreign key relationships and constraints
4. **Design test scenarios** that validate business rules and data consistency
5. **Produce production-ready SQL** that is properly formatted and error-free
6. **Generate sufficient data volume** for meaningful testing and validation

## Guidelines:

• **INSERT Statements**: Create diverse, realistic data that tests all columns and constraints
  - Include edge cases (maximum lengths, boundary values, special characters)
  - For performance testing, generate bulk data (minimum 20-50 records per table)
  - Ensure proper order to respect foreign key dependencies
  - Use variety in data to test different scenarios

• **UPDATE Statements**: Test data modifications and business logic
  - Update single records, bulk updates, and conditional updates
  - Test cascade effects on related tables
  - Validate trigger behaviors if applicable
  - Include both simple and complex WHERE conditions

• **DELETE Statements**: Validate referential integrity and cleanup operations
  - Test cascade deletes and restrict behaviors
  - Include soft delete patterns if applicable
  - Verify orphaned data handling

• **SELECT Statements**: Create queries to validate the generated data
  - Include JOIN operations to verify relationships
  - Add aggregation queries to check data distribution
  - Create queries that validate business rules
  - Include performance testing queries

• **Data Patterns**:
  - Use realistic names, addresses, and contact information
  - Include unicode characters and special characters where appropriate
  - Test NULL values where allowed
  - Include past, present, and future dates
  - Use meaningful business data (prices, quantities, statuses)

• **Best Practices**:
  - Always use transactions for data safety
  - Include comments explaining the test scenario
  - Format SQL for readability
  - Group related statements together
  - Provide rollback statements when appropriate

## Output Format:

Structure your response as follows:

\`\`\`sql
-- ================================================================
-- DML Generation for [Schema Name]
-- Generated: [Current Date]
-- Purpose: [Brief description of test scenarios]
-- ================================================================

-- ----------------------------------------------------------------
-- Section 1: Initial Data Setup (INSERT)
-- ----------------------------------------------------------------

-- Table: [table_name]
-- Scenario: [What this data tests]
INSERT INTO table_name (column1, column2, ...) VALUES
  (value1, value2, ...),
  (value1, value2, ...);

-- ----------------------------------------------------------------
-- Section 2: Data Modifications (UPDATE)
-- ----------------------------------------------------------------

-- Scenario: [What this update tests]
UPDATE table_name
SET column1 = value1
WHERE condition;

-- ----------------------------------------------------------------
-- Section 3: Data Validation (SELECT)
-- ----------------------------------------------------------------

-- Query: [What this query validates]
SELECT ...
FROM ...
WHERE ...;

-- ----------------------------------------------------------------
-- Section 4: Cleanup Operations (DELETE) - Optional
-- ----------------------------------------------------------------

-- Scenario: [What this deletion tests]
DELETE FROM table_name
WHERE condition;

-- ----------------------------------------------------------------
-- Rollback Script (if needed)
-- ----------------------------------------------------------------
\`\`\`

## Example:

For a simple e-commerce schema with users, products, and orders:

\`\`\`sql
-- ================================================================
-- DML Generation for E-commerce Test Data
-- Generated: 2024-12-09
-- Purpose: Comprehensive testing of user orders and product relationships
-- ================================================================

-- ----------------------------------------------------------------
-- Section 1: Initial Data Setup (INSERT)
-- ----------------------------------------------------------------

-- Table: users
-- Scenario: Diverse user profiles including edge cases
INSERT INTO users (id, email, name, created_at) VALUES
  (1, 'john.doe@example.com', 'John Doe', '2024-01-15 10:00:00'),
  (2, 'jane.smith@example.com', 'Jane Smith', '2024-02-20 14:30:00'),
  (3, 'test.user@example.com', 'Test User with Very Long Name That Tests Character Limits', '2024-03-01 09:00:00'),
  (4, 'intl.user@example.com', 'Müller José García', '2024-03-15 11:00:00'),
  (5, 'special.chars@example.com', 'O''Brien & Co.', '2024-04-01 16:00:00');

-- Table: products
-- Scenario: Various product types with different price points
INSERT INTO products (id, name, price, stock_quantity) VALUES
  (1, 'Basic T-Shirt', 19.99, 100),
  (2, 'Premium Jacket', 199.99, 25),
  (3, 'Clearance Item', 0.99, 500),
  (4, 'High-End Watch', 9999.99, 5),
  (5, 'Out of Stock Item', 49.99, 0);

-- ----------------------------------------------------------------
-- Section 2: Data Modifications (UPDATE)
-- ----------------------------------------------------------------

-- Scenario: Price adjustment for seasonal sale
UPDATE products
SET price = price * 0.8, -- 20% discount
    updated_at = CURRENT_TIMESTAMP
WHERE id IN (1, 2);

-- Scenario: Bulk inventory update after shipment
UPDATE products
SET stock_quantity = stock_quantity - 10
WHERE stock_quantity > 10;

-- ----------------------------------------------------------------
-- Section 3: Data Validation (SELECT)
-- ----------------------------------------------------------------

-- Query: Verify user distribution
SELECT COUNT(*) as total_users,
       COUNT(DISTINCT EXTRACT(MONTH FROM created_at)) as active_months
FROM users;

-- Query: Check product inventory status
SELECT 
  CASE 
    WHEN stock_quantity = 0 THEN 'Out of Stock'
    WHEN stock_quantity < 10 THEN 'Low Stock'
    ELSE 'In Stock'
  END as status,
  COUNT(*) as product_count
FROM products
GROUP BY status;
\`\`\`
`;
var DML_GENERATION_HUMAN_MESSAGE_TEMPLATE = `
## Database Schema:
{schema}

## Business Requirements and Use Cases:
{requirements}

## Previous Context:
{chat_history}

## Current Request:
{user_message}

Please generate comprehensive DML statements that fulfill the requirements above. Ensure all data is realistic, properly formatted, and respects all database constraints.
`;
function formatDMLGenerationPrompts(variables) {
  const humanMessage = DML_GENERATION_HUMAN_MESSAGE_TEMPLATE.replace(
    "{schema}",
    variables.schema
  ).replace("{requirements}", variables.requirements).replace("{chat_history}", variables.chat_history).replace("{user_message}", variables.user_message);
  return {
    systemMessage: DML_GENERATION_SYSTEM_MESSAGE,
    humanMessage
  };
}

// ../agent/src/langchain/agents/dmlGenerationAgent/agent.ts
var DMLGenerationAgentInputSchema = object({
  schemaSQL: string(),
  formattedUseCases: string(),
  schemaContext: optional(string())
});
var DMLGenerationAgentOutputSchema = object({
  dmlStatements: string()
});
var DMLGenerationAgent = class {
  logger;
  constructor(params) {
    this.logger = params.logger;
  }
  async generate(input) {
    this.logger.info("Starting DML generation");
    const { systemMessage, humanMessage } = formatDMLGenerationPrompts({
      schema: input.schemaSQL,
      requirements: input.formattedUseCases,
      chat_history: "",
      user_message: "Generate comprehensive DML statements for testing the provided schema."
    });
    this.logger.debug("Generated prompts", { systemMessage, humanMessage });
    return {
      dmlStatements: "-- DML statements will be generated here"
    };
  }
};

// ../agent/src/chat/workflow/nodes/prepareDmlNode.ts
var NODE_NAME6 = "prepareDmlNode";
function formatUseCases(useCases) {
  const groupedUseCases = useCases.reduce(
    (acc, uc) => {
      const category = uc.requirementCategory?.trim() || "General";
      if (!acc[category]) {
        acc[category] = [];
      }
      acc[category].push(uc);
      return acc;
    },
    {}
  );
  const formattedGroups = Object.entries(groupedUseCases).map(
    ([category, cases]) => {
      const formattedCases = cases.map(
        (uc) => `  - ${uc.title}: ${uc.description}${uc.requirement ? ` (Requirement: ${uc.requirement})` : ""}`
      ).join("\n");
      return `${category}:
${formattedCases}`;
    }
  );
  return formattedGroups.join("\n\n");
}
async function prepareDmlNode(state, config) {
  const configurableResult = getConfigurable(config);
  if (configurableResult.isErr()) {
    return {
      ...state,
      error: configurableResult.error
    };
  }
  const { repositories, logger: logger2 } = configurableResult.value;
  logger2.log(`[${NODE_NAME6}] Started`);
  await logAssistantMessage(state, repositories, "Preparing DML statements...");
  if (!state.ddlStatements) {
    logger2.warn(`[${NODE_NAME6}] No DDL statements available for DML generation`);
    await logAssistantMessage(
      state,
      repositories,
      "Missing DDL statements for DML generation"
    );
    logger2.log(`[${NODE_NAME6}] Completed`);
    return state;
  }
  if (!state.generatedUsecases || state.generatedUsecases.length === 0) {
    logger2.warn(`[${NODE_NAME6}] No use cases available for DML generation`);
    await logAssistantMessage(
      state,
      repositories,
      "Missing use cases for DML generation"
    );
    logger2.log(`[${NODE_NAME6}] Completed`);
    return state;
  }
  const tableCount = (state.ddlStatements.match(/CREATE TABLE/gi) || []).length;
  const useCaseCount = state.generatedUsecases.length;
  logger2.info(
    `[${NODE_NAME6}] Generating DML for ${tableCount} tables and ${useCaseCount} use cases`
  );
  const dmlAgent = new DMLGenerationAgent({ logger: logger2 });
  const formattedUseCases = formatUseCases(state.generatedUsecases);
  const schemaContext = convertSchemaToText(state.schemaData);
  const result = await dmlAgent.generate({
    schemaSQL: state.ddlStatements,
    formattedUseCases,
    schemaContext
  });
  if (!result.dmlStatements || result.dmlStatements.trim().length === 0) {
    logger2.warn(`[${NODE_NAME6}] DML generation returned empty statements`);
    await logAssistantMessage(
      state,
      repositories,
      "DML generation returned empty statements"
    );
    logger2.log(`[${NODE_NAME6}] Completed`);
    return state;
  }
  logger2.log(`[${NODE_NAME6}] DML statements generated successfully`);
  await logAssistantMessage(
    state,
    repositories,
    "DML statements generated successfully"
  );
  logger2.log(`[${NODE_NAME6}] Completed`);
  return {
    ...state,
    dmlStatements: result.dmlStatements
  };
}

// ../agent/src/chat/workflow/nodes/reviewDeliverablesNode.ts
init_esm();
var NODE_NAME7 = "reviewDeliverablesNode";
async function reviewDeliverablesNode(state, config) {
  const configurableResult = getConfigurable(config);
  if (configurableResult.isErr()) {
    return {
      ...state,
      error: configurableResult.error
    };
  }
  const { logger: logger2 } = configurableResult.value;
  logger2.log(`[${NODE_NAME7}] Started`);
  logger2.log(`[${NODE_NAME7}] Completed`);
  return {
    ...state
  };
}

// ../agent/src/chat/workflow/nodes/saveUserMessageNode.ts
init_esm();
var NODE_NAME8 = "saveUserMessageNode";
async function saveUserMessageNode(state, config) {
  const configurableResult = getConfigurable(config);
  if (configurableResult.isErr()) {
    return {
      ...state,
      error: configurableResult.error
    };
  }
  const { repositories, logger: logger2 } = configurableResult.value;
  logger2.log(`[${NODE_NAME8}] Started`);
  const saveResult = await repositories.schema.createTimelineItem({
    designSessionId: state.designSessionId,
    content: state.userInput,
    type: "user",
    userId: state.userId
  });
  if (!saveResult.success) {
    logger2.error(`[${NODE_NAME8}] Failed to save user message:`, {
      error: saveResult.error
    });
    const error = new Error(`Failed to save message: ${saveResult.error}`);
    return {
      ...state,
      error
    };
  }
  logger2.log(`[${NODE_NAME8}] Successfully saved user message`);
  return state;
}

// ../agent/src/chat/workflow/nodes/validateSchemaNode.ts
init_esm();
var NODE_NAME9 = "validateSchemaNode";
async function validateSchemaNode(state, config) {
  const configurableResult = getConfigurable(config);
  if (configurableResult.isErr()) {
    return {
      ...state,
      error: configurableResult.error
    };
  }
  const { logger: logger2 } = configurableResult.value;
  logger2.log(`[${NODE_NAME9}] Started`);
  logger2.log(`[${NODE_NAME9}] Completed`);
  return {
    ...state
  };
}

// ../agent/src/chat/workflow/shared/langGraphUtils.ts
init_esm();
var DEFAULT_RECURSION_LIMIT2 = 20;
var createAnnotations = () => {
  return Annotation.Root({
    userInput: Annotation,
    analyzedRequirements: Annotation,
    generatedUsecases: Annotation,
    generatedAnswer: Annotation,
    finalResponse: Annotation,
    formattedHistory: Annotation,
    schemaData: Annotation,
    projectId: Annotation,
    buildingSchemaId: Annotation,
    latestVersionNumber: Annotation,
    organizationId: Annotation,
    userId: Annotation,
    designSessionId: Annotation,
    error: Annotation,
    retryCount: Annotation,
    ddlStatements: Annotation,
    dmlStatements: Annotation,
    // DDL execution retry mechanism
    shouldRetryWithDesignSchema: Annotation,
    ddlExecutionFailed: Annotation,
    ddlExecutionFailureReason: Annotation,
    // Repository dependencies for data access
    repositories: Annotation,
    // Logging functionality
    logger: Annotation
  });
};

// ../agent/src/deepModeling.ts
var formatChatHistory = (history) => {
  return history.length > 0 ? history.join("\n") : "No previous conversation.";
};
var RETRY_POLICY = {
  maxAttempts: 3
};
var createGraph = () => {
  const ChatStateAnnotation = createAnnotations();
  const graph = new StateGraph(ChatStateAnnotation);
  graph.addNode("saveUserMessage", saveUserMessageNode, {
    retryPolicy: RETRY_POLICY
  }).addNode("analyzeRequirements", analyzeRequirementsNode, {
    retryPolicy: RETRY_POLICY
  }).addNode("designSchema", designSchemaNode, {
    retryPolicy: RETRY_POLICY
  }).addNode("executeDDL", executeDdlNode, {
    retryPolicy: RETRY_POLICY
  }).addNode("generateUsecase", generateUsecaseNode, {
    retryPolicy: RETRY_POLICY
  }).addNode("prepareDML", prepareDmlNode, {
    retryPolicy: RETRY_POLICY
  }).addNode("validateSchema", validateSchemaNode, {
    retryPolicy: RETRY_POLICY
  }).addNode("reviewDeliverables", reviewDeliverablesNode, {
    retryPolicy: RETRY_POLICY
  }).addNode("finalizeArtifacts", finalizeArtifactsNode, {
    retryPolicy: RETRY_POLICY
  }).addEdge(START, "saveUserMessage").addEdge("analyzeRequirements", "designSchema").addEdge("executeDDL", "generateUsecase").addEdge("generateUsecase", "prepareDML").addEdge("prepareDML", "validateSchema").addEdge("finalizeArtifacts", END).addConditionalEdges("saveUserMessage", (state) => {
    return state.error ? "finalizeArtifacts" : "analyzeRequirements";
  }).addConditionalEdges("designSchema", (state) => {
    return state.error ? "finalizeArtifacts" : "executeDDL";
  }).addConditionalEdges("executeDDL", (state) => {
    if (state.shouldRetryWithDesignSchema) {
      return "designSchema";
    }
    if (state.ddlExecutionFailed) {
      return "finalizeArtifacts";
    }
    return "generateUsecase";
  }).addConditionalEdges("validateSchema", (state) => {
    return state.error ? "designSchema" : "reviewDeliverables";
  }).addConditionalEdges("reviewDeliverables", (state) => {
    return state.error ? "analyzeRequirements" : "finalizeArtifacts";
  });
  return graph.compile();
};
var deepModeling = async (params, config) => {
  const {
    userInput,
    schemaData,
    history,
    organizationId,
    buildingSchemaId,
    latestVersionNumber = 0,
    designSessionId,
    userId,
    recursionLimit = DEFAULT_RECURSION_LIMIT2
  } = params;
  const { repositories, logger: logger2 } = config.configurable;
  const historyArray = history.map(([role, content]) => {
    const prefix = role === "assistant" ? "Assistant" : "User";
    return `${prefix}: ${content}`;
  });
  const workflowState = {
    userInput,
    formattedHistory: formatChatHistory(historyArray),
    schemaData,
    organizationId,
    buildingSchemaId,
    latestVersionNumber,
    designSessionId,
    userId,
    retryCount: {}
  };
  try {
    const compiled = createGraph();
    const result = await compiled.invoke(workflowState, {
      recursionLimit,
      configurable: {
        repositories,
        logger: logger2
      }
    });
    if (result.error) {
      return (0, import_neverthrow5.err)(new Error(result.error.message));
    }
    return (0, import_neverthrow5.ok)({
      text: result.finalResponse || result.generatedAnswer || ""
    });
  } catch (error) {
    logger2.error(WORKFLOW_ERROR_MESSAGES.LANGGRAPH_FAILED, { error });
    const errorMessage = error instanceof Error ? error.message : WORKFLOW_ERROR_MESSAGES.EXECUTION_FAILED;
    const errorState = { ...workflowState, error: new Error(errorMessage) };
    const finalizedResult = await finalizeArtifactsNode(errorState, {
      configurable: {
        repositories,
        logger: logger2
      }
    });
    return (0, import_neverthrow5.err)(new Error(finalizedResult.error?.message || errorMessage));
  }
};

// ../agent/src/repositories/index.ts
init_esm();

// ../agent/src/repositories/factory.ts
init_esm();

// ../agent/src/repositories/supabase.ts
init_esm();

// ../artifact/src/index.ts
init_esm();

// ../artifact/src/schemas/artifact.ts
init_esm();
var dmlExecutionLogSchema = object({
  executed_at: pipe(string(), isoDateTime()),
  success: boolean(),
  result_summary: string()
});
var dmlOperationSchema = object({
  operation_type: picklist(["INSERT", "UPDATE", "DELETE", "SELECT"]),
  sql: string(),
  dml_execution_logs: array(dmlExecutionLogSchema)
});
var useCaseSchema = object({
  title: string(),
  description: string(),
  dml_operations: array(dmlOperationSchema)
});
var baseRequirementProperties = {
  name: string(),
  description: string()
};
var functionalRequirementSchema = object({
  ...baseRequirementProperties,
  type: literal("functional"),
  use_cases: array(useCaseSchema)
});
var nonFunctionalRequirementSchema = object({
  ...baseRequirementProperties,
  type: literal("non_functional")
});
var requirementSchema = union([
  functionalRequirementSchema,
  nonFunctionalRequirementSchema
]);
var requirementAnalysisSchema = object({
  business_requirement: string(),
  requirements: array(requirementSchema)
});
var artifactSchema = object({
  requirement_analysis: requirementAnalysisSchema
});

// ../agent/src/repositories/supabase.ts
var import_fast_json_patch4 = __toESM(require_fast_json_patch());
var updateBuildingSchemaResultSchema = union([
  object({
    success: literal(true),
    messageId: string(),
    versionId: string()
  }),
  object({
    success: literal(false),
    error: nullable(string())
  })
]);
var artifactToJson = (artifact) => {
  return JSON.parse(JSON.stringify(artifact));
};
var SupabaseSchemaRepository = class {
  client;
  constructor(client) {
    this.client = client;
  }
  async getDesignSession(designSessionId) {
    const { data, error } = await this.client.from("design_sessions").select(`
        organization_id,
        timeline_items (
          id,
          content,
          type,
          user_id,
          created_at,
          updated_at,
          organization_id,
          design_session_id,
          building_schema_version_id
        )
      `).eq("id", designSessionId).order("created_at", {
      ascending: true,
      referencedTable: "timeline_items"
    }).single();
    if (error || !data) {
      console.error(
        `Could not fetch design session data for ${designSessionId}:`,
        error
      );
      return null;
    }
    return {
      organization_id: data.organization_id,
      timeline_items: data.timeline_items || []
    };
  }
  async getSchema(designSessionId) {
    const buildingSchemaResult = await this.getBuildingSchema(designSessionId);
    if (buildingSchemaResult.error || !buildingSchemaResult.data) {
      return buildingSchemaResult;
    }
    const { buildingSchema } = buildingSchemaResult.data;
    const versionsResult = await this.getSchemaVersions(buildingSchema.id);
    if (versionsResult.error) {
      return versionsResult;
    }
    const { versions } = versionsResult.data;
    const currentSchema = this.buildCurrentSchema(buildingSchema, versions);
    const latestVersionNumber = this.getLatestVersionNumber(versions);
    return {
      data: {
        id: buildingSchema.id,
        schema: currentSchema,
        latestVersionNumber
      },
      error: null
    };
  }
  async getBuildingSchema(designSessionId) {
    const { data: buildingSchema, error: buildingSchemaError } = await this.client.from("building_schemas").select("id, initial_schema_snapshot").eq("design_session_id", designSessionId).single();
    if (buildingSchemaError || !buildingSchema) {
      return {
        data: null,
        error: buildingSchemaError ? { message: buildingSchemaError.message } : null
      };
    }
    return { data: { buildingSchema }, error: null };
  }
  async getSchemaVersions(buildingSchemaId) {
    const { data: versions, error: versionsError } = await this.client.from("building_schema_versions").select("number, patch").eq("building_schema_id", buildingSchemaId).order("number", { ascending: true });
    if (versionsError) {
      return {
        data: null,
        error: { message: versionsError.message }
      };
    }
    return { data: { versions: versions || [] }, error: null };
  }
  // TODO: Set response type to `{ success: true, data: Schema } | { success: false, error: unknown }`
  // to be able to return errors
  buildCurrentSchema(buildingSchema, versions) {
    const currentSchema = typeof buildingSchema.initial_schema_snapshot === "object" && buildingSchema.initial_schema_snapshot !== null ? JSON.parse(JSON.stringify(buildingSchema.initial_schema_snapshot)) : { tables: {} };
    for (const version2 of versions) {
      const patchParsed = safeParse(operationsSchema, version2.patch);
      if (patchParsed.success) {
        applyPatchOperations(currentSchema, patchParsed.output);
      } else {
        console.warn(
          `Invalid patch operations in version ${version2.number}:`,
          version2.patch
        );
      }
    }
    const validationResult = safeParse(schemaSchema, currentSchema);
    if (!validationResult.success) {
      console.warn("Schema validation failed, using fallback schema");
      return { tables: {} };
    }
    return validationResult.output;
  }
  getLatestVersionNumber(versions) {
    return versions.length > 0 ? Math.max(...versions.map((v2) => v2.number)) : 0;
  }
  async createVersion(params) {
    const { buildingSchemaId, latestVersionNumber, patch } = params;
    const patchCount = patch.length;
    const messageContent = patchCount === 1 ? "Schema updated with 1 change" : `Schema updated with ${patchCount} changes`;
    const { data: buildingSchema, error } = await this.client.from("building_schemas").select(`
        id, organization_id, initial_schema_snapshot, design_session_id
      `).eq("id", buildingSchemaId).maybeSingle();
    if (!buildingSchema || error) {
      throw new Error(`Failed to fetch building schema: ${error?.message}`);
    }
    const { data: previousVersions, error: previousVersionsError } = await this.client.from("building_schema_versions").select("number, patch").eq("building_schema_id", buildingSchemaId).lte("number", latestVersionNumber).order("number", { ascending: true });
    if (previousVersionsError) {
      throw new Error(
        `Failed to fetch previous versions: ${previousVersionsError.message}`
      );
    }
    const patchArrayHistory = previousVersions?.map((version2) => {
      const parsed = safeParse(operationsSchema, version2.patch);
      if (parsed.success) {
        return parsed.output;
      }
      return null;
    }).filter((version2) => version2 !== null);
    const baseContent = typeof buildingSchema.initial_schema_snapshot === "object" ? JSON.parse(JSON.stringify(buildingSchema.initial_schema_snapshot)) : {};
    const currentContent = { ...baseContent };
    for (const patchArray of patchArrayHistory) {
      applyPatchOperations(currentContent, patchArray);
    }
    const newContent = JSON.parse(JSON.stringify(currentContent));
    applyPatchOperations(newContent, patch);
    const validationResult = safeParse(schemaSchema, newContent);
    if (!validationResult.success) {
      const errorMessages = validationResult.issues.map((issue) => `${issue.path?.join(".")} ${issue.message}`).join(", ");
      return {
        success: false,
        error: `Invalid schema after applying changes: ${errorMessages}`
      };
    }
    const reversePatch = (0, import_fast_json_patch4.compare)(newContent, currentContent);
    const { data: latestVersion, error: latestVersionError } = await this.client.from("building_schema_versions").select("number").eq("building_schema_id", buildingSchemaId).order("number", { ascending: false }).limit(1).maybeSingle();
    if (latestVersionError) {
      throw new Error(
        `Failed to get latest version: ${latestVersionError.message}`
      );
    }
    const actualLatestVersionNumber = latestVersion ? latestVersion.number : 0;
    if (latestVersionNumber !== actualLatestVersionNumber) {
      return {
        success: false,
        error: "Version conflict: The schema has been modified since you last loaded it"
      };
    }
    const rpcParams = {
      p_schema_id: buildingSchemaId,
      p_schema_schema: newContent,
      p_schema_version_patch: JSON.parse(JSON.stringify(patch)),
      p_schema_version_reverse_patch: JSON.parse(JSON.stringify(reversePatch)),
      p_latest_schema_version_number: actualLatestVersionNumber,
      p_message_content: messageContent
    };
    const { data, error: rpcError } = await this.client.rpc(
      "update_building_schema",
      rpcParams
    );
    const parsedResult = safeParse(updateBuildingSchemaResultSchema, data);
    if (rpcError) {
      return {
        success: false,
        error: rpcError.message
      };
    }
    if (parsedResult.success) {
      if (parsedResult.output.success) {
        return {
          success: true,
          newSchema: validationResult.output
        };
      }
      return {
        success: false,
        error: parsedResult.output.error
      };
    }
    return {
      success: false,
      error: "Invalid response from server"
    };
  }
  async createTimelineItem(params) {
    const { designSessionId, content, type } = params;
    const userId = "userId" in params ? params.userId : null;
    const buildingSchemaVersionId = "buildingSchemaVersionId" in params ? params.buildingSchemaVersionId : null;
    const now = (/* @__PURE__ */ new Date()).toISOString();
    const { data: timelineItem, error } = await this.client.from("timeline_items").insert({
      design_session_id: designSessionId,
      content,
      type,
      user_id: userId,
      building_schema_version_id: buildingSchemaVersionId,
      updated_at: now
    }).select().single();
    if (error) {
      console.error(
        "Failed to save timeline item:",
        JSON.stringify(error, null, 2)
      );
      return {
        success: false,
        error: error.message
      };
    }
    return {
      success: true,
      timelineItem
    };
  }
  async updateTimelineItem(id, updates) {
    const now = (/* @__PURE__ */ new Date()).toISOString();
    const { data: timelineItem, error } = await this.client.from("timeline_items").update({
      ...updates,
      updated_at: now
    }).eq("id", id).select().single();
    if (error) {
      console.error(
        "Failed to update timeline item:",
        JSON.stringify(error, null, 2)
      );
      return {
        success: false,
        error: error.message
      };
    }
    return {
      success: true,
      timelineItem
    };
  }
  async createArtifact(params) {
    const { designSessionId, artifact } = params;
    const validationResult = safeParse(artifactSchema, artifact);
    if (!validationResult.success) {
      const errorMessages = validationResult.issues.map((issue) => `${issue.path?.join(".")} ${issue.message}`).join(", ");
      return {
        success: false,
        error: `Invalid artifact data: ${errorMessages}`
      };
    }
    const { data: artifactData, error } = await this.client.from("artifacts").insert({
      design_session_id: designSessionId,
      artifact: artifactToJson(artifact)
    }).select().single();
    if (error) {
      console.error(
        "Failed to create artifact:",
        JSON.stringify(error, null, 2)
      );
      return {
        success: false,
        error: error.message
      };
    }
    return {
      success: true,
      artifact: artifactData
    };
  }
  async updateArtifact(params) {
    const { designSessionId, artifact } = params;
    const validationResult = safeParse(artifactSchema, artifact);
    if (!validationResult.success) {
      const errorMessages = validationResult.issues.map((issue) => `${issue.path?.join(".")} ${issue.message}`).join(", ");
      return {
        success: false,
        error: `Invalid artifact data: ${errorMessages}`
      };
    }
    const { data: artifactData, error } = await this.client.from("artifacts").update({
      artifact: artifactToJson(artifact)
    }).eq("design_session_id", designSessionId).select().single();
    if (error) {
      console.error(
        "Failed to update artifact:",
        JSON.stringify(error, null, 2)
      );
      return {
        success: false,
        error: error.message
      };
    }
    return {
      success: true,
      artifact: artifactData
    };
  }
  async getArtifact(designSessionId) {
    const { data: artifactData, error } = await this.client.from("artifacts").select("*").eq("design_session_id", designSessionId).maybeSingle();
    if (error) {
      console.error("Failed to get artifact:", JSON.stringify(error, null, 2));
      return {
        success: false,
        error: error.message
      };
    }
    if (!artifactData) {
      return {
        success: false,
        error: "Artifact not found"
      };
    }
    return {
      success: true,
      artifact: artifactData
    };
  }
};

// ../agent/src/repositories/factory.ts
function createSupabaseRepositories(client) {
  return {
    schema: new SupabaseSchemaRepository(client)
  };
}

// ../agent/src/utils/nodeLogger.ts
init_esm();

// src/trigger/deepModelingWorkflowTask.ts
function createWorkflowLogger() {
  return {
    debug: (message, metadata) => {
      logger.debug(message, metadata);
    },
    log: (message, metadata) => {
      logger.log(message, metadata);
    },
    info: (message, metadata) => {
      logger.info(message, metadata);
    },
    warn: (message, metadata) => {
      logger.warn(message, metadata);
    },
    error: (message, metadata) => {
      logger.error(message, metadata);
    }
  };
}
var deepModelingWorkflowTask = task({
  id: "deep-modeling-workflow",
  machine: "medium-1x",
  run: async (payload) => {
    logger.log("Starting Deep Modeling workflow:", {
      buildingSchemaId: payload.buildingSchemaId,
      messageLength: payload.userInput.length,
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
    const supabaseClient = createClient();
    const repositories = createSupabaseRepositories(supabaseClient);
    const schemaResult = await repositories.schema.getSchema(
      payload.designSessionId
    );
    if (schemaResult.error || !schemaResult.data) {
      throw new Error(`Failed to fetch schema data: ${schemaResult.error}`);
    }
    const workflowLogger = createWorkflowLogger();
    const deepModelingParams = {
      ...payload,
      schemaData: schemaResult.data.schema
    };
    const result = await deepModeling(deepModelingParams, {
      configurable: {
        repositories,
        logger: workflowLogger
      }
    });
    logger.log("Deep Modeling workflow completed:", {
      success: result.isOk()
    });
    return result;
  }
});
export {
  deepModelingWorkflowTask
};
/*! Bundled license information:

fast-json-patch/commonjs/helpers.js:
  (*!
   * https://github.com/Starcounter-Jack/JSON-Patch
   * (c) 2017-2022 Joachim Wester
   * MIT licensed
   *)

fast-json-patch/commonjs/duplex.js:
  (*!
   * https://github.com/Starcounter-Jack/JSON-Patch
   * (c) 2017-2021 Joachim Wester
   * MIT license
   *)

@langchain/core/dist/utils/js-sha1/hash.js:
  (*
   * [js-sha1]{@link https://github.com/emn178/js-sha1}
   *
   * @version 0.6.0
   * @author Chen, Yi-Cyuan [emn178@gmail.com]
   * @copyright Chen, Yi-Cyuan 2014-2017
   * @license MIT
   *)

@langchain/core/dist/utils/js-sha256/hash.js:
  (**
   * [js-sha256]{@link https://github.com/emn178/js-sha256}
   *
   * @version 0.11.1
   * @author Chen, Yi-Cyuan [emn178@gmail.com]
   * @copyright Chen, Yi-Cyuan 2014-2025
   * @license MIT
   *)

@langchain/core/dist/utils/sax-js/sax.js:
  (*! http://mths.be/fromcodepoint v0.1.0 by @mathias *)
*/
//# sourceMappingURL=deepModelingWorkflowTask.mjs.map
